{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"Overview","text":""},{"location":"#proxystore","title":"ProxyStore","text":"<p>ProxyStore is a library that facilitates efficient data management in distributed Python applications. At the core of ProxyStore is the proxy object which acts as a transparent reference to an object living in a global object store. This pass-by-reference interface with just-in-time object resolution works across processes, machines, and sites, and enables data producers to change the low-level communication method dynamically without altering application code or behavior.</p> <p>ProxyStore accelerates the development of dynamic task-based workflows, serverless applications, and more by (1) decoupling control flow from data flow, (2) abstracting low-level communication mechanisms, and (3) eliminating the need for shims, wrapper functions, and boilerplate code.</p> <p>ProxyStore supports a diverse set of programming paradigms:</p> <ul> <li>Task-based Workflows</li> <li>Function-as-a-Service/Serverless Applications</li> <li>Distributed Futures</li> <li>Bulk Data Streaming</li> <li>and more!</li> </ul> <p>ProxyStore provides support for many third-party mediated communication methods out-of-the-box including DAOS, Globus Transfer, Kafka, KeyDB, and Redis. Custom communication methods built on Mochi, UCX, WebRTC, and ZeroMQ are provided for high-performance and peer-to-peer applications.</p> <p>Read more about ProxyStore's concepts here. Complete documentation for ProxyStore is available at docs.proxystore.dev.</p>"},{"location":"#installation","title":"Installation","text":"<p>The base ProxyStore package can be installed with <code>pip</code>. <pre><code>pip install proxystore\n</code></pre></p> <p>Many features require dependencies that are not installed by default but can be enabled via extras installation options such as <code>endpoints</code>, <code>kafka</code>, or <code>redis</code>. All optional dependencies can be installed with: <pre><code>pip install proxystore[all]\n</code></pre> This will also install the <code>proxystore-ex</code> package which contains extension and experimental features. The extensions package can also be installed with <code>pip</code> using <code>proxystore[extensions]</code> or <code>proxystore-ex</code>.</p> <p>See the Installation guide for more information about the available extras installation options. See the Contributing guide to get started for local development.</p>"},{"location":"#example","title":"Example","text":"<p>Getting started with ProxyStore requires a few lines of code.</p> <pre><code>from proxystore.connectors.redis import RedisConnector\nfrom proxystore.proxy import Proxy\nfrom proxystore.store import register_store\nfrom proxystore.store import Store\n\nstore = Store('my-store', RedisConnector('localhost', 6379))\n\n# Store the object and get a proxy. The proxy acts\n# like a reference to the object.\ndata = MyDataType(...)\nproxy = store.proxy(data)\nassert isinstance(proxy, Proxy)\n\ndef my_function(x: MyDataType) -&gt; ...:\n    # x is resolved my-store on first use transparently to the\n    # function. Then x behaves as an instance of MyDataType.\n    assert isinstance(x, MyDataType)\n\nmy_function(proxy)  # Succeeds\n</code></pre> <p>Check out the Get Started guide to learn more!</p>"},{"location":"#citation","title":"Citation","text":"<p>If you use ProxyStore or any of this code in your work, please cite our ProxyStore (SC '23) and Proxy Patterns (arXiv preprint) papers. <pre><code>@inproceedings{pauloski2023proxystore,\n    author = {Pauloski, J. Gregory and Hayot-Sasson, Valerie and Ward, Logan and Hudson, Nathaniel and Sabino, Charlie and Baughman, Matt and Chard, Kyle and Foster, Ian},\n    title = {{Accelerating Communications in Federated Applications with Transparent Object Proxies}},\n    address = {New York, NY, USA},\n    articleno = {59},\n    booktitle = {Proceedings of the International Conference for High Performance Computing, Networking, Storage and Analysis},\n    doi = {10.1145/3581784.3607047},\n    isbn = {9798400701092},\n    location = {Denver, CO, USA},\n    numpages = {15},\n    publisher = {Association for Computing Machinery},\n    series = {SC '23},\n    url = {https://doi.org/10.1145/3581784.3607047},\n    year = {2023}\n}\n\n@misc{pauloski2024proxystore,\n    author = {J. Gregory Pauloski and Valerie Hayot-Sasson and Logan Ward and Alexander Brace and Andr\u00e9 Bauer and Kyle Chard and Ian Foster},\n    title = {{Object Proxy Patterns for Accelerating Distributed Applications}},\n    archiveprefix = {arXiv},\n    eprint = {2407.01764},\n    primaryclass = {cs.DC},\n    url = {https://arxiv.org/abs/2407.01764},\n    year = {2024}\n}\n</code></pre></p>"},{"location":"examples/","title":"Examples","text":""},{"location":"examples/#integration-examples","title":"Integration Examples","text":"<p>Examples of integrating ProxyStore into distributed applications built on Globus Compute (formerly called funcX) and Parsl are on GitHub.</p>"},{"location":"examples/#benchmarks","title":"Benchmarks","text":"<p>ProxyStore benchmarks are maintained at github.com/proxystore/benchmarks. These benchmarks can be used as reference for ProxyStore usage or to test your own extensions for ProxyStore.</p>"},{"location":"faq/","title":"Frequently Asked Questions","text":"<p>Open a new issue if you have a question not answered in the FAQ, Guides, or API docs.</p>"},{"location":"faq/#working-with-proxies","title":"Working with Proxies","text":""},{"location":"faq/#what-is-resolving-my-proxy","title":"What is resolving my proxy?","text":"<p>Certain data structures can unintenionally resolve a proxy. This is because the <code>Proxy</code> type forwards all special methods to the target object. For example, data structures which use the hash of an object, such as <code>set()</code> or <code>dict()</code>, will cause a proxy to resolve because <code>proxy.__hash__()</code> is forwarded to the target object's <code>__hash__()</code>.</p> <pre><code>from proxystore.proxy import Proxy\nfrom proxystore.proxy import is_resolved\n\nproxy = Proxy(lambda: 42)\nassert not is_resolved(proxy)\n\nmy_set = set()\nmy_set.add(proxy)\nassert is_resolved(proxy)\n</code></pre> <p>Tip</p> <p>The <code>cache_defaults=True</code> and <code>target</code> flags can be used inside the <code>Proxy</code> constructor to cache the <code>__hash__</code> value of the target which will make the proxy hashable without needing to be resolved first. This only applies to hashable target objects. Similarly, passing <code>populate_target=True</code> to <code>Store.proxy()</code> will automatically set these flags on the returned proxy.</p> <p>There are a few mechanisms for determining when a proxy is getting resolved while debugging.</p> <ul> <li>Use <code>is_resolved()</code>.</li> <li>Use a fake factory which raises an error to halt the program and get a traceback at the point the proxy was resolved.   <pre><code>from proxystore.proxy import Proxy\n\ndef alert_factory() -&gt; None:\n    raise RuntimeError('Proxy was resolved!')\n\nproxy = Proxy(alert_factory)\n</code></pre></li> <li>Proxies created via a <code>Store</code> will produce <code>DEBUG</code> level logs when a proxy is created and resolved.   Enabling <code>DEBUG</code> level logging can help determine when or how often a proxy is getting resolved.   Look for the <code>PUT</code> and <code>GET</code> messages indicating a target object was put in the store when creating the proxy and when the target object is retrieved when the proxy is resolved, respectively.</li> </ul>"},{"location":"faq/#how-do-i-serialize-a-proxy","title":"How do I serialize a proxy?","text":"<p>A <code>Proxy</code> can be serialized using most common serializers.</p> <pre><code>from proxystore.proxy import Proxy\n\ndef factory() -&gt; int:\n    return 42\n\nproxy = Proxy(factory)\n\n# Cloudpickle\nimport cloudpickle\ndump = cloudpickle.dumps(proxy)\nnew_proxy = cloudpickle.loads(dump)\nassert isinstance(new_proxy, Proxy)\nassert new_proxy == 42\n\n# Dill\nimport dill\ndump = dill.dumps(proxy)\nnew_proxy = dill.loads(dump)\nassert isinstance(new_proxy, Proxy)\nassert new_proxy == 42\n\n# Pickle\nimport pickle\ndump = pickle.dumps(proxy)\nnew_proxy = pickle.loads(dump)\nassert isinstance(new_proxy, Proxy)\nassert new_proxy == 42\n</code></pre> <p>Importantly, only the factory of the proxy will be serialized, not the target object. This means that the factory must be serializable (lambda functions, for example, are not serializable with pickle), and the serialized size of the proxy is a function of the factory and not the target object. This typically means that proxies can be very efficiently serialized. For example, here the target object is a large 10,000 character string but the serialized proxy is less than 200 bytes.</p> <pre><code>import sys\nimport pickle\nfrom proxystore.proxy import Proxy\n\ntarget = 'x' * 10000\nassert sys.getsizeof(target) &gt;= 10000\n\ndef factory() -&gt; str:\n    return target\n\nproxy = Proxy(factory)\n\ndump = pickle.dumps(proxy)\nassert sys.getsizeof(dump) &lt; 200\n</code></pre>"},{"location":"faq/#runtime-type-checking","title":"Runtime Type Checking","text":""},{"location":"faq/#how-do-i-check-the-type-of-a-proxy","title":"How do I check the type of a proxy?","text":"<p>To check if an object is a proxy, use <code>isinstance(obj, Proxy)</code>. This will not resolve the proxy.</p> <p>Checking the type of a proxy's target object requires more care because <code>isinstance(proxy, MyType)</code> will resolve the proxy. This can be avoided by doing a direct type comparisons (e.g., <code>type(proxy) == MyType)</code>) but this will mean that type comparisons with subclasses will not work.</p> <pre><code>from proxystore.proxy import Proxy\nfrom proxystore.proxy import is_resolved\n\nproxy = Proxy(lambda: 42)\nassert not is_resolved(proxy)\n\nassert isinstance(proxy, Proxy)\nassert not is_resolved(proxy)\n\nassert type(proxy) != str\nassert not is_resolved(proxy)\n\nassert not isinstance(proxy, str)\nassert is_resolved(proxy)\n</code></pre> <p>If the target object is known when creating a proxy, the <code>cache_defaults</code> and <code>target</code> parameters can be used to cache the type of the target so that <code>isinstance</code> checks do not need to resolve the proxy.</p> <pre><code>from proxystore.proxy import Proxy\nfrom proxystore.proxy import is_resolved\n\nvalue = 'value'\nproxy = Proxy(lambda: value, cache_defaults=True, target=value)\ndel proxy.__proxy_wrapped__  # (1)!\nassert not is_resolved(proxy)\n\nassert isinstance(proxy, str)  # (2)!\nassert not is_resolved(proxy)\n</code></pre> <ol> <li>Passing <code>target=value</code> will create a proxy that is already resolved.    Deleting the wrapped target object will \"unresolve\" the proxy.</li> <li><code>isinstance</code> can be used safely because the <code>__class__</code> value of the target was cached inside the proxy instance.</li> </ol>"},{"location":"faq/#why-does-isinstance-behave-differently-with-proxies","title":"Why does <code>isinstance()</code> behave differently with proxies?","text":"<p>Generally, <code>isinstance()</code> works the same with proxies as with other types. However, there are some edge cases where behavior is different. This is most common with special generic alias types such as <code>typing.Mapping</code> or <code>typing.Sequence</code>. Consider the following example, where a <code>Proxy</code> with a <code>dict</code> target object is an instance of <code>dict</code> but not <code>typing.Mapping</code>.</p> <pre><code>import collections\nimport typing\nfrom proxystore.proxy import Proxy\n\nmy_dict = {}\nassert isinstance(my_dict, dict)\nassert isinstance(my_dict, typing.Mapping)\nassert isinstance(my_dict, collections.abc.Mapping)\n\nmy_dict_proxy = Proxy(lambda: my_dict)\nassert isinstance(my_dict_proxy, dict)\nassert not isinstance(my_dict_proxy, typing.Mapping)\nassert isinstance(my_dict_proxy, collections.abc.Mapping)\n</code></pre> <p>Here, the <code>isinstance()</code> check fails with the aliased type <code>typing.Mapping</code> but succeeds with the ABC <code>collections.abc.Mapping</code>. If you encounter a similar issue, try replacing the deprecated <code>typing</code> aliases with the types defined in <code>collections.abc</code>.</p> <p>An alternative solution is to <code>extract()</code> the proxy before type checking. This will incur the cost of resolving the proxy, if it was not already resolved, but <code>isinstance()</code> checks will often resolve a proxy anyways. See the related discussion on checking the type of a proxy.</p> <pre><code>import typing\nfrom proxystore.proxy import extract, Proxy\n\nmy_dict = Proxy(lambda: {})\n\nif isinstance(my_dict, Proxy):\n    my_dict = extract(my_dict)\n\nassert isinstance(my_dict, typing.Mapping)\n</code></pre> <p>The <code>isinstance(my_dict, Proxy)</code> check is not necessary in this specific example as we know <code>my_dict</code> is a <code>Proxy</code> instance. However, this pattern is useful in the general case where you may have a type <code>T</code> or a <code>Proxy[T]</code>.</p>"},{"location":"faq/#static-type-checking","title":"Static Type Checking","text":""},{"location":"faq/#how-do-i-annotate-a-proxy-type","title":"How do I annotate a proxy type?","text":"<p>The <code>Proxy</code> is a generic type on its target object, and mypy will infer the correct type of the target from the provided factory function. For example, the <code>extract()</code> function is annotated as follows.</p> <pre><code>from typing import TypeVar\nfrom proxystore.proxy import Proxy\n\nT = TypeVar('T')\n\ndef extract(proxy: Proxy[T]) -&gt; T:\n    ...\n\nproxy = Proxy(lambda: 42)\nreveal_type(proxy)  # Revealed type is Proxy[int]\n\ntarget = extract(proxy)\nreveal_type(target)  # Revealed type is int\n</code></pre> <p>In the event a proxy's type is ambiguous, an annotation can be provided directly. For example, this is the case with <code>Store.proxy_from_key()</code> because the type system cannot infer the target type from a key which is a tuple of metadata.</p> <pre><code>from proxystore.connectors.local import LocalConnector\nfrom proxystore.store import Store\n\nwith Store('example', LocalConnector()) as store:\n    key = store.put('value')\n    proxy: Proxy[str] = store.proxy_from_key(key)\n</code></pre>"},{"location":"faq/#can-mypy-infer-attributes-of-a-proxied-type","title":"Can mypy infer attributes of a proxied type?","text":"<p>In general, no. Attributes and methods of an object of type <code>T</code>, accessed indirectly via a <code>Proxy[T]</code>, are ambiguous to mypy and will typically resolve to <code>Any</code>.</p> <p>However, ProxyStore provides a mypy plugin that, when enabled, will help mypy resolve types related to proxies correctly. Check out the mypy plugin to learn more.</p>"},{"location":"faq/#proxystore-endpoints","title":"ProxyStore Endpoints","text":""},{"location":"faq/#why-are-my-endpoints-not-working","title":"Why are my endpoints not working?","text":"<p>Check out the Endpoints Debugging Guide.</p>"},{"location":"get-started/","title":"Get Started","text":"<p>Figure 1: ProxyStore allows developers to communicate objects via proxies. Proxies act as lightweight references that resolve to a target object upon use. Communication via proxies gives applications the illusion that objects are moving through a specified path (e.g., through a network socket, cloud server, workflow engine, etc.) while the true path the data takes is different. Transporting the lightweight proxies through the application or systems can be far more efficient and reduce overheads.</p>"},{"location":"get-started/#overview","title":"Overview","text":"<p>ProxyStore provides a unique interface to object stores through transparent object proxies that is designed to simplify the use of object stores for transferring large objects in distributed applications.</p> <p>Proxies are used to intercept and redefine operations on a target object. A transparent proxy behaves identically to its target object because the proxy forwards all operations on itself to the target. A lazy proxy provides just-in-time resolution of the target object via a factory function. Factories return the target object when called, and a proxy, initialized with a factory, will delay calling the factory to retrieve the target object until the first time the proxy is accessed.</p> <p>ProxyStore uses lazy transparent object proxies as the interface to object stores. When an object is proxied, the object is placed in the specified object store, a factory containing the information needed to retrieve the object from the store is created, and a proxy, initialized with the factory, is returned. The resulting proxy is essentially a lightweight reference to the target that will resolve itself to the target and behave as the target once the proxy is first used. Thus, proxies can be used anywhere in-place of the true object and will resolve themselves without the program being aware.</p> <p>ProxyStore provides the proxy interface to a number of commonly used object stores as well as the <code>Proxy</code> and <code>Factory</code> building blocks to allow developers to create powerful just-in-time resolution functionality for Python objects.</p>"},{"location":"get-started/#usage","title":"Usage","text":"<p>ProxyStore is intended to be used via the <code>Store</code> interface which provide the <code>Store.proxy()</code> method for placing objects in stores and creating proxies that will resolve to the associated object in the store.</p> <p>A <code>Store</code> is initialized with a <code>Connector</code> which serves as the low-level interface to an byte-level object store. ProxyStore provides many <code>Connector</code> implementations and third-party code can provide custom implementations provided they meet the <code>Connector</code> protocol specification.</p> <p>The following example uses the <code>RedisConnector</code> to interface with an already running Redis server using proxies.</p> Basic ProxyStore Usage<pre><code>from proxystore.connectors.redis import RedisConnector\nfrom proxystore.store import get_store\nfrom proxystore.store import Store\n\nstore = Store(\n    'my-store',\n    RedisConnector(hostname='localhost', port=1234),\n    register=True,\n)\n\nstore = get_store('my-store')  # (1)!\n\nkey = store.put(my_object)  # (2)!\nassert my_object == store.get(key)\n\np = store.proxy(my_object)  # (3)!\n\nassert isinstance(p, type(my_object))  # (4)!\n</code></pre> <ol> <li>Passing <code>register=True</code> adds the store by name to a global registry, and registered store can be retrieved by name.</li> <li>Stores have basic get/put functionality.</li> <li>Place an object in the store and return a proxy.</li> <li>The proxy, when used, will behave as the target.</li> </ol> <p>This proxy, <code>p</code>, can be cheaply serialized and communicated to any arbitrary Python process as if it were the target object itself. Once the proxy is used on the remote process, the underlying factory function will be executed to retrieve the target object from the Redis server.</p> <p>Using the <code>Store</code> store interface allows developers to write code without needing to worry about how data communication is handled and reduces the number of lines of code that need to be changed when adding or changing the communication methods.</p> <p>For example, if you want to execute a function and the input data may be passed directly, via a key to an object in Redis, or as a filepath to a serialized object on disk, you will need boilerplate code that looks like:</p> <pre><code>def my_function(input: MyDataType | str | ...) -&gt; None:\n   if is_filepath(input_data):\n       data = read_and_deserialize(input)\n   elif is_redis_key(input_data):\n       data = redis_client.get(input)\n   elif is_other_communication_method(input_data):\n       ...\n   elif isinstance(input, MyDataType):\n       data = input\n   else:\n        raise ValueError(...)\n\n   # Compute using the data\n</code></pre> <p>This function is hard to type and must be extended every time a new communication method is used. With proxies, all of the boilerplate code can be removed because the proxy will contain within itself all of the necessary code to resolve the object.</p> <pre><code>def my_function(input: MyDataType) -&gt; None:\n   assert isinstance(input, MyDataType)  # (1)!\n\n   # Compute using the data\n</code></pre> <ol> <li>Always true even if input is a proxy.</li> </ol> <p>In this model, only the producer of the data needs to be aware of which ProxyStore backend to use, and no modification to consumer code are ever required.</p> <p>How is this more efficient?</p> <p>The ProxyStore model can improve application performance in many ways:</p> <ol> <li>Unused proxies are not resolved so not resources/time were wasted on the    communication.</li> <li>Object communication always takes place between the producer, the store, and    the consumer meaning communication is not wasted on intermediate processes    which have a proxy but do not use it.</li> <li>Different backends can be used that are optimized for specific usage    patterns.</li> <li>Proxies have built-in caching for frequently used objects.</li> </ol>"},{"location":"get-started/#learn-more","title":"Learn More","text":"<p>See the Concepts to learn more about ProxyStore's core concepts.</p> <p>ProxyStore provides many higher level interfaces for advanced application design patterns.</p> <ul> <li>Distributed Futures</li> <li>Distributed Memory Management</li> <li>Stream by Proxy</li> </ul>"},{"location":"installation/","title":"Installation","text":""},{"location":"installation/#base-install","title":"Base Install","text":"<p>We always recommend installing packages inside of your virtual environment of choice. E.g., <pre><code>$ python -m venv venv\n$ . venv/bin/activate\n</code></pre></p> <p>Once your virtual environment is activated, install ProxyStore with <code>pip</code>. <pre><code>$ pip install proxystore\n</code></pre></p>"},{"location":"installation/#extras-options","title":"Extras Options","text":"<p>The base installation is designed to be as lightweight as possible, but ProxyStore provides many features with extra dependencies that can be installed with the appropriate extras option.</p> Install Purpose <code>pip install proxystore[all]</code> Install all extras except <code>dev</code> and <code>docs</code> <code>pip install proxystore[endpoints]</code> Use ProxyStore Endpoints <code>pip install proxystore[extensions]</code> Install the <code>proxystore-ex</code> package <code>pip install proxystore[kafka]</code> Use Kafka stream shims <code>pip install proxystore[redis]</code> Use Redis stream shims or the <code>RedisConnector</code> <code>pip install proxystore[zmq]</code> Use ZeroMQ stream shims <code>pip install proxystore[dev]</code> Development dependencies <code>pip install proxystore[docs]</code> Documentation dependencies <p>Multiple extras options can be install at the same time.</p> <pre><code>$ pip install proxystore[endpoints,redis]\n</code></pre> <p>Or everything can be installed at once (this does not install the development packages).</p> <pre><code>$ pip install proxystore[all]\n</code></pre>"},{"location":"installation/#proxystore-extensions","title":"ProxyStore Extensions","text":"<p>Additional features are available in the <code>proxystore-ex</code> package (repository and docs). Features in the extensions package tend to be more experimental or have heavier not pip-installable dependencies.</p> <p>The extensions package can be installed alongside ProxyStore. <pre><code>$ pip install proxystore[extensions]\n</code></pre> Or standalone. <pre><code>$ pip install proxystore-ex\n</code></pre></p> <p>Rather than importing from <code>proxystore_ex</code> directly, ProxyStore re-exports all packages and modules via the <code>proxystore.ex</code> submodule.</p>"},{"location":"api/","title":"proxystore","text":"<code>proxystore/__init__.py</code> <p>ProxyStore is a library for decoupling object communication from code.</p>"},{"location":"api/SUMMARY/","title":"SUMMARY","text":"<ul> <li>proxystore</li> <li>proxystore.connectors<ul> <li>dim</li> <li>endpoint</li> <li>file</li> <li>globus</li> <li>local</li> <li>multi</li> <li>protocols</li> <li>redis</li> </ul> </li> <li>proxystore.endpoint<ul> <li>cli</li> <li>client</li> <li>commands</li> <li>config</li> <li>constants</li> <li>endpoint</li> <li>exceptions</li> <li>messages</li> <li>serve</li> <li>storage</li> </ul> </li> <li>proxystore.ex</li> <li>proxystore.factory</li> <li>proxystore.globus<ul> <li>cli</li> <li>client</li> <li>manager</li> <li>scopes</li> <li>storage</li> <li>transfer</li> </ul> </li> <li>proxystore.mypy_plugin</li> <li>proxystore.p2p<ul> <li>chunks</li> <li>connection</li> <li>exceptions</li> <li>manager</li> <li>nat</li> <li>relay<ul> <li>authenticate</li> <li>client</li> <li>config</li> <li>exceptions</li> <li>manager</li> <li>messages</li> <li>run</li> <li>server</li> </ul> </li> </ul> </li> <li>proxystore.proxy</li> <li>proxystore.serialize</li> <li>proxystore.store<ul> <li>base</li> <li>cache</li> <li>config</li> <li>exceptions</li> <li>executor</li> <li>factory</li> <li>future</li> <li>lifetimes</li> <li>metrics</li> <li>ref</li> <li>scopes</li> <li>types</li> <li>utils</li> </ul> </li> <li>proxystore.stream<ul> <li>events</li> <li>exceptions</li> <li>filters</li> <li>interface</li> <li>protocols</li> <li>shims<ul> <li>kafka</li> <li>queue</li> <li>redis</li> <li>zmq</li> </ul> </li> </ul> </li> <li>proxystore.utils<ul> <li>config</li> <li>counter</li> <li>data</li> <li>environment</li> <li>imports</li> <li>tasks</li> <li>timer</li> </ul> </li> <li>proxystore.warnings</li> </ul>"},{"location":"api/cli/","title":"CLI Reference","text":""},{"location":"api/cli/#cli-reference","title":"CLI Reference","text":"<p>This page provides documentation for our command line tools.</p>"},{"location":"api/cli/#proxystore-globus-auth","title":"proxystore-globus-auth","text":"<p>ProxyStore Globus Auth.</p> <p>Usage:</p> <pre><code>proxystore-globus-auth [OPTIONS] COMMAND [ARGS]...\n</code></pre> <p>Options:</p> Name Type Description Default <code>--help</code> boolean Show this message and exit. <code>False</code> <p>Subcommands</p> <ul> <li>login: Authenticate with Globus Auth.</li> <li>logout: Revoke and remove all Globus tokens.</li> </ul>"},{"location":"api/cli/#proxystore-globus-auth-login","title":"proxystore-globus-auth login","text":"<p>Authenticate with Globus Auth.</p> <p>This requests scopes for Globus Auth, Globus Transfer, and the ProxyStore relay server. Collections or scopes options can be strung together. E.g., request transfer scope for multiple collections with:</p> <p>$ proxystore-globus-auth -c UUID -c UUID -c UUID</p> <p>Usage:</p> <pre><code>proxystore-globus-auth login [OPTIONS]\n</code></pre> <p>Options:</p> Name Type Description Default <code>--collection</code>, <code>-c</code> text Globus Collection UUID to request transfer scopes for. None <code>--scope</code>, <code>-s</code> text Additional scope to request. None <code>--help</code> boolean Show this message and exit. <code>False</code>"},{"location":"api/cli/#proxystore-globus-auth-logout","title":"proxystore-globus-auth logout","text":"<p>Revoke and remove all Globus tokens.</p> <p>Usage:</p> <pre><code>proxystore-globus-auth logout [OPTIONS]\n</code></pre> <p>Options:</p> Name Type Description Default <code>--help</code> boolean Show this message and exit. <code>False</code>"},{"location":"api/cli/#proxystore-endpoint","title":"proxystore-endpoint","text":"<p>Manage and start ProxyStore Endpoints.</p> <p>Usage:</p> <pre><code>proxystore-endpoint [OPTIONS] COMMAND [ARGS]...\n</code></pre> <p>Options:</p> Name Type Description Default <code>--log-level</code> choice (<code>ERROR</code> | <code>WARNING</code> | <code>INFO</code> | <code>DEBUG</code>) Minimum logging level. <code>INFO</code> <code>--help</code> boolean Show this message and exit. <code>False</code> <p>Subcommands</p> <ul> <li>check-nat: Check the type of NAT you are behind.</li> <li>configure: Configure a new endpoint.</li> <li>help: Show available commands and options.</li> <li>list: List all user endpoints.</li> <li>remove: Remove an endpoint.</li> <li>start: Start an endpoint.</li> <li>stop: Stop a detached endpoint.</li> <li>test: Execute test commands on an endpoint.</li> <li>version: Show the ProxyStore version.</li> </ul>"},{"location":"api/cli/#proxystore-endpoint-check-nat","title":"proxystore-endpoint check-nat","text":"<p>Check the type of NAT you are behind.</p> <p>Usage:</p> <pre><code>proxystore-endpoint check-nat [OPTIONS]\n</code></pre> <p>Options:</p> Name Type Description Default <code>--host</code> text Network interface address to listen on. <code>0.0.0.0</code> <code>--port</code> integer Port to listen on. <code>54320</code> <code>--help</code> boolean Show this message and exit. <code>False</code>"},{"location":"api/cli/#proxystore-endpoint-configure","title":"proxystore-endpoint configure","text":"<p>Configure a new endpoint.</p> <p>Usage:</p> <pre><code>proxystore-endpoint configure [OPTIONS] NAME\n</code></pre> <p>Options:</p> Name Type Description Default <code>--port</code> integer Port to listen on. <code>8765</code> <code>--relay-address</code> text Relay server address. <code>wss://relay.proxystore.dev</code> <code>--relay-auth</code> / <code>--no-relay-auth</code> boolean Disable relay server authentication. <code>True</code> <code>--relay-server</code> / <code>--no-relay-server</code> boolean Disable connecting to the relay server on start. <code>True</code> <code>--peer-channels</code> integer Datachannels to use per peer connection. <code>1</code> <code>--persist</code> / <code>--no-persist</code> boolean Optionally persist data to a database. <code>False</code> <code>--help</code> boolean Show this message and exit. <code>False</code>"},{"location":"api/cli/#proxystore-endpoint-help","title":"proxystore-endpoint help","text":"<p>Show available commands and options.</p> <p>Usage:</p> <pre><code>proxystore-endpoint help [OPTIONS]\n</code></pre> <p>Options:</p> Name Type Description Default <code>--help</code> boolean Show this message and exit. <code>False</code>"},{"location":"api/cli/#proxystore-endpoint-list","title":"proxystore-endpoint list","text":"<p>List all user endpoints.</p> <p>Usage:</p> <pre><code>proxystore-endpoint list [OPTIONS]\n</code></pre> <p>Options:</p> Name Type Description Default <code>--help</code> boolean Show this message and exit. <code>False</code>"},{"location":"api/cli/#proxystore-endpoint-remove","title":"proxystore-endpoint remove","text":"<p>Remove an endpoint.</p> <p>Usage:</p> <pre><code>proxystore-endpoint remove [OPTIONS] NAME\n</code></pre> <p>Options:</p> Name Type Description Default <code>--help</code> boolean Show this message and exit. <code>False</code>"},{"location":"api/cli/#proxystore-endpoint-start","title":"proxystore-endpoint start","text":"<p>Start an endpoint.</p> <p>Usage:</p> <pre><code>proxystore-endpoint start [OPTIONS] NAME\n</code></pre> <p>Options:</p> Name Type Description Default <code>--detach</code> / <code>--no-detach</code> boolean Run as daemon. <code>True</code> <code>--help</code> boolean Show this message and exit. <code>False</code>"},{"location":"api/cli/#proxystore-endpoint-stop","title":"proxystore-endpoint stop","text":"<p>Stop a detached endpoint.</p> <p>Usage:</p> <pre><code>proxystore-endpoint stop [OPTIONS] NAME\n</code></pre> <p>Options:</p> Name Type Description Default <code>--help</code> boolean Show this message and exit. <code>False</code>"},{"location":"api/cli/#proxystore-endpoint-test","title":"proxystore-endpoint test","text":"<p>Execute test commands on an endpoint.</p> <p>Usage:</p> <pre><code>proxystore-endpoint test [OPTIONS] NAME COMMAND [ARGS]...\n</code></pre> <p>Options:</p> Name Type Description Default <code>--remote</code> text Optional UUID of remote endpoint to use. None <code>--help</code> boolean Show this message and exit. <code>False</code> <p>Subcommands</p> <ul> <li>evict: Evict object from an endpoint.</li> <li>exists: Check if object exists in an endpoint.</li> <li>get: Get an object from an endpoint.</li> <li>put: Put an object in an endpoint.</li> </ul>"},{"location":"api/cli/#proxystore-endpoint-test-name-evict","title":"proxystore-endpoint test NAME evict","text":"<p>Evict object from an endpoint.</p> <p>Usage:</p> <pre><code>proxystore-endpoint test NAME evict [OPTIONS] KEY\n</code></pre> <p>Options:</p> Name Type Description Default <code>--help</code> boolean Show this message and exit. <code>False</code>"},{"location":"api/cli/#proxystore-endpoint-test-name-exists","title":"proxystore-endpoint test NAME exists","text":"<p>Check if object exists in an endpoint.</p> <p>Usage:</p> <pre><code>proxystore-endpoint test NAME exists [OPTIONS] KEY\n</code></pre> <p>Options:</p> Name Type Description Default <code>--help</code> boolean Show this message and exit. <code>False</code>"},{"location":"api/cli/#proxystore-endpoint-test-name-get","title":"proxystore-endpoint test NAME get","text":"<p>Get an object from an endpoint.</p> <p>Usage:</p> <pre><code>proxystore-endpoint test NAME get [OPTIONS] KEY\n</code></pre> <p>Options:</p> Name Type Description Default <code>--help</code> boolean Show this message and exit. <code>False</code>"},{"location":"api/cli/#proxystore-endpoint-test-name-put","title":"proxystore-endpoint test NAME put","text":"<p>Put an object in an endpoint.</p> <p>Usage:</p> <pre><code>proxystore-endpoint test NAME put [OPTIONS] DATA\n</code></pre> <p>Options:</p> Name Type Description Default <code>--help</code> boolean Show this message and exit. <code>False</code>"},{"location":"api/cli/#proxystore-endpoint-version","title":"proxystore-endpoint version","text":"<p>Show the ProxyStore version.</p> <p>Usage:</p> <pre><code>proxystore-endpoint version [OPTIONS]\n</code></pre> <p>Options:</p> Name Type Description Default <code>--help</code> boolean Show this message and exit. <code>False</code>"},{"location":"api/cli/#proxystore-relay","title":"proxystore-relay","text":"<p>Run a relay server instance.</p> <p>The relay server is used by clients to establish peer-to-peer WebRTC connections. If no configuration file is provided, a default configuration will be created from <code>RelayServingConfig()</code>. The remaining CLI options will override the options provided in the configuration object.</p> <p>Usage:</p> <pre><code>proxystore-relay [OPTIONS]\n</code></pre> <p>Options:</p> Name Type Description Default <code>--config</code>, <code>-c</code> text Configuration file. None <code>--host</code> text Interface to bind to. None <code>--port</code> integer Port to bind to. None <code>--log-dir</code> text Logging directoryy. None <code>--log-level</code> choice (<code>CRITICAL</code> | <code>ERROR</code> | <code>WARNING</code> | <code>INFO</code> | <code>DEBUG</code>) Minimum logging level. None <code>--help</code> boolean Show this message and exit. <code>False</code>"},{"location":"api/ex/","title":"proxystore.ex","text":"<code>proxystore/ex.py</code> <p>Extension modules.</p> <p>This module re-exports packages and modules from the <code>proxystore-ex</code> package, and is the recommended method by which to import features from the extensions package.</p> Example <p>Extension features can be imported directly. E.g., <pre><code>from proxystore_ex.connectors.daos import DAOSConnector\n</code></pre> But we recommend replacing <code>proxystore_ex</code> with <code>proxystore.ex</code>. E.g., <pre><code>from proxystore.ex.connectors.daos import DAOSConnector\n</code></pre></p> <p>The API reference for the extensions package can be found at extensions.proxystore.dev/latest/api.</p> Warning <p>A import error will be raised if <code>proxystore-ex</code> is not installed. See the Installation page for installation instructions.</p>"},{"location":"api/factory/","title":"proxystore.factory","text":"<code>proxystore/factory.py</code> <p>Factory implementations.</p> <p>Factories are callable classes that wrap up the functionality needed to resolve a proxy, where resolving is the process of retrieving the object from wherever it is stored such that the proxy can act as the object.</p>"},{"location":"api/factory/#proxystore.factory.Factory","title":"Factory","text":"<pre><code>Factory()\n</code></pre> <p>             Bases: <code>Generic[T]</code></p> <p>Abstract Factory Class.</p> <p>A factory is a callable object that when called, returns an object. The <code>Proxy</code> constructor takes an instance of a factory and calls the factory when the proxy does its just-in-time resolution.</p> Note <p>If a custom factory is not-pickleable, <code>__getnewargs_ex__</code> may need to be implemented. Writing custom pickling functions is also beneifical to ensure that a pickled factory does not contain the object itself, just what is needed to resolve the object to keep the final pickled factory as small as possible.</p> Source code in <code>proxystore/factory.py</code> <pre><code>def __init__(self) -&gt; None:\n    raise NotImplementedError\n</code></pre>"},{"location":"api/factory/#proxystore.factory.Factory.__call__","title":"__call__()","text":"<pre><code>__call__() -&gt; T\n</code></pre> <p>Alias <code>Factory.resolve()</code>.</p> Source code in <code>proxystore/factory.py</code> <pre><code>def __call__(self) -&gt; T:\n    \"\"\"Alias [`Factory.resolve()`][proxystore.factory.Factory.resolve].\"\"\"\n    return self.resolve()\n</code></pre>"},{"location":"api/factory/#proxystore.factory.Factory.resolve","title":"resolve()","text":"<pre><code>resolve() -&gt; T\n</code></pre> <p>Resolve and return object.</p> Source code in <code>proxystore/factory.py</code> <pre><code>def resolve(self) -&gt; T:\n    \"\"\"Resolve and return object.\"\"\"\n    raise NotImplementedError\n</code></pre>"},{"location":"api/factory/#proxystore.factory.SimpleFactory","title":"SimpleFactory","text":"<pre><code>SimpleFactory(obj: T)\n</code></pre> <p>             Bases: <code>Factory[T]</code></p> <p>Simple Factory that stores object as class attribute.</p> <p>Parameters:</p> <ul> <li> <code>obj</code>             (<code>T</code>)         \u2013          <p>Object to produce when factory is called.</p> </li> </ul> Source code in <code>proxystore/factory.py</code> <pre><code>def __init__(self, obj: T) -&gt; None:\n    self._obj = obj\n</code></pre>"},{"location":"api/factory/#proxystore.factory.SimpleFactory.__call__","title":"__call__()","text":"<pre><code>__call__() -&gt; T\n</code></pre> <p>Alias <code>Factory.resolve()</code>.</p> Source code in <code>proxystore/factory.py</code> <pre><code>def __call__(self) -&gt; T:\n    \"\"\"Alias [`Factory.resolve()`][proxystore.factory.Factory.resolve].\"\"\"\n    return self.resolve()\n</code></pre>"},{"location":"api/factory/#proxystore.factory.SimpleFactory.resolve","title":"resolve()","text":"<pre><code>resolve() -&gt; T\n</code></pre> <p>Return the object.</p> Source code in <code>proxystore/factory.py</code> <pre><code>def resolve(self) -&gt; T:\n    \"\"\"Return the object.\"\"\"\n    return self._obj\n</code></pre>"},{"location":"api/factory/#proxystore.factory.LambdaFactory","title":"LambdaFactory","text":"<pre><code>LambdaFactory(\n    target: Callable[..., T], *args: Any, **kwargs: Any\n)\n</code></pre> <p>             Bases: <code>Factory[T]</code></p> <p>Factory that takes any callable object.</p> <p>Parameters:</p> <ul> <li> <code>target</code>             (<code>Callable[..., T]</code>)         \u2013          <p>Callable object (function, class, lambda) to be invoked when the factory is resolved.</p> </li> <li> <code>args</code>             (<code>Any</code>, default:                 <code>()</code> )         \u2013          <p>Argument tuple for target invocation.</p> </li> <li> <code>kwargs</code>             (<code>Any</code>, default:                 <code>{}</code> )         \u2013          <p>Dictionary of keyword arguments for target invocation.</p> </li> </ul> Source code in <code>proxystore/factory.py</code> <pre><code>def __init__(\n    self,\n    target: Callable[..., T],\n    *args: Any,\n    **kwargs: Any,\n) -&gt; None:\n    self._target = target\n    self._args = args\n    self._kwargs = kwargs\n</code></pre>"},{"location":"api/factory/#proxystore.factory.LambdaFactory.__call__","title":"__call__()","text":"<pre><code>__call__() -&gt; T\n</code></pre> <p>Alias <code>Factory.resolve()</code>.</p> Source code in <code>proxystore/factory.py</code> <pre><code>def __call__(self) -&gt; T:\n    \"\"\"Alias [`Factory.resolve()`][proxystore.factory.Factory.resolve].\"\"\"\n    return self.resolve()\n</code></pre>"},{"location":"api/factory/#proxystore.factory.LambdaFactory.resolve","title":"resolve()","text":"<pre><code>resolve() -&gt; T\n</code></pre> <p>Return the target object.</p> Source code in <code>proxystore/factory.py</code> <pre><code>def resolve(self) -&gt; T:\n    \"\"\"Return the target object.\"\"\"\n    return self._target(*self._args, **self._kwargs)\n</code></pre>"},{"location":"api/mypy_plugin/","title":"proxystore.mypy_plugin","text":"<code>proxystore/mypy_plugin.py</code> <p>ProxyStore mypy plugin.</p> <p>The <code>Proxy</code> class behaves poorly with mypy out of the box. Consider the following example. Mypy can determine that <code>proxy</code> is of type <code>Proxy[Foo]</code> but is unable to determine the correct types when accessing an attribute of <code>Foo</code> indirectly via the <code>Proxy</code> instance.</p> <pre><code>from proxystore.proxy import Proxy\n\nclass Foo:\n    def bar(self) -&gt; int:\n        return 42\n\ndef factory() -&gt; Foo:\n    return Foo()\n\nproxy = Proxy(factory)\nreveal_type(proxy)  # Revealed type is \"Proxy[Foo]\"\n\nbar = proxy.bar()\nreveal_type(bar)  # Revealed type is \"Any\"\n</code></pre> <p>ProxyStore (v0.6.5 and later) comes with an optional mypy plugin which can fix these type resolution limitations. With the mypy plugin enabled, we get the correct type.</p> <pre><code>proxy = Proxy(factory)\nreveal_type(proxy)  # Revealed type is \"Proxy[Foo]\"\n\nbar = proxy.bar()\nreveal_type(bar)  # Revealed type is \"int\"\n</code></pre> <p>Enable the plugin by adding <code>proxystore.mypy_plugin</code> to the list of plugins in your mypy config file.</p> <ul> <li><code>pyproject.toml</code> <pre><code>[tools.mypy]\nplugins = [\"proxystore.mypy_plugin\"]\n</code></pre></li> <li><code>mypy.ini</code> and <code>setup.cfg</code> <pre><code>[mypy]\nplugins = proxystore.mypy_plugin\n</code></pre></li> </ul>"},{"location":"api/serialize/","title":"proxystore.serialize","text":"<code>proxystore/serialize.py</code> <p>Serialization functions.</p>"},{"location":"api/serialize/#proxystore.serialize.SerializationError","title":"SerializationError","text":"<p>             Bases: <code>Exception</code></p> <p>Base Serialization Exception.</p>"},{"location":"api/serialize/#proxystore.serialize.serialize","title":"serialize()","text":"<pre><code>serialize(obj: Any) -&gt; bytes\n</code></pre> <p>Serialize object.</p> <p>Objects are serialized with different mechanisms depending on their type.</p> <ul> <li>bytes types are not serialized.</li> <li>str types are encoded to bytes.</li> <li>numpy.ndarray     types are serialized using     numpy.save.</li> <li>pandas.DataFrame     types are serialized using     to_pickle.</li> <li>polars.DataFrame     types are serialized using     write_ipc.</li> <li>Other types are     pickled.     If pickle fails,     cloudpickle     is used as a fallback.</li> </ul> <p>Parameters:</p> <ul> <li> <code>obj</code>             (<code>Any</code>)         \u2013          <p>Object to serialize.</p> </li> </ul> <p>Returns:</p> <ul> <li> <code>bytes</code>         \u2013          <p>Bytes that can be passed to         <code>deserialize()</code>.</p> </li> </ul> <p>Raises:</p> <ul> <li> <code>SerializationError</code>           \u2013          <p>If serializing the object fails with all available serializers. Cloudpickle is the last resort, so this error will typically be raised from a cloudpickle error.</p> </li> </ul> Source code in <code>proxystore/serialize.py</code> <pre><code>def serialize(obj: Any) -&gt; bytes:\n    \"\"\"Serialize object.\n\n    Objects are serialized with different mechanisms depending on their type.\n\n      - [bytes][] types are not serialized.\n      - [str][] types are encoded to bytes.\n      - [numpy.ndarray](https://numpy.org/doc/stable/reference/generated/numpy.ndarray.html){target=_blank}\n        types are serialized using\n        [numpy.save](https://numpy.org/doc/stable/reference/generated/numpy.save.html){target=_blank}.\n      - [pandas.DataFrame](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.html){target=_blank}\n        types are serialized using\n        [to_pickle](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.to_pickle.html){target=_blank}.\n      - [polars.DataFrame](https://pola-rs.github.io/polars/py-polars/html/reference/dataframe/index.html){target=_blank}\n        types are serialized using\n        [write_ipc](https://docs.pola.rs/api/python/stable/reference/api/polars.DataFrame.write_ipc.html){target=_blank}.\n      - Other types are\n        [pickled](https://docs.python.org/3/library/pickle.html){target=_blank}.\n        If pickle fails,\n        [cloudpickle](https://github.com/cloudpipe/cloudpickle){target=_blank}\n        is used as a fallback.\n\n    Args:\n        obj: Object to serialize.\n\n    Returns:\n        Bytes that can be passed to \\\n        [`deserialize()`][proxystore.serialize.deserialize].\n\n    Raises:\n        SerializationError: If serializing the object fails with all available\n            serializers. Cloudpickle is the last resort, so this error will\n            typically be raised from a cloudpickle error.\n    \"\"\"\n    last_exception: Exception | None = None\n    for identifier, serializer in _SERIALIZERS.items():\n        if serializer.supported(obj):\n            try:\n                with io.BytesIO() as buffer:\n                    buffer.write(identifier + b'\\n')\n                    serializer.serialize(obj, buffer)\n                    return buffer.getvalue()\n            except Exception as e:\n                last_exception = e\n\n    assert last_exception is not None\n    raise SerializationError(\n        f'Object of type {type(obj)} is not supported.',\n    ) from last_exception\n</code></pre>"},{"location":"api/serialize/#proxystore.serialize.deserialize","title":"deserialize()","text":"<pre><code>deserialize(data: bytes) -&gt; Any\n</code></pre> <p>Deserialize object.</p> Warning <p>Pickled data is not secure, and malicious pickled object can execute arbitrary code when upickled. Only unpickle data you trust.</p> <p>Parameters:</p> <ul> <li> <code>data</code>             (<code>bytes</code>)         \u2013          <p>Bytes produced by <code>serialize()</code>.</p> </li> </ul> <p>Returns:</p> <ul> <li> <code>Any</code>         \u2013          <p>The deserialized object.</p> </li> </ul> <p>Raises:</p> <ul> <li> <code>ValueError</code>           \u2013          <p>If <code>data</code> is not of type <code>bytes</code>.</p> </li> <li> <code>SerializationError</code>           \u2013          <p>If the identifier of <code>data</code> is missing or invalid. The identifier is prepended to the string in <code>serialize()</code> to indicate which serialization method was used (e.g., no serialization, pickle, etc.).</p> </li> <li> <code>SerializationError</code>           \u2013          <p>If pickle or cloudpickle raise an exception when deserializing the object.</p> </li> </ul> Source code in <code>proxystore/serialize.py</code> <pre><code>def deserialize(data: bytes) -&gt; Any:\n    \"\"\"Deserialize object.\n\n    Warning:\n        Pickled data is not secure, and malicious pickled object can execute\n        arbitrary code when upickled. Only unpickle data you trust.\n\n    Args:\n        data: Bytes produced by\n            [`serialize()`][proxystore.serialize.serialize].\n\n    Returns:\n        The deserialized object.\n\n    Raises:\n        ValueError: If `data` is not of type `bytes`.\n        SerializationError: If the identifier of `data` is missing or\n            invalid. The identifier is prepended to the string in\n            [`serialize()`][proxystore.serialize.serialize] to indicate which\n            serialization method was used (e.g., no serialization, pickle,\n            etc.).\n        SerializationError: If pickle or cloudpickle raise an exception\n            when deserializing the object.\n    \"\"\"\n    if not isinstance(data, bytes):\n        raise ValueError(\n            f'Expected data to be of type bytes, not {type(data)}.',\n        )\n\n    with io.BytesIO(data) as buffer:\n        identifier = buffer.readline().strip()\n        if identifier not in _SERIALIZERS:\n            raise SerializationError(\n                f'Unknown identifier {identifier!r} for deserialization.',\n            )\n\n        serializer = _SERIALIZERS[identifier]\n        try:\n            return serializer.deserialize(buffer)\n        except Exception as e:\n            raise SerializationError(\n                'Failed to deserialize object using the '\n                f'{serializer.name} serializer.',\n            ) from e\n</code></pre>"},{"location":"api/warnings/","title":"proxystore.warnings","text":"<code>proxystore/warnings.py</code> <p>Warning types.</p>"},{"location":"api/warnings/#proxystore.warnings.ExperimentalWarning","title":"ExperimentalWarning","text":"<p>             Bases: <code>Warning</code></p> <p>ProxyStore experimental feature warning.</p>"},{"location":"api/connectors/","title":"proxystore.connectors","text":"<code>proxystore/connectors/__init__.py</code> <p>Connector implementations.</p> <p>A <code>Connector</code> is an interface to a mediated communication channel or object store. Connectors operate on low-level bytes and are used by the <code>Store</code> to store and get serialized Python objects.</p> <p>Third-party code can provide custom connectors by implementing the <code>Connector</code> protocol. (Note: because <code>Connector</code> is a <code>Protocol</code>, custom connectors do not need to inherit from <code>Connector</code>.)</p> Example <pre><code>from proxystore.connectors.file import FileConnector\n\nconnector = FileConnector('./data-store')\nkey = connector.put(b'hello')\nconnector.get(key)\n&gt;&gt;&gt; b'hello'\nconnector.evict(key)\nconnector.exists(key)\n&gt;&gt;&gt; False\nconnector.close()\n</code></pre> Tip <p>All of the <code>Connector</code> implementations in this module can be used as context managers. Context manager support is not a required component of the <code>Connector</code> protocol. It is simply provided for convenience with the native implementations. <pre><code>from proxystore.connectors.file import FileConnector\n\nwith FileConnector('./data-store') as connector:\n    # connector.close() will be automatically called when the\n    # context manager is exited\n    ...\n</code></pre></p>"},{"location":"api/connectors/dim/","title":"proxystore.connectors.dim","text":"<code>proxystore/connectors/dim.py</code> <p>Distributed in-memory store connectors.</p> Warning <p>The distributed in-memory connector implementations have moved to the ProxyStore Extensions package as of ProxyStore v0.6.0. To update, install the <code>proxystore-ex</code> package <pre><code>$ pip install proxystore[extensions]  # or\n$ pip install proxystore-ex\n</code></pre> and change the imports accordingly. E.g., <pre><code>from proxystore.connectors.dim.zmq import ZeroMQConnector  # OLD\nfrom proxystore.ex.connectors.dim.zmq import ZeroMQConnector  # NEW\n</code></pre></p>"},{"location":"api/connectors/endpoint/","title":"proxystore.connectors.endpoint","text":"<code>proxystore/connectors/endpoint.py</code> <p>Endpoint connector implementation.</p>"},{"location":"api/connectors/endpoint/#proxystore.connectors.endpoint.EndpointConnectorError","title":"EndpointConnectorError","text":"<p>             Bases: <code>Exception</code></p> <p>Exception resulting from request to Endpoint.</p>"},{"location":"api/connectors/endpoint/#proxystore.connectors.endpoint.EndpointKey","title":"EndpointKey","text":"<p>             Bases: <code>NamedTuple</code></p> <p>Key to object in an Endpoint.</p> <p>Attributes:</p> <ul> <li> <code>object_id</code>             (<code>str</code>)         \u2013          <p>Unique object ID.</p> </li> <li> <code>endpoint_id</code>             (<code>str | None</code>)         \u2013          <p>Endpoint UUID where object is stored.</p> </li> </ul>"},{"location":"api/connectors/endpoint/#proxystore.connectors.endpoint.EndpointConnector","title":"EndpointConnector","text":"<pre><code>EndpointConnector(\n    endpoints: Sequence[str | UUID],\n    proxystore_dir: str | None = None,\n)\n</code></pre> <p>Connector to ProxyStore Endpoints.</p> Warning <p>Specifying a custom <code>proxystore_dir</code> can cause problems if the <code>proxystore_dir</code> is not the same on all systems that a proxy created by this store could end up on. It is recommended to leave the <code>proxystore_dir</code> unspecified so the correct default directory will be used.</p> <p>Parameters:</p> <ul> <li> <code>endpoints</code>             (<code>Sequence[str | UUID]</code>)         \u2013          <p>Sequence of valid and running endpoint UUIDs to use. At least one of these endpoints must be accessible by this process.</p> </li> <li> <code>proxystore_dir</code>             (<code>str | None</code>, default:                 <code>None</code> )         \u2013          <p>Optionally specify the proxystore home directory. Defaults to <code>home_dir()</code>.</p> </li> </ul> <p>Raises:</p> <ul> <li> <code>ValueError</code>           \u2013          <p>If endpoints is an empty list.</p> </li> <li> <code>EndpointConnectorError</code>           \u2013          <p>If unable to connect to one of the endpoints provided.</p> </li> </ul> Source code in <code>proxystore/connectors/endpoint.py</code> <pre><code>def __init__(\n    self,\n    endpoints: Sequence[str | UUID],\n    proxystore_dir: str | None = None,\n) -&gt; None:\n    if len(endpoints) == 0:\n        raise ValueError('At least one endpoint must be specified.')\n    self.endpoints: list[UUID] = [\n        e if isinstance(e, UUID) else UUID(e, version=4) for e in endpoints\n    ]\n    self.proxystore_dir = proxystore_dir\n\n    # Maintain single session for connection pooling persistence to\n    # speed up repeat requests to same endpoint.\n    self._session = requests.Session()\n\n    # Find the first locally accessible endpoint to use as our\n    # home endpoint\n    available_endpoints = get_configs(\n        home_dir() if self.proxystore_dir is None else self.proxystore_dir,\n    )\n    found_endpoint: EndpointConfig | None = None\n    for endpoint in available_endpoints:\n        endpoint_uuid = UUID(endpoint.uuid)\n        if endpoint_uuid not in self.endpoints:\n            continue\n        if endpoint.host is None:\n            logger.warning(\n                'Found valid configuration for endpoint '\n                f'\"{endpoint.name}\" ({endpoint_uuid}), but the endpoint '\n                'has not been started',\n            )\n            continue\n        logger.debug(f'Attempting connection to {endpoint_uuid}')\n        response = self._session.get(\n            f'http://{endpoint.host}:{endpoint.port}/endpoint',\n        )\n        if response.status_code == 200:\n            uuid_ = response.json()['uuid']\n            if endpoint_uuid == UUID(uuid_):\n                logger.debug(\n                    f'Connection to {endpoint_uuid} successful, using '\n                    'as local endpoint',\n                )\n                found_endpoint = endpoint\n                break\n            else:\n                logger.debug(\n                    f'Connection to {endpoint_uuid} returned '\n                    'different UUID',\n                )\n        else:\n            logger.debug(f'Connection to {endpoint_uuid} failed')\n\n    if found_endpoint is None:\n        self._session.close()\n        raise EndpointConnectorError(\n            'Failed to find an endpoint configuration matching one of the '\n            'provided endpoint UUIDs, or an endpoint configuration was '\n            'found but the endpoint could not be connected to. '\n            'Enable debug level logging for more more details.',\n        )\n    self.endpoint_uuid: uuid.UUID = uuid.UUID(found_endpoint.uuid)\n    self.endpoint_host: str | None = found_endpoint.host\n    self.endpoint_port: int = found_endpoint.port\n\n    self.address = f'http://{self.endpoint_host}:{self.endpoint_port}'\n</code></pre>"},{"location":"api/connectors/endpoint/#proxystore.connectors.endpoint.EndpointConnector.close","title":"close()","text":"<pre><code>close() -&gt; None\n</code></pre> <p>Close the connector and clean up.</p> Source code in <code>proxystore/connectors/endpoint.py</code> <pre><code>def close(self) -&gt; None:\n    \"\"\"Close the connector and clean up.\"\"\"\n    self._session.close()\n</code></pre>"},{"location":"api/connectors/endpoint/#proxystore.connectors.endpoint.EndpointConnector.config","title":"config()","text":"<pre><code>config() -&gt; dict[str, Any]\n</code></pre> <p>Get the connector configuration.</p> <p>The configuration contains all the information needed to reconstruct the connector object.</p> Source code in <code>proxystore/connectors/endpoint.py</code> <pre><code>def config(self) -&gt; dict[str, Any]:\n    \"\"\"Get the connector configuration.\n\n    The configuration contains all the information needed to reconstruct\n    the connector object.\n    \"\"\"\n    return {\n        'endpoints': [str(ep) for ep in self.endpoints],\n        'proxystore_dir': self.proxystore_dir,\n    }\n</code></pre>"},{"location":"api/connectors/endpoint/#proxystore.connectors.endpoint.EndpointConnector.from_config","title":"from_config()  <code>classmethod</code>","text":"<pre><code>from_config(config: dict[str, Any]) -&gt; EndpointConnector\n</code></pre> <p>Create a new connector instance from a configuration.</p> <p>Parameters:</p> <ul> <li> <code>config</code>             (<code>dict[str, Any]</code>)         \u2013          <p>Configuration returned by <code>.config()</code>.</p> </li> </ul> Source code in <code>proxystore/connectors/endpoint.py</code> <pre><code>@classmethod\ndef from_config(cls, config: dict[str, Any]) -&gt; EndpointConnector:\n    \"\"\"Create a new connector instance from a configuration.\n\n    Args:\n        config: Configuration returned by `#!python .config()`.\n    \"\"\"\n    return cls(**config)\n</code></pre>"},{"location":"api/connectors/endpoint/#proxystore.connectors.endpoint.EndpointConnector.evict","title":"evict()","text":"<pre><code>evict(key: EndpointKey) -&gt; None\n</code></pre> <p>Evict the object associated with the key.</p> <p>Parameters:</p> <ul> <li> <code>key</code>             (<code>EndpointKey</code>)         \u2013          <p>Key associated with object to evict.</p> </li> </ul> Source code in <code>proxystore/connectors/endpoint.py</code> <pre><code>def evict(self, key: EndpointKey) -&gt; None:\n    \"\"\"Evict the object associated with the key.\n\n    Args:\n        key: Key associated with object to evict.\n    \"\"\"\n    try:\n        client.evict(\n            self.address,\n            key.object_id,\n            key.endpoint_id,\n            session=self._session,\n        )\n    except requests.exceptions.RequestException as e:\n        assert e.response is not None\n        raise EndpointConnectorError(\n            f'Evict failed with error code {e.response.status_code}.',\n        ) from e\n</code></pre>"},{"location":"api/connectors/endpoint/#proxystore.connectors.endpoint.EndpointConnector.exists","title":"exists()","text":"<pre><code>exists(key: EndpointKey) -&gt; bool\n</code></pre> <p>Check if an object associated with the key exists.</p> <p>Parameters:</p> <ul> <li> <code>key</code>             (<code>EndpointKey</code>)         \u2013          <p>Key potentially associated with stored object.</p> </li> </ul> <p>Returns:</p> <ul> <li> <code>bool</code>         \u2013          <p>If an object associated with the key exists.</p> </li> </ul> Source code in <code>proxystore/connectors/endpoint.py</code> <pre><code>def exists(self, key: EndpointKey) -&gt; bool:\n    \"\"\"Check if an object associated with the key exists.\n\n    Args:\n        key: Key potentially associated with stored object.\n\n    Returns:\n        If an object associated with the key exists.\n    \"\"\"\n    try:\n        return client.exists(\n            self.address,\n            key.object_id,\n            key.endpoint_id,\n            session=self._session,\n        )\n    except requests.exceptions.RequestException as e:\n        assert e.response is not None\n        raise EndpointConnectorError(\n            f'Exists failed with error code {e.response.status_code}.',\n        ) from e\n</code></pre>"},{"location":"api/connectors/endpoint/#proxystore.connectors.endpoint.EndpointConnector.get","title":"get()","text":"<pre><code>get(key: EndpointKey) -&gt; bytes | None\n</code></pre> <p>Get the serialized object associated with the key.</p> <p>Parameters:</p> <ul> <li> <code>key</code>             (<code>EndpointKey</code>)         \u2013          <p>Key associated with the object to retrieve.</p> </li> </ul> <p>Returns:</p> <ul> <li> <code>bytes | None</code>         \u2013          <p>Serialized object or <code>None</code> if the object does not exist.</p> </li> </ul> Source code in <code>proxystore/connectors/endpoint.py</code> <pre><code>def get(self, key: EndpointKey) -&gt; bytes | None:\n    \"\"\"Get the serialized object associated with the key.\n\n    Args:\n        key: Key associated with the object to retrieve.\n\n    Returns:\n        Serialized object or `None` if the object does not exist.\n    \"\"\"\n    try:\n        return client.get(\n            self.address,\n            key.object_id,\n            key.endpoint_id,\n            session=self._session,\n        )\n    except requests.exceptions.RequestException as e:\n        assert e.response is not None\n        raise EndpointConnectorError(\n            f'Get failed with error code {e.response.status_code}.',\n        ) from e\n</code></pre>"},{"location":"api/connectors/endpoint/#proxystore.connectors.endpoint.EndpointConnector.get_batch","title":"get_batch()","text":"<pre><code>get_batch(\n    keys: Sequence[EndpointKey],\n) -&gt; list[bytes | None]\n</code></pre> <p>Get a batch of serialized objects associated with the keys.</p> <p>Parameters:</p> <ul> <li> <code>keys</code>             (<code>Sequence[EndpointKey]</code>)         \u2013          <p>Sequence of keys associated with objects to retrieve.</p> </li> </ul> <p>Returns:</p> <ul> <li> <code>list[bytes | None]</code>         \u2013          <p>List with same order as <code>keys</code> with the serialized objects or             <code>None</code> if the corresponding key does not have an associated object.</p> </li> </ul> Source code in <code>proxystore/connectors/endpoint.py</code> <pre><code>def get_batch(self, keys: Sequence[EndpointKey]) -&gt; list[bytes | None]:\n    \"\"\"Get a batch of serialized objects associated with the keys.\n\n    Args:\n        keys: Sequence of keys associated with objects to retrieve.\n\n    Returns:\n        List with same order as `keys` with the serialized objects or \\\n        `None` if the corresponding key does not have an associated object.\n    \"\"\"\n    return [self.get(key) for key in keys]\n</code></pre>"},{"location":"api/connectors/endpoint/#proxystore.connectors.endpoint.EndpointConnector.new_key","title":"new_key()","text":"<pre><code>new_key(obj: bytes | None = None) -&gt; EndpointKey\n</code></pre> <p>Create a new key.</p> Warning <p>The returned key will be associated with this instance's local endpoint. I.e., when <code>set()</code> is called on this key, the connector must be connected to the same local endpoint.</p> <p>Parameters:</p> <ul> <li> <code>obj</code>             (<code>bytes | None</code>, default:                 <code>None</code> )         \u2013          <p>Optional object which the key will be associated with. Ignored in this implementation.</p> </li> </ul> <p>Returns:</p> <ul> <li> <code>EndpointKey</code>         \u2013          <p>Key which can be used to retrieve an object once             <code>set()</code>             has been called on the key.</p> </li> </ul> Source code in <code>proxystore/connectors/endpoint.py</code> <pre><code>def new_key(self, obj: bytes | None = None) -&gt; EndpointKey:\n    \"\"\"Create a new key.\n\n    Warning:\n        The returned key will be associated with this instance's local\n        endpoint. I.e., when\n        [`set()`][proxystore.connectors.endpoint.EndpointConnector.set]\n        is called on this key, the connector must be connected to the same\n        local endpoint.\n\n    Args:\n        obj: Optional object which the key will be associated with.\n            Ignored in this implementation.\n\n    Returns:\n        Key which can be used to retrieve an object once \\\n        [`set()`][proxystore.connectors.endpoint.EndpointConnector.set] \\\n        has been called on the key.\n    \"\"\"\n    return EndpointKey(\n        object_id=str(uuid.uuid4()),\n        endpoint_id=str(self.endpoint_uuid),\n    )\n</code></pre>"},{"location":"api/connectors/endpoint/#proxystore.connectors.endpoint.EndpointConnector.put","title":"put()","text":"<pre><code>put(obj: bytes) -&gt; EndpointKey\n</code></pre> <p>Put a serialized object in the store.</p> <p>Parameters:</p> <ul> <li> <code>obj</code>             (<code>bytes</code>)         \u2013          <p>Serialized object to put in the store.</p> </li> </ul> <p>Returns:</p> <ul> <li> <code>EndpointKey</code>         \u2013          <p>Key which can be used to retrieve the object.</p> </li> </ul> Source code in <code>proxystore/connectors/endpoint.py</code> <pre><code>def put(self, obj: bytes) -&gt; EndpointKey:\n    \"\"\"Put a serialized object in the store.\n\n    Args:\n        obj: Serialized object to put in the store.\n\n    Returns:\n        Key which can be used to retrieve the object.\n    \"\"\"\n    key = EndpointKey(\n        object_id=str(uuid.uuid4()),\n        endpoint_id=str(self.endpoint_uuid),\n    )\n    self.set(key, obj)\n    return key\n</code></pre>"},{"location":"api/connectors/endpoint/#proxystore.connectors.endpoint.EndpointConnector.put_batch","title":"put_batch()","text":"<pre><code>put_batch(objs: Sequence[bytes]) -&gt; list[EndpointKey]\n</code></pre> <p>Put a batch of serialized objects in the store.</p> <p>Parameters:</p> <ul> <li> <code>objs</code>             (<code>Sequence[bytes]</code>)         \u2013          <p>Sequence of serialized objects to put in the store.</p> </li> </ul> <p>Returns:</p> <ul> <li> <code>list[EndpointKey]</code>         \u2013          <p>List of keys with the same order as <code>objs</code> which can be used to             retrieve the objects.</p> </li> </ul> Source code in <code>proxystore/connectors/endpoint.py</code> <pre><code>def put_batch(self, objs: Sequence[bytes]) -&gt; list[EndpointKey]:\n    \"\"\"Put a batch of serialized objects in the store.\n\n    Args:\n        objs: Sequence of serialized objects to put in the store.\n\n    Returns:\n        List of keys with the same order as `objs` which can be used to \\\n        retrieve the objects.\n    \"\"\"\n    return [self.put(obj) for obj in objs]\n</code></pre>"},{"location":"api/connectors/endpoint/#proxystore.connectors.endpoint.EndpointConnector.set","title":"set()","text":"<pre><code>set(key: EndpointKey, obj: bytes) -&gt; None\n</code></pre> <p>Set the object associated with a key.</p> Note <p>The <code>Connector</code> provides write-once, read-many semantics. Thus, <code>set()</code> should only be called once per key, otherwise unexpected behavior can occur.</p> <p>Parameters:</p> <ul> <li> <code>key</code>             (<code>EndpointKey</code>)         \u2013          <p>Key that the object will be associated with.</p> </li> <li> <code>obj</code>             (<code>bytes</code>)         \u2013          <p>Object to associate with the key.</p> </li> </ul> Source code in <code>proxystore/connectors/endpoint.py</code> <pre><code>def set(self, key: EndpointKey, obj: bytes) -&gt; None:\n    \"\"\"Set the object associated with a key.\n\n    Note:\n        The [`Connector`][proxystore.connectors.protocols.Connector]\n        provides write-once, read-many semantics. Thus,\n        [`set()`][proxystore.connectors.endpoint.EndpointConnector.set]\n        should only be called once per key, otherwise unexpected behavior\n        can occur.\n\n    Args:\n        key: Key that the object will be associated with.\n        obj: Object to associate with the key.\n    \"\"\"\n    try:\n        client.put(\n            self.address,\n            key.object_id,\n            obj,\n            key.endpoint_id,\n            session=self._session,\n        )\n    except requests.exceptions.RequestException as e:\n        assert e.response is not None\n        raise EndpointConnectorError(\n            f'Put failed with error code {e.response.status_code}.',\n        ) from e\n</code></pre>"},{"location":"api/connectors/file/","title":"proxystore.connectors.file","text":"<code>proxystore/connectors/file.py</code> <p>File system connector implementation.</p>"},{"location":"api/connectors/file/#proxystore.connectors.file.FileKey","title":"FileKey","text":"<p>             Bases: <code>NamedTuple</code></p> <p>Key to objects in a file system directory.</p> <p>Attributes:</p> <ul> <li> <code>filename</code>             (<code>str</code>)         \u2013          <p>Unique object filename.</p> </li> </ul>"},{"location":"api/connectors/file/#proxystore.connectors.file.FileConnector","title":"FileConnector","text":"<pre><code>FileConnector(store_dir: str, clear: bool = True)\n</code></pre> <p>Connector to shared file system.</p> <p>This connector writes objects to unique files within <code>store_dir</code>. Marker files are used to indicate that an object is finished being written to avoid race conditions.</p> <p>Parameters:</p> <ul> <li> <code>store_dir</code>             (<code>str</code>)         \u2013          <p>Path to directory to store data in. Note this directory will be deleted upon closing the store.</p> </li> <li> <code>clear</code>             (<code>bool</code>, default:                 <code>True</code> )         \u2013          <p>Clear all objects on <code>close()</code> by removing <code>store_dir</code>.</p> </li> </ul> Source code in <code>proxystore/connectors/file.py</code> <pre><code>def __init__(self, store_dir: str, clear: bool = True) -&gt; None:\n    self.store_dir = os.path.abspath(store_dir)\n    self.clear = clear\n\n    if not os.path.exists(self.store_dir):\n        os.makedirs(self.store_dir, exist_ok=True)\n</code></pre>"},{"location":"api/connectors/file/#proxystore.connectors.file.FileConnector.close","title":"close()","text":"<pre><code>close(clear: bool | None = None) -&gt; None\n</code></pre> <p>Close the connector and clean up.</p> Warning <p>This will delete the <code>store_dir</code> directory by default.</p> Warning <p>This method should only be called at the end of the program when the connector will no longer be used, for example once all proxies have been resolved.</p> <p>Parameters:</p> <ul> <li> <code>clear</code>             (<code>bool | None</code>, default:                 <code>None</code> )         \u2013          <p>Remove the store directory. Overrides the default value of <code>clear</code> provided when the <code>FileConnector</code> was instantiated.</p> </li> </ul> Source code in <code>proxystore/connectors/file.py</code> <pre><code>def close(self, clear: bool | None = None) -&gt; None:\n    \"\"\"Close the connector and clean up.\n\n    Warning:\n        This will delete the `store_dir` directory by default.\n\n    Warning:\n        This method should only be called at the end of the program\n        when the connector will no longer be used, for example once all\n        proxies have been resolved.\n\n    Args:\n        clear: Remove the store directory. Overrides the default\n            value of `clear` provided when the\n            [`FileConnector`][proxystore.connectors.file.FileConnector]\n            was instantiated.\n    \"\"\"\n    clear = self.clear if clear is None else clear\n    if clear and os.path.isdir(self.store_dir):\n        shutil.rmtree(self.store_dir, ignore_errors=True)\n</code></pre>"},{"location":"api/connectors/file/#proxystore.connectors.file.FileConnector.config","title":"config()","text":"<pre><code>config() -&gt; dict[str, Any]\n</code></pre> <p>Get the connector configuration.</p> <p>The configuration contains all the information needed to reconstruct the connector object.</p> Source code in <code>proxystore/connectors/file.py</code> <pre><code>def config(self) -&gt; dict[str, Any]:\n    \"\"\"Get the connector configuration.\n\n    The configuration contains all the information needed to reconstruct\n    the connector object.\n    \"\"\"\n    return {'store_dir': self.store_dir, 'clear': self.clear}\n</code></pre>"},{"location":"api/connectors/file/#proxystore.connectors.file.FileConnector.from_config","title":"from_config()  <code>classmethod</code>","text":"<pre><code>from_config(config: dict[str, Any]) -&gt; FileConnector\n</code></pre> <p>Create a new connector instance from a configuration.</p> <p>Parameters:</p> <ul> <li> <code>config</code>             (<code>dict[str, Any]</code>)         \u2013          <p>Configuration returned by <code>.config()</code>.</p> </li> </ul> Source code in <code>proxystore/connectors/file.py</code> <pre><code>@classmethod\ndef from_config(cls, config: dict[str, Any]) -&gt; FileConnector:\n    \"\"\"Create a new connector instance from a configuration.\n\n    Args:\n        config: Configuration returned by `#!python .config()`.\n    \"\"\"\n    return cls(**config)\n</code></pre>"},{"location":"api/connectors/file/#proxystore.connectors.file.FileConnector.evict","title":"evict()","text":"<pre><code>evict(key: FileKey) -&gt; None\n</code></pre> <p>Evict the object associated with the key.</p> <p>Parameters:</p> <ul> <li> <code>key</code>             (<code>FileKey</code>)         \u2013          <p>Key associated with object to evict.</p> </li> </ul> Source code in <code>proxystore/connectors/file.py</code> <pre><code>def evict(self, key: FileKey) -&gt; None:\n    \"\"\"Evict the object associated with the key.\n\n    Args:\n        key: Key associated with object to evict.\n    \"\"\"\n    path = os.path.join(self.store_dir, key.filename)\n    if os.path.exists(path):\n        os.remove(path)\n    marker = path + '.ready'\n    if os.path.exists(marker):\n        os.remove(marker)\n</code></pre>"},{"location":"api/connectors/file/#proxystore.connectors.file.FileConnector.exists","title":"exists()","text":"<pre><code>exists(key: FileKey) -&gt; bool\n</code></pre> <p>Check if an object associated with the key exists.</p> <p>Parameters:</p> <ul> <li> <code>key</code>             (<code>FileKey</code>)         \u2013          <p>Key potentially associated with stored object.</p> </li> </ul> <p>Returns:</p> <ul> <li> <code>bool</code>         \u2013          <p>If an object associated with the key exists.</p> </li> </ul> Source code in <code>proxystore/connectors/file.py</code> <pre><code>def exists(self, key: FileKey) -&gt; bool:\n    \"\"\"Check if an object associated with the key exists.\n\n    Args:\n        key: Key potentially associated with stored object.\n\n    Returns:\n        If an object associated with the key exists.\n    \"\"\"\n    path = os.path.join(self.store_dir, key.filename + '.ready')\n    return os.path.exists(path)\n</code></pre>"},{"location":"api/connectors/file/#proxystore.connectors.file.FileConnector.get","title":"get()","text":"<pre><code>get(key: FileKey) -&gt; bytes | None\n</code></pre> <p>Get the serialized object associated with the key.</p> <p>Parameters:</p> <ul> <li> <code>key</code>             (<code>FileKey</code>)         \u2013          <p>Key associated with the object to retrieve.</p> </li> </ul> <p>Returns:</p> <ul> <li> <code>bytes | None</code>         \u2013          <p>Serialized object or <code>None</code> if the object does not exist.</p> </li> </ul> Source code in <code>proxystore/connectors/file.py</code> <pre><code>def get(self, key: FileKey) -&gt; bytes | None:\n    \"\"\"Get the serialized object associated with the key.\n\n    Args:\n        key: Key associated with the object to retrieve.\n\n    Returns:\n        Serialized object or `None` if the object does not exist.\n    \"\"\"\n    path = os.path.join(self.store_dir, key.filename)\n    marker = path + '.ready'\n    if os.path.exists(marker):\n        with open(path, 'rb') as f:\n            data = f.read()\n            return data\n    return None\n</code></pre>"},{"location":"api/connectors/file/#proxystore.connectors.file.FileConnector.get_batch","title":"get_batch()","text":"<pre><code>get_batch(keys: Sequence[FileKey]) -&gt; list[bytes | None]\n</code></pre> <p>Get a batch of serialized objects associated with the keys.</p> <p>Parameters:</p> <ul> <li> <code>keys</code>             (<code>Sequence[FileKey]</code>)         \u2013          <p>Sequence of keys associated with objects to retrieve.</p> </li> </ul> <p>Returns:</p> <ul> <li> <code>list[bytes | None]</code>         \u2013          <p>List with same order as <code>keys</code> with the serialized objects or</p> </li> <li> <code>list[bytes | None]</code>         \u2013          <p><code>None</code> if the corresponding key does not have an associated object.</p> </li> </ul> Source code in <code>proxystore/connectors/file.py</code> <pre><code>def get_batch(self, keys: Sequence[FileKey]) -&gt; list[bytes | None]:\n    \"\"\"Get a batch of serialized objects associated with the keys.\n\n    Args:\n        keys: Sequence of keys associated with objects to retrieve.\n\n    Returns:\n        List with same order as `keys` with the serialized objects or\n        `None` if the corresponding key does not have an associated object.\n    \"\"\"\n    return [self.get(key) for key in keys]\n</code></pre>"},{"location":"api/connectors/file/#proxystore.connectors.file.FileConnector.new_key","title":"new_key()","text":"<pre><code>new_key(obj: bytes | None = None) -&gt; FileKey\n</code></pre> <p>Create a new key.</p> <p>Parameters:</p> <ul> <li> <code>obj</code>             (<code>bytes | None</code>, default:                 <code>None</code> )         \u2013          <p>Optional object which the key will be associated with. Ignored by this implementation.</p> </li> </ul> <p>Returns:</p> <ul> <li> <code>FileKey</code>         \u2013          <p>Key which can be used to retrieve an object once             <code>set()</code>             has been called on the key.</p> </li> </ul> Source code in <code>proxystore/connectors/file.py</code> <pre><code>def new_key(self, obj: bytes | None = None) -&gt; FileKey:\n    \"\"\"Create a new key.\n\n    Args:\n        obj: Optional object which the key will be associated with.\n            Ignored by this implementation.\n\n    Returns:\n        Key which can be used to retrieve an object once \\\n        [`set()`][proxystore.connectors.file.FileConnector.set] \\\n        has been called on the key.\n    \"\"\"\n    return FileKey(filename=str(uuid.uuid4()))\n</code></pre>"},{"location":"api/connectors/file/#proxystore.connectors.file.FileConnector.put","title":"put()","text":"<pre><code>put(obj: bytes) -&gt; FileKey\n</code></pre> <p>Put a serialized object in the store.</p> <p>Parameters:</p> <ul> <li> <code>obj</code>             (<code>bytes</code>)         \u2013          <p>Serialized object to put in the store.</p> </li> </ul> <p>Returns:</p> <ul> <li> <code>FileKey</code>         \u2013          <p>Key which can be used to retrieve the object.</p> </li> </ul> Source code in <code>proxystore/connectors/file.py</code> <pre><code>def put(self, obj: bytes) -&gt; FileKey:\n    \"\"\"Put a serialized object in the store.\n\n    Args:\n        obj: Serialized object to put in the store.\n\n    Returns:\n        Key which can be used to retrieve the object.\n    \"\"\"\n    key = FileKey(filename=str(uuid.uuid4()))\n    self.set(key, obj)\n    return key\n</code></pre>"},{"location":"api/connectors/file/#proxystore.connectors.file.FileConnector.put_batch","title":"put_batch()","text":"<pre><code>put_batch(objs: Sequence[bytes]) -&gt; list[FileKey]\n</code></pre> <p>Put a batch of serialized objects in the store.</p> <p>Parameters:</p> <ul> <li> <code>objs</code>             (<code>Sequence[bytes]</code>)         \u2013          <p>Sequence of serialized objects to put in the store.</p> </li> </ul> <p>Returns:</p> <ul> <li> <code>list[FileKey]</code>         \u2013          <p>List of keys with the same order as <code>objs</code> which can be used to</p> </li> <li> <code>list[FileKey]</code>         \u2013          <p>retrieve the objects.</p> </li> </ul> Source code in <code>proxystore/connectors/file.py</code> <pre><code>def put_batch(self, objs: Sequence[bytes]) -&gt; list[FileKey]:\n    \"\"\"Put a batch of serialized objects in the store.\n\n    Args:\n        objs: Sequence of serialized objects to put in the store.\n\n    Returns:\n        List of keys with the same order as `objs` which can be used to\n        retrieve the objects.\n    \"\"\"\n    return [self.put(obj) for obj in objs]\n</code></pre>"},{"location":"api/connectors/file/#proxystore.connectors.file.FileConnector.set","title":"set()","text":"<pre><code>set(key: FileKey, obj: bytes) -&gt; None\n</code></pre> <p>Set the object associated with a key.</p> Note <p>The <code>Connector</code> provides write-once, read-many semantics. Thus, <code>set()</code> should only be called once per key, otherwise unexpected behavior can occur.</p> <p>Parameters:</p> <ul> <li> <code>key</code>             (<code>FileKey</code>)         \u2013          <p>Key that the object will be associated with.</p> </li> <li> <code>obj</code>             (<code>bytes</code>)         \u2013          <p>Object to associate with the key.</p> </li> </ul> Source code in <code>proxystore/connectors/file.py</code> <pre><code>def set(self, key: FileKey, obj: bytes) -&gt; None:\n    \"\"\"Set the object associated with a key.\n\n    Note:\n        The [`Connector`][proxystore.connectors.protocols.Connector]\n        provides write-once, read-many semantics. Thus,\n        [`set()`][proxystore.connectors.file.FileConnector.set]\n        should only be called once per key, otherwise unexpected behavior\n        can occur.\n\n    Args:\n        key: Key that the object will be associated with.\n        obj: Object to associate with the key.\n    \"\"\"\n    path = os.path.join(self.store_dir, key.filename)\n    with open(path, 'wb', buffering=0) as f:\n        f.write(obj)\n    marker = path + '.ready'\n    open(marker, 'wb').close()\n</code></pre>"},{"location":"api/connectors/globus/","title":"proxystore.connectors.globus","text":"<code>proxystore/connectors/globus.py</code> <p>Globus transfer connector implementation.</p>"},{"location":"api/connectors/globus/#proxystore.connectors.globus.GlobusEndpoint","title":"GlobusEndpoint","text":"<pre><code>GlobusEndpoint(\n    uuid: str,\n    endpoint_path: str,\n    local_path: str | None,\n    host_regex: str | Pattern[str],\n)\n</code></pre> <p>Globus endpoint representation.</p> <p>Parameters:</p> <ul> <li> <code>uuid</code>             (<code>str</code>)         \u2013          <p>UUID of Globus endpoint.</p> </li> <li> <code>endpoint_path</code>             (<code>str</code>)         \u2013          <p>Path within endpoint to directory to use for storing objects.</p> </li> <li> <code>local_path</code>             (<code>str | None</code>)         \u2013          <p>Local path (as seen by the host filesystem) that corresponds to the directory specified by <code>endpoint_path</code>.</p> </li> <li> <code>host_regex</code>             (<code>str | Pattern[str]</code>)         \u2013          <p>String that matches the host where the Globus endpoint exists or regex pattern than can be used to match the host. The host pattern is needed so that proxies can figure out what the local endpoint is when they are resolved.</p> </li> </ul> Source code in <code>proxystore/connectors/globus.py</code> <pre><code>def __init__(\n    self,\n    uuid: str,\n    endpoint_path: str,\n    local_path: str | None,\n    host_regex: str | Pattern[str],\n) -&gt; None:\n    if not isinstance(uuid, str):\n        raise TypeError('uuid must be a str.')\n    if not isinstance(endpoint_path, str):\n        raise TypeError('endpoint_path must be a str.')\n    if not isinstance(local_path, str):\n        raise TypeError('local_path must be a str.')\n    if not isinstance(host_regex, (str, Pattern)):\n        raise TypeError('host_regex must be a str or re.Pattern.')\n\n    self.uuid = uuid\n    self.endpoint_path = endpoint_path\n    self.local_path = local_path\n    self.host_regex = host_regex\n</code></pre>"},{"location":"api/connectors/globus/#proxystore.connectors.globus.GlobusEndpoints","title":"GlobusEndpoints","text":"<pre><code>GlobusEndpoints(endpoints: Collection[GlobusEndpoint])\n</code></pre> <p>A collection of Globus endpoints.</p> <p>Parameters:</p> <ul> <li> <code>endpoints</code>             (<code>Collection[GlobusEndpoint]</code>)         \u2013          <p>Iterable of <code>GlobusEndpoints</code> instances.</p> </li> </ul> <p>Raises:</p> <ul> <li> <code>ValueError</code>           \u2013          <p>If <code>endpoints</code> has length 0 or if multiple endpoints with             the same UUID are provided.</p> </li> </ul> Source code in <code>proxystore/connectors/globus.py</code> <pre><code>def __init__(self, endpoints: Collection[GlobusEndpoint]) -&gt; None:\n    if len(endpoints) == 0:\n        raise ValueError(\n            'GlobusEndpoints must be passed at least one GlobusEndpoint '\n            'object',\n        )\n    self._endpoints: dict[str, GlobusEndpoint] = {}\n    for endpoint in endpoints:\n        if endpoint.uuid in self._endpoints:\n            raise ValueError(\n                'Cannot pass multiple GlobusEndpoint objects with the '\n                'same Globus endpoint UUID.',\n            )\n        self._endpoints[endpoint.uuid] = endpoint\n</code></pre>"},{"location":"api/connectors/globus/#proxystore.connectors.globus.GlobusEndpoints.from_dict","title":"from_dict()  <code>classmethod</code>","text":"<pre><code>from_dict(\n    json_object: dict[str, dict[str, str]]\n) -&gt; GlobusEndpoints\n</code></pre> <p>Construct an endpoints collection from a dictionary.</p> <p>Example:</p> <pre><code>```python\n{\n  \"endpoint-uuid-1\": {\n    \"host_regex\": \"host1-regex\",\n    \"endpoint_path\": \"/path/to/endpoint/dir\",\n    \"local_path\": \"/path/to/local/dir\"\n  },\n  \"endpoint-uuid-2\": {\n    \"host_regex\": \"host2-regex\",\n    \"endpoint_path\": \"/path/to/endpoint/dir\",\n    \"local_path\": \"/path/to/local/dir\"\n  }\n}\n```\n</code></pre> Source code in <code>proxystore/connectors/globus.py</code> <pre><code>@classmethod\ndef from_dict(\n    cls: type[GlobusEndpoints],\n    json_object: dict[str, dict[str, str]],\n) -&gt; GlobusEndpoints:\n    \"\"\"Construct an endpoints collection from a dictionary.\n\n    Example:\n\n        ```python\n        {\n          \"endpoint-uuid-1\": {\n            \"host_regex\": \"host1-regex\",\n            \"endpoint_path\": \"/path/to/endpoint/dir\",\n            \"local_path\": \"/path/to/local/dir\"\n          },\n          \"endpoint-uuid-2\": {\n            \"host_regex\": \"host2-regex\",\n            \"endpoint_path\": \"/path/to/endpoint/dir\",\n            \"local_path\": \"/path/to/local/dir\"\n          }\n        }\n        ```\n    \"\"\"  # noqa: D412\n    endpoints = []\n    for ep_uuid, params in json_object.items():\n        endpoints.append(\n            GlobusEndpoint(\n                uuid=ep_uuid,\n                endpoint_path=params['endpoint_path'],\n                local_path=params['local_path'],\n                host_regex=params['host_regex'],\n            ),\n        )\n    return GlobusEndpoints(endpoints)\n</code></pre>"},{"location":"api/connectors/globus/#proxystore.connectors.globus.GlobusEndpoints.from_json","title":"from_json()  <code>classmethod</code>","text":"<pre><code>from_json(json_file: str) -&gt; GlobusEndpoints\n</code></pre> <p>Construct a GlobusEndpoints object from a json file.</p> <p>The <code>dict</code> read from the JSON file will be passed to <code>from_dict()</code> and should match the format expected by <code>from_dict()</code>.</p> Source code in <code>proxystore/connectors/globus.py</code> <pre><code>@classmethod\ndef from_json(cls, json_file: str) -&gt; GlobusEndpoints:\n    \"\"\"Construct a GlobusEndpoints object from a json file.\n\n    The `dict` read from the JSON file will be passed to\n    [`from_dict()`][proxystore.connectors.globus.GlobusEndpoints.from_dict]\n    and should match the format expected by\n    [`from_dict()`][proxystore.connectors.globus.GlobusEndpoints.from_dict].\n    \"\"\"\n    with open(json_file) as f:\n        data = f.read()\n    return cls.from_dict(json.loads(data))\n</code></pre>"},{"location":"api/connectors/globus/#proxystore.connectors.globus.GlobusEndpoints.dict","title":"dict()","text":"<pre><code>dict() -&gt; dict[str, dict[str, str]]\n</code></pre> <p>Convert the GlobusEndpoints to a dict.</p> <p>Note that the <code>GlobusEndpoints</code> object can be reconstructed by passing the <code>dict</code> to. <code>from_dict()</code>.</p> Source code in <code>proxystore/connectors/globus.py</code> <pre><code>def dict(self) -&gt; dict[str, dict[str, str]]:\n    \"\"\"Convert the GlobusEndpoints to a dict.\n\n    Note that the\n    [`GlobusEndpoints`][proxystore.connectors.globus.GlobusEndpoints]\n    object can be reconstructed by passing the `dict` to.\n    [`from_dict()`][proxystore.connectors.globus.GlobusEndpoints.from_dict].\n    \"\"\"\n    data = {}\n    for endpoint in self:\n        data[endpoint.uuid] = {\n            'endpoint_path': endpoint.endpoint_path,\n            'local_path': endpoint.local_path,\n            'host_regex': endpoint.host_regex.pattern\n            if isinstance(endpoint.host_regex, Pattern)\n            else endpoint.host_regex,\n        }\n    return data\n</code></pre>"},{"location":"api/connectors/globus/#proxystore.connectors.globus.GlobusEndpoints.get_by_host","title":"get_by_host()","text":"<pre><code>get_by_host(host: str) -&gt; GlobusEndpoint\n</code></pre> <p>Get endpoint by host.</p> <p>Searches the endpoints for a endpoint who's <code>host_regex</code> matches <code>host</code>.</p> <p>Parameters:</p> <ul> <li> <code>host</code>             (<code>str</code>)         \u2013          <p>Host to match.</p> </li> </ul> <p>Returns:</p> <ul> <li> <code>GlobusEndpoint</code>         \u2013          <p>Globus endpoint.</p> </li> </ul> <p>Raises:</p> <ul> <li> <code>ValueError</code>           \u2013          <p>If <code>host</code> does not match any of the endpoints.</p> </li> </ul> Source code in <code>proxystore/connectors/globus.py</code> <pre><code>def get_by_host(self, host: str) -&gt; GlobusEndpoint:\n    \"\"\"Get endpoint by host.\n\n    Searches the endpoints for a endpoint who's `host_regex` matches\n    `host`.\n\n    Args:\n        host: Host to match.\n\n    Returns:\n        Globus endpoint.\n\n    Raises:\n        ValueError: If `host` does not match any of the endpoints.\n    \"\"\"\n    for endpoint in self._endpoints.values():\n        if re.fullmatch(endpoint.host_regex, host) is not None:\n            return endpoint\n    raise ValueError(f'Cannot find endpoint matching host {host}')\n</code></pre>"},{"location":"api/connectors/globus/#proxystore.connectors.globus.GlobusKey","title":"GlobusKey","text":"<p>             Bases: <code>NamedTuple</code></p> <p>Key to object transferred with Globus.</p> <p>Attributes:</p> <ul> <li> <code>filename</code>             (<code>str</code>)         \u2013          <p>Unique object filename.</p> </li> <li> <code>task_id</code>             (<code>str | tuple[str, ...]</code>)         \u2013          <p>Globus transfer task IDs for the file.</p> </li> </ul>"},{"location":"api/connectors/globus/#proxystore.connectors.globus.GlobusKey.__eq__","title":"__eq__()","text":"<pre><code>__eq__(other: Any) -&gt; bool\n</code></pre> <p>Match keys by filename only.</p> <p>This is a hack around the fact that the task_id is not created until after the filename is so there can be a state where the task_id is empty.</p> Source code in <code>proxystore/connectors/globus.py</code> <pre><code>def __eq__(self, other: Any) -&gt; bool:\n    \"\"\"Match keys by filename only.\n\n    This is a hack around the fact that the task_id is not created until\n    after the filename is so there can be a state where the task_id\n    is empty.\n    \"\"\"\n    if isinstance(other, tuple):\n        return self[0] == other[0]\n    return False\n</code></pre>"},{"location":"api/connectors/globus/#proxystore.connectors.globus.GlobusConnector","title":"GlobusConnector","text":"<pre><code>GlobusConnector(\n    endpoints: (\n        GlobusEndpoints\n        | list[GlobusEndpoint]\n        | dict[str, dict[str, str]]\n    ),\n    polling_interval: int = 1,\n    sync_level: (\n        int | Literal[\"exists\", \"size\", \"mtime\", \"checksum\"]\n    ) = \"mtime\",\n    timeout: int = 60,\n    clear: bool = True,\n)\n</code></pre> <p>Globus transfer connector.</p> <p>The <code>GlobusConnector</code> is similar to a <code>FileConnector</code> in that objects are saved to disk but allows for the transfer of objects between two remote file systems. The two directories on the separate file systems are kept in sync via Globus transfers. The <code>GlobusConnector</code> is useful when moving data between hosts that have a Globus endpoint but may have restrictions that prevent the use of other store backends (e.g., ports cannot be opened for using a <code>RedisConnector</code>.</p> Note <p>To use Globus for data transfer, Globus authentication needs to be performed with the <code>proxystore-globus-auth</code> CLI. If authentication is not performed before initializing a <code>GlobusConnector</code>, the program will prompt the user to perform authentication. This can result in unexpected program hangs while the constructor waits on the user to authenticate. Authentication only needs to be performed once per system</p> <p>Parameters:</p> <ul> <li> <code>endpoints</code>             (<code>GlobusEndpoints | list[GlobusEndpoint] | dict[str, dict[str, str]]</code>)         \u2013          <p>Globus endpoints to keep in sync. If passed as a <code>dict</code>, the dictionary must match the format expected by <code>GlobusEndpoints.from_dict()</code>. Note that given <code>n</code> endpoints there will be <code>n-1</code> Globus transfers per operation, so we suggest not using too many endpoints at the same time.</p> </li> <li> <code>polling_interval</code>             (<code>int</code>, default:                 <code>1</code> )         \u2013          <p>Interval in seconds to check if Globus tasks have finished.</p> </li> <li> <code>sync_level</code>             (<code>int | Literal['exists', 'size', 'mtime', 'checksum']</code>, default:                 <code>'mtime'</code> )         \u2013          <p>Globus transfer sync level.</p> </li> <li> <code>timeout</code>             (<code>int</code>, default:                 <code>60</code> )         \u2013          <p>Timeout in seconds for waiting on Globus tasks.</p> </li> <li> <code>clear</code>             (<code>bool</code>, default:                 <code>True</code> )         \u2013          <p>Clear all objects on <code>close()</code> by deleting the <code>local_path</code> of each endpoint.</p> </li> </ul> <p>Raises:</p> <ul> <li> <code>GlobusAuthFileError</code>           \u2013          <p>If the Globus authentication file cannot be found.</p> </li> <li> <code>ValueError</code>           \u2013          <p>If <code>endpoints</code> is of an incorrect type.</p> </li> <li> <code>ValueError</code>           \u2013          <p>If fewer than two endpoints are provided.</p> </li> </ul> Source code in <code>proxystore/connectors/globus.py</code> <pre><code>def __init__(\n    self,\n    endpoints: GlobusEndpoints\n    | list[GlobusEndpoint]\n    | dict[str, dict[str, str]],\n    polling_interval: int = 1,\n    sync_level: int\n    | Literal['exists', 'size', 'mtime', 'checksum'] = 'mtime',\n    timeout: int = 60,\n    clear: bool = True,\n) -&gt; None:\n    if isinstance(endpoints, GlobusEndpoints):\n        self.endpoints = endpoints\n    elif isinstance(endpoints, list):\n        self.endpoints = GlobusEndpoints(endpoints)\n    elif isinstance(endpoints, dict):\n        self.endpoints = GlobusEndpoints.from_dict(endpoints)\n    else:\n        raise ValueError(\n            'endpoints must be of type GlobusEndpoints or a list of '\n            f'GlobusEndpoint. Got {type(endpoints)}.',\n        )\n    if len(endpoints) &lt; 2:\n        raise ValueError('At least two Globus endpoints are required.')\n    self.polling_interval = polling_interval\n    self.sync_level = sync_level\n    self.timeout = timeout\n    self.clear = clear\n\n    self._transfer_client = get_transfer_client_flow(\n        check_collections=[ep.uuid for ep in self.endpoints],\n    )\n</code></pre>"},{"location":"api/connectors/globus/#proxystore.connectors.globus.GlobusConnector.close","title":"close()","text":"<pre><code>close(clear: bool | None = None) -&gt; None\n</code></pre> <p>Close the connector and clean up.</p> Warning <p>This will delete the directory at <code>local_path</code> on each endpoint by default.</p> Warning <p>This method should only be called at the end of the program when the store will no longer be used, for example once all proxies have been resolved.</p> <p>Parameters:</p> <ul> <li> <code>clear</code>             (<code>bool | None</code>, default:                 <code>None</code> )         \u2013          <p>Remove the store directory. Overrides the default value of <code>clear</code> provided when the <code>GlobusConnector</code> was instantiated.</p> </li> </ul> Source code in <code>proxystore/connectors/globus.py</code> <pre><code>def close(self, clear: bool | None = None) -&gt; None:\n    \"\"\"Close the connector and clean up.\n\n    Warning:\n        This will delete the directory at `local_path` on each endpoint\n        by default.\n\n    Warning:\n        This method should only be called at the end of the program when\n        the store will no longer be used, for example once all proxies\n        have been resolved.\n\n    Args:\n        clear: Remove the store directory. Overrides the default\n            value of `clear` provided when the\n            [`GlobusConnector`][proxystore.connectors.globus.GlobusConnector]\n            was instantiated.\n    \"\"\"\n    clear = self.clear if clear is None else clear\n    if clear:\n        for endpoint in self.endpoints:\n            delete_task = globus_sdk.DeleteData(\n                self._transfer_client,\n                endpoint=endpoint.uuid,\n                recursive=True,\n            )\n            delete_task['notify_on_succeeded'] = False\n            delete_task['notify_on_failed'] = False\n            delete_task['notify_on_inactive'] = False\n            delete_task.add_item(endpoint.endpoint_path)\n            tdata = _submit_transfer_action(\n                self._transfer_client,\n                delete_task,\n            )\n            self._wait_on_tasks(tdata['task_id'])\n</code></pre>"},{"location":"api/connectors/globus/#proxystore.connectors.globus.GlobusConnector.config","title":"config()","text":"<pre><code>config() -&gt; dict[str, Any]\n</code></pre> <p>Get the connector configuration.</p> <p>The configuration contains all the information needed to reconstruct the connector object.</p> Source code in <code>proxystore/connectors/globus.py</code> <pre><code>def config(self) -&gt; dict[str, Any]:\n    \"\"\"Get the connector configuration.\n\n    The configuration contains all the information needed to reconstruct\n    the connector object.\n    \"\"\"\n    return {\n        'endpoints': self.endpoints.dict(),\n        'polling_interval': self.polling_interval,\n        'sync_level': self.sync_level,\n        'timeout': self.timeout,\n        'clear': self.clear,\n    }\n</code></pre>"},{"location":"api/connectors/globus/#proxystore.connectors.globus.GlobusConnector.from_config","title":"from_config()  <code>classmethod</code>","text":"<pre><code>from_config(config: dict[str, Any]) -&gt; GlobusConnector\n</code></pre> <p>Create a new connector instance from a configuration.</p> <p>Parameters:</p> <ul> <li> <code>config</code>             (<code>dict[str, Any]</code>)         \u2013          <p>Configuration returned by <code>.config()</code>.</p> </li> </ul> Source code in <code>proxystore/connectors/globus.py</code> <pre><code>@classmethod\ndef from_config(cls, config: dict[str, Any]) -&gt; GlobusConnector:\n    \"\"\"Create a new connector instance from a configuration.\n\n    Args:\n        config: Configuration returned by `#!python .config()`.\n    \"\"\"\n    return cls(**config)\n</code></pre>"},{"location":"api/connectors/globus/#proxystore.connectors.globus.GlobusConnector.evict","title":"evict()","text":"<pre><code>evict(key: GlobusKey) -&gt; None\n</code></pre> <p>Evict the object associated with the key.</p> <p>Parameters:</p> <ul> <li> <code>key</code>             (<code>GlobusKey</code>)         \u2013          <p>Key associated with object to evict.</p> </li> </ul> Source code in <code>proxystore/connectors/globus.py</code> <pre><code>def evict(self, key: GlobusKey) -&gt; None:\n    \"\"\"Evict the object associated with the key.\n\n    Args:\n        key: Key associated with object to evict.\n    \"\"\"\n    if not self.exists(key):\n        return\n\n    path = self._get_filepath(key.filename)\n    os.remove(path)\n    self._transfer_files(key.filename, delete=True)\n</code></pre>"},{"location":"api/connectors/globus/#proxystore.connectors.globus.GlobusConnector.exists","title":"exists()","text":"<pre><code>exists(key: GlobusKey) -&gt; bool\n</code></pre> <p>Check if an object associated with the key exists.</p> Note <p>If the corresponding Globus transfer is still in progress, this method will wait to make sure the transfers is successful.</p> <p>Parameters:</p> <ul> <li> <code>key</code>             (<code>GlobusKey</code>)         \u2013          <p>Key potentially associated with stored object.</p> </li> </ul> <p>Returns:</p> <ul> <li> <code>bool</code>         \u2013          <p>If an object associated with the key exists.</p> </li> </ul> Source code in <code>proxystore/connectors/globus.py</code> <pre><code>def exists(self, key: GlobusKey) -&gt; bool:\n    \"\"\"Check if an object associated with the key exists.\n\n    Note:\n        If the corresponding Globus transfer is still in progress, this\n        method will wait to make sure the transfers is successful.\n\n    Args:\n        key: Key potentially associated with stored object.\n\n    Returns:\n        If an object associated with the key exists.\n    \"\"\"\n    if not self._validate_task_id(key.task_id):\n        return False\n    self._wait_on_tasks(key.task_id)\n    return os.path.exists(self._get_filepath(key.filename))\n</code></pre>"},{"location":"api/connectors/globus/#proxystore.connectors.globus.GlobusConnector.get","title":"get()","text":"<pre><code>get(key: GlobusKey) -&gt; bytes | None\n</code></pre> <p>Get the serialized object associated with the key.</p> <p>Parameters:</p> <ul> <li> <code>key</code>             (<code>GlobusKey</code>)         \u2013          <p>Key associated with the object to retrieve.</p> </li> </ul> <p>Returns:</p> <ul> <li> <code>bytes | None</code>         \u2013          <p>Serialized object or <code>None</code> if the object does not exist.</p> </li> </ul> Source code in <code>proxystore/connectors/globus.py</code> <pre><code>def get(self, key: GlobusKey) -&gt; bytes | None:\n    \"\"\"Get the serialized object associated with the key.\n\n    Args:\n        key: Key associated with the object to retrieve.\n\n    Returns:\n        Serialized object or `None` if the object does not exist.\n    \"\"\"\n    if not self.exists(key):\n        return None\n\n    path = self._get_filepath(key.filename)\n    with open(path, 'rb') as f:\n        return f.read()\n</code></pre>"},{"location":"api/connectors/globus/#proxystore.connectors.globus.GlobusConnector.get_batch","title":"get_batch()","text":"<pre><code>get_batch(keys: Sequence[GlobusKey]) -&gt; list[bytes | None]\n</code></pre> <p>Get a batch of serialized objects associated with the keys.</p> <p>Parameters:</p> <ul> <li> <code>keys</code>             (<code>Sequence[GlobusKey]</code>)         \u2013          <p>Sequence of keys associated with objects to retrieve.</p> </li> </ul> <p>Returns:</p> <ul> <li> <code>list[bytes | None]</code>         \u2013          <p>List with same order as <code>keys</code> with the serialized objects or             <code>None</code> if the corresponding key does not have an associated object.</p> </li> </ul> Source code in <code>proxystore/connectors/globus.py</code> <pre><code>def get_batch(self, keys: Sequence[GlobusKey]) -&gt; list[bytes | None]:\n    \"\"\"Get a batch of serialized objects associated with the keys.\n\n    Args:\n        keys: Sequence of keys associated with objects to retrieve.\n\n    Returns:\n        List with same order as `keys` with the serialized objects or \\\n        `None` if the corresponding key does not have an associated object.\n    \"\"\"\n    return [self.get(key) for key in keys]\n</code></pre>"},{"location":"api/connectors/globus/#proxystore.connectors.globus.GlobusConnector.put","title":"put()","text":"<pre><code>put(obj: bytes) -&gt; GlobusKey\n</code></pre> <p>Put a serialized object in the store.</p> <p>Parameters:</p> <ul> <li> <code>obj</code>             (<code>bytes</code>)         \u2013          <p>Serialized object to put in the store.</p> </li> </ul> <p>Returns:</p> <ul> <li> <code>GlobusKey</code>         \u2013          <p>Key which can be used to retrieve the object.</p> </li> </ul> Source code in <code>proxystore/connectors/globus.py</code> <pre><code>def put(self, obj: bytes) -&gt; GlobusKey:\n    \"\"\"Put a serialized object in the store.\n\n    Args:\n        obj: Serialized object to put in the store.\n\n    Returns:\n        Key which can be used to retrieve the object.\n    \"\"\"\n    filename = str(uuid.uuid4())\n\n    path = self._get_filepath(filename)\n    os.makedirs(os.path.dirname(path), exist_ok=True)\n\n    with open(path, 'wb', buffering=0) as f:\n        f.write(obj)\n\n    tids = self._transfer_files(filename)\n\n    return GlobusKey(filename=filename, task_id=tids)\n</code></pre>"},{"location":"api/connectors/globus/#proxystore.connectors.globus.GlobusConnector.put_batch","title":"put_batch()","text":"<pre><code>put_batch(objs: Sequence[bytes]) -&gt; list[GlobusKey]\n</code></pre> <p>Put a batch of serialized objects in the store.</p> <p>Parameters:</p> <ul> <li> <code>objs</code>             (<code>Sequence[bytes]</code>)         \u2013          <p>Sequence of serialized objects to put in the store.</p> </li> </ul> <p>Returns:</p> <ul> <li> <code>list[GlobusKey]</code>         \u2013          <p>List of keys with the same order as <code>objs</code> which can be used to             retrieve the objects.</p> </li> </ul> Source code in <code>proxystore/connectors/globus.py</code> <pre><code>def put_batch(self, objs: Sequence[bytes]) -&gt; list[GlobusKey]:\n    \"\"\"Put a batch of serialized objects in the store.\n\n    Args:\n        objs: Sequence of serialized objects to put in the store.\n\n    Returns:\n        List of keys with the same order as `objs` which can be used to \\\n        retrieve the objects.\n    \"\"\"\n    filenames = [str(uuid.uuid4()) for _ in objs]\n\n    for filename, obj in zip(filenames, objs):\n        path = self._get_filepath(filename)\n        os.makedirs(os.path.dirname(path), exist_ok=True)\n\n        with open(path, 'wb', buffering=0) as f:\n            f.write(obj)\n\n    tids = self._transfer_files(filenames)\n\n    return [\n        GlobusKey(filename=filename, task_id=tids)\n        for filename in filenames\n    ]\n</code></pre>"},{"location":"api/connectors/local/","title":"proxystore.connectors.local","text":"<code>proxystore/connectors/local.py</code> <p>In-process local storage connector implementation.</p>"},{"location":"api/connectors/local/#proxystore.connectors.local.LocalKey","title":"LocalKey","text":"<p>             Bases: <code>NamedTuple</code></p> <p>Key to objects store in a <code>LocalConnector</code>.</p> <p>Attributes:</p> <ul> <li> <code>id</code>             (<code>str</code>)         \u2013          <p>Unique object ID.</p> </li> </ul>"},{"location":"api/connectors/local/#proxystore.connectors.local.LocalConnector","title":"LocalConnector","text":"<pre><code>LocalConnector(\n    store_dict: dict[LocalKey, bytes] | None = None,\n    *,\n    include_data_in_config: bool = False\n)\n</code></pre> <p>Connector that store objects in the local process's memory.</p> Warning <p>This connector exists primarily for testing purposes.</p> <p>Parameters:</p> <ul> <li> <code>store_dict</code>             (<code>dict[LocalKey, bytes] | None</code>, default:                 <code>None</code> )         \u2013          <p>Dictionary to store data in. If not specified, a new empty dict will be generated.</p> </li> <li> <code>include_data_in_config</code>             (<code>bool</code>, default:                 <code>False</code> )         \u2013          <p>Include the data in the connector in the connector's state. This is very innefficient and only useful for testing.</p> </li> </ul> Source code in <code>proxystore/connectors/local.py</code> <pre><code>def __init__(\n    self,\n    store_dict: dict[LocalKey, bytes] | None = None,\n    *,\n    include_data_in_config: bool = False,\n) -&gt; None:\n    self._store: dict[LocalKey, bytes] = (\n        {} if store_dict is None else store_dict\n    )\n    self._include_data_in_config = include_data_in_config\n</code></pre>"},{"location":"api/connectors/local/#proxystore.connectors.local.LocalConnector.close","title":"close()","text":"<pre><code>close() -&gt; None\n</code></pre> <p>Close the connector and clean up.</p> Source code in <code>proxystore/connectors/local.py</code> <pre><code>def close(self) -&gt; None:\n    \"\"\"Close the connector and clean up.\"\"\"\n    pass\n</code></pre>"},{"location":"api/connectors/local/#proxystore.connectors.local.LocalConnector.config","title":"config()","text":"<pre><code>config() -&gt; dict[str, Any]\n</code></pre> <p>Get the connector configuration.</p> <p>The configuration contains all the information needed to reconstruct the connector object.</p> Source code in <code>proxystore/connectors/local.py</code> <pre><code>def config(self) -&gt; dict[str, Any]:\n    \"\"\"Get the connector configuration.\n\n    The configuration contains all the information needed to reconstruct\n    the connector object.\n    \"\"\"\n    config: dict[str, Any] = {\n        'include_data_in_config': self._include_data_in_config,\n    }\n    if self._include_data_in_config:\n        config['store_dict'] = self._store\n    return config\n</code></pre>"},{"location":"api/connectors/local/#proxystore.connectors.local.LocalConnector.from_config","title":"from_config()  <code>classmethod</code>","text":"<pre><code>from_config(config: dict[str, Any]) -&gt; LocalConnector\n</code></pre> <p>Create a new connector instance from a configuration.</p> <p>Parameters:</p> <ul> <li> <code>config</code>             (<code>dict[str, Any]</code>)         \u2013          <p>Configuration returned by <code>.config()</code>.</p> </li> </ul> Source code in <code>proxystore/connectors/local.py</code> <pre><code>@classmethod\ndef from_config(cls, config: dict[str, Any]) -&gt; LocalConnector:\n    \"\"\"Create a new connector instance from a configuration.\n\n    Args:\n        config: Configuration returned by `#!python .config()`.\n    \"\"\"\n    return cls(**config)\n</code></pre>"},{"location":"api/connectors/local/#proxystore.connectors.local.LocalConnector.evict","title":"evict()","text":"<pre><code>evict(key: LocalKey) -&gt; None\n</code></pre> <p>Evict the object associated with the key.</p> <p>Parameters:</p> <ul> <li> <code>key</code>             (<code>LocalKey</code>)         \u2013          <p>Key associated with object to evict.</p> </li> </ul> Source code in <code>proxystore/connectors/local.py</code> <pre><code>def evict(self, key: LocalKey) -&gt; None:\n    \"\"\"Evict the object associated with the key.\n\n    Args:\n        key: Key associated with object to evict.\n    \"\"\"\n    if key in self._store:\n        del self._store[key]\n</code></pre>"},{"location":"api/connectors/local/#proxystore.connectors.local.LocalConnector.exists","title":"exists()","text":"<pre><code>exists(key: LocalKey) -&gt; bool\n</code></pre> <p>Check if an object associated with the key exists.</p> <p>Parameters:</p> <ul> <li> <code>key</code>             (<code>LocalKey</code>)         \u2013          <p>Key potentially associated with stored object.</p> </li> </ul> <p>Returns:</p> <ul> <li> <code>bool</code>         \u2013          <p>If an object associated with the key exists.</p> </li> </ul> Source code in <code>proxystore/connectors/local.py</code> <pre><code>def exists(self, key: LocalKey) -&gt; bool:\n    \"\"\"Check if an object associated with the key exists.\n\n    Args:\n        key: Key potentially associated with stored object.\n\n    Returns:\n        If an object associated with the key exists.\n    \"\"\"\n    return key in self._store\n</code></pre>"},{"location":"api/connectors/local/#proxystore.connectors.local.LocalConnector.get","title":"get()","text":"<pre><code>get(key: LocalKey) -&gt; bytes | None\n</code></pre> <p>Get the serialized object associated with the key.</p> <p>Parameters:</p> <ul> <li> <code>key</code>             (<code>LocalKey</code>)         \u2013          <p>Key associated with the object to retrieve.</p> </li> </ul> <p>Returns:</p> <ul> <li> <code>bytes | None</code>         \u2013          <p>Serialized object or <code>None</code> if the object does not exist.</p> </li> </ul> Source code in <code>proxystore/connectors/local.py</code> <pre><code>def get(self, key: LocalKey) -&gt; bytes | None:\n    \"\"\"Get the serialized object associated with the key.\n\n    Args:\n        key: Key associated with the object to retrieve.\n\n    Returns:\n        Serialized object or `None` if the object does not exist.\n    \"\"\"\n    return self._store.get(key, None)\n</code></pre>"},{"location":"api/connectors/local/#proxystore.connectors.local.LocalConnector.get_batch","title":"get_batch()","text":"<pre><code>get_batch(keys: Sequence[LocalKey]) -&gt; list[bytes | None]\n</code></pre> <p>Get a batch of serialized objects associated with the keys.</p> <p>Parameters:</p> <ul> <li> <code>keys</code>             (<code>Sequence[LocalKey]</code>)         \u2013          <p>Sequence of keys associated with objects to retrieve.</p> </li> </ul> <p>Returns:</p> <ul> <li> <code>list[bytes | None]</code>         \u2013          <p>List with same order as <code>keys</code> with the serialized objects or             <code>None</code> if the corresponding key does not have an associated object.</p> </li> </ul> Source code in <code>proxystore/connectors/local.py</code> <pre><code>def get_batch(self, keys: Sequence[LocalKey]) -&gt; list[bytes | None]:\n    \"\"\"Get a batch of serialized objects associated with the keys.\n\n    Args:\n        keys: Sequence of keys associated with objects to retrieve.\n\n    Returns:\n        List with same order as `keys` with the serialized objects or \\\n        `None` if the corresponding key does not have an associated object.\n    \"\"\"\n    return [self.get(key) for key in keys]\n</code></pre>"},{"location":"api/connectors/local/#proxystore.connectors.local.LocalConnector.new_key","title":"new_key()","text":"<pre><code>new_key(obj: bytes | None = None) -&gt; LocalKey\n</code></pre> <p>Create a new key.</p> <p>Parameters:</p> <ul> <li> <code>obj</code>             (<code>bytes | None</code>, default:                 <code>None</code> )         \u2013          <p>Optional object which the key will be associated with. Ignored in this implementation.</p> </li> </ul> <p>Returns:</p> <ul> <li> <code>LocalKey</code>         \u2013          <p>Key which can be used to retrieve an object once             <code>set()</code>             has been called on the key.</p> </li> </ul> Source code in <code>proxystore/connectors/local.py</code> <pre><code>def new_key(self, obj: bytes | None = None) -&gt; LocalKey:\n    \"\"\"Create a new key.\n\n    Args:\n        obj: Optional object which the key will be associated with.\n            Ignored in this implementation.\n\n    Returns:\n        Key which can be used to retrieve an object once \\\n        [`set()`][proxystore.connectors.local.LocalConnector.set] \\\n        has been called on the key.\n    \"\"\"\n    return LocalKey(str(uuid.uuid4()))\n</code></pre>"},{"location":"api/connectors/local/#proxystore.connectors.local.LocalConnector.put","title":"put()","text":"<pre><code>put(obj: bytes) -&gt; LocalKey\n</code></pre> <p>Put a serialized object in the store.</p> <p>Parameters:</p> <ul> <li> <code>obj</code>             (<code>bytes</code>)         \u2013          <p>Serialized object to put in the store.</p> </li> </ul> <p>Returns:</p> <ul> <li> <code>LocalKey</code>         \u2013          <p>Key which can be used to retrieve the object.</p> </li> </ul> Source code in <code>proxystore/connectors/local.py</code> <pre><code>def put(self, obj: bytes) -&gt; LocalKey:\n    \"\"\"Put a serialized object in the store.\n\n    Args:\n        obj: Serialized object to put in the store.\n\n    Returns:\n        Key which can be used to retrieve the object.\n    \"\"\"\n    key = LocalKey(str(uuid.uuid4()))\n    self._store[key] = obj\n    return key\n</code></pre>"},{"location":"api/connectors/local/#proxystore.connectors.local.LocalConnector.put_batch","title":"put_batch()","text":"<pre><code>put_batch(objs: Sequence[bytes]) -&gt; list[LocalKey]\n</code></pre> <p>Put a batch of serialized objects in the store.</p> <p>Parameters:</p> <ul> <li> <code>objs</code>             (<code>Sequence[bytes]</code>)         \u2013          <p>Sequence of serialized objects to put in the store.</p> </li> </ul> <p>Returns:</p> <ul> <li> <code>list[LocalKey]</code>         \u2013          <p>List of keys with the same order as <code>objs</code> which can be used to             retrieve the objects.</p> </li> </ul> Source code in <code>proxystore/connectors/local.py</code> <pre><code>def put_batch(self, objs: Sequence[bytes]) -&gt; list[LocalKey]:\n    \"\"\"Put a batch of serialized objects in the store.\n\n    Args:\n        objs: Sequence of serialized objects to put in the store.\n\n    Returns:\n        List of keys with the same order as `objs` which can be used to \\\n        retrieve the objects.\n    \"\"\"\n    return [self.put(obj) for obj in objs]\n</code></pre>"},{"location":"api/connectors/local/#proxystore.connectors.local.LocalConnector.set","title":"set()","text":"<pre><code>set(key: LocalKey, obj: bytes) -&gt; None\n</code></pre> <p>Set the object associated with a key.</p> <p>Parameters:</p> <ul> <li> <code>key</code>             (<code>LocalKey</code>)         \u2013          <p>Key that the object will be associated with.</p> </li> <li> <code>obj</code>             (<code>bytes</code>)         \u2013          <p>Object to associate with the key.</p> </li> </ul> Source code in <code>proxystore/connectors/local.py</code> <pre><code>def set(self, key: LocalKey, obj: bytes) -&gt; None:\n    \"\"\"Set the object associated with a key.\n\n    Args:\n        key: Key that the object will be associated with.\n        obj: Object to associate with the key.\n    \"\"\"\n    self._store[key] = obj\n</code></pre>"},{"location":"api/connectors/multi/","title":"proxystore.connectors.multi","text":"<code>proxystore/connectors/multi.py</code> <p>Multi-connector implementation.</p>"},{"location":"api/connectors/multi/#proxystore.connectors.multi.ConnectorPolicyConfig","title":"ConnectorPolicyConfig  <code>module-attribute</code>","text":"<pre><code>ConnectorPolicyConfig = Tuple[\n    str, Dict[str, Any], PolicyDict\n]\n</code></pre> <p>Type of the configuration for a connector and policy pair.</p> <p>Element zero is the fully qualified path of the connector type, element one is the connector's configuration dictionary, and element two is the policy in dictionary form.</p>"},{"location":"api/connectors/multi/#proxystore.connectors.multi.PolicyDict","title":"PolicyDict","text":"<p>             Bases: <code>TypedDict</code></p> <p>JSON compatible representation of a <code>Policy</code>.</p>"},{"location":"api/connectors/multi/#proxystore.connectors.multi.Policy","title":"Policy  <code>dataclass</code>","text":"<pre><code>Policy(\n    priority: int = 0,\n    host_pattern: Iterable[str] | str | None = None,\n    min_size_bytes: int = 0,\n    max_size_bytes: int = sys.maxsize,\n    subset_tags: list[str] = list(),\n    superset_tags: list[str] = list(),\n)\n</code></pre> <p>Policy that allows validating a set of constraints.</p> <p>Attributes:</p> <ul> <li> <code>priority</code>             (<code>int</code>)         \u2013          <p>Priority for breaking ties between policies (higher is preferred).</p> </li> <li> <code>host_pattern</code>             (<code>Iterable[str] | str | None</code>)         \u2013          <p>Pattern or iterable of patterns of valid hostnames. The hostname returned by <code>hostname()</code> is matched against <code>host_pattern</code> using <code>re.fullmatch()</code>. If <code>host_pattern</code> is an iterable, at least one of the patterns must match the hostname.</p> </li> <li> <code>min_size_bytes</code>             (<code>int</code>)         \u2013          <p>Minimum size in bytes allowed.</p> </li> <li> <code>max_size_bytes</code>             (<code>int</code>)         \u2013          <p>Maximum size in bytes allowed.</p> </li> <li> <code>subset_tags</code>             (<code>list[str]</code>)         \u2013          <p>Subset tags. See <code>is_valid()</code> for more details.</p> </li> <li> <code>superset_tags</code>             (<code>list[str]</code>)         \u2013          <p>Superset tags. See <code>is_valid()</code> for more details.</p> </li> </ul>"},{"location":"api/connectors/multi/#proxystore.connectors.multi.Policy.is_valid","title":"is_valid()","text":"<pre><code>is_valid(\n    *,\n    size_bytes: int | None = None,\n    subset_tags: Iterable[str] | None = None,\n    superset_tags: Iterable[str] | None = None\n) -&gt; bool\n</code></pre> <p>Check if set of constraints is valid for this policy.</p> Note <p>All arguments are optional keyword arguments that default to <code>None</code>. If left as the default, that constraint will not be checked against the policy.</p> <p>Parameters:</p> <ul> <li> <code>size_bytes</code>             (<code>int | None</code>, default:                 <code>None</code> )         \u2013          <p>Object size in bytes.</p> </li> <li> <code>subset_tags</code>             (<code>Iterable[str] | None</code>, default:                 <code>None</code> )         \u2013          <p>Set of tags that must be a subset of the Policy's <code>subset_tags</code> to be valid.</p> </li> <li> <code>superset_tags</code>             (<code>Iterable[str] | None</code>, default:                 <code>None</code> )         \u2013          <p>Set of tags that must be a superset of the Policy's <code>superset_tags</code> to be valid.</p> </li> </ul> <p>Returns:</p> <ul> <li> <code>bool</code>         \u2013          <p>If the provided constraints are valid for the policy.</p> </li> </ul> Source code in <code>proxystore/connectors/multi.py</code> <pre><code>def is_valid(\n    self,\n    *,\n    size_bytes: int | None = None,\n    subset_tags: Iterable[str] | None = None,\n    superset_tags: Iterable[str] | None = None,\n) -&gt; bool:\n    \"\"\"Check if set of constraints is valid for this policy.\n\n    Note:\n        All arguments are optional keyword arguments that default to\n        `None`. If left as the default, that constraint will not be\n        checked against the policy.\n\n    Args:\n        size_bytes: Object size in bytes.\n        subset_tags: Set of tags that must be a subset\n            of the Policy's `subset_tags` to be valid.\n        superset_tags: Set of tags that must be a superset\n            of the Policy's `superset_tags` to be valid.\n\n    Returns:\n        If the provided constraints are valid for the policy.\n    \"\"\"\n    if size_bytes is not None and (\n        size_bytes &lt; self.min_size_bytes\n        or size_bytes &gt; self.max_size_bytes\n    ):\n        return False\n    if subset_tags is not None and not set(subset_tags).issubset(\n        self.subset_tags,\n    ):\n        return False\n    if superset_tags is not None and not set(superset_tags).issuperset(\n        self.superset_tags,\n    ):\n        return False\n    return self.is_valid_on_host()\n</code></pre>"},{"location":"api/connectors/multi/#proxystore.connectors.multi.Policy.is_valid_on_host","title":"is_valid_on_host()","text":"<pre><code>is_valid_on_host() -&gt; bool\n</code></pre> <p>Check if this policy is valid on the current host.</p> Source code in <code>proxystore/connectors/multi.py</code> <pre><code>def is_valid_on_host(self) -&gt; bool:\n    \"\"\"Check if this policy is valid on the current host.\"\"\"\n    if self.host_pattern is None:\n        return True\n\n    patterns: Iterable[str]\n    if isinstance(self.host_pattern, str):\n        patterns = [self.host_pattern]\n    else:\n        patterns = self.host_pattern\n    hostname = utils.hostname()\n    return any(re.fullmatch(p, hostname) for p in patterns)\n</code></pre>"},{"location":"api/connectors/multi/#proxystore.connectors.multi.Policy.as_dict","title":"as_dict()","text":"<pre><code>as_dict() -&gt; PolicyDict\n</code></pre> <p>Convert the Policy to a JSON compatible dict.</p> Example <pre><code>&gt;&gt;&gt; policy = Policy(...)\n&gt;&gt;&gt; policy_dict = policy.as_dict()\n&gt;&gt;&gt; Policy(**policy_dict) == policy\nTrue\n</code></pre> Source code in <code>proxystore/connectors/multi.py</code> <pre><code>def as_dict(self) -&gt; PolicyDict:\n    \"\"\"Convert the Policy to a JSON compatible dict.\n\n    Example:\n        ```python\n        &gt;&gt;&gt; policy = Policy(...)\n        &gt;&gt;&gt; policy_dict = policy.as_dict()\n        &gt;&gt;&gt; Policy(**policy_dict) == policy\n        True\n        ```\n    \"\"\"\n    # We could use dataclasses.asdict(self) but this gives us the benefit\n    # of typing on the return dict.\n    host_pattern = (\n        self.host_pattern\n        if isinstance(self.host_pattern, str) or self.host_pattern is None\n        else list(self.host_pattern)\n    )\n    return PolicyDict(\n        priority=self.priority,\n        host_pattern=host_pattern,\n        min_size_bytes=self.min_size_bytes,\n        max_size_bytes=self.max_size_bytes,\n        subset_tags=self.subset_tags,\n        superset_tags=self.superset_tags,\n    )\n</code></pre>"},{"location":"api/connectors/multi/#proxystore.connectors.multi.MultiConnectorError","title":"MultiConnectorError","text":"<p>             Bases: <code>Exception</code></p> <p>Exceptions raised by the <code>MultiConnector</code>.</p>"},{"location":"api/connectors/multi/#proxystore.connectors.multi.MultiKey","title":"MultiKey","text":"<p>             Bases: <code>NamedTuple</code></p> <p>Key to objects in <code>MultiConnector</code>.</p> <p>Attributes:</p> <ul> <li> <code>connector_name</code>             (<code>str</code>)         \u2013          <p>Name of connector that the associated object is stored in.</p> </li> <li> <code>connector_key</code>             (<code>Any</code>)         \u2013          <p>Key associated with the object.</p> </li> </ul>"},{"location":"api/connectors/multi/#proxystore.connectors.multi.MultiConnector","title":"MultiConnector","text":"<pre><code>MultiConnector(\n    connectors: dict[str, tuple[Connector[Any], Policy]],\n    dormant_connectors: (\n        dict[str, ConnectorPolicyConfig] | None\n    ) = None,\n)\n</code></pre> <p>Policy based manager for a <code>Connector</code> collection.</p> Example <pre><code>from proxystore.connectors.file import FileConnector\nfrom proxystore.connectors.multi import Policy\nfrom proxystore.connectors.multi import MultiConnector\nfrom proxystore.connectors.redis import RedisConnector\n\nfile_connector = FileConnector(...)\nredis_connector = RedisConnector(...)\n\nconnectors = {\n    'small': (file_connector, Policy(max_size_bytes=1000000)),\n    'large': (redis_connector, Policy(min_size_bytes=1000000)),\n}\nconnector = MultiConnector(connector)\n</code></pre> Note <p>Methods of this class will raise <code>MultiConnectorError</code> if they are passed an invalid key where a key could be invalid because the connector which created the key is not known by this class instance or because the corresponding connector is dormant.</p> <p>Parameters:</p> <ul> <li> <code>connectors</code>             (<code>dict[str, tuple[Connector[Any], Policy]]</code>)         \u2013          <p>Mapping of names to tuples of a <code>Connector</code> and <code>Policy</code>.</p> </li> <li> <code>dormant_connectors</code>             (<code>dict[str, ConnectorPolicyConfig] | None</code>, default:                 <code>None</code> )         \u2013          <p>Mapping of names to tuples containing the configuration of a dormant connector. A dormant connector is a connector that is unused in this process, but could potentially be initialized and used on another process. For example, because the <code>host_pattern</code> of the policy does not match the current host. It is not recommended to create dormant connector configurations yourself. Rather, create your connectors and use the <code>host_pattern</code> of the policy to determine when a connector should be dormant.</p> </li> </ul> Source code in <code>proxystore/connectors/multi.py</code> <pre><code>def __init__(\n    self,\n    connectors: dict[str, tuple[Connector[Any], Policy]],\n    dormant_connectors: dict[str, ConnectorPolicyConfig] | None = None,\n) -&gt; None:\n    self.connectors = {\n        name: _ConnectorPolicy(connector, policy)\n        for name, (connector, policy) in connectors.items()\n    }\n    self.dormant_connectors = dormant_connectors\n\n    names = list(self.connectors.keys())\n    self.connectors_by_priority = sorted(\n        names,\n        key=lambda name: self.connectors[name].policy.priority,\n        reverse=True,\n    )\n</code></pre>"},{"location":"api/connectors/multi/#proxystore.connectors.multi.MultiConnector.close","title":"close()","text":"<pre><code>close() -&gt; None\n</code></pre> <p>Close the connector and clean up.</p> Warning <p>This will call <code>close()</code> on all managed connectors.</p> Source code in <code>proxystore/connectors/multi.py</code> <pre><code>def close(self) -&gt; None:\n    \"\"\"Close the connector and clean up.\n\n    Warning:\n        This will call `close()` on all managed connectors.\n    \"\"\"\n    for connector, _ in self.connectors.values():\n        connector.close()\n</code></pre>"},{"location":"api/connectors/multi/#proxystore.connectors.multi.MultiConnector.config","title":"config()","text":"<pre><code>config() -&gt; dict[str, ConnectorPolicyConfig]\n</code></pre> <p>Get the connector configuration.</p> <p>The configuration contains all the information needed to reconstruct the connector object.</p> Source code in <code>proxystore/connectors/multi.py</code> <pre><code>def config(self) -&gt; dict[str, ConnectorPolicyConfig]:\n    \"\"\"Get the connector configuration.\n\n    The configuration contains all the information needed to reconstruct\n    the connector object.\n    \"\"\"\n    configs: dict[str, ConnectorPolicyConfig] = (\n        self.dormant_connectors\n        if self.dormant_connectors is not None\n        else {}\n    )\n    configs.update(\n        {\n            name: (\n                get_object_path(type(connector)),\n                connector.config(),\n                policy.as_dict(),\n            )\n            for name, (connector, policy) in self.connectors.items()\n        },\n    )\n    return configs\n</code></pre>"},{"location":"api/connectors/multi/#proxystore.connectors.multi.MultiConnector.from_config","title":"from_config()  <code>classmethod</code>","text":"<pre><code>from_config(\n    config: dict[str, ConnectorPolicyConfig]\n) -&gt; MultiConnector\n</code></pre> <p>Create a new connector instance from a configuration.</p> <p>Parameters:</p> <ul> <li> <code>config</code>             (<code>dict[str, ConnectorPolicyConfig]</code>)         \u2013          <p>Configuration returned by <code>.config()</code>.</p> </li> </ul> Source code in <code>proxystore/connectors/multi.py</code> <pre><code>@classmethod\ndef from_config(\n    cls,\n    config: dict[str, ConnectorPolicyConfig],\n) -&gt; MultiConnector:\n    \"\"\"Create a new connector instance from a configuration.\n\n    Args:\n        config: Configuration returned by `#!python .config()`.\n    \"\"\"\n    connectors: dict[str, tuple[Connector[Any], Policy]] = {}\n    dormant_connectors: dict[str, ConnectorPolicyConfig] = {}\n    for name, (conn_path, conn_config, policy_dict) in config.items():\n        policy = Policy(**policy_dict)\n        if policy.is_valid_on_host():\n            connector_type = import_from_path(conn_path)\n            connector = connector_type.from_config(conn_config)\n            connectors[name] = (connector, policy)\n        else:\n            dormant_connectors[name] = config[name]\n    return cls(\n        connectors=connectors,\n        dormant_connectors=dormant_connectors,\n    )\n</code></pre>"},{"location":"api/connectors/multi/#proxystore.connectors.multi.MultiConnector.evict","title":"evict()","text":"<pre><code>evict(key: MultiKey) -&gt; None\n</code></pre> <p>Evict the object associated with the key.</p> <p>Parameters:</p> <ul> <li> <code>key</code>             (<code>MultiKey</code>)         \u2013          <p>Key associated with object to evict.</p> </li> </ul> Source code in <code>proxystore/connectors/multi.py</code> <pre><code>def evict(self, key: MultiKey) -&gt; None:\n    \"\"\"Evict the object associated with the key.\n\n    Args:\n        key: Key associated with object to evict.\n    \"\"\"\n    connector = self._connector_from_key(key)\n    connector.evict(key.connector_key)\n</code></pre>"},{"location":"api/connectors/multi/#proxystore.connectors.multi.MultiConnector.exists","title":"exists()","text":"<pre><code>exists(key: MultiKey) -&gt; bool\n</code></pre> <p>Check if an object associated with the key exists.</p> <p>Parameters:</p> <ul> <li> <code>key</code>             (<code>MultiKey</code>)         \u2013          <p>Key potentially associated with stored object.</p> </li> </ul> <p>Returns:</p> <ul> <li> <code>bool</code>         \u2013          <p>If an object associated with the key exists.</p> </li> </ul> Source code in <code>proxystore/connectors/multi.py</code> <pre><code>def exists(self, key: MultiKey) -&gt; bool:\n    \"\"\"Check if an object associated with the key exists.\n\n    Args:\n        key: Key potentially associated with stored object.\n\n    Returns:\n        If an object associated with the key exists.\n    \"\"\"\n    connector = self._connector_from_key(key)\n    return connector.exists(key.connector_key)\n</code></pre>"},{"location":"api/connectors/multi/#proxystore.connectors.multi.MultiConnector.get","title":"get()","text":"<pre><code>get(key: MultiKey) -&gt; bytes | None\n</code></pre> <p>Get the serialized object associated with the key.</p> <p>Parameters:</p> <ul> <li> <code>key</code>             (<code>MultiKey</code>)         \u2013          <p>Key associated with the object to retrieve.</p> </li> </ul> <p>Returns:</p> <ul> <li> <code>bytes | None</code>         \u2013          <p>Serialized object or <code>None</code> if the object does not exist.</p> </li> </ul> Source code in <code>proxystore/connectors/multi.py</code> <pre><code>def get(self, key: MultiKey) -&gt; bytes | None:\n    \"\"\"Get the serialized object associated with the key.\n\n    Args:\n        key: Key associated with the object to retrieve.\n\n    Returns:\n        Serialized object or `None` if the object does not exist.\n    \"\"\"\n    connector = self._connector_from_key(key)\n    return connector.get(key.connector_key)\n</code></pre>"},{"location":"api/connectors/multi/#proxystore.connectors.multi.MultiConnector.get_batch","title":"get_batch()","text":"<pre><code>get_batch(keys: Sequence[MultiKey]) -&gt; list[bytes | None]\n</code></pre> <p>Get a batch of serialized objects associated with the keys.</p> <p>Parameters:</p> <ul> <li> <code>keys</code>             (<code>Sequence[MultiKey]</code>)         \u2013          <p>Sequence of keys associated with objects to retrieve.</p> </li> </ul> <p>Returns:</p> <ul> <li> <code>list[bytes | None]</code>         \u2013          <p>List with same order as <code>keys</code> with the serialized objects or             <code>None</code> if the corresponding key does not have an associated object.</p> </li> </ul> Source code in <code>proxystore/connectors/multi.py</code> <pre><code>def get_batch(self, keys: Sequence[MultiKey]) -&gt; list[bytes | None]:\n    \"\"\"Get a batch of serialized objects associated with the keys.\n\n    Args:\n        keys: Sequence of keys associated with objects to retrieve.\n\n    Returns:\n        List with same order as `keys` with the serialized objects or \\\n        `None` if the corresponding key does not have an associated object.\n    \"\"\"\n    return [self.get(key) for key in keys]\n</code></pre>"},{"location":"api/connectors/multi/#proxystore.connectors.multi.MultiConnector.put","title":"put()","text":"<pre><code>put(\n    obj: bytes,\n    subset_tags: Iterable[str] = (),\n    superset_tags: Iterable[str] = (),\n) -&gt; MultiKey\n</code></pre> <p>Put a serialized object in the store.</p> <p>Parameters:</p> <ul> <li> <code>obj</code>             (<code>bytes</code>)         \u2013          <p>Serialized object to put in the store.</p> </li> <li> <code>subset_tags</code>             (<code>Iterable[str]</code>, default:                 <code>()</code> )         \u2013          <p>Iterable of tags that must be a subset of a connector's policy <code>subset_tags</code> to match.</p> </li> <li> <code>superset_tags</code>             (<code>Iterable[str]</code>, default:                 <code>()</code> )         \u2013          <p>Iterable of tags that must be a superset of a connectors's policy <code>superset_tags</code> to match.</p> </li> </ul> <p>Returns:</p> <ul> <li> <code>MultiKey</code>         \u2013          <p>Key which can be used to retrieve the object.</p> </li> </ul> <p>Raises:</p> <ul> <li> <code>MultiConnectorError</code>           \u2013          <p>If no connector policy matches the arguments.</p> </li> </ul> Source code in <code>proxystore/connectors/multi.py</code> <pre><code>def put(\n    self,\n    obj: bytes,\n    subset_tags: Iterable[str] = (),\n    superset_tags: Iterable[str] = (),\n) -&gt; MultiKey:\n    \"\"\"Put a serialized object in the store.\n\n    Args:\n        obj: Serialized object to put in the store.\n        subset_tags: Iterable of tags that must be a subset\n            of a connector's policy `subset_tags` to match.\n        superset_tags: Iterable of tags that must be a superset\n            of a connectors's policy `superset_tags` to match.\n\n    Returns:\n        Key which can be used to retrieve the object.\n\n    Raises:\n        MultiConnectorError: If no connector policy matches the arguments.\n    \"\"\"\n    for connector_name in self.connectors_by_priority:\n        connector, policy = self.connectors[connector_name]\n        if policy.is_valid(\n            size_bytes=len(obj),\n            subset_tags=subset_tags,\n            superset_tags=superset_tags,\n        ):\n            key = connector.put(obj)\n            return MultiKey(\n                connector_name=connector_name,\n                connector_key=key,\n            )\n    raise MultiConnectorError(\n        'No connector policy was suitable for the constraints: '\n        f'subset_tags={subset_tags}, superset_tags={superset_tags}.',\n    )\n</code></pre>"},{"location":"api/connectors/multi/#proxystore.connectors.multi.MultiConnector.put_batch","title":"put_batch()","text":"<pre><code>put_batch(\n    objs: Sequence[bytes],\n    subset_tags: Iterable[str] = (),\n    superset_tags: Iterable[str] = (),\n) -&gt; list[MultiKey]\n</code></pre> <p>Put a batch of serialized objects in the store.</p> Warning <p>This method calls <code>put()</code> individually for each item in the batch so items in the batch can potentially be placed in different connectors.</p> <p>Parameters:</p> <ul> <li> <code>objs</code>             (<code>Sequence[bytes]</code>)         \u2013          <p>Sequence of serialized objects to put in the store.</p> </li> <li> <code>subset_tags</code>             (<code>Iterable[str]</code>, default:                 <code>()</code> )         \u2013          <p>Iterable of tags that must be a subset of a connector's policy <code>subset_tags</code> to match.</p> </li> <li> <code>superset_tags</code>             (<code>Iterable[str]</code>, default:                 <code>()</code> )         \u2013          <p>Iterable of tags that must be a superset of a connectors's policy <code>superset_tags</code> to match.</p> </li> </ul> <p>Returns:</p> <ul> <li> <code>list[MultiKey]</code>         \u2013          <p>List of keys with the same order as <code>objs</code> which can be used to             retrieve the objects.</p> </li> </ul> <p>Raises:</p> <ul> <li> <code>MultiConnectorError</code>           \u2013          <p>If no connector policy matches the arguments.</p> </li> </ul> Source code in <code>proxystore/connectors/multi.py</code> <pre><code>def put_batch(\n    self,\n    objs: Sequence[bytes],\n    subset_tags: Iterable[str] = (),\n    superset_tags: Iterable[str] = (),\n) -&gt; list[MultiKey]:\n    \"\"\"Put a batch of serialized objects in the store.\n\n    Warning:\n        This method calls\n        [`put()`][proxystore.connectors.multi.MultiConnector] individually\n        for each item in the batch so items in the batch can potentially\n        be placed in different connectors.\n\n    Args:\n        objs: Sequence of serialized objects to put in the store.\n        subset_tags: Iterable of tags that must be a subset\n            of a connector's policy `subset_tags` to match.\n        superset_tags: Iterable of tags that must be a superset\n            of a connectors's policy `superset_tags` to match.\n\n    Returns:\n        List of keys with the same order as `objs` which can be used to \\\n        retrieve the objects.\n\n    Raises:\n        MultiConnectorError: If no connector policy matches the arguments.\n    \"\"\"\n    return [\n        self.put(obj, subset_tags=subset_tags, superset_tags=superset_tags)\n        for obj in objs\n    ]\n</code></pre>"},{"location":"api/connectors/protocols/","title":"proxystore.connectors.protocols","text":"<code>proxystore/connectors/protocols.py</code> <p>Connector protocol.</p>"},{"location":"api/connectors/protocols/#proxystore.connectors.protocols.Connector","title":"Connector","text":"<p>             Bases: <code>Protocol[KeyT]</code></p> <p>Connector protocol for interfacing with external object storage.</p> <p>The Connector protocol defines the interface for interacting with a byte-level object store.</p>"},{"location":"api/connectors/protocols/#proxystore.connectors.protocols.Connector.close","title":"close()","text":"<pre><code>close() -&gt; None\n</code></pre> <p>Close the connector and clean up.</p> Note <p>Implementations should make this idempotent.</p> Source code in <code>proxystore/connectors/protocols.py</code> <pre><code>def close(self) -&gt; None:\n    \"\"\"Close the connector and clean up.\n\n    Note:\n        Implementations should make this idempotent.\n    \"\"\"\n    ...\n</code></pre>"},{"location":"api/connectors/protocols/#proxystore.connectors.protocols.Connector.config","title":"config()","text":"<pre><code>config() -&gt; dict[str, Any]\n</code></pre> <p>Get the connector configuration.</p> <p>The configuration contains all the information needed to reconstruct the connector object.</p> <p>Returns:</p> <ul> <li> <code>dict[str, Any]</code>         \u2013          <p>Connector configuration.</p> </li> </ul> Source code in <code>proxystore/connectors/protocols.py</code> <pre><code>def config(self) -&gt; dict[str, Any]:\n    \"\"\"Get the connector configuration.\n\n    The configuration contains all the information needed to reconstruct\n    the connector object.\n\n    Returns:\n        Connector configuration.\n    \"\"\"\n    ...\n</code></pre>"},{"location":"api/connectors/protocols/#proxystore.connectors.protocols.Connector.from_config","title":"from_config()  <code>classmethod</code>","text":"<pre><code>from_config(config: dict[str, Any]) -&gt; Connector[Any]\n</code></pre> <p>Create a new connector instance from a configuration.</p> <p>Parameters:</p> <ul> <li> <code>config</code>             (<code>dict[str, Any]</code>)         \u2013          <p>Configuration returned by <code>.config()</code>.</p> </li> </ul> <p>Returns:</p> <ul> <li> <code>Connector[Any]</code>         \u2013          <p>Connector instance.</p> </li> </ul> Source code in <code>proxystore/connectors/protocols.py</code> <pre><code>@classmethod\ndef from_config(cls, config: dict[str, Any]) -&gt; Connector[Any]:\n    \"\"\"Create a new connector instance from a configuration.\n\n    Args:\n        config: Configuration returned by `#!python .config()`.\n\n    Returns:\n        Connector instance.\n    \"\"\"\n    ...\n</code></pre>"},{"location":"api/connectors/protocols/#proxystore.connectors.protocols.Connector.evict","title":"evict()","text":"<pre><code>evict(key: KeyT) -&gt; None\n</code></pre> <p>Evict the object associated with the key.</p> <p>Parameters:</p> <ul> <li> <code>key</code>             (<code>KeyT</code>)         \u2013          <p>Key associated with object to evict.</p> </li> </ul> Source code in <code>proxystore/connectors/protocols.py</code> <pre><code>def evict(self, key: KeyT) -&gt; None:\n    \"\"\"Evict the object associated with the key.\n\n    Args:\n        key: Key associated with object to evict.\n    \"\"\"\n    ...\n</code></pre>"},{"location":"api/connectors/protocols/#proxystore.connectors.protocols.Connector.exists","title":"exists()","text":"<pre><code>exists(key: KeyT) -&gt; bool\n</code></pre> <p>Check if an object associated with the key exists.</p> <p>Parameters:</p> <ul> <li> <code>key</code>             (<code>KeyT</code>)         \u2013          <p>Key potentially associated with stored object.</p> </li> </ul> <p>Returns:</p> <ul> <li> <code>bool</code>         \u2013          <p>If an object associated with the key exists.</p> </li> </ul> Source code in <code>proxystore/connectors/protocols.py</code> <pre><code>def exists(self, key: KeyT) -&gt; bool:\n    \"\"\"Check if an object associated with the key exists.\n\n    Args:\n        key: Key potentially associated with stored object.\n\n    Returns:\n        If an object associated with the key exists.\n    \"\"\"\n    ...\n</code></pre>"},{"location":"api/connectors/protocols/#proxystore.connectors.protocols.Connector.get","title":"get()","text":"<pre><code>get(key: KeyT) -&gt; bytes | None\n</code></pre> <p>Get the serialized object associated with the key.</p> <p>Parameters:</p> <ul> <li> <code>key</code>             (<code>KeyT</code>)         \u2013          <p>Key associated with the object to retrieve.</p> </li> </ul> <p>Returns:</p> <ul> <li> <code>bytes | None</code>         \u2013          <p>Serialized object or <code>None</code> if the object does not exist.</p> </li> </ul> Source code in <code>proxystore/connectors/protocols.py</code> <pre><code>def get(self, key: KeyT) -&gt; bytes | None:\n    \"\"\"Get the serialized object associated with the key.\n\n    Args:\n        key: Key associated with the object to retrieve.\n\n    Returns:\n        Serialized object or `None` if the object does not exist.\n    \"\"\"\n    ...\n</code></pre>"},{"location":"api/connectors/protocols/#proxystore.connectors.protocols.Connector.get_batch","title":"get_batch()","text":"<pre><code>get_batch(keys: Sequence[KeyT]) -&gt; list[bytes | None]\n</code></pre> <p>Get a batch of serialized objects associated with the keys.</p> <p>Parameters:</p> <ul> <li> <code>keys</code>             (<code>Sequence[KeyT]</code>)         \u2013          <p>Sequence of keys associated with objects to retrieve.</p> </li> </ul> <p>Returns:</p> <ul> <li> <code>list[bytes | None]</code>         \u2013          <p>List with same order as <code>keys</code> with the serialized objects or             <code>None</code> if the corresponding key does not have an associated object.</p> </li> </ul> Source code in <code>proxystore/connectors/protocols.py</code> <pre><code>def get_batch(self, keys: Sequence[KeyT]) -&gt; list[bytes | None]:\n    \"\"\"Get a batch of serialized objects associated with the keys.\n\n    Args:\n        keys: Sequence of keys associated with objects to retrieve.\n\n    Returns:\n        List with same order as `keys` with the serialized objects or \\\n        `None` if the corresponding key does not have an associated object.\n    \"\"\"\n    ...\n</code></pre>"},{"location":"api/connectors/protocols/#proxystore.connectors.protocols.Connector.put","title":"put()","text":"<pre><code>put(obj: bytes) -&gt; KeyT\n</code></pre> <p>Put a serialized object in the store.</p> <p>Parameters:</p> <ul> <li> <code>obj</code>             (<code>bytes</code>)         \u2013          <p>Serialized object to put in the store.</p> </li> </ul> <p>Returns:</p> <ul> <li> <code>KeyT</code>         \u2013          <p>Key which can be used to retrieve the object.</p> </li> </ul> Source code in <code>proxystore/connectors/protocols.py</code> <pre><code>def put(self, obj: bytes) -&gt; KeyT:\n    \"\"\"Put a serialized object in the store.\n\n    Args:\n        obj: Serialized object to put in the store.\n\n    Returns:\n        Key which can be used to retrieve the object.\n    \"\"\"\n    ...\n</code></pre>"},{"location":"api/connectors/protocols/#proxystore.connectors.protocols.Connector.put_batch","title":"put_batch()","text":"<pre><code>put_batch(objs: Sequence[bytes]) -&gt; list[KeyT]\n</code></pre> <p>Put a batch of serialized objects in the store.</p> <p>Parameters:</p> <ul> <li> <code>objs</code>             (<code>Sequence[bytes]</code>)         \u2013          <p>Sequence of serialized objects to put in the store.</p> </li> </ul> <p>Returns:</p> <ul> <li> <code>list[KeyT]</code>         \u2013          <p>List of keys with the same order as <code>objs</code> which can be used to             retrieve the objects.</p> </li> </ul> Source code in <code>proxystore/connectors/protocols.py</code> <pre><code>def put_batch(self, objs: Sequence[bytes]) -&gt; list[KeyT]:\n    \"\"\"Put a batch of serialized objects in the store.\n\n    Args:\n        objs: Sequence of serialized objects to put in the store.\n\n    Returns:\n        List of keys with the same order as `objs` which can be used to \\\n        retrieve the objects.\n    \"\"\"\n    ...\n</code></pre>"},{"location":"api/connectors/protocols/#proxystore.connectors.protocols.DeferrableConnector","title":"DeferrableConnector","text":"<p>             Bases: <code>Protocol[KeyT]</code></p> <p>Extension of the <code>Connector</code> with <code>set</code> semantics.</p> <p>Extends the <code>Connector</code> protocol with additional methods necessary for creating a key while deferring associated an object with the key.</p>"},{"location":"api/connectors/protocols/#proxystore.connectors.protocols.DeferrableConnector.new_key","title":"new_key()","text":"<pre><code>new_key(obj: bytes | None = None) -&gt; KeyT\n</code></pre> <p>Create a new key.</p> Note <p>Implementations may choose to require the object be provided, or place restrictions on the scope of the key.</p> <p>Parameters:</p> <ul> <li> <code>obj</code>             (<code>bytes | None</code>, default:                 <code>None</code> )         \u2013          <p>Optional object which the key will be associated with.</p> </li> </ul> <p>Returns:</p> <ul> <li> <code>KeyT</code>         \u2013          <p>Key which can be used to retrieve an object once             <code>set()</code>             has been called on the key.</p> </li> </ul> Source code in <code>proxystore/connectors/protocols.py</code> <pre><code>def new_key(self, obj: bytes | None = None) -&gt; KeyT:\n    \"\"\"Create a new key.\n\n    Note:\n        Implementations may choose to require the object be provided, or\n        place restrictions on the scope of the key.\n\n    Args:\n        obj: Optional object which the key will be associated with.\n\n    Returns:\n        Key which can be used to retrieve an object once \\\n        [`set()`][proxystore.connectors.protocols.DeferrableConnector.set] \\\n        has been called on the key.\n    \"\"\"  # noqa: E501\n    ...\n</code></pre>"},{"location":"api/connectors/protocols/#proxystore.connectors.protocols.DeferrableConnector.set","title":"set()","text":"<pre><code>set(key: KeyT, obj: bytes) -&gt; None\n</code></pre> <p>Set the object associated with a key.</p> Note <p>The <code>Connector</code> provides write-once, read-many semantics. Thus, <code>set()</code> should only be called once per key, otherwise unexpected behavior can occur.</p> Warning <p>This method is not required to be atomic and could therefore result in race conditions with calls to <code>get()</code>.</p> <p>Parameters:</p> <ul> <li> <code>key</code>             (<code>KeyT</code>)         \u2013          <p>Key that the object will be associated with.</p> </li> <li> <code>obj</code>             (<code>bytes</code>)         \u2013          <p>Object to associate with the key.</p> </li> </ul> Source code in <code>proxystore/connectors/protocols.py</code> <pre><code>def set(self, key: KeyT, obj: bytes) -&gt; None:\n    \"\"\"Set the object associated with a key.\n\n    Note:\n        The [`Connector`][proxystore.connectors.protocols.Connector]\n        provides write-once, read-many semantics. Thus,\n        [`set()`][proxystore.connectors.protocols.DeferrableConnector.set]\n        should only be called once per key, otherwise unexpected behavior\n        can occur.\n\n    Warning:\n        This method is not required to be atomic and could therefore\n        result in race conditions with calls to\n        [`get()`][proxystore.connectors.protocols.Connector.get].\n\n    Args:\n        key: Key that the object will be associated with.\n        obj: Object to associate with the key.\n    \"\"\"\n    ...\n</code></pre>"},{"location":"api/connectors/redis/","title":"proxystore.connectors.redis","text":"<code>proxystore/connectors/redis.py</code> <p>Redis connector implementation.</p>"},{"location":"api/connectors/redis/#proxystore.connectors.redis.RedisKey","title":"RedisKey","text":"<p>             Bases: <code>NamedTuple</code></p> <p>Key to objects store in a Redis server.</p> <p>Attributes:</p> <ul> <li> <code>redis_key</code>             (<code>str</code>)         \u2013          <p>Unique object ID.</p> </li> </ul>"},{"location":"api/connectors/redis/#proxystore.connectors.redis.RedisConnector","title":"RedisConnector","text":"<pre><code>RedisConnector(\n    hostname: str, port: int, clear: bool = False\n)\n</code></pre> <p>Redis server connector.</p> <p>Parameters:</p> <ul> <li> <code>hostname</code>             (<code>str</code>)         \u2013          <p>Redis server hostname.</p> </li> <li> <code>port</code>             (<code>int</code>)         \u2013          <p>Redis server port.</p> </li> <li> <code>clear</code>             (<code>bool</code>, default:                 <code>False</code> )         \u2013          <p>Remove all keys from the Redis server when <code>close()</code> is called. This will delete keys regardless of if they were created by ProxyStore or not.</p> </li> </ul> Source code in <code>proxystore/connectors/redis.py</code> <pre><code>def __init__(self, hostname: str, port: int, clear: bool = False) -&gt; None:\n    self.hostname = hostname\n    self.port = port\n    self.clear = clear\n    self._redis_client = redis.StrictRedis(host=hostname, port=port)\n</code></pre>"},{"location":"api/connectors/redis/#proxystore.connectors.redis.RedisConnector.close","title":"close()","text":"<pre><code>close(clear: bool | None = None) -&gt; None\n</code></pre> <p>Close the connector and clean up.</p> Warning <p>Passing <code>clear=True</code> will result in ALL keys in the Redis server being deleted regardless of if they were created by ProxyStore or not.</p> <p>Parameters:</p> <ul> <li> <code>clear</code>             (<code>bool | None</code>, default:                 <code>None</code> )         \u2013          <p>Remove all keys in the Redis server. Overrides the default value of <code>clear</code> provided when the <code>RedisConnector</code> was instantiated.</p> </li> </ul> Source code in <code>proxystore/connectors/redis.py</code> <pre><code>def close(self, clear: bool | None = None) -&gt; None:\n    \"\"\"Close the connector and clean up.\n\n    Warning:\n        Passing `clear=True` will result in **ALL** keys in the Redis\n        server being deleted regardless of if they were created by\n        ProxyStore or not.\n\n    Args:\n        clear: Remove all keys in the Redis server. Overrides the default\n            value of `clear` provided when the\n            [`RedisConnector`][proxystore.connectors.redis.RedisConnector]\n            was instantiated.\n    \"\"\"\n    if self.clear if clear is None else clear:\n        self._redis_client.flushdb()\n    self._redis_client.close()\n</code></pre>"},{"location":"api/connectors/redis/#proxystore.connectors.redis.RedisConnector.config","title":"config()","text":"<pre><code>config() -&gt; dict[str, Any]\n</code></pre> <p>Get the connector configuration.</p> <p>The configuration contains all the information needed to reconstruct the connector object.</p> Source code in <code>proxystore/connectors/redis.py</code> <pre><code>def config(self) -&gt; dict[str, Any]:\n    \"\"\"Get the connector configuration.\n\n    The configuration contains all the information needed to reconstruct\n    the connector object.\n    \"\"\"\n    return {\n        'hostname': self.hostname,\n        'port': self.port,\n        'clear': self.clear,\n    }\n</code></pre>"},{"location":"api/connectors/redis/#proxystore.connectors.redis.RedisConnector.from_config","title":"from_config()  <code>classmethod</code>","text":"<pre><code>from_config(config: dict[str, Any]) -&gt; RedisConnector\n</code></pre> <p>Create a new connector instance from a configuration.</p> <p>Parameters:</p> <ul> <li> <code>config</code>             (<code>dict[str, Any]</code>)         \u2013          <p>Configuration returned by <code>.config()</code>.</p> </li> </ul> Source code in <code>proxystore/connectors/redis.py</code> <pre><code>@classmethod\ndef from_config(cls, config: dict[str, Any]) -&gt; RedisConnector:\n    \"\"\"Create a new connector instance from a configuration.\n\n    Args:\n        config: Configuration returned by `#!python .config()`.\n    \"\"\"\n    return cls(**config)\n</code></pre>"},{"location":"api/connectors/redis/#proxystore.connectors.redis.RedisConnector.evict","title":"evict()","text":"<pre><code>evict(key: RedisKey) -&gt; None\n</code></pre> <p>Evict the object associated with the key.</p> <p>Parameters:</p> <ul> <li> <code>key</code>             (<code>RedisKey</code>)         \u2013          <p>Key associated with object to evict.</p> </li> </ul> Source code in <code>proxystore/connectors/redis.py</code> <pre><code>def evict(self, key: RedisKey) -&gt; None:\n    \"\"\"Evict the object associated with the key.\n\n    Args:\n        key: Key associated with object to evict.\n    \"\"\"\n    self._redis_client.delete(key.redis_key)\n</code></pre>"},{"location":"api/connectors/redis/#proxystore.connectors.redis.RedisConnector.exists","title":"exists()","text":"<pre><code>exists(key: RedisKey) -&gt; bool\n</code></pre> <p>Check if an object associated with the key exists.</p> <p>Parameters:</p> <ul> <li> <code>key</code>             (<code>RedisKey</code>)         \u2013          <p>Key potentially associated with stored object.</p> </li> </ul> <p>Returns:</p> <ul> <li> <code>bool</code>         \u2013          <p>If an object associated with the key exists.</p> </li> </ul> Source code in <code>proxystore/connectors/redis.py</code> <pre><code>def exists(self, key: RedisKey) -&gt; bool:\n    \"\"\"Check if an object associated with the key exists.\n\n    Args:\n        key: Key potentially associated with stored object.\n\n    Returns:\n        If an object associated with the key exists.\n    \"\"\"\n    return bool(self._redis_client.exists(key.redis_key))\n</code></pre>"},{"location":"api/connectors/redis/#proxystore.connectors.redis.RedisConnector.get","title":"get()","text":"<pre><code>get(key: RedisKey) -&gt; bytes | None\n</code></pre> <p>Get the serialized object associated with the key.</p> <p>Parameters:</p> <ul> <li> <code>key</code>             (<code>RedisKey</code>)         \u2013          <p>Key associated with the object to retrieve.</p> </li> </ul> <p>Returns:</p> <ul> <li> <code>bytes | None</code>         \u2013          <p>Serialized object or <code>None</code> if the object does not exist.</p> </li> </ul> Source code in <code>proxystore/connectors/redis.py</code> <pre><code>def get(self, key: RedisKey) -&gt; bytes | None:\n    \"\"\"Get the serialized object associated with the key.\n\n    Args:\n        key: Key associated with the object to retrieve.\n\n    Returns:\n        Serialized object or `None` if the object does not exist.\n    \"\"\"\n    return self._redis_client.get(key.redis_key)\n</code></pre>"},{"location":"api/connectors/redis/#proxystore.connectors.redis.RedisConnector.get_batch","title":"get_batch()","text":"<pre><code>get_batch(keys: Sequence[RedisKey]) -&gt; list[bytes | None]\n</code></pre> <p>Get a batch of serialized objects associated with the keys.</p> <p>Parameters:</p> <ul> <li> <code>keys</code>             (<code>Sequence[RedisKey]</code>)         \u2013          <p>Sequence of keys associated with objects to retrieve.</p> </li> </ul> <p>Returns:</p> <ul> <li> <code>list[bytes | None]</code>         \u2013          <p>List with same order as <code>keys</code> with the serialized objects or             <code>None</code> if the corresponding key does not have an associated object.</p> </li> </ul> Source code in <code>proxystore/connectors/redis.py</code> <pre><code>def get_batch(self, keys: Sequence[RedisKey]) -&gt; list[bytes | None]:\n    \"\"\"Get a batch of serialized objects associated with the keys.\n\n    Args:\n        keys: Sequence of keys associated with objects to retrieve.\n\n    Returns:\n        List with same order as `keys` with the serialized objects or \\\n        `None` if the corresponding key does not have an associated object.\n    \"\"\"\n    return self._redis_client.mget([key.redis_key for key in keys])\n</code></pre>"},{"location":"api/connectors/redis/#proxystore.connectors.redis.RedisConnector.new_key","title":"new_key()","text":"<pre><code>new_key(obj: bytes | None = None) -&gt; RedisKey\n</code></pre> <p>Create a new key.</p> <p>Parameters:</p> <ul> <li> <code>obj</code>             (<code>bytes | None</code>, default:                 <code>None</code> )         \u2013          <p>Optional object which the key will be associated with. Ignored in this implementation.</p> </li> </ul> <p>Returns:</p> <ul> <li> <code>RedisKey</code>         \u2013          <p>Key which can be used to retrieve an object once             <code>set()</code>             has been called on the key.</p> </li> </ul> Source code in <code>proxystore/connectors/redis.py</code> <pre><code>def new_key(self, obj: bytes | None = None) -&gt; RedisKey:\n    \"\"\"Create a new key.\n\n    Args:\n        obj: Optional object which the key will be associated with.\n            Ignored in this implementation.\n\n    Returns:\n        Key which can be used to retrieve an object once \\\n        [`set()`][proxystore.connectors.redis.RedisConnector.set] \\\n        has been called on the key.\n    \"\"\"\n    return RedisKey(redis_key=str(uuid.uuid4()))\n</code></pre>"},{"location":"api/connectors/redis/#proxystore.connectors.redis.RedisConnector.put","title":"put()","text":"<pre><code>put(obj: bytes) -&gt; RedisKey\n</code></pre> <p>Put a serialized object in the store.</p> <p>Parameters:</p> <ul> <li> <code>obj</code>             (<code>bytes</code>)         \u2013          <p>Serialized object to put in the store.</p> </li> </ul> <p>Returns:</p> <ul> <li> <code>RedisKey</code>         \u2013          <p>Key which can be used to retrieve the object.</p> </li> </ul> Source code in <code>proxystore/connectors/redis.py</code> <pre><code>def put(self, obj: bytes) -&gt; RedisKey:\n    \"\"\"Put a serialized object in the store.\n\n    Args:\n        obj: Serialized object to put in the store.\n\n    Returns:\n        Key which can be used to retrieve the object.\n    \"\"\"\n    key = RedisKey(redis_key=str(uuid.uuid4()))\n    self._redis_client.set(key.redis_key, obj)\n    return key\n</code></pre>"},{"location":"api/connectors/redis/#proxystore.connectors.redis.RedisConnector.put_batch","title":"put_batch()","text":"<pre><code>put_batch(objs: Sequence[bytes]) -&gt; list[RedisKey]\n</code></pre> <p>Put a batch of serialized objects in the store.</p> <p>Parameters:</p> <ul> <li> <code>objs</code>             (<code>Sequence[bytes]</code>)         \u2013          <p>Sequence of serialized objects to put in the store.</p> </li> </ul> <p>Returns:</p> <ul> <li> <code>list[RedisKey]</code>         \u2013          <p>List of keys with the same order as <code>objs</code> which can be used to             retrieve the objects.</p> </li> </ul> Source code in <code>proxystore/connectors/redis.py</code> <pre><code>def put_batch(self, objs: Sequence[bytes]) -&gt; list[RedisKey]:\n    \"\"\"Put a batch of serialized objects in the store.\n\n    Args:\n        objs: Sequence of serialized objects to put in the store.\n\n    Returns:\n        List of keys with the same order as `objs` which can be used to \\\n        retrieve the objects.\n    \"\"\"\n    keys = [RedisKey(redis_key=str(uuid.uuid4())) for _ in objs]\n    self._redis_client.mset(\n        {key.redis_key: obj for key, obj in zip(keys, objs)},\n    )\n    return keys\n</code></pre>"},{"location":"api/connectors/redis/#proxystore.connectors.redis.RedisConnector.set","title":"set()","text":"<pre><code>set(key: RedisKey, obj: bytes) -&gt; None\n</code></pre> <p>Set the object associated with a key.</p> Note <p>The <code>Connector</code> provides write-once, read-many semantics. Thus, <code>set()</code> should only be called once per key, otherwise unexpected behavior can occur.</p> <p>Parameters:</p> <ul> <li> <code>key</code>             (<code>RedisKey</code>)         \u2013          <p>Key that the object will be associated with.</p> </li> <li> <code>obj</code>             (<code>bytes</code>)         \u2013          <p>Object to associate with the key.</p> </li> </ul> Source code in <code>proxystore/connectors/redis.py</code> <pre><code>def set(self, key: RedisKey, obj: bytes) -&gt; None:\n    \"\"\"Set the object associated with a key.\n\n    Note:\n        The [`Connector`][proxystore.connectors.protocols.Connector]\n        provides write-once, read-many semantics. Thus,\n        [`set()`][proxystore.connectors.redis.RedisConnector.set]\n        should only be called once per key, otherwise unexpected behavior\n        can occur.\n\n    Args:\n        key: Key that the object will be associated with.\n        obj: Object to associate with the key.\n    \"\"\"\n    self._redis_client.set(key.redis_key, obj)\n</code></pre>"},{"location":"api/endpoint/","title":"proxystore.endpoint","text":"<code>proxystore/endpoint/__init__.py</code> <p>Endpoints for direct, cross-site communication.</p> Note <p>Please refer to the Endpoints Guide for an introduction to endpoints in ProxyStore.</p> <p><code>Endpoints</code> are in-memory object stores with peering capabilities. Endpoints enable peer-to-peer data transfer between clients behind different NATs. See the <code>proxystore-endpoint</code> CLI reference to start your own endpoints.</p>"},{"location":"api/endpoint/cli/","title":"proxystore.endpoint.cli","text":"<code>proxystore/endpoint/cli.py</code> <p><code>proxystore-endpoint</code> command-line interface.</p> <p>See the CLI Reference for the <code>proxystore-endpoint</code> usage instructions.</p>"},{"location":"api/endpoint/cli/#proxystore.endpoint.cli.cli","title":"cli()","text":"<pre><code>cli(ctx: Context, log_level: str) -&gt; None\n</code></pre> <p>Manage and start ProxyStore Endpoints.</p> Source code in <code>proxystore/endpoint/cli.py</code> <pre><code>@click.group()\n@click.option(\n    '--log-level',\n    default='INFO',\n    type=click.Choice(\n        ['ERROR', 'WARNING', 'INFO', 'DEBUG'],\n        case_sensitive=False,\n    ),\n    help='Minimum logging level.',\n)\n@click.pass_context\ndef cli(ctx: click.Context, log_level: str) -&gt; None:\n    \"\"\"Manage and start ProxyStore Endpoints.\"\"\"\n    handler = logging.StreamHandler(sys.stdout)\n    handler.setFormatter(_CLIFormatter())\n    logging.basicConfig(level=log_level, handlers=[handler])\n    ctx.ensure_object(dict)\n    ctx.obj['LOG_LEVEL'] = log_level\n</code></pre>"},{"location":"api/endpoint/cli/#proxystore.endpoint.cli.show_help","title":"show_help()","text":"<pre><code>show_help() -&gt; None\n</code></pre> <p>Show available commands and options.</p> Source code in <code>proxystore/endpoint/cli.py</code> <pre><code>@cli.command(name='help')\ndef show_help() -&gt; None:\n    \"\"\"Show available commands and options.\"\"\"\n    with click.Context(cli) as ctx:\n        click.echo(cli.get_help(ctx))\n</code></pre>"},{"location":"api/endpoint/cli/#proxystore.endpoint.cli.version","title":"version()","text":"<pre><code>version() -&gt; None\n</code></pre> <p>Show the ProxyStore version.</p> Source code in <code>proxystore/endpoint/cli.py</code> <pre><code>@cli.command()\ndef version() -&gt; None:\n    \"\"\"Show the ProxyStore version.\"\"\"\n    click.echo(f'ProxyStore v{proxystore.__version__}')\n</code></pre>"},{"location":"api/endpoint/cli/#proxystore.endpoint.cli.check_nat_command","title":"check_nat_command()","text":"<pre><code>check_nat_command(host: str, port: int) -&gt; None\n</code></pre> <p>Check the type of NAT you are behind.</p> Source code in <code>proxystore/endpoint/cli.py</code> <pre><code>@cli.command(name='check-nat')\n@click.option(\n    '--host',\n    default='0.0.0.0',\n    metavar='ADDR',\n    help='Network interface address to listen on.',\n)\n@click.option(\n    '--port',\n    default=54320,\n    type=int,\n    metavar='PORT',\n    help='Port to listen on.',\n)\ndef check_nat_command(host: str, port: int) -&gt; None:\n    \"\"\"Check the type of NAT you are behind.\"\"\"\n    check_nat_and_log(host, port)\n</code></pre>"},{"location":"api/endpoint/cli/#proxystore.endpoint.cli.configure","title":"configure()","text":"<pre><code>configure(\n    name: str,\n    port: int,\n    relay_address: str,\n    relay_auth: bool,\n    relay_server: bool,\n    peer_channels: int,\n    persist: bool,\n) -&gt; None\n</code></pre> <p>Configure a new endpoint.</p> Source code in <code>proxystore/endpoint/cli.py</code> <pre><code>@cli.command()\n@click.argument('name', metavar='NAME', required=True)\n@click.option(\n    '--port',\n    default=8765,\n    type=int,\n    metavar='PORT',\n    help='Port to listen on.',\n)\n@click.option(\n    '--relay-address',\n    default='wss://relay.proxystore.dev',\n    metavar='ADDR',\n    help='Relay server address.',\n)\n@click.option(\n    '--relay-auth/--no-relay-auth',\n    default=True,\n    metavar='BOOL',\n    help='Disable relay server authentication.',\n)\n@click.option(\n    '--relay-server/--no-relay-server',\n    default=True,\n    metavar='BOOL',\n    help='Disable connecting to the relay server on start.',\n)\n@click.option(\n    '--peer-channels',\n    default=1,\n    type=int,\n    metavar='COUNT',\n    help='Datachannels to use per peer connection.',\n)\n@click.option(\n    '--persist/--no-persist',\n    default=False,\n    metavar='BOOL',\n    help='Optionally persist data to a database.',\n)\ndef configure(\n    name: str,\n    port: int,\n    relay_address: str,\n    relay_auth: bool,\n    relay_server: bool,\n    peer_channels: int,\n    persist: bool,\n) -&gt; None:\n    \"\"\"Configure a new endpoint.\"\"\"\n    raise SystemExit(\n        configure_endpoint(\n            name,\n            port=port,\n            relay_server=relay_address if relay_server else None,\n            relay_auth=relay_auth,\n            peer_channels=peer_channels,\n            persist_data=persist,\n        ),\n    )\n</code></pre>"},{"location":"api/endpoint/cli/#proxystore.endpoint.cli.list_all","title":"list_all()","text":"<pre><code>list_all() -&gt; None\n</code></pre> <p>List all user endpoints.</p> Source code in <code>proxystore/endpoint/cli.py</code> <pre><code>@cli.command(name='list')\ndef list_all() -&gt; None:\n    \"\"\"List all user endpoints.\"\"\"\n    raise SystemExit(list_endpoints())\n</code></pre>"},{"location":"api/endpoint/cli/#proxystore.endpoint.cli.remove","title":"remove()","text":"<pre><code>remove(name: str) -&gt; None\n</code></pre> <p>Remove an endpoint.</p> Source code in <code>proxystore/endpoint/cli.py</code> <pre><code>@cli.command()\n@click.argument('name', metavar='NAME', required=True)\ndef remove(name: str) -&gt; None:\n    \"\"\"Remove an endpoint.\"\"\"\n    raise SystemExit(remove_endpoint(name))\n</code></pre>"},{"location":"api/endpoint/cli/#proxystore.endpoint.cli.start","title":"start()","text":"<pre><code>start(ctx: Context, name: str, detach: bool) -&gt; None\n</code></pre> <p>Start an endpoint.</p> Source code in <code>proxystore/endpoint/cli.py</code> <pre><code>@cli.command()\n@click.argument('name', metavar='NAME', required=True)\n@click.option('--detach/--no-detach', default=True, help='Run as daemon.')\n@click.pass_context\ndef start(ctx: click.Context, name: str, detach: bool) -&gt; None:\n    \"\"\"Start an endpoint.\"\"\"\n    raise SystemExit(\n        start_endpoint(name, detach=detach, log_level=ctx.obj['LOG_LEVEL']),\n    )\n</code></pre>"},{"location":"api/endpoint/cli/#proxystore.endpoint.cli.stop","title":"stop()","text":"<pre><code>stop(name: str) -&gt; None\n</code></pre> <p>Stop a detached endpoint.</p> Source code in <code>proxystore/endpoint/cli.py</code> <pre><code>@cli.command()\n@click.argument('name', metavar='NAME', required=True)\ndef stop(name: str) -&gt; None:\n    \"\"\"Stop a detached endpoint.\"\"\"\n    raise SystemExit(stop_endpoint(name))\n</code></pre>"},{"location":"api/endpoint/cli/#proxystore.endpoint.cli.test","title":"test()","text":"<pre><code>test(ctx: Context, name: str, remote: str | None) -&gt; None\n</code></pre> <p>Execute test commands on an endpoint.</p> Source code in <code>proxystore/endpoint/cli.py</code> <pre><code>@cli.group()\n@click.argument('name', metavar='NAME', required=True)\n@click.option(\n    '--remote',\n    metavar='UUID',\n    help='Optional UUID of remote endpoint to use.',\n)\n@click.pass_context\ndef test(\n    ctx: click.Context,\n    name: str,\n    remote: str | None,\n) -&gt; None:\n    \"\"\"Execute test commands on an endpoint.\"\"\"\n    ctx.ensure_object(dict)\n\n    proxystore_dir = home_dir()\n    endpoint_dir = os.path.join(proxystore_dir, name)\n    if os.path.isdir(endpoint_dir):\n        cfg = read_config(endpoint_dir)\n    else:\n        logger.error(f'An endpoint named {name} does not exist.')\n        raise SystemExit(1)\n\n    ctx.obj['ENDPOINT_ADDRESS'] = f'http://{cfg.host}:{cfg.port}'\n    ctx.obj['REMOTE_ENDPOINT_UUID'] = remote\n</code></pre>"},{"location":"api/endpoint/cli/#proxystore.endpoint.cli.evict","title":"evict()","text":"<pre><code>evict(ctx: Context, key: str) -&gt; None\n</code></pre> <p>Evict object from an endpoint.</p> Source code in <code>proxystore/endpoint/cli.py</code> <pre><code>@test.command()\n@click.argument('key', metavar='KEY', required=True)\n@click.pass_context\ndef evict(ctx: click.Context, key: str) -&gt; None:\n    \"\"\"Evict object from an endpoint.\"\"\"\n    address = ctx.obj['ENDPOINT_ADDRESS']\n    remote = ctx.obj['REMOTE_ENDPOINT_UUID']\n    try:\n        client.evict(address, key, remote)\n    except requests.exceptions.ConnectionError as e:\n        logger.error(f'Unable to connect to endpoint at {address}.')\n        logger.debug(e)\n        sys.exit(1)\n    except requests.exceptions.RequestException as e:\n        logger.error(e)\n        sys.exit(1)\n    else:\n        logger.info('Evicted object from endpoint.')\n</code></pre>"},{"location":"api/endpoint/cli/#proxystore.endpoint.cli.exists","title":"exists()","text":"<pre><code>exists(ctx: Context, key: str) -&gt; None\n</code></pre> <p>Check if object exists in an endpoint.</p> Source code in <code>proxystore/endpoint/cli.py</code> <pre><code>@test.command()\n@click.argument('key', metavar='KEY', required=True)\n@click.pass_context\ndef exists(ctx: click.Context, key: str) -&gt; None:\n    \"\"\"Check if object exists in an endpoint.\"\"\"\n    address = ctx.obj['ENDPOINT_ADDRESS']\n    remote = ctx.obj['REMOTE_ENDPOINT_UUID']\n    try:\n        res = client.exists(address, key, remote)\n    except requests.exceptions.ConnectionError as e:\n        logger.error(f'Unable to connect to endpoint at {address}.')\n        logger.debug(e)\n        sys.exit(1)\n    except requests.exceptions.RequestException as e:\n        logger.error(e)\n        sys.exit(1)\n    else:\n        logger.info(f'Object exists: {res}')\n</code></pre>"},{"location":"api/endpoint/cli/#proxystore.endpoint.cli.get","title":"get()","text":"<pre><code>get(ctx: Context, key: str) -&gt; None\n</code></pre> <p>Get an object from an endpoint.</p> Source code in <code>proxystore/endpoint/cli.py</code> <pre><code>@test.command()\n@click.argument('key', metavar='KEY', required=True)\n@click.pass_context\ndef get(ctx: click.Context, key: str) -&gt; None:\n    \"\"\"Get an object from an endpoint.\"\"\"\n    address = ctx.obj['ENDPOINT_ADDRESS']\n    remote = ctx.obj['REMOTE_ENDPOINT_UUID']\n    try:\n        res = client.get(address, key, remote)\n    except requests.exceptions.ConnectionError as e:\n        logger.error(f'Unable to connect to endpoint at {address}.')\n        logger.debug(e)\n        sys.exit(1)\n    except requests.exceptions.RequestException as e:\n        logger.error(e)\n        sys.exit(1)\n\n    if res is None:\n        logger.info('Object does not exist.')\n    else:\n        obj = deserialize(res)\n        logger.info(f'Result: {obj}')\n</code></pre>"},{"location":"api/endpoint/cli/#proxystore.endpoint.cli.put","title":"put()","text":"<pre><code>put(ctx: Context, data: str) -&gt; None\n</code></pre> <p>Put an object in an endpoint.</p> Source code in <code>proxystore/endpoint/cli.py</code> <pre><code>@test.command()\n@click.argument('data', required=True)\n@click.pass_context\ndef put(ctx: click.Context, data: str) -&gt; None:\n    \"\"\"Put an object in an endpoint.\"\"\"\n    address = ctx.obj['ENDPOINT_ADDRESS']\n    remote = ctx.obj['REMOTE_ENDPOINT_UUID']\n    key = str(uuid.uuid4())\n    data_ = serialize(data)\n    try:\n        client.put(address, key, data_, remote)\n    except requests.exceptions.ConnectionError as e:\n        logger.error(f'Unable to connect to endpoint at {address}.')\n        logger.debug(e)\n        sys.exit(1)\n    except requests.exceptions.RequestException as e:\n        logger.error(e)\n        sys.exit(1)\n    else:\n        logger.info(f'Put object in endpoint with key {key}')\n</code></pre>"},{"location":"api/endpoint/client/","title":"proxystore.endpoint.client","text":"<code>proxystore/endpoint/client.py</code> <p>Utilities for client interactions with endpoints.</p>"},{"location":"api/endpoint/client/#proxystore.endpoint.client.evict","title":"evict()","text":"<pre><code>evict(\n    address: str,\n    key: str,\n    endpoint: UUID | str | None = None,\n    session: Session | None = None,\n) -&gt; None\n</code></pre> <p>Evict the object associated with the key.</p> <p>Parameters:</p> <ul> <li> <code>address</code>             (<code>str</code>)         \u2013          <p>Address of endpoint.</p> </li> <li> <code>key</code>             (<code>str</code>)         \u2013          <p>Key associated with object to evict.</p> </li> <li> <code>endpoint</code>             (<code>UUID | str | None</code>, default:                 <code>None</code> )         \u2013          <p>Optional UUID of remote endpoint to forward operation to.</p> </li> <li> <code>session</code>             (<code>Session | None</code>, default:                 <code>None</code> )         \u2013          <p>Session instance to use for making the request. Reusing the same session across multiple requests to the same host can improve performance.</p> </li> </ul> <p>Raises:</p> <ul> <li> <code>RequestException</code>           \u2013          <p>If the endpoint request results in an unexpected error code.</p> </li> </ul> Source code in <code>proxystore/endpoint/client.py</code> <pre><code>def evict(\n    address: str,\n    key: str,\n    endpoint: uuid.UUID | str | None = None,\n    session: requests.Session | None = None,\n) -&gt; None:\n    \"\"\"Evict the object associated with the key.\n\n    Args:\n        address: Address of endpoint.\n        key: Key associated with object to evict.\n        endpoint: Optional UUID of remote endpoint to forward operation to.\n        session: Session instance to use for making the request. Reusing the\n            same session across multiple requests to the same host can improve\n            performance.\n\n    Raises:\n        RequestException: If the endpoint request results in an unexpected\n            error code.\n    \"\"\"\n    endpoint_str = (\n        str(endpoint) if isinstance(endpoint, uuid.UUID) else endpoint\n    )\n    post = requests.post if session is None else session.post\n    response = post(\n        f'{address}/evict',\n        params={'key': key, 'endpoint': endpoint_str},\n    )\n    if not response.ok:\n        raise requests.exceptions.RequestException(\n            f'Endpoint returned HTTP error code {response.status_code}. '\n            f'{response.text}',\n            response=response,\n        )\n</code></pre>"},{"location":"api/endpoint/client/#proxystore.endpoint.client.exists","title":"exists()","text":"<pre><code>exists(\n    address: str,\n    key: str,\n    endpoint: UUID | str | None = None,\n    session: Session | None = None,\n) -&gt; bool\n</code></pre> <p>Check if an object associated with the key exists.</p> <p>Parameters:</p> <ul> <li> <code>address</code>             (<code>str</code>)         \u2013          <p>Address of endpoint.</p> </li> <li> <code>key</code>             (<code>str</code>)         \u2013          <p>Key potentially associated with stored object.</p> </li> <li> <code>endpoint</code>             (<code>UUID | str | None</code>, default:                 <code>None</code> )         \u2013          <p>Optional UUID of remote endpoint to forward operation to.</p> </li> <li> <code>session</code>             (<code>Session | None</code>, default:                 <code>None</code> )         \u2013          <p>Session instance to use for making the request. Reusing the same session across multiple requests to the same host can improve performance.</p> </li> </ul> <p>Returns:</p> <ul> <li> <code>bool</code>         \u2013          <p>If an object associated with the key exists.</p> </li> </ul> <p>Raises:</p> <ul> <li> <code>RequestException</code>           \u2013          <p>If the endpoint request results in an unexpected error code.</p> </li> </ul> Source code in <code>proxystore/endpoint/client.py</code> <pre><code>def exists(\n    address: str,\n    key: str,\n    endpoint: uuid.UUID | str | None = None,\n    session: requests.Session | None = None,\n) -&gt; bool:\n    \"\"\"Check if an object associated with the key exists.\n\n    Args:\n        address: Address of endpoint.\n        key: Key potentially associated with stored object.\n        endpoint: Optional UUID of remote endpoint to forward operation to.\n        session: Session instance to use for making the request. Reusing the\n            same session across multiple requests to the same host can improve\n            performance.\n\n    Returns:\n        If an object associated with the key exists.\n\n    Raises:\n        RequestException: If the endpoint request results in an unexpected\n            error code.\n    \"\"\"\n    endpoint_str = (\n        str(endpoint) if isinstance(endpoint, uuid.UUID) else endpoint\n    )\n    get_ = requests.get if session is None else session.get\n    response = get_(\n        f'{address}/exists',\n        params={'key': key, 'endpoint': endpoint_str},\n    )\n    if not response.ok:\n        raise requests.exceptions.RequestException(\n            f'Endpoint returned HTTP error code {response.status_code}. '\n            f'{response.text}',\n            response=response,\n        )\n    return response.json()['exists']\n</code></pre>"},{"location":"api/endpoint/client/#proxystore.endpoint.client.get","title":"get()","text":"<pre><code>get(\n    address: str,\n    key: str,\n    endpoint: UUID | str | None = None,\n    session: Session | None = None,\n) -&gt; bytes | None\n</code></pre> <p>Get the serialized object associated with the key.</p> <p>Parameters:</p> <ul> <li> <code>address</code>             (<code>str</code>)         \u2013          <p>Address of endpoint.</p> </li> <li> <code>key</code>             (<code>str</code>)         \u2013          <p>Key associated with object to retrieve.</p> </li> <li> <code>endpoint</code>             (<code>UUID | str | None</code>, default:                 <code>None</code> )         \u2013          <p>Optional UUID of remote endpoint to forward operation to.</p> </li> <li> <code>session</code>             (<code>Session | None</code>, default:                 <code>None</code> )         \u2013          <p>Session instance to use for making the request. Reusing the same session across multiple requests to the same host can improve performance.</p> </li> </ul> <p>Returns:</p> <ul> <li> <code>bytes | None</code>         \u2013          <p>Serialized object or <code>None</code> if the object does not exist.</p> </li> </ul> <p>Raises:</p> <ul> <li> <code>RequestException</code>           \u2013          <p>If the endpoint request results in an unexpected error code.</p> </li> </ul> Source code in <code>proxystore/endpoint/client.py</code> <pre><code>def get(\n    address: str,\n    key: str,\n    endpoint: uuid.UUID | str | None = None,\n    session: requests.Session | None = None,\n) -&gt; bytes | None:\n    \"\"\"Get the serialized object associated with the key.\n\n    Args:\n        address: Address of endpoint.\n        key: Key associated with object to retrieve.\n        endpoint: Optional UUID of remote endpoint to forward operation to.\n        session: Session instance to use for making the request. Reusing the\n            same session across multiple requests to the same host can improve\n            performance.\n\n    Returns:\n        Serialized object or `None` if the object does not exist.\n\n    Raises:\n        RequestException: If the endpoint request results in an unexpected\n            error code.\n    \"\"\"\n    endpoint_str = (\n        str(endpoint) if isinstance(endpoint, uuid.UUID) else endpoint\n    )\n    get_ = requests.get if session is None else session.get\n    response = get_(\n        f'{address}/get',\n        params={'key': key, 'endpoint': endpoint_str},\n        stream=True,\n    )\n\n    # Status code 404 is only returned if there's no data associated with the\n    # provided key.\n    if response.status_code == 404:\n        return None\n\n    if not response.ok:\n        raise requests.exceptions.RequestException(\n            f'Endpoint returned HTTP error code {response.status_code}. '\n            f'{response.text}',\n            response=response,\n        )\n\n    data = bytearray()\n    for chunk in response.iter_content(chunk_size=None):\n        data += chunk\n    return bytes(data)\n</code></pre>"},{"location":"api/endpoint/client/#proxystore.endpoint.client.put","title":"put()","text":"<pre><code>put(\n    address: str,\n    key: str,\n    data: bytes,\n    endpoint: UUID | str | None = None,\n    session: Session | None = None,\n) -&gt; None\n</code></pre> <p>Put a serialized object in the store.</p> <p>Parameters:</p> <ul> <li> <code>address</code>             (<code>str</code>)         \u2013          <p>Address of endpoint.</p> </li> <li> <code>key</code>             (<code>str</code>)         \u2013          <p>Key associated with object to retrieve.</p> </li> <li> <code>data</code>             (<code>bytes</code>)         \u2013          <p>Serialized data to put in the store.</p> </li> <li> <code>endpoint</code>             (<code>UUID | str | None</code>, default:                 <code>None</code> )         \u2013          <p>Optional UUID of remote endpoint to forward operation to.</p> </li> <li> <code>session</code>             (<code>Session | None</code>, default:                 <code>None</code> )         \u2013          <p>Session instance to use for making the request. Reusing the same session across multiple requests to the same host can improve performance.</p> </li> </ul> <p>Raises:</p> <ul> <li> <code>RequestException</code>           \u2013          <p>If the endpoint request results in an unexpected error code.</p> </li> </ul> Source code in <code>proxystore/endpoint/client.py</code> <pre><code>def put(\n    address: str,\n    key: str,\n    data: bytes,\n    endpoint: uuid.UUID | str | None = None,\n    session: requests.Session | None = None,\n) -&gt; None:\n    \"\"\"Put a serialized object in the store.\n\n    Args:\n        address: Address of endpoint.\n        key: Key associated with object to retrieve.\n        data: Serialized data to put in the store.\n        endpoint: Optional UUID of remote endpoint to forward operation to.\n        session: Session instance to use for making the request. Reusing the\n            same session across multiple requests to the same host can improve\n            performance.\n\n    Raises:\n        RequestException: If the endpoint request results in an unexpected\n            error code.\n    \"\"\"\n    endpoint_str = (\n        str(endpoint) if isinstance(endpoint, uuid.UUID) else endpoint\n    )\n    post = requests.post if session is None else session.post\n    response = post(\n        f'{address}/set',\n        headers={'Content-Type': 'application/octet-stream'},\n        params={'key': key, 'endpoint': endpoint_str},\n        data=chunk_bytes(data, MAX_CHUNK_LENGTH),\n        stream=True,\n    )\n    if not response.ok:\n        raise requests.exceptions.RequestException(\n            f'Endpoint returned HTTP error code {response.status_code}. '\n            f'{response.text}',\n            response=response,\n        )\n</code></pre>"},{"location":"api/endpoint/commands/","title":"proxystore.endpoint.commands","text":"<code>proxystore/endpoint/commands.py</code> <p>Endpoint management commands.</p> <p>These are the implementations of the commands available via the <code>proxystore-endpoint</code> command. Subsequently, all commands log errors and results and return status codes (rather than raising errors and returning results).</p>"},{"location":"api/endpoint/commands/#proxystore.endpoint.commands.EndpointStatus","title":"EndpointStatus","text":"<p>             Bases: <code>Enum</code></p> <p>Endpoint status.</p>"},{"location":"api/endpoint/commands/#proxystore.endpoint.commands.EndpointStatus.RUNNING","title":"RUNNING  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>RUNNING = auto()\n</code></pre> <p>Endpoint is running on this host.</p>"},{"location":"api/endpoint/commands/#proxystore.endpoint.commands.EndpointStatus.STOPPED","title":"STOPPED  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>STOPPED = auto()\n</code></pre> <p>Endpoint is stopped.</p>"},{"location":"api/endpoint/commands/#proxystore.endpoint.commands.EndpointStatus.UNKNOWN","title":"UNKNOWN  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>UNKNOWN = auto()\n</code></pre> <p>Endpoint cannot be found (missing/corrupted directory).</p>"},{"location":"api/endpoint/commands/#proxystore.endpoint.commands.EndpointStatus.HANGING","title":"HANGING  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>HANGING = auto()\n</code></pre> <p>Endpoint PID file exists but process is not active.</p> <p>This is either because the process died unexpectedly or the endpoint is running on another host.</p>"},{"location":"api/endpoint/commands/#proxystore.endpoint.commands.get_status","title":"get_status()","text":"<pre><code>get_status(\n    name: str, proxystore_dir: str | None = None\n) -&gt; EndpointStatus\n</code></pre> <p>Check status of endpoint.</p> <p>Parameters:</p> <ul> <li> <code>name</code>             (<code>str</code>)         \u2013          <p>Name of endpoint to check.</p> </li> <li> <code>proxystore_dir</code>             (<code>str | None</code>, default:                 <code>None</code> )         \u2013          <p>Optionally specify the proxystore home directory. Defaults to <code>home_dir()</code>.</p> </li> </ul> <p>Returns:</p> <ul> <li> <code>EndpointStatus</code>         \u2013          <p><code>EndpointStatus.RUNNING</code> if the endpoint has a valid directory and         the PID file points to a running process.         <code>EndpointStatus.STOPPED</code> if the endpoint has a valid directory and no         PID file.         <code>EndpointStatus.UNKNOWN</code> if the endpoint directory is missing or the         config file is missing/unreadable.         <code>EndpointStatus.HANGING</code> if the endpoint has a valid directory but         the PID file does not point to a running process. This can be due to         the endpoint process dying unexpectedly or the endpoint process is on         a different host.</p> </li> </ul> Source code in <code>proxystore/endpoint/commands.py</code> <pre><code>def get_status(name: str, proxystore_dir: str | None = None) -&gt; EndpointStatus:\n    \"\"\"Check status of endpoint.\n\n    Args:\n        name: Name of endpoint to check.\n        proxystore_dir: Optionally specify the proxystore home directory.\n            Defaults to [`home_dir()`][proxystore.utils.environment.home_dir].\n\n    Returns:\n        `EndpointStatus.RUNNING` if the endpoint has a valid directory and \\\n        the PID file points to a running process. \\\n        `EndpointStatus.STOPPED` if the endpoint has a valid directory and no \\\n        PID file. \\\n        `EndpointStatus.UNKNOWN` if the endpoint directory is missing or the \\\n        config file is missing/unreadable. \\\n        `EndpointStatus.HANGING` if the endpoint has a valid directory but \\\n        the PID file does not point to a running process. This can be due to \\\n        the endpoint process dying unexpectedly or the endpoint process is on \\\n        a different host.\n    \"\"\"\n    if proxystore_dir is None:\n        proxystore_dir = home_dir()\n\n    endpoint_dir = os.path.join(proxystore_dir, name)\n    if not os.path.isdir(endpoint_dir):\n        return EndpointStatus.UNKNOWN\n\n    try:\n        read_config(endpoint_dir)\n    except (FileNotFoundError, ValueError) as e:\n        logger.error(e)\n        return EndpointStatus.UNKNOWN\n\n    pid_file = get_pid_filepath(endpoint_dir)\n    if not os.path.isfile(pid_file):\n        return EndpointStatus.STOPPED\n\n    with open(pid_file) as f:\n        pid = int(f.read().strip())\n\n    if psutil.pid_exists(pid):\n        return EndpointStatus.RUNNING\n    else:\n        return EndpointStatus.HANGING\n</code></pre>"},{"location":"api/endpoint/commands/#proxystore.endpoint.commands.configure_endpoint","title":"configure_endpoint()","text":"<pre><code>configure_endpoint(\n    name: str,\n    *,\n    port: int,\n    relay_server: str | None,\n    relay_auth: bool = True,\n    proxystore_dir: str | None = None,\n    peer_channels: int = 1,\n    persist_data: bool = False\n) -&gt; int\n</code></pre> <p>Configure a new endpoint.</p> <p>Parameters:</p> <ul> <li> <code>name</code>             (<code>str</code>)         \u2013          <p>Name of endpoint.</p> </li> <li> <code>port</code>             (<code>int</code>)         \u2013          <p>Port for endpoint to listen on.</p> </li> <li> <code>relay_server</code>             (<code>str | None</code>)         \u2013          <p>Optional relay server address for P2P endpoint connections.</p> </li> <li> <code>relay_auth</code>             (<code>bool</code>, default:                 <code>True</code> )         \u2013          <p>Relay server used Globus Auth.</p> </li> <li> <code>proxystore_dir</code>             (<code>str | None</code>, default:                 <code>None</code> )         \u2013          <p>Optionally specify the proxystore home directory. Defaults to <code>home_dir()</code>.</p> </li> <li> <code>peer_channels</code>             (<code>int</code>, default:                 <code>1</code> )         \u2013          <p>Number of datachannels per peer connection to another endpoint to communicate over.</p> </li> <li> <code>persist_data</code>             (<code>bool</code>, default:                 <code>False</code> )         \u2013          <p>Persist data stored in the endpoint.</p> </li> </ul> <p>Returns:</p> <ul> <li> <code>int</code>         \u2013          <p>Exit code where 0 is success and 1 is failure. Failure messages         are logged to the default logger.</p> </li> </ul> Source code in <code>proxystore/endpoint/commands.py</code> <pre><code>def configure_endpoint(\n    name: str,\n    *,\n    port: int,\n    relay_server: str | None,\n    relay_auth: bool = True,\n    proxystore_dir: str | None = None,\n    peer_channels: int = 1,\n    persist_data: bool = False,\n) -&gt; int:\n    \"\"\"Configure a new endpoint.\n\n    Args:\n        name: Name of endpoint.\n        port: Port for endpoint to listen on.\n        relay_server: Optional relay server address for P2P endpoint\n            connections.\n        relay_auth: Relay server used Globus Auth.\n        proxystore_dir: Optionally specify the proxystore home directory.\n            Defaults to [`home_dir()`][proxystore.utils.environment.home_dir].\n        peer_channels: Number of datachannels per peer connection\n            to another endpoint to communicate over.\n        persist_data: Persist data stored in the endpoint.\n\n    Returns:\n        Exit code where 0 is success and 1 is failure. Failure messages \\\n        are logged to the default logger.\n    \"\"\"\n    if proxystore_dir is None:\n        proxystore_dir = home_dir()\n    endpoint_dir = os.path.join(proxystore_dir, name)\n\n    database_path = (\n        os.path.join(endpoint_dir, ENDPOINT_DATABASE_FILE)\n        if persist_data\n        else None\n    )\n\n    try:\n        cfg = EndpointConfig(\n            name=name,\n            uuid=str(uuid.uuid4()),\n            host=None,\n            port=port,\n            relay=EndpointRelayConfig(\n                address=relay_server,\n                auth=EndpointRelayAuthConfig(\n                    method='globus' if relay_auth else None,\n                ),\n                peer_channels=peer_channels,\n            ),\n            storage=EndpointStorageConfig(database_path=database_path),\n        )\n    except ValueError as e:\n        logger.error(str(e))\n        return 1\n\n    if os.path.exists(endpoint_dir):\n        logger.error(f'An endpoint named {name} already exists.')\n        logger.info('To reconfigure the endpoint, remove and try again.')\n        return 1\n\n    write_config(cfg, endpoint_dir)\n\n    logger.info(f'Configured endpoint: {cfg.name} &lt;{cfg.uuid}&gt;')\n    logger.info(f'Config and log file directory: {endpoint_dir}')\n    logger.info('Start the endpoint with:')\n    logger.info(f'  $ proxystore-endpoint start {cfg.name}')\n\n    return 0\n</code></pre>"},{"location":"api/endpoint/commands/#proxystore.endpoint.commands.list_endpoints","title":"list_endpoints()","text":"<pre><code>list_endpoints(*, proxystore_dir: str | None = None) -&gt; int\n</code></pre> <p>List available endpoints.</p> <p>Parameters:</p> <ul> <li> <code>proxystore_dir</code>             (<code>str | None</code>, default:                 <code>None</code> )         \u2013          <p>Optionally specify the proxystore home directory. Defaults to <code>home_dir()</code>.</p> </li> </ul> <p>Returns:</p> <ul> <li> <code>int</code>         \u2013          <p>Exit code where 0 is success and 1 is failure. Failure messages         are logged to the default logger.</p> </li> </ul> Source code in <code>proxystore/endpoint/commands.py</code> <pre><code>def list_endpoints(\n    *,\n    proxystore_dir: str | None = None,\n) -&gt; int:\n    \"\"\"List available endpoints.\n\n    Args:\n        proxystore_dir: Optionally specify the proxystore home directory.\n            Defaults to [`home_dir()`][proxystore.utils.environment.home_dir].\n\n    Returns:\n        Exit code where 0 is success and 1 is failure. Failure messages \\\n        are logged to the default logger.\n    \"\"\"\n    if proxystore_dir is None:\n        proxystore_dir = home_dir()\n\n    endpoints = get_configs(proxystore_dir)\n\n    max_status_chars = max(\n        len('STATUS'),\n        *(len(e.name) for e in EndpointStatus),\n    )\n    # Note: endpoints can be empty so we need to pass an iterable rather\n    # than unpacking the arguments\n    max_endpoint_chars = max([18] + [len(e.name) for e in endpoints])\n\n    if len(endpoints) == 0:\n        logger.info(f'No valid endpoint configurations in {proxystore_dir}.')\n        return 0\n\n    eps = [(e.name, str(e.uuid)) for e in endpoints]\n    eps = sorted(eps, key=lambda x: x[0])\n    logger.info(\n        f'{\"NAME\":&lt;{max_endpoint_chars}} {\"STATUS\":&lt;{max_status_chars}} UUID',\n        extra={'simple': True},\n    )\n\n    toprule_len = 2 + max_endpoint_chars + max_status_chars + len(eps[0][1])\n    logger.info('=' * toprule_len, extra={'simple': True})\n\n    for name, uuid_ in eps:\n        status = get_status(name, proxystore_dir)\n        logger.info(\n            f'{name:{max_endpoint_chars}.{max_endpoint_chars}} '\n            f'{status.name:&lt;{max_status_chars}.{max_status_chars}} {uuid_}',\n            extra={'simple': True},\n        )\n\n    return 0\n</code></pre>"},{"location":"api/endpoint/commands/#proxystore.endpoint.commands.remove_endpoint","title":"remove_endpoint()","text":"<pre><code>remove_endpoint(\n    name: str, *, proxystore_dir: str | None = None\n) -&gt; int\n</code></pre> <p>Remove endpoint.</p> <p>Parameters:</p> <ul> <li> <code>name</code>             (<code>str</code>)         \u2013          <p>Name of endpoint to remove.</p> </li> <li> <code>proxystore_dir</code>             (<code>str | None</code>, default:                 <code>None</code> )         \u2013          <p>Optionally specify the proxystore home directory. Defaults to <code>home_dir()</code>.</p> </li> </ul> <p>Returns:</p> <ul> <li> <code>int</code>         \u2013          <p>Exit code where 0 is success and 1 is failure. Failure messages         are logged to the default logger.</p> </li> </ul> Source code in <code>proxystore/endpoint/commands.py</code> <pre><code>def remove_endpoint(\n    name: str,\n    *,\n    proxystore_dir: str | None = None,\n) -&gt; int:\n    \"\"\"Remove endpoint.\n\n    Args:\n        name: Name of endpoint to remove.\n        proxystore_dir: Optionally specify the proxystore home directory.\n            Defaults to [`home_dir()`][proxystore.utils.environment.home_dir].\n\n    Returns:\n        Exit code where 0 is success and 1 is failure. Failure messages \\\n        are logged to the default logger.\n    \"\"\"\n    if proxystore_dir is None:\n        proxystore_dir = home_dir()\n    endpoint_dir = os.path.join(proxystore_dir, name)\n\n    if not os.path.exists(endpoint_dir):\n        logger.error(f'An endpoint named {name} does not exist.')\n        return 1\n\n    status = get_status(name, proxystore_dir)\n    if status in (EndpointStatus.RUNNING, EndpointStatus.HANGING):\n        logger.error('Endpoint must be stopped before removing.')\n        logger.error(f'  $ proxystore-endpoint stop {name}')\n        return 1\n\n    shutil.rmtree(endpoint_dir)\n\n    logger.info(f'Removed endpoint named {name}.')\n\n    return 0\n</code></pre>"},{"location":"api/endpoint/commands/#proxystore.endpoint.commands.start_endpoint","title":"start_endpoint()","text":"<pre><code>start_endpoint(\n    name: str,\n    *,\n    detach: bool = False,\n    log_level: str = \"INFO\",\n    proxystore_dir: str | None = None\n) -&gt; int\n</code></pre> <p>Start endpoint.</p> <p>Parameters:</p> <ul> <li> <code>name</code>             (<code>str</code>)         \u2013          <p>Name of endpoint to start.</p> </li> <li> <code>detach</code>             (<code>bool</code>, default:                 <code>False</code> )         \u2013          <p>Start the endpoint as a daemon process.</p> </li> <li> <code>log_level</code>             (<code>str</code>, default:                 <code>'INFO'</code> )         \u2013          <p>Logging level of the endpoint.</p> </li> <li> <code>proxystore_dir</code>             (<code>str | None</code>, default:                 <code>None</code> )         \u2013          <p>Optionally specify the proxystore home directory. Defaults to <code>home_dir()</code>.</p> </li> </ul> <p>Returns:</p> <ul> <li> <code>int</code>         \u2013          <p>Exit code where 0 is success and 1 is failure. Failure messages         are logged to the default logger.</p> </li> </ul> Source code in <code>proxystore/endpoint/commands.py</code> <pre><code>def start_endpoint(\n    name: str,\n    *,\n    detach: bool = False,\n    log_level: str = 'INFO',\n    proxystore_dir: str | None = None,\n) -&gt; int:\n    \"\"\"Start endpoint.\n\n    Args:\n        name: Name of endpoint to start.\n        detach: Start the endpoint as a daemon process.\n        log_level: Logging level of the endpoint.\n        proxystore_dir: Optionally specify the proxystore home directory.\n            Defaults to [`home_dir()`][proxystore.utils.environment.home_dir].\n\n    Returns:\n        Exit code where 0 is success and 1 is failure. Failure messages \\\n        are logged to the default logger.\n    \"\"\"\n    if proxystore_dir is None:\n        proxystore_dir = home_dir()\n\n    status = get_status(name, proxystore_dir)\n    if status == EndpointStatus.RUNNING:\n        logger.error(f'Endpoint {name} is already running.')\n        return 1\n    elif status == EndpointStatus.UNKNOWN:\n        logger.error(f'A valid endpoint named {name} does not exist.')\n        logger.error('Use `list` to see available endpoints.')\n        return 1\n\n    endpoint_dir = os.path.join(proxystore_dir, name)\n    cfg = read_config(endpoint_dir)\n    # Use IP address here which is generally more reliable\n    hostname = socket.gethostbyname(utils.hostname())\n\n    pid_file = get_pid_filepath(endpoint_dir)\n\n    if (\n        status == EndpointStatus.HANGING\n        and cfg.host is not None\n        and hostname != cfg.host\n    ):\n        logger.error(\n            'A PID file exists for the endpoint, but the config indicates the '\n            f'endpoint is running on a host named {cfg.host}. Try stopping '\n            f'the endpoint on {cfg.host}. Otherwise, delete the PID file at '\n            f'{pid_file} and try again.',\n        )\n        return 1\n    elif status == EndpointStatus.HANGING:\n        logger.debug(f'Removing invalid PID file ({pid_file}).')\n        os.remove(pid_file)\n\n    # Write out new config with host so clients can see the current host\n    cfg.host = hostname\n    write_config(cfg, endpoint_dir)\n\n    log_file = get_log_filepath(endpoint_dir)\n\n    if detach:\n        logger.info('Starting endpoint process as daemon.')\n        logger.info(f'Logs will be written to {log_file}')\n\n        context = daemon.DaemonContext(\n            working_directory=endpoint_dir,\n            umask=0o002,\n            pidfile=daemon.pidfile.PIDLockFile(pid_file),\n            detach_process=True,\n            # Note: stdin, stdout, stderr left as None which binds to /dev/null\n        )\n    else:\n        context = _attached_pid_manager(pid_file)\n\n    with context:\n        # Note: serve will handle most interrupts which can be reasonably\n        # handled and return gracefully.\n        serve(cfg, log_level=log_level, log_file=log_file)\n\n    return 0\n</code></pre>"},{"location":"api/endpoint/commands/#proxystore.endpoint.commands.stop_endpoint","title":"stop_endpoint()","text":"<pre><code>stop_endpoint(\n    name: str, *, proxystore_dir: str | None = None\n) -&gt; int\n</code></pre> <p>Stop endpoint.</p> <p>Parameters:</p> <ul> <li> <code>name</code>             (<code>str</code>)         \u2013          <p>Name of endpoint to start.</p> </li> <li> <code>proxystore_dir</code>             (<code>str | None</code>, default:                 <code>None</code> )         \u2013          <p>Optionally specify the proxystore home directory. Defaults to <code>home_dir()</code>.</p> </li> </ul> <p>Returns:</p> <ul> <li> <code>int</code>         \u2013          <p>Exit code where 0 is success and 1 is failure. Failure messages         are logged to the default logger.</p> </li> </ul> Source code in <code>proxystore/endpoint/commands.py</code> <pre><code>def stop_endpoint(name: str, *, proxystore_dir: str | None = None) -&gt; int:\n    \"\"\"Stop endpoint.\n\n    Args:\n        name: Name of endpoint to start.\n        proxystore_dir: Optionally specify the proxystore home directory.\n            Defaults to [`home_dir()`][proxystore.utils.environment.home_dir].\n\n    Returns:\n        Exit code where 0 is success and 1 is failure. Failure messages \\\n        are logged to the default logger.\n    \"\"\"\n    if proxystore_dir is None:\n        proxystore_dir = home_dir()\n\n    status = get_status(name, proxystore_dir)\n    if status == EndpointStatus.UNKNOWN:\n        logger.error(f'A valid endpoint named {name} does not exist.')\n        logger.error('Use `list` to see available endpoints.')\n        return 1\n    elif status == EndpointStatus.STOPPED:\n        logger.info(f'Endpoint {name} is not running.')\n        return 0\n\n    endpoint_dir = os.path.join(proxystore_dir, name)\n    cfg = read_config(endpoint_dir)\n    hostname = utils.hostname()\n    pid_file = get_pid_filepath(endpoint_dir)\n\n    if (\n        status == EndpointStatus.HANGING\n        and cfg.host is not None\n        and hostname != cfg.host\n    ):\n        logger.error(\n            'A PID file exists for the endpoint, but the config indicates the '\n            f'endpoint is running on a host named {cfg.host}. Try stopping '\n            f'the endpoint on {cfg.host}. Otherwise, delete the PID file at '\n            f'{pid_file} and try again.',\n        )\n        return 1\n    elif status == EndpointStatus.HANGING:\n        logger.debug(f'Removing invalid PID file ({pid_file}).')\n        os.remove(pid_file)\n        logger.info(f'Endpoint {name} is not running.')\n        return 0\n\n    assert status == EndpointStatus.RUNNING\n    with open(pid_file) as f:\n        pid = int(f.read().strip())\n\n    logger.debug(f'Terminating endpoint process (PID: {pid}).')\n    # Source: https://github.com/funcx-faas/funcX/blob/facf37348f9a9eb4e1a0572793d7b6819be5754d/funcx_endpoint/funcx_endpoint/endpoint/endpoint.py#L360  # noqa: E501\n    parent = psutil.Process(pid)\n    processes = parent.children(recursive=True)\n    processes.append(parent)\n    for p in processes:\n        p.send_signal(signal.SIGTERM)\n\n    terminated, alive = psutil.wait_procs(processes, timeout=1)\n    for p in alive:  # pragma: no cover\n        try:\n            p.send_signal(signal.SIGKILL)\n        except psutil.NoSuchProcess:\n            pass\n\n    if os.path.isfile(pid_file):  # pragma: no branch\n        logger.debug(f'Cleaning up PID file ({pid_file}).')\n        os.remove(pid_file)\n\n    logger.info(f'Endpoint {name} has been stopped.')\n    return 0\n</code></pre>"},{"location":"api/endpoint/config/","title":"proxystore.endpoint.config","text":"<code>proxystore/endpoint/config.py</code> <p>Endpoint configuration.</p>"},{"location":"api/endpoint/config/#proxystore.endpoint.config.EndpointRelayAuthConfig","title":"EndpointRelayAuthConfig","text":"<p>             Bases: <code>BaseModel</code></p> <p>Endpoint relay server authentication configuration.</p> <p>Attributes:</p> <ul> <li> <code>method</code>             (<code>Optional[Literal['globus']]</code>)         \u2013          <p>Relay server authentication method.</p> </li> <li> <code>kwargs</code>             (<code>Dict[str, Any]</code>)         \u2013          <p>Arbitrary options used by the authentication method.</p> </li> </ul>"},{"location":"api/endpoint/config/#proxystore.endpoint.config.EndpointRelayConfig","title":"EndpointRelayConfig","text":"<p>             Bases: <code>BaseModel</code></p> <p>Endpoint relay server configuration.</p> <p>Attributes:</p> <ul> <li> <code>address</code>             (<code>Optional[str]</code>)         \u2013          <p>Address of the relay server to register with.</p> </li> <li> <code>auth</code>             (<code>EndpointRelayAuthConfig</code>)         \u2013          <p>Relay server authentication configuration.</p> </li> <li> <code>peer_channels</code>             (<code>int</code>)         \u2013          <p>Number of peer channels to multiplex communication over.</p> </li> <li> <code>verify_certificates</code>             (<code>int</code>)         \u2013          <p>Validate the relay server's SSL certificate. This should only be disabled when testing endpoint with local relay servers using self-signed certificates.</p> </li> </ul>"},{"location":"api/endpoint/config/#proxystore.endpoint.config.EndpointStorageConfig","title":"EndpointStorageConfig","text":"<p>             Bases: <code>BaseModel</code></p> <p>Endpoint data storage configuration.</p> <p>Attributes:</p> <ul> <li> <code>database_path</code>             (<code>Optional[str]</code>)         \u2013          <p>Optional path to SQLite database file that will be used for storing endpoint data. If <code>None</code>, data will only be stored in-memory.</p> </li> <li> <code>max_object_size</code>             (<code>Optional[int]</code>)         \u2013          <p>Optional maximum object size.</p> </li> </ul>"},{"location":"api/endpoint/config/#proxystore.endpoint.config.EndpointConfig","title":"EndpointConfig","text":"<p>             Bases: <code>BaseModel</code></p> <p>Endpoint configuration.</p> <p>Attributes:</p> <ul> <li> <code>name</code>             (<code>str</code>)         \u2013          <p>Endpoint name.</p> </li> <li> <code>uuid</code>             (<code>str</code>)         \u2013          <p>Endpoint UUID.</p> </li> <li> <code>host</code>             (<code>Optional[str]</code>)         \u2013          <p>Host endpoint is running on.</p> </li> <li> <code>port</code>             (<code>int</code>)         \u2013          <p>Port endpoint is running on.</p> </li> <li> <code>peering</code>             (<code>int</code>)         \u2013          <p>Peering configuration.</p> </li> <li> <code>storage</code>             (<code>EndpointStorageConfig</code>)         \u2013          <p>Storage configuration.</p> </li> </ul> <p>Raises:</p> <ul> <li> <code>ValueError</code>           \u2013          <p>If the name does not contain only alphanumeric, dash, or underscore characters, if the UUID cannot be parsed, or if the port is not in the range [1, 65535].</p> </li> </ul>"},{"location":"api/endpoint/config/#proxystore.endpoint.config.get_configs","title":"get_configs()","text":"<pre><code>get_configs(proxystore_dir: str) -&gt; list[EndpointConfig]\n</code></pre> <p>Get all valid endpoint configurations in parent directory.</p> <p>Parameters:</p> <ul> <li> <code>proxystore_dir</code>             (<code>str</code>)         \u2013          <p>Parent directory containing possible endpoint configurations.</p> </li> </ul> <p>Returns:</p> <ul> <li> <code>list[EndpointConfig]</code>         \u2013          <p>List of found configs.</p> </li> </ul> Source code in <code>proxystore/endpoint/config.py</code> <pre><code>def get_configs(proxystore_dir: str) -&gt; list[EndpointConfig]:\n    \"\"\"Get all valid endpoint configurations in parent directory.\n\n    Args:\n        proxystore_dir: Parent directory containing possible endpoint\n            configurations.\n\n    Returns:\n        List of found configs.\n    \"\"\"\n    endpoints: list[EndpointConfig] = []\n\n    if not os.path.isdir(proxystore_dir):\n        return endpoints\n\n    for dirpath, _, _ in os.walk(proxystore_dir):\n        if os.path.samefile(proxystore_dir, dirpath):\n            continue\n        try:\n            cfg = read_config(dirpath)\n        except FileNotFoundError:\n            continue\n        except ValueError:\n            continue\n        else:\n            endpoints.append(cfg)\n\n    return endpoints\n</code></pre>"},{"location":"api/endpoint/config/#proxystore.endpoint.config.get_log_filepath","title":"get_log_filepath()","text":"<pre><code>get_log_filepath(endpoint_dir: str) -&gt; str\n</code></pre> <p>Return path to log file for endpoint.</p> <p>Parameters:</p> <ul> <li> <code>endpoint_dir</code>             (<code>str</code>)         \u2013          <p>Directory for the endpoint.</p> </li> </ul> <p>Returns:</p> <ul> <li> <code>str</code>         \u2013          <p>Path to log file.</p> </li> </ul> Source code in <code>proxystore/endpoint/config.py</code> <pre><code>def get_log_filepath(endpoint_dir: str) -&gt; str:\n    \"\"\"Return path to log file for endpoint.\n\n    Args:\n        endpoint_dir: Directory for the endpoint.\n\n    Returns:\n        Path to log file.\n    \"\"\"\n    return os.path.join(endpoint_dir, ENDPOINT_LOG_FILE)\n</code></pre>"},{"location":"api/endpoint/config/#proxystore.endpoint.config.get_pid_filepath","title":"get_pid_filepath()","text":"<pre><code>get_pid_filepath(endpoint_dir: str) -&gt; str\n</code></pre> <p>Return path to PID file for endpoint.</p> <p>Parameters:</p> <ul> <li> <code>endpoint_dir</code>             (<code>str</code>)         \u2013          <p>Directory for the endpoint.</p> </li> </ul> <p>Returns:</p> <ul> <li> <code>str</code>         \u2013          <p>Path to PID file.</p> </li> </ul> Source code in <code>proxystore/endpoint/config.py</code> <pre><code>def get_pid_filepath(endpoint_dir: str) -&gt; str:\n    \"\"\"Return path to PID file for endpoint.\n\n    Args:\n        endpoint_dir: Directory for the endpoint.\n\n    Returns:\n        Path to PID file.\n    \"\"\"\n    return os.path.join(endpoint_dir, ENDPOINT_PID_FILE)\n</code></pre>"},{"location":"api/endpoint/config/#proxystore.endpoint.config.read_config","title":"read_config()","text":"<pre><code>read_config(endpoint_dir: str) -&gt; EndpointConfig\n</code></pre> <p>Read endpoint config file.</p> <p>Parameters:</p> <ul> <li> <code>endpoint_dir</code>             (<code>str</code>)         \u2013          <p>Directory containing endpoint configuration file.</p> </li> </ul> <p>Returns:</p> <ul> <li> <code>EndpointConfig</code>         \u2013          <p>Config found in <code>endpoint_dir</code>.</p> </li> </ul> <p>Raises:</p> <ul> <li> <code>FileNotFoundError</code>           \u2013          <p>If a config files does not exist in the directory.</p> </li> <li> <code>ValueError</code>           \u2013          <p>If config contains an invalid value or cannot be parsed.</p> </li> </ul> Source code in <code>proxystore/endpoint/config.py</code> <pre><code>def read_config(endpoint_dir: str) -&gt; EndpointConfig:\n    \"\"\"Read endpoint config file.\n\n    Args:\n        endpoint_dir: Directory containing endpoint configuration file.\n\n    Returns:\n        Config found in `endpoint_dir`.\n\n    Raises:\n        FileNotFoundError: If a config files does not exist in the directory.\n        ValueError: If config contains an invalid value or cannot be parsed.\n    \"\"\"\n    path = os.path.join(endpoint_dir, ENDPOINT_CONFIG_FILE)\n\n    if os.path.exists(path):\n        with open(path, 'rb') as f:\n            try:\n                return load(EndpointConfig, f)\n            except Exception as e:\n                raise ValueError(\n                    f'Unable to parse ({path}): {e!s}.',\n                ) from None\n    else:\n        raise FileNotFoundError(\n            f'Endpoint directory {endpoint_dir} does not contain a valid '\n            'configuration.',\n        )\n</code></pre>"},{"location":"api/endpoint/config/#proxystore.endpoint.config.validate_name","title":"validate_name()","text":"<pre><code>validate_name(name: str) -&gt; bool\n</code></pre> <p>Validate name only contains alphanumeric or dash/underscore chars.</p> Source code in <code>proxystore/endpoint/config.py</code> <pre><code>def validate_name(name: str) -&gt; bool:\n    \"\"\"Validate name only contains alphanumeric or dash/underscore chars.\"\"\"\n    return len(re.findall(r'[^A-Za-z0-9_\\-]', name)) == 0 and len(name) &gt; 0\n</code></pre>"},{"location":"api/endpoint/config/#proxystore.endpoint.config.write_config","title":"write_config()","text":"<pre><code>write_config(\n    cfg: EndpointConfig, endpoint_dir: str\n) -&gt; None\n</code></pre> <p>Write config to endpoint directory.</p> <p>Parameters:</p> <ul> <li> <code>cfg</code>             (<code>EndpointConfig</code>)         \u2013          <p>Configuration to write.</p> </li> <li> <code>endpoint_dir</code>             (<code>str</code>)         \u2013          <p>Directory to write config to.</p> </li> </ul> Source code in <code>proxystore/endpoint/config.py</code> <pre><code>def write_config(cfg: EndpointConfig, endpoint_dir: str) -&gt; None:\n    \"\"\"Write config to endpoint directory.\n\n    Args:\n        cfg: Configuration to write.\n        endpoint_dir: Directory to write config to.\n    \"\"\"\n    os.makedirs(endpoint_dir, exist_ok=True)\n    path = os.path.join(endpoint_dir, ENDPOINT_CONFIG_FILE)\n    with open(path, 'wb') as f:\n        dump(cfg, f)\n</code></pre>"},{"location":"api/endpoint/constants/","title":"proxystore.endpoint.constants","text":"<code>proxystore/endpoint/constants.py</code> <p>Endpoint constants.</p>"},{"location":"api/endpoint/constants/#proxystore.endpoint.constants.MAX_CHUNK_LENGTH","title":"MAX_CHUNK_LENGTH  <code>module-attribute</code>","text":"<pre><code>MAX_CHUNK_LENGTH = 1000000\n</code></pre> <p>Maximum chunk length (bytes) for GET/SET requests to/from the endpoint.</p>"},{"location":"api/endpoint/constants/#proxystore.endpoint.constants.MAX_OBJECT_SIZE_DEFAULT","title":"MAX_OBJECT_SIZE_DEFAULT  <code>module-attribute</code>","text":"<pre><code>MAX_OBJECT_SIZE_DEFAULT = 100000000\n</code></pre> <p>Default maximum endpoint object size in bytes.</p>"},{"location":"api/endpoint/endpoint/","title":"proxystore.endpoint.endpoint","text":"<code>proxystore/endpoint/endpoint.py</code> <p>Endpoint implementation.</p>"},{"location":"api/endpoint/endpoint/#proxystore.endpoint.endpoint.EndpointMode","title":"EndpointMode","text":"<p>             Bases: <code>Enum</code></p> <p>Endpoint mode.</p>"},{"location":"api/endpoint/endpoint/#proxystore.endpoint.endpoint.EndpointMode.PEERING","title":"PEERING  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>PEERING = 1\n</code></pre> <p>Endpoint will establish peer connections with other endpoints.</p>"},{"location":"api/endpoint/endpoint/#proxystore.endpoint.endpoint.EndpointMode.SOLO","title":"SOLO  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>SOLO = 2\n</code></pre> <p>Endpoint is operating in isolation and will ignore peer requests.</p>"},{"location":"api/endpoint/endpoint/#proxystore.endpoint.endpoint.Endpoint","title":"Endpoint","text":"<pre><code>Endpoint(\n    name: str | None = None,\n    uuid: UUID | None = None,\n    *,\n    peer_manager: PeerManager | None = None,\n    storage: Storage | None = None\n)\n</code></pre> <p>ProxyStore Endpoint.</p> <p>An endpoint is an object store with <code>get</code>/<code>set</code> functionality.</p> <p>By default, an endpoint operates in <code>EndpointMode.SOLO</code> mode where the endpoint acts just as an isolated object store. Endpoints can also be configured in <code>EndpointMode.PEERING</code> mode by initializing the endpoint with a <code>PeerManager</code>. The <code>PeerManager</code> is connected to a relay server which is used to establish peer-to-peer connections with other endpoints connected to the same relay server. After peer connections are established, endpoints can forward operations between each other. Peering is available even when endpoints are behind separate NATs. See the <code>proxystore.p2p</code> module to learn more about peering.</p> Warning <p>Requests made to remote endpoints will only invoke the request on the remote and return the result. I.e., invoking GET on a remote will return the value but will not store it on the local endpoint.</p> Example <p>Solo Mode Usage</p> <pre><code>async with Endpoint('ep1', uuid.uuid4()) as endpoint:\n    serialized_data = b'data string'\n    await endpoint.set('key', serialized_data)\n    assert await endpoint.get('key') == serialized_data\n    await endpoint.evict('key')\n    assert not await endpoint.exists('key')\n</code></pre> Example <p>Peering Mode Usage</p> <pre><code>pm1 = await PeerManager(RelayClient(...))\npm2 = await PeerManager(RelayClient(...))\nep1 = await Endpoint(peer_manager=pm1)\nep2 = await Endpoint(peer_manager=pm2)\n\nserialized_data = b'data string'\nawait ep1.set('key', serialized_data)\nassert await ep2.get('key', endpoint=ep1.uuid) == serialized_data\nassert await ep1.exists('key')\nassert not await ep1.exists('key', endpoint=ep2.uuid)\n\nawait ep1.close()\nawait ep2.close()\n</code></pre> Note <p>Endpoints can be configured and started via the <code>proxystore-endpoint</code> command-line interface.</p> Note <p>If the endpoint is being used in peering mode, the endpoint should be used as a context manager or initialized with await. This will ensure <code>Endpoint.async_init()</code> is called which initializes the background task that listens for incoming peer messages.</p> <pre><code>endpoint = await Endpoint(...)\nawait endpoint.close()\n</code></pre> <pre><code>async with Endpoint(...) as endpoint:\n    ...\n</code></pre> <p>Parameters:</p> <ul> <li> <code>name</code>             (<code>str | None</code>, default:                 <code>None</code> )         \u2013          <p>Readable name of the endpoint. Only used if <code>peer_manager</code> is not provided. Otherwise the name will be set to <code>PeerManager.name</code>.</p> </li> <li> <code>uuid</code>             (<code>UUID | None</code>, default:                 <code>None</code> )         \u2013          <p>UUID of the endpoint. Only used if <code>peer_manager</code> is not provided. Otherwise the UUID will be set to <code>PeerManager.uuid</code>.</p> </li> <li> <code>peer_manager</code>             (<code>PeerManager | None</code>, default:                 <code>None</code> )         \u2013          <p>Optional peer manager that is connected to a relay server which will be used for establishing peer connections to other endpoints connected to the same relay server.</p> </li> <li> <code>storage</code>             (<code>Storage | None</code>, default:                 <code>None</code> )         \u2013          <p>Storage interface to use. If <code>None</code>, <code>DictStorage</code> is used.</p> </li> </ul> <p>Raises:</p> <ul> <li> <code>ValueError</code>           \u2013          <p>if neither <code>name</code>/<code>uuid</code> or <code>peer_manager</code> are set.</p> </li> </ul> Source code in <code>proxystore/endpoint/endpoint.py</code> <pre><code>def __init__(\n    self,\n    name: str | None = None,\n    uuid: UUID | None = None,\n    *,\n    peer_manager: PeerManager | None = None,\n    storage: Storage | None = None,\n) -&gt; None:\n    if peer_manager is None and (name is None or uuid is None):\n        raise ValueError(\n            'The name and uuid parameters must be provided if '\n            'a PeerManager is not provided.',\n        )\n\n    self._default_name = name\n    self._default_uuid = uuid\n    self._peer_manager = peer_manager\n    self._storage = DictStorage() if storage is None else storage\n\n    self._mode = (\n        EndpointMode.SOLO if peer_manager is None else EndpointMode.PEERING\n    )\n    self._pending_requests: dict[\n        str,\n        asyncio.Future[EndpointRequest],\n    ] = {}\n    self._peer_handler_task: asyncio.Task[None] | None = None\n\n    if self._mode is EndpointMode.SOLO:\n        # Initialization is not complete for endpoints in peering mode\n        # until async_init() is called.\n        logger.info(\n            f'{self._log_prefix}: initialized endpoint operating '\n            f'in {self._mode.name} mode',\n        )\n</code></pre>"},{"location":"api/endpoint/endpoint/#proxystore.endpoint.endpoint.Endpoint.name","title":"name  <code>property</code>","text":"<pre><code>name: str\n</code></pre> <p>Name of this endpoint.</p>"},{"location":"api/endpoint/endpoint/#proxystore.endpoint.endpoint.Endpoint.uuid","title":"uuid  <code>property</code>","text":"<pre><code>uuid: UUID\n</code></pre> <p>UUID of this endpoint.</p>"},{"location":"api/endpoint/endpoint/#proxystore.endpoint.endpoint.Endpoint.peer_manager","title":"peer_manager  <code>property</code>","text":"<pre><code>peer_manager: PeerManager | None\n</code></pre> <p>Peer manager.</p> <p>Raises:</p> <ul> <li> <code>PeeringNotAvailableError</code>           \u2013          <p>if the endpoint was initialized with a <code>PeerManager</code> but <code>Endpoint.async_init()</code> has not been called. This is likely because the endpoint was not initialized with the <code>await</code> keyword.</p> </li> </ul>"},{"location":"api/endpoint/endpoint/#proxystore.endpoint.endpoint.Endpoint.async_init","title":"async_init()  <code>async</code>","text":"<pre><code>async_init() -&gt; None\n</code></pre> <p>Initialize connections and tasks necessary for peering.</p> Note <p>This will also call <code>PeerManager.async_init()</code> if one is provided so that asynchronous resources for both the <code>PeerManager</code> and endpoint can be initialized later after creation.</p> Source code in <code>proxystore/endpoint/endpoint.py</code> <pre><code>async def async_init(self) -&gt; None:\n    \"\"\"Initialize connections and tasks necessary for peering.\n\n    Note:\n        This will also call\n        [`PeerManager.async_init()`][proxystore.p2p.manager.PeerManager.async_init]\n        if one is provided so that asynchronous resources for both the\n        [`PeerManager`][proxystore.p2p.manager.PeerManager]\n        and endpoint can be initialized later after creation.\n    \"\"\"\n    if self._peer_manager is not None and self._peer_handler_task is None:\n        await self._peer_manager.async_init()\n        self._peer_handler_task = spawn_guarded_background_task(\n            self._handle_peer_requests,\n        )\n        self._peer_handler_task.set_name(\n            f'endpoint-{self.uuid}-handle-peer-requests',\n        )\n        logger.info(\n            f'{self._log_prefix}: initialized endpoint operating '\n            f'in {self._mode.name} mode',\n        )\n</code></pre>"},{"location":"api/endpoint/endpoint/#proxystore.endpoint.endpoint.Endpoint.evict","title":"evict()  <code>async</code>","text":"<pre><code>evict(key: str, endpoint: UUID | None = None) -&gt; None\n</code></pre> <p>Evict key from endpoint.</p> <p>Parameters:</p> <ul> <li> <code>key</code>             (<code>str</code>)         \u2013          <p>Key to evict.</p> </li> <li> <code>endpoint</code>             (<code>UUID | None</code>, default:                 <code>None</code> )         \u2013          <p>Endpoint to perform operation on. If unspecified or if the endpoint is on solo mode, the operation will be performed on the local endpoint.</p> </li> </ul> <p>Raises:</p> <ul> <li> <code>PeerRequestError</code>           \u2013          <p>If request to a peer endpoint fails.</p> </li> </ul> Source code in <code>proxystore/endpoint/endpoint.py</code> <pre><code>async def evict(self, key: str, endpoint: UUID | None = None) -&gt; None:\n    \"\"\"Evict key from endpoint.\n\n    Args:\n        key: Key to evict.\n        endpoint: Endpoint to perform operation on. If\n            unspecified or if the endpoint is on solo mode, the operation\n            will be performed on the local endpoint.\n\n    Raises:\n        PeerRequestError: If request to a peer endpoint fails.\n    \"\"\"\n    logger.debug(\n        f'{self._log_prefix}: EVICT key={key} on endpoint={endpoint}',\n    )\n    if self._is_peer_request(endpoint):\n        assert endpoint is not None\n        request = EndpointRequest(\n            kind='request',\n            op='evict',\n            uuid=str(uuid4()),\n            key=key,\n        )\n        request_future = await self._request_from_peer(endpoint, request)\n        await request_future\n    else:\n        await self._storage.evict(key)\n</code></pre>"},{"location":"api/endpoint/endpoint/#proxystore.endpoint.endpoint.Endpoint.exists","title":"exists()  <code>async</code>","text":"<pre><code>exists(key: str, endpoint: UUID | None = None) -&gt; bool\n</code></pre> <p>Check if key exists on endpoint.</p> <p>Parameters:</p> <ul> <li> <code>key</code>             (<code>str</code>)         \u2013          <p>Key to check.</p> </li> <li> <code>endpoint</code>             (<code>UUID | None</code>, default:                 <code>None</code> )         \u2013          <p>Endpoint to perform operation on. If unspecified or if the endpoint is on solo mode, the operation will be performed on the local endpoint.</p> </li> </ul> <p>Returns:</p> <ul> <li> <code>bool</code>         \u2013          <p>If the key exists.</p> </li> </ul> <p>Raises:</p> <ul> <li> <code>PeerRequestError</code>           \u2013          <p>If request to a peer endpoint fails.</p> </li> </ul> Source code in <code>proxystore/endpoint/endpoint.py</code> <pre><code>async def exists(self, key: str, endpoint: UUID | None = None) -&gt; bool:\n    \"\"\"Check if key exists on endpoint.\n\n    Args:\n        key: Key to check.\n        endpoint: Endpoint to perform operation on. If\n            unspecified or if the endpoint is on solo mode, the operation\n            will be performed on the local endpoint.\n\n    Returns:\n        If the key exists.\n\n    Raises:\n        PeerRequestError: If request to a peer endpoint fails.\n    \"\"\"\n    logger.debug(\n        f'{self._log_prefix}: EXISTS key={key} on endpoint={endpoint}',\n    )\n    if self._is_peer_request(endpoint):\n        assert endpoint is not None\n        request = EndpointRequest(\n            kind='request',\n            op='exists',\n            uuid=str(uuid4()),\n            key=key,\n        )\n        request_future = await self._request_from_peer(endpoint, request)\n        response = await request_future\n        assert isinstance(response.exists, bool)\n        return response.exists\n    else:\n        return await self._storage.exists(key)\n</code></pre>"},{"location":"api/endpoint/endpoint/#proxystore.endpoint.endpoint.Endpoint.get","title":"get()  <code>async</code>","text":"<pre><code>get(key: str, endpoint: UUID | None = None) -&gt; bytes | None\n</code></pre> <p>Get value associated with key on endpoint.</p> <p>Parameters:</p> <ul> <li> <code>key</code>             (<code>str</code>)         \u2013          <p>Key to get value for.</p> </li> <li> <code>endpoint</code>             (<code>UUID | None</code>, default:                 <code>None</code> )         \u2013          <p>Endpoint to perform operation on. If unspecified or if the endpoint is on solo mode, the operation will be performed on the local endpoint.</p> </li> </ul> <p>Returns:</p> <ul> <li> <code>bytes | None</code>         \u2013          <p>Value associated with key.</p> </li> </ul> <p>Raises:</p> <ul> <li> <code>PeerRequestError</code>           \u2013          <p>If request to a peer endpoint fails.</p> </li> </ul> Source code in <code>proxystore/endpoint/endpoint.py</code> <pre><code>async def get(\n    self,\n    key: str,\n    endpoint: UUID | None = None,\n) -&gt; bytes | None:\n    \"\"\"Get value associated with key on endpoint.\n\n    Args:\n        key: Key to get value for.\n        endpoint: Endpoint to perform operation on. If\n            unspecified or if the endpoint is on solo mode, the operation\n            will be performed on the local endpoint.\n\n    Returns:\n        Value associated with key.\n\n    Raises:\n        PeerRequestError: If request to a peer endpoint fails.\n    \"\"\"\n    logger.debug(\n        f'{self._log_prefix}: GET key={key} on endpoint={endpoint}',\n    )\n    if self._is_peer_request(endpoint):\n        assert endpoint is not None\n        request = EndpointRequest(\n            kind='request',\n            op='get',\n            uuid=str(uuid4()),\n            key=key,\n        )\n        request_future = await self._request_from_peer(endpoint, request)\n        response = await request_future\n        return response.data\n    else:\n        return await self._storage.get(key, None)\n</code></pre>"},{"location":"api/endpoint/endpoint/#proxystore.endpoint.endpoint.Endpoint.set","title":"set()  <code>async</code>","text":"<pre><code>set(\n    key: str, data: bytes, endpoint: UUID | None = None\n) -&gt; None\n</code></pre> <p>Set key with data on endpoint.</p> <p>Parameters:</p> <ul> <li> <code>key</code>             (<code>str</code>)         \u2013          <p>Key to associate with value.</p> </li> <li> <code>data</code>             (<code>bytes</code>)         \u2013          <p>Value to associate with key.</p> </li> <li> <code>endpoint</code>             (<code>UUID | None</code>, default:                 <code>None</code> )         \u2013          <p>Endpoint to perform operation on. If unspecified or if the endpoint is on solo mode, the operation will be performed on the local endpoint.</p> </li> </ul> <p>Raises:</p> <ul> <li> <code>ObjectSizeExceededError</code>           \u2013          <p>If the max object size is configured and the data exceeds that size.</p> </li> <li> <code>PeerRequestError</code>           \u2013          <p>If request to a peer endpoint fails.</p> </li> </ul> Source code in <code>proxystore/endpoint/endpoint.py</code> <pre><code>async def set(\n    self,\n    key: str,\n    data: bytes,\n    endpoint: UUID | None = None,\n) -&gt; None:\n    \"\"\"Set key with data on endpoint.\n\n    Args:\n        key: Key to associate with value.\n        data: Value to associate with key.\n        endpoint: Endpoint to perform operation on. If\n            unspecified or if the endpoint is on solo mode, the operation\n            will be performed on the local endpoint.\n\n    Raises:\n        ObjectSizeExceededError: If the max object size is configured and\n            the data exceeds that size.\n        PeerRequestError: If request to a peer endpoint fails.\n    \"\"\"\n    logger.debug(\n        f'{self._log_prefix}: SET key={key} on endpoint={endpoint}',\n    )\n\n    if self._is_peer_request(endpoint):\n        assert endpoint is not None\n        request = EndpointRequest(\n            kind='request',\n            op='set',\n            uuid=str(uuid4()),\n            key=key,\n            data=data,\n        )\n        request_future = await self._request_from_peer(endpoint, request)\n        await request_future\n    else:\n        await self._storage.set(key, data)\n</code></pre>"},{"location":"api/endpoint/endpoint/#proxystore.endpoint.endpoint.Endpoint.close","title":"close()  <code>async</code>","text":"<pre><code>close() -&gt; None\n</code></pre> <p>Close the endpoint and any open connections safely.</p> Source code in <code>proxystore/endpoint/endpoint.py</code> <pre><code>async def close(self) -&gt; None:\n    \"\"\"Close the endpoint and any open connections safely.\"\"\"\n    if self._peer_handler_task is not None:\n        self._peer_handler_task.cancel()\n        try:\n            await self._peer_handler_task\n        except asyncio.CancelledError:\n            pass\n    if self._peer_manager is not None:\n        await self._peer_manager.close()\n    await self._storage.close()\n    logger.info(f'{self._log_prefix}: endpoint closed')\n</code></pre>"},{"location":"api/endpoint/exceptions/","title":"proxystore.endpoint.exceptions","text":"<code>proxystore/endpoint/exceptions.py</code> <p>Endpoint exceptions.</p>"},{"location":"api/endpoint/exceptions/#proxystore.endpoint.exceptions.FileDumpNotAvailableError","title":"FileDumpNotAvailableError","text":"<p>             Bases: <code>Exception</code></p> <p>Error raised when dumping objects to file is not available.</p>"},{"location":"api/endpoint/exceptions/#proxystore.endpoint.exceptions.ObjectSizeExceededError","title":"ObjectSizeExceededError","text":"<p>             Bases: <code>Exception</code></p> <p>Exception raised when an object exceeds the max allowable size.</p>"},{"location":"api/endpoint/exceptions/#proxystore.endpoint.exceptions.PeeringNotAvailableError","title":"PeeringNotAvailableError","text":"<p>             Bases: <code>Exception</code></p> <p>Exception when a peer request is made but peering is not available.</p>"},{"location":"api/endpoint/exceptions/#proxystore.endpoint.exceptions.PeerRequestError","title":"PeerRequestError","text":"<p>             Bases: <code>Exception</code></p> <p>Exception raised when a request to a peer fails.</p>"},{"location":"api/endpoint/messages/","title":"proxystore.endpoint.messages","text":"<code>proxystore/endpoint/messages.py</code> <p>Endpoint to endpoint messages.</p>"},{"location":"api/endpoint/messages/#proxystore.endpoint.messages.EndpointRequest","title":"EndpointRequest  <code>dataclass</code>","text":"<pre><code>EndpointRequest(\n    kind: Literal[\"request\", \"response\"],\n    op: Literal[\"evict\", \"exists\", \"get\", \"set\"],\n    uuid: str,\n    key: str,\n    data: bytes | None = None,\n    exists: bool | None = None,\n    error: Exception | None = None,\n)\n</code></pre> <p>Message type for requests between endpoints.</p> <p>Attributes:</p> <ul> <li> <code>kind</code>             (<code>Literal['request', 'response']</code>)         \u2013          <p>One of <code>'request'</code> or <code>'response'</code>.</p> </li> <li> <code>op</code>             (<code>Literal['evict', 'exists', 'get', 'set']</code>)         \u2013          <p>One of <code>'evict'</code>, <code>'exists'</code>, <code>'get'</code>, or <code>'set'</code>.</p> </li> <li> <code>uuid</code>             (<code>str</code>)         \u2013          <p>UUID of sender.</p> </li> <li> <code>key</code>             (<code>str</code>)         \u2013          <p>Key to operate on.</p> </li> <li> <code>data</code>             (<code>bytes | None</code>)         \u2013          <p>Optional data to operate on.</p> </li> <li> <code>exists</code>             (<code>bool | None</code>)         \u2013          <p>Result of <code>exists</code> operation.</p> </li> <li> <code>error</code>             (<code>Exception | None</code>)         \u2013          <p>Error raised by operation.</p> </li> </ul>"},{"location":"api/endpoint/serve/","title":"proxystore.endpoint.serve","text":"<code>proxystore/endpoint/serve.py</code> <p>Endpoint serving.</p>"},{"location":"api/endpoint/serve/#proxystore.endpoint.serve.create_app","title":"create_app()","text":"<pre><code>create_app(\n    endpoint: Endpoint,\n    max_content_length: int | None = None,\n    body_timeout: int = 300,\n) -&gt; Quart\n</code></pre> <p>Create quart app for endpoint and registers routes.</p> <p>Parameters:</p> <ul> <li> <code>endpoint</code>             (<code>Endpoint</code>)         \u2013          <p>Initialized endpoint to forward quart routes to.</p> </li> <li> <code>max_content_length</code>             (<code>int | None</code>, default:                 <code>None</code> )         \u2013          <p>Max request body size in bytes.</p> </li> <li> <code>body_timeout</code>             (<code>int</code>, default:                 <code>300</code> )         \u2013          <p>Number of seconds to wait for the body to be completely received.</p> </li> </ul> <p>Returns:</p> <ul> <li> <code>Quart</code>         \u2013          <p>Quart app.</p> </li> </ul> Source code in <code>proxystore/endpoint/serve.py</code> <pre><code>def create_app(\n    endpoint: Endpoint,\n    max_content_length: int | None = None,\n    body_timeout: int = 300,\n) -&gt; quart.Quart:\n    \"\"\"Create quart app for endpoint and registers routes.\n\n    Args:\n        endpoint: Initialized endpoint to forward quart routes to.\n        max_content_length: Max request body size in bytes.\n        body_timeout: Number of seconds to wait for the body to be\n            completely received.\n\n    Returns:\n        Quart app.\n    \"\"\"\n    app = quart.Quart(__name__)\n\n    app.config['endpoint'] = endpoint\n\n    app.register_blueprint(routes_blueprint, url_prefix='')\n\n    app.config['MAX_CONTENT_LENGTH'] = max_content_length\n    app.config['BODY_TIMEOUT'] = body_timeout\n\n    return app\n</code></pre>"},{"location":"api/endpoint/serve/#proxystore.endpoint.serve.serve","title":"serve()","text":"<pre><code>serve(\n    config: EndpointConfig,\n    *,\n    log_level: int | str = logging.INFO,\n    log_file: str | None = None,\n    use_uvloop: bool = True\n) -&gt; None\n</code></pre> <p>Initialize endpoint and serve Quart app.</p> Warning <p>This function does not return until the Quart app is terminated.</p> <p>Parameters:</p> <ul> <li> <code>config</code>             (<code>EndpointConfig</code>)         \u2013          <p>Configuration object.</p> </li> <li> <code>log_level</code>             (<code>int | str</code>, default:                 <code>INFO</code> )         \u2013          <p>Logging level of endpoint.</p> </li> <li> <code>log_file</code>             (<code>str | None</code>, default:                 <code>None</code> )         \u2013          <p>Optional file path to append log to.</p> </li> <li> <code>use_uvloop</code>             (<code>bool</code>, default:                 <code>True</code> )         \u2013          <p>Install uvloop as the default event loop implementation.</p> </li> </ul> Source code in <code>proxystore/endpoint/serve.py</code> <pre><code>def serve(\n    config: EndpointConfig,\n    *,\n    log_level: int | str = logging.INFO,\n    log_file: str | None = None,\n    use_uvloop: bool = True,\n) -&gt; None:\n    \"\"\"Initialize endpoint and serve Quart app.\n\n    Warning:\n        This function does not return until the Quart app is terminated.\n\n    Args:\n        config: Configuration object.\n        log_level: Logging level of endpoint.\n        log_file: Optional file path to append log to.\n        use_uvloop: Install uvloop as the default event loop implementation.\n    \"\"\"\n    if log_file is not None:\n        parent_dir = os.path.dirname(log_file)\n        if not os.path.isdir(parent_dir):\n            os.makedirs(parent_dir, exist_ok=True)\n        logging.getLogger().handlers.append(logging.FileHandler(log_file))\n\n    for handler in logging.getLogger().handlers:\n        handler.setFormatter(\n            logging.Formatter(\n                '[%(asctime)s.%(msecs)03d] %(levelname)-5s (%(name)s) :: '\n                '%(message)s',\n                datefmt='%Y-%m-%d %H:%M:%S',\n            ),\n        )\n    logging.getLogger().setLevel(log_level)\n\n    if use_uvloop:  # pragma: no cover\n        logger.info('Installing uvloop as default event loop')\n        uvloop.install()\n    else:\n        logger.warning(\n            'Not installing uvloop. Uvicorn may override and install anyways',\n        )\n\n    # Convert SIGTERM to SIGINT which will be handled by Uvicorn first,\n    # then passed on by this function.\n    signal.signal(\n        signal.SIGTERM,\n        lambda *_args: signal.raise_signal(signal.SIGINT),\n    )\n\n    # The remaining set up and serving code is deferred to within the\n    # _serve_async helper function which will be executed within an event loop.\n    try:\n        asyncio.run(_serve_async(config))\n    except Exception as e:\n        # Intercept exception so we can log it in the case that the endpoint\n        # is running as a daemon process. Otherwise the user will never see\n        # the exception.\n        logger.exception(f'Caught unhandled exception: {e!r}')\n        raise\n    except KeyboardInterrupt:  # pragma: no cover\n        # Uvicorn&lt;0.29.0 captures SIGINT and does not propagate is.\n        # Uvicorn&gt;=0.29.1 changes this behavior to propagate the SIGINT after\n        # Uvicorn has done it's cleanup, so we need to catch the exception\n        # here and pass on it since we let Uvicorn handle our clean up in\n        # the \"after_app_serving\" shutdown callback. This is excluded from\n        # coverage because it depends on the Uvicorn version.\n        # Relevant PR: https://github.com/encode/uvicorn/pull/1600\n        pass\n    finally:\n        logger.info(f'Finished serving endpoint: {config.name}')\n</code></pre>"},{"location":"api/endpoint/serve/#proxystore.endpoint.serve.endpoint_handler","title":"endpoint_handler()  <code>async</code>","text":"<pre><code>endpoint_handler() -&gt; Response\n</code></pre> <p>Route handler for <code>GET /endpoint</code>.</p> <p>Responses:</p> <ul> <li><code>Status Code 200</code>: JSON containing the key <code>uuid</code> with the value as   the string UUID of this endpoint.</li> </ul> Source code in <code>proxystore/endpoint/serve.py</code> <pre><code>@routes_blueprint.route('/endpoint', methods=['GET'])\nasync def endpoint_handler() -&gt; Response:\n    \"\"\"Route handler for `GET /endpoint`.\n\n    Responses:\n\n    * `Status Code 200`: JSON containing the key `uuid` with the value as\n      the string UUID of this endpoint.\n    \"\"\"\n    endpoint = quart.current_app.config['endpoint']\n    return Response(\n        json.dumps({'uuid': str(endpoint.uuid)}),\n        200,\n        content_type='application/json',\n    )\n</code></pre>"},{"location":"api/endpoint/serve/#proxystore.endpoint.serve.evict_handler","title":"evict_handler()  <code>async</code>","text":"<pre><code>evict_handler() -&gt; Response\n</code></pre> <p>Route handler for <code>POST /evict</code>.</p> <p>Responses:</p> <ul> <li><code>Status Code 200</code>: If the operation succeeds. The response message will   be empty.</li> <li><code>Status Code 400</code>: If the key argument is missing or the endpoint UUID   argument is present but not a valid UUID.</li> <li><code>Status Code 500</code>: If there was a peer request error. The response   will contain the string representation of the internal error.</li> </ul> Source code in <code>proxystore/endpoint/serve.py</code> <pre><code>@routes_blueprint.route('/evict', methods=['POST'])\nasync def evict_handler() -&gt; Response:\n    \"\"\"Route handler for `POST /evict`.\n\n    Responses:\n\n    * `Status Code 200`: If the operation succeeds. The response message will\n      be empty.\n    * `Status Code 400`: If the key argument is missing or the endpoint UUID\n      argument is present but not a valid UUID.\n    * `Status Code 500`: If there was a peer request error. The response\n      will contain the string representation of the internal error.\n    \"\"\"\n    key = request.args.get('key', None)\n    if key is None:\n        return Response('request missing key', 400)\n\n    endpoint_uuid: str | uuid.UUID | None = request.args.get(\n        'endpoint',\n        None,\n    )\n    endpoint = quart.current_app.config['endpoint']\n    if isinstance(endpoint_uuid, str):\n        try:\n            endpoint_uuid = uuid.UUID(endpoint_uuid, version=4)\n        except ValueError:\n            return Response(f'{endpoint_uuid} is not a valid UUID4', 400)\n\n    try:\n        await endpoint.evict(key=key, endpoint=endpoint_uuid)\n        return Response('', 200)\n    except PeerRequestError as e:\n        return Response(str(e), 500)\n</code></pre>"},{"location":"api/endpoint/serve/#proxystore.endpoint.serve.exists_handler","title":"exists_handler()  <code>async</code>","text":"<pre><code>exists_handler() -&gt; Response\n</code></pre> <p>Route handler for <code>GET /exists</code>.</p> <p>Responses:</p> <ul> <li><code>Status Code 200</code>: If the operation succeeds. The response message will   be empty.</li> <li><code>Status Code 400</code>: If the key argument is missing or the endpoint UUID   argument is present but not a valid UUID.</li> <li><code>Status Code 500</code>: If there was a peer request error. The response   will contain the string representation of the internal error.</li> </ul> Source code in <code>proxystore/endpoint/serve.py</code> <pre><code>@routes_blueprint.route('/exists', methods=['GET'])\nasync def exists_handler() -&gt; Response:\n    \"\"\"Route handler for `GET /exists`.\n\n    Responses:\n\n    * `Status Code 200`: If the operation succeeds. The response message will\n      be empty.\n    * `Status Code 400`: If the key argument is missing or the endpoint UUID\n      argument is present but not a valid UUID.\n    * `Status Code 500`: If there was a peer request error. The response\n      will contain the string representation of the internal error.\n    \"\"\"\n    key = request.args.get('key', None)\n    if key is None:\n        return Response('request missing key', 400)\n\n    endpoint_uuid: str | uuid.UUID | None = request.args.get(\n        'endpoint',\n        None,\n    )\n    endpoint = quart.current_app.config['endpoint']\n    if isinstance(endpoint_uuid, str):\n        try:\n            endpoint_uuid = uuid.UUID(endpoint_uuid, version=4)\n        except ValueError:\n            return Response(f'{endpoint_uuid} is not a valid UUID4', 400)\n\n    try:\n        exists = await endpoint.exists(key=key, endpoint=endpoint_uuid)\n        return Response(\n            json.dumps({'exists': exists}),\n            200,\n            content_type='application/json',\n        )\n    except PeerRequestError as e:\n        return Response(str(e), 500)\n</code></pre>"},{"location":"api/endpoint/serve/#proxystore.endpoint.serve.get_handler","title":"get_handler()  <code>async</code>","text":"<pre><code>get_handler() -&gt; Response\n</code></pre> <p>Route handler for <code>GET /get</code>.</p> <p>Responses:</p> <ul> <li><code>Status Code 200</code>: If the operation succeeds. The response message will    contain the octet-stream of the requested data.</li> <li><code>Status Code 400</code>: If the key argument is missing or the endpoint UUID   argument is present but not a valid UUID.</li> <li><code>Status Code 404</code>: If there is no data associated with the provided key.</li> <li><code>Status Code 500</code>: If there was a peer request error. The response   will contain the string representation of the internal error.</li> </ul> Source code in <code>proxystore/endpoint/serve.py</code> <pre><code>@routes_blueprint.route('/get', methods=['GET'])\nasync def get_handler() -&gt; Response:\n    \"\"\"Route handler for `GET /get`.\n\n    Responses:\n\n    * `Status Code 200`: If the operation succeeds. The response message will\n       contain the octet-stream of the requested data.\n    * `Status Code 400`: If the key argument is missing or the endpoint UUID\n      argument is present but not a valid UUID.\n    * `Status Code 404`: If there is no data associated with the provided key.\n    * `Status Code 500`: If there was a peer request error. The response\n      will contain the string representation of the internal error.\n    \"\"\"\n    key = request.args.get('key', None)\n    if key is None:\n        return Response('request missing key', 400)\n\n    endpoint_uuid: str | uuid.UUID | None = request.args.get(\n        'endpoint',\n        None,\n    )\n    endpoint = quart.current_app.config['endpoint']\n    if isinstance(endpoint_uuid, str):\n        try:\n            endpoint_uuid = uuid.UUID(endpoint_uuid, version=4)\n        except ValueError:\n            return Response(f'{endpoint_uuid} is not a valid UUID4', 400)\n\n    try:\n        data = await endpoint.get(key=key, endpoint=endpoint_uuid)\n    except PeerRequestError as e:\n        return Response(str(e), 500)\n\n    if data is not None:\n        return Response(\n            response=chunk_bytes(data, MAX_CHUNK_LENGTH),\n            content_type='application/octet-stream',\n        )\n    else:\n        return Response('no data associated with request key', 404)\n</code></pre>"},{"location":"api/endpoint/serve/#proxystore.endpoint.serve.set_handler","title":"set_handler()  <code>async</code>","text":"<pre><code>set_handler() -&gt; Response\n</code></pre> <p>Route handler for <code>POST /set</code>.</p> <p>Responses:</p> <ul> <li><code>Status Code 200</code>: If the operation succeeds. The response message will   be empty.</li> <li><code>Status Code 400</code>: If the key argument is missing, the endpoint UUID   argument is present but not a valid UUID, or the request is missing   the data payload.</li> <li><code>Status Code 500</code>: If there was a peer request error. The response   will contain the string representation of the internal error.</li> </ul> Source code in <code>proxystore/endpoint/serve.py</code> <pre><code>@routes_blueprint.route('/set', methods=['POST'])\nasync def set_handler() -&gt; Response:\n    \"\"\"Route handler for `POST /set`.\n\n    Responses:\n\n    * `Status Code 200`: If the operation succeeds. The response message will\n      be empty.\n    * `Status Code 400`: If the key argument is missing, the endpoint UUID\n      argument is present but not a valid UUID, or the request is missing\n      the data payload.\n    * `Status Code 500`: If there was a peer request error. The response\n      will contain the string representation of the internal error.\n    \"\"\"\n    key = request.args.get('key', None)\n    if key is None:\n        return Response('request missing key', 400)\n\n    endpoint_uuid: str | uuid.UUID | None = request.args.get(\n        'endpoint',\n        None,\n    )\n    endpoint = quart.current_app.config['endpoint']\n    if isinstance(endpoint_uuid, str):\n        try:\n            endpoint_uuid = uuid.UUID(endpoint_uuid, version=4)\n        except ValueError:\n            return Response(f'{endpoint_uuid} is not a valid UUID4', 400)\n\n    data = bytearray()\n    # Note: tests/endpoint/serve_test.py::test_empty_chunked_data handles\n    # the branching case for where the code in the for loop is not executed\n    # but coverage is not detecting that hence the pragma here\n    async for chunk in request.body:  # pragma: no branch\n        data += chunk\n\n    if len(data) == 0:\n        return Response('received empty payload', 400)\n\n    try:\n        await endpoint.set(key=key, data=bytes(data), endpoint=endpoint_uuid)\n    except PeerRequestError as e:\n        return Response(str(e), 500)\n    else:\n        return Response('', 200)\n</code></pre>"},{"location":"api/endpoint/storage/","title":"proxystore.endpoint.storage","text":"<code>proxystore/endpoint/storage.py</code> <p>Blob storage interface for endpoints.</p>"},{"location":"api/endpoint/storage/#proxystore.endpoint.storage.Storage","title":"Storage","text":"<p>             Bases: <code>Protocol</code></p> <p>Endpoint storage protocol for blobs.</p>"},{"location":"api/endpoint/storage/#proxystore.endpoint.storage.Storage.evict","title":"evict()  <code>async</code>","text":"<pre><code>evict(key: str) -&gt; None\n</code></pre> <p>Evict a blob from storage.</p> <p>Parameters:</p> <ul> <li> <code>key</code>             (<code>str</code>)         \u2013          <p>Key associated with blob to evict.</p> </li> </ul> Source code in <code>proxystore/endpoint/storage.py</code> <pre><code>async def evict(self, key: str) -&gt; None:\n    \"\"\"Evict a blob from storage.\n\n    Args:\n        key: Key associated with blob to evict.\n    \"\"\"\n    ...\n</code></pre>"},{"location":"api/endpoint/storage/#proxystore.endpoint.storage.Storage.exists","title":"exists()  <code>async</code>","text":"<pre><code>exists(key: str) -&gt; bool\n</code></pre> <p>Check if a blob exists in the storage.</p> <p>Parameters:</p> <ul> <li> <code>key</code>             (<code>str</code>)         \u2013          <p>Key associated with the blob to check.</p> </li> </ul> <p>Returns:</p> <ul> <li> <code>bool</code>         \u2013          <p>If a blob associated with the key exists.</p> </li> </ul> Source code in <code>proxystore/endpoint/storage.py</code> <pre><code>async def exists(self, key: str) -&gt; bool:\n    \"\"\"Check if a blob exists in the storage.\n\n    Args:\n        key: Key associated with the blob to check.\n\n    Returns:\n        If a blob associated with the key exists.\n    \"\"\"\n    ...\n</code></pre>"},{"location":"api/endpoint/storage/#proxystore.endpoint.storage.Storage.get","title":"get()  <code>async</code>","text":"<pre><code>get(key: str, default: bytes | None = None) -&gt; bytes | None\n</code></pre> <p>Get a blob from storage.</p> <p>Parameters:</p> <ul> <li> <code>key</code>             (<code>str</code>)         \u2013          <p>Key associated with the blob to get.</p> </li> <li> <code>default</code>             (<code>bytes | None</code>, default:                 <code>None</code> )         \u2013          <p>Default return value if the blob does not exist.</p> </li> </ul> <p>Returns:</p> <ul> <li> <code>bytes | None</code>         \u2013          <p>The blob associated with the key or the value of <code>default</code>.</p> </li> </ul> Source code in <code>proxystore/endpoint/storage.py</code> <pre><code>async def get(\n    self,\n    key: str,\n    default: bytes | None = None,\n) -&gt; bytes | None:\n    \"\"\"Get a blob from storage.\n\n    Args:\n        key: Key associated with the blob to get.\n        default: Default return value if the blob does not exist.\n\n    Returns:\n        The blob associated with the key or the value of `default`.\n    \"\"\"\n    ...\n</code></pre>"},{"location":"api/endpoint/storage/#proxystore.endpoint.storage.Storage.set","title":"set()  <code>async</code>","text":"<pre><code>set(key: str, blob: bytes) -&gt; None\n</code></pre> <p>Store the blob associated with a key.</p> <p>Parameters:</p> <ul> <li> <code>key</code>             (<code>str</code>)         \u2013          <p>Key that will be used to retrieve the blob.</p> </li> <li> <code>blob</code>             (<code>bytes</code>)         \u2013          <p>Blob to store.</p> </li> </ul> <p>Raises:</p> <ul> <li> <code>ObjectSizeExceededError</code>           \u2013          <p>If the max object size is configured and the data exceeds that size.</p> </li> </ul> Source code in <code>proxystore/endpoint/storage.py</code> <pre><code>async def set(self, key: str, blob: bytes) -&gt; None:\n    \"\"\"Store the blob associated with a key.\n\n    Args:\n        key: Key that will be used to retrieve the blob.\n        blob: Blob to store.\n\n    Raises:\n        ObjectSizeExceededError: If the max object size is configured and\n            the data exceeds that size.\n    \"\"\"\n    ...\n</code></pre>"},{"location":"api/endpoint/storage/#proxystore.endpoint.storage.Storage.close","title":"close()  <code>async</code>","text":"<pre><code>close() -&gt; None\n</code></pre> <p>Close the storage.</p> Source code in <code>proxystore/endpoint/storage.py</code> <pre><code>async def close(self) -&gt; None:\n    \"\"\"Close the storage.\"\"\"\n    ...\n</code></pre>"},{"location":"api/endpoint/storage/#proxystore.endpoint.storage.DictStorage","title":"DictStorage","text":"<pre><code>DictStorage(\n    *, max_object_size: int | None = MAX_OBJECT_SIZE_DEFAULT\n)\n</code></pre> <p>Simple dictionary-based storage for blobs.</p> <p>Parameters:</p> <ul> <li> <code>max_object_size</code>             (<code>int | None</code>, default:                 <code>MAX_OBJECT_SIZE_DEFAULT</code> )         \u2013          <p>Optional max size in bytes for any single object stored by the endpoint. If exceeded, an error is raised.</p> </li> </ul> Source code in <code>proxystore/endpoint/storage.py</code> <pre><code>def __init__(\n    self,\n    *,\n    max_object_size: int | None = MAX_OBJECT_SIZE_DEFAULT,\n) -&gt; None:\n    self._data: dict[str, bytes] = {}\n    self._max_object_size = max_object_size\n</code></pre>"},{"location":"api/endpoint/storage/#proxystore.endpoint.storage.DictStorage.evict","title":"evict()  <code>async</code>","text":"<pre><code>evict(key: str) -&gt; None\n</code></pre> <p>Evict a blob from storage.</p> <p>Parameters:</p> <ul> <li> <code>key</code>             (<code>str</code>)         \u2013          <p>Key associated with blob to evict.</p> </li> </ul> Source code in <code>proxystore/endpoint/storage.py</code> <pre><code>async def evict(self, key: str) -&gt; None:\n    \"\"\"Evict a blob from storage.\n\n    Args:\n        key: Key associated with blob to evict.\n    \"\"\"\n    self._data.pop(key, None)\n</code></pre>"},{"location":"api/endpoint/storage/#proxystore.endpoint.storage.DictStorage.exists","title":"exists()  <code>async</code>","text":"<pre><code>exists(key: str) -&gt; bool\n</code></pre> <p>Check if a blob exists in the storage.</p> <p>Parameters:</p> <ul> <li> <code>key</code>             (<code>str</code>)         \u2013          <p>Key associated with the blob to check.</p> </li> </ul> <p>Returns:</p> <ul> <li> <code>bool</code>         \u2013          <p>If a blob associated with the key exists.</p> </li> </ul> Source code in <code>proxystore/endpoint/storage.py</code> <pre><code>async def exists(self, key: str) -&gt; bool:\n    \"\"\"Check if a blob exists in the storage.\n\n    Args:\n        key: Key associated with the blob to check.\n\n    Returns:\n        If a blob associated with the key exists.\n    \"\"\"\n    return key in self._data\n</code></pre>"},{"location":"api/endpoint/storage/#proxystore.endpoint.storage.DictStorage.get","title":"get()  <code>async</code>","text":"<pre><code>get(key: str, default: bytes | None = None) -&gt; bytes | None\n</code></pre> <p>Get a blob from storage.</p> <p>Parameters:</p> <ul> <li> <code>key</code>             (<code>str</code>)         \u2013          <p>Key associated with the blob to get.</p> </li> <li> <code>default</code>             (<code>bytes | None</code>, default:                 <code>None</code> )         \u2013          <p>Default return value if the blob does not exist.</p> </li> </ul> <p>Returns:</p> <ul> <li> <code>bytes | None</code>         \u2013          <p>The blob associated with the key or the value of <code>default</code>.</p> </li> </ul> Source code in <code>proxystore/endpoint/storage.py</code> <pre><code>async def get(\n    self,\n    key: str,\n    default: bytes | None = None,\n) -&gt; bytes | None:\n    \"\"\"Get a blob from storage.\n\n    Args:\n        key: Key associated with the blob to get.\n        default: Default return value if the blob does not exist.\n\n    Returns:\n        The blob associated with the key or the value of `default`.\n    \"\"\"\n    return self._data.get(key, default)\n</code></pre>"},{"location":"api/endpoint/storage/#proxystore.endpoint.storage.DictStorage.set","title":"set()  <code>async</code>","text":"<pre><code>set(key: str, blob: bytes) -&gt; None\n</code></pre> <p>Store the blob associated with a key.</p> <p>Parameters:</p> <ul> <li> <code>key</code>             (<code>str</code>)         \u2013          <p>Key that will be used to retrieve the blob.</p> </li> <li> <code>blob</code>             (<code>bytes</code>)         \u2013          <p>Blob to store.</p> </li> </ul> <p>Raises:</p> <ul> <li> <code>ObjectSizeExceededError</code>           \u2013          <p>If the max object size is configured and the data exceeds that size.</p> </li> </ul> Source code in <code>proxystore/endpoint/storage.py</code> <pre><code>async def set(self, key: str, blob: bytes) -&gt; None:\n    \"\"\"Store the blob associated with a key.\n\n    Args:\n        key: Key that will be used to retrieve the blob.\n        blob: Blob to store.\n\n    Raises:\n        ObjectSizeExceededError: If the max object size is configured and\n            the data exceeds that size.\n    \"\"\"\n    if (\n        self._max_object_size is not None\n        and len(blob) &gt; self._max_object_size\n    ):\n        raise ObjectSizeExceededError(\n            f'Bytes value has size {bytes_to_readable(len(blob))} which '\n            f'exceeds the {bytes_to_readable(self._max_object_size)} '\n            'object limit.',\n        )\n    self._data[key] = blob\n</code></pre>"},{"location":"api/endpoint/storage/#proxystore.endpoint.storage.DictStorage.close","title":"close()  <code>async</code>","text":"<pre><code>close() -&gt; None\n</code></pre> <p>Clear all stored blobs.</p> Source code in <code>proxystore/endpoint/storage.py</code> <pre><code>async def close(self) -&gt; None:\n    \"\"\"Clear all stored blobs.\"\"\"\n    self._data.clear()\n</code></pre>"},{"location":"api/endpoint/storage/#proxystore.endpoint.storage.SQLiteStorage","title":"SQLiteStorage","text":"<pre><code>SQLiteStorage(\n    database_path: str | Path = \":memory:\",\n    *,\n    max_object_size: int | None = MAX_OBJECT_SIZE_DEFAULT\n)\n</code></pre> <p>SQLite storage protocol for blobs.</p> <p>Parameters:</p> <ul> <li> <code>database_path</code>             (<code>str | Path</code>, default:                 <code>':memory:'</code> )         \u2013          <p>Path to database file.</p> </li> <li> <code>max_object_size</code>             (<code>int | None</code>, default:                 <code>MAX_OBJECT_SIZE_DEFAULT</code> )         \u2013          <p>Optional max size in bytes for any single object stored by the endpoint. If exceeded, an error is raised.</p> </li> </ul> Source code in <code>proxystore/endpoint/storage.py</code> <pre><code>def __init__(\n    self,\n    database_path: str | pathlib.Path = ':memory:',\n    *,\n    max_object_size: int | None = MAX_OBJECT_SIZE_DEFAULT,\n) -&gt; None:\n    if database_path == ':memory:':\n        self.database_path = database_path\n    else:\n        path = pathlib.Path(database_path).expanduser().resolve()\n        self.database_path = str(path)\n\n    self._max_object_size = max_object_size\n    self._db: aiosqlite.Connection | None = None\n</code></pre>"},{"location":"api/endpoint/storage/#proxystore.endpoint.storage.SQLiteStorage.db","title":"db()  <code>async</code>","text":"<pre><code>db() -&gt; Connection\n</code></pre> <p>Get the database connection object.</p> Source code in <code>proxystore/endpoint/storage.py</code> <pre><code>async def db(self) -&gt; aiosqlite.Connection:\n    \"\"\"Get the database connection object.\"\"\"\n    if self._db is None:\n        self._db = await aiosqlite.connect(self.database_path)\n        await self._db.execute(\n            'CREATE TABLE IF NOT EXISTS blobs'\n            '(key TEXT PRIMARY KEY, value BLOB NOT NULL)',\n        )\n    return self._db\n</code></pre>"},{"location":"api/endpoint/storage/#proxystore.endpoint.storage.SQLiteStorage.evict","title":"evict()  <code>async</code>","text":"<pre><code>evict(key: str) -&gt; None\n</code></pre> <p>Evict a blob from storage.</p> <p>Parameters:</p> <ul> <li> <code>key</code>             (<code>str</code>)         \u2013          <p>Key associated with blob to evict.</p> </li> </ul> Source code in <code>proxystore/endpoint/storage.py</code> <pre><code>async def evict(self, key: str) -&gt; None:\n    \"\"\"Evict a blob from storage.\n\n    Args:\n        key: Key associated with blob to evict.\n    \"\"\"\n    db = await self.db()\n    await db.execute('DELETE FROM blobs WHERE key=?', (key,))\n    await db.commit()\n</code></pre>"},{"location":"api/endpoint/storage/#proxystore.endpoint.storage.SQLiteStorage.exists","title":"exists()  <code>async</code>","text":"<pre><code>exists(key: str) -&gt; bool\n</code></pre> <p>Check if a blob exists in the storage.</p> <p>Parameters:</p> <ul> <li> <code>key</code>             (<code>str</code>)         \u2013          <p>Key associated with the blob to check.</p> </li> </ul> <p>Returns:</p> <ul> <li> <code>bool</code>         \u2013          <p>If a blob associated with the key exists.</p> </li> </ul> Source code in <code>proxystore/endpoint/storage.py</code> <pre><code>async def exists(self, key: str) -&gt; bool:\n    \"\"\"Check if a blob exists in the storage.\n\n    Args:\n        key: Key associated with the blob to check.\n\n    Returns:\n        If a blob associated with the key exists.\n    \"\"\"\n    db = await self.db()\n    async with db.execute(\n        'SELECT count(*) FROM blobs WHERE key=?',\n        (key,),\n    ) as cursor:\n        result = await cursor.fetchone()\n        # count() won't ever return 0 rows but mypy doesn't know this\n        assert result is not None\n        (count,) = result\n        return bool(count)\n</code></pre>"},{"location":"api/endpoint/storage/#proxystore.endpoint.storage.SQLiteStorage.get","title":"get()  <code>async</code>","text":"<pre><code>get(key: str, default: bytes | None = None) -&gt; bytes | None\n</code></pre> <p>Get a blob from storage.</p> <p>Parameters:</p> <ul> <li> <code>key</code>             (<code>str</code>)         \u2013          <p>Key associated with the blob to get.</p> </li> <li> <code>default</code>             (<code>bytes | None</code>, default:                 <code>None</code> )         \u2013          <p>Default return value if the blob does not exist.</p> </li> </ul> <p>Returns:</p> <ul> <li> <code>bytes | None</code>         \u2013          <p>The blob associated with the key or the value of <code>default</code>.</p> </li> </ul> Source code in <code>proxystore/endpoint/storage.py</code> <pre><code>async def get(\n    self,\n    key: str,\n    default: bytes | None = None,\n) -&gt; bytes | None:\n    \"\"\"Get a blob from storage.\n\n    Args:\n        key: Key associated with the blob to get.\n        default: Default return value if the blob does not exist.\n\n    Returns:\n        The blob associated with the key or the value of `default`.\n    \"\"\"\n    db = await self.db()\n    async with db.execute(\n        'SELECT value FROM blobs WHERE key=?',\n        (key,),\n    ) as cursor:\n        result = await cursor.fetchone()\n        if result is None:\n            return default\n        else:\n            return result[0]\n</code></pre>"},{"location":"api/endpoint/storage/#proxystore.endpoint.storage.SQLiteStorage.set","title":"set()  <code>async</code>","text":"<pre><code>set(key: str, blob: bytes) -&gt; None\n</code></pre> <p>Store the blob associated with a key.</p> <p>Parameters:</p> <ul> <li> <code>key</code>             (<code>str</code>)         \u2013          <p>Key that will be used to retrieve the blob.</p> </li> <li> <code>blob</code>             (<code>bytes</code>)         \u2013          <p>Blob to store.</p> </li> </ul> <p>Raises:</p> <ul> <li> <code>ObjectSizeExceededError</code>           \u2013          <p>If the max object size is configured and the data exceeds that size.</p> </li> </ul> Source code in <code>proxystore/endpoint/storage.py</code> <pre><code>async def set(self, key: str, blob: bytes) -&gt; None:\n    \"\"\"Store the blob associated with a key.\n\n    Args:\n        key: Key that will be used to retrieve the blob.\n        blob: Blob to store.\n\n    Raises:\n        ObjectSizeExceededError: If the max object size is configured and\n            the data exceeds that size.\n    \"\"\"\n    if (\n        self._max_object_size is not None\n        and len(blob) &gt; self._max_object_size\n    ):\n        raise ObjectSizeExceededError(\n            f'Bytes value has size {bytes_to_readable(len(blob))} which '\n            f'exceeds the {bytes_to_readable(self._max_object_size)} '\n            'object limit.',\n        )\n    db = await self.db()\n    await db.execute(\n        'INSERT OR REPLACE INTO blobs (key, value) VALUES (?, ?)',\n        (key, blob),\n    )\n    await db.commit()\n</code></pre>"},{"location":"api/endpoint/storage/#proxystore.endpoint.storage.SQLiteStorage.close","title":"close()  <code>async</code>","text":"<pre><code>close() -&gt; None\n</code></pre> <p>Close the storage.</p> Source code in <code>proxystore/endpoint/storage.py</code> <pre><code>async def close(self) -&gt; None:\n    \"\"\"Close the storage.\"\"\"\n    if self._db is not None:\n        await self._db.close()\n</code></pre>"},{"location":"api/globus/","title":"proxystore.globus","text":"<code>proxystore/globus/__init__.py</code> <p>ProxyStore Globus SDK tools.</p> <p>The Globus Auth flows are largely based on Globus Compute's implementation.</p>"},{"location":"api/globus/cli/","title":"proxystore.globus.cli","text":"<code>proxystore/globus/cli.py</code> <p>ProxyStore Globus Auth CLI.</p> <pre><code># basic login/logout\nproxystore-globus-auth login\nproxystore-globus-auth logout\n# give consent for specific collections\nproxystore-globus-auth login --collection COLLECTION_UUID --collection COLLECTION_UUID ...\n# specify additional scopes\nproxystore-globus-auth login --scope SCOPE --scope SCOPE ...\n</code></pre>"},{"location":"api/globus/cli/#proxystore.globus.cli.cli","title":"cli()","text":"<pre><code>cli() -&gt; None\n</code></pre> <p>ProxyStore Globus Auth.</p> Source code in <code>proxystore/globus/cli.py</code> <pre><code>@click.group()\ndef cli() -&gt; None:  # pragma: no cover\n    \"\"\"ProxyStore Globus Auth.\"\"\"\n    pass\n</code></pre>"},{"location":"api/globus/cli/#proxystore.globus.cli.login","title":"login()","text":"<pre><code>login(collection: list[str], scope: list[str]) -&gt; None\n</code></pre> <p>Authenticate with Globus Auth.</p> <p>This requests scopes for Globus Auth, Globus Transfer, and the ProxyStore relay server. Collections or scopes options can be strung together. E.g., request transfer scope for multiple collections with:</p> <p>$ proxystore-globus-auth -c UUID -c UUID -c UUID</p> Source code in <code>proxystore/globus/cli.py</code> <pre><code>@cli.command()\n@click.option(\n    '--collection',\n    '-c',\n    metavar='UUID',\n    multiple=True,\n    help='Globus Collection UUID to request transfer scopes for.',\n)\n@click.option(\n    '--scope',\n    '-s',\n    metavar='SCOPE',\n    multiple=True,\n    help='Additional scope to request.',\n)\ndef login(collection: list[str], scope: list[str]) -&gt; None:\n    \"\"\"Authenticate with Globus Auth.\n\n    This requests scopes for Globus Auth, Globus Transfer, and the ProxyStore\n    relay server. Collections or scopes options can be strung together. E.g.,\n    request transfer scope for multiple collections with:\n\n    $ proxystore-globus-auth -c UUID -c UUID -c UUID\n    \"\"\"\n    basic_scopes = get_all_scopes_by_resource_server(collection)\n    manager = NativeAppAuthManager(resource_server_scopes=basic_scopes)\n\n    if manager.logged_in:\n        click.echo(\n            'Globus authentication tokens already exist. '\n            'To recreate, logout and login again.',\n        )\n    else:\n        manager.login(additional_scopes=scope)\n</code></pre>"},{"location":"api/globus/cli/#proxystore.globus.cli.logout","title":"logout()","text":"<pre><code>logout() -&gt; None\n</code></pre> <p>Revoke and remove all Globus tokens.</p> Source code in <code>proxystore/globus/cli.py</code> <pre><code>@cli.command()\ndef logout() -&gt; None:\n    \"\"\"Revoke and remove all Globus tokens.\"\"\"\n    manager = NativeAppAuthManager()\n    manager.logout()\n</code></pre>"},{"location":"api/globus/client/","title":"proxystore.globus.client","text":"<code>proxystore/globus/client.py</code> <p>Create Globus Auth clients.</p>"},{"location":"api/globus/client/#proxystore.globus.client.get_confidential_app_auth_client","title":"get_confidential_app_auth_client()","text":"<pre><code>get_confidential_app_auth_client(\n    client_id: str | None = None,\n    client_secret: str | None = None,\n) -&gt; ConfidentialAppAuthClient\n</code></pre> <p>Create a confidential application authentication client.</p> Note <p>See the Globus SDK docs to learn how to create a confidential application and get the ID and secret.</p> Note <p>This function will not perform the OAuth2 flow.</p> <p>Parameters:</p> <ul> <li> <code>client_id</code>             (<code>str | None</code>, default:                 <code>None</code> )         \u2013          <p>Client ID. If either <code>client_id</code> or <code>client_secret</code> is <code>None</code>, the values will be read from the <code>PROXYSTORE_GLOBUS_CLIENT_ID</code> and <code>PROXYSTORE_GLOBUS_CLIENT_SECRET</code> environment variables.</p> </li> <li> <code>client_secret</code>             (<code>str | None</code>, default:                 <code>None</code> )         \u2013          <p>Client secret.</p> </li> </ul> <p>Returns:</p> <ul> <li> <code>ConfidentialAppAuthClient</code>         \u2013          <p>Authorization client.</p> </li> </ul> <p>Raises:</p> <ul> <li> <code>ValueError</code>           \u2013          <p>if <code>client_id</code> or <code>client_secret</code> are not provided and one or both of <code>PROXYSTORE_GLOBUS_CLIENT_ID</code> and <code>PROXYSTORE_GLOBUS_CLIENT_SECRET</code> are not set.</p> </li> <li> <code>ValueError</code>           \u2013          <p>if the provided <code>client_id</code> or ID read from the environment is not a valid UUID.</p> </li> </ul> Source code in <code>proxystore/globus/client.py</code> <pre><code>def get_confidential_app_auth_client(\n    client_id: str | None = None,\n    client_secret: str | None = None,\n) -&gt; globus_sdk.ConfidentialAppAuthClient:\n    \"\"\"Create a confidential application authentication client.\n\n    Note:\n        See the [Globus SDK docs](https://globus-sdk-python.readthedocs.io/en/stable/examples/client_credentials.html#get-a-client)\n        to learn how to create a confidential application and get the ID\n        and secret.\n\n    Note:\n        This function will not perform the OAuth2 flow.\n\n    Args:\n        client_id: Client ID. If either `client_id` or `client_secret` is\n            `None`, the values will be read from the\n            `PROXYSTORE_GLOBUS_CLIENT_ID` and `PROXYSTORE_GLOBUS_CLIENT_SECRET`\n            environment variables.\n        client_secret: Client secret.\n\n    Returns:\n        Authorization client.\n\n    Raises:\n        ValueError: if `client_id` or `client_secret` are not provided and\n            one or both of `PROXYSTORE_GLOBUS_CLIENT_ID` and\n            `PROXYSTORE_GLOBUS_CLIENT_SECRET` are not set.\n        ValueError: if the provided `client_id` or ID read from the environment\n            is not a valid UUID.\n    \"\"\"\n    if client_id is None or client_secret is None:\n        client_id, client_secret = _get_client_credentials_from_env()\n\n    try:\n        uuid.UUID(client_id)\n    except ValueError as e:\n        raise ValueError(\n            f'Client ID \"{client_id}\" is not a valid UUID. '\n            'Did you use the username instead of ID?',\n        ) from e\n\n    return globus_sdk.ConfidentialAppAuthClient(\n        client_id=str(client_id),\n        client_secret=str(client_secret),\n    )\n</code></pre>"},{"location":"api/globus/client/#proxystore.globus.client.get_native_app_auth_client","title":"get_native_app_auth_client()","text":"<pre><code>get_native_app_auth_client(\n    client_id: str = _PROXYSTORE_GLOBUS_APPLICATION_ID,\n    app_name: str = \"proxystore-client\",\n) -&gt; NativeAppAuthClient\n</code></pre> <p>Create a native app authentication client.</p> Note <p>This function will not perform the OAuth2 flow.</p> <p>Parameters:</p> <ul> <li> <code>client_id</code>             (<code>str</code>, default:                 <code>_PROXYSTORE_GLOBUS_APPLICATION_ID</code> )         \u2013          <p>Application ID. Defaults to the ProxyStore application ID.</p> </li> <li> <code>app_name</code>             (<code>str</code>, default:                 <code>'proxystore-client'</code> )         \u2013          <p>Application name.</p> </li> </ul> <p>Returns:</p> <ul> <li> <code>NativeAppAuthClient</code>         \u2013          <p>Authorization client.</p> </li> </ul> Source code in <code>proxystore/globus/client.py</code> <pre><code>def get_native_app_auth_client(\n    client_id: str = _PROXYSTORE_GLOBUS_APPLICATION_ID,\n    app_name: str = 'proxystore-client',\n) -&gt; globus_sdk.NativeAppAuthClient:\n    \"\"\"Create a native app authentication client.\n\n    Note:\n        This function will not perform the OAuth2 flow.\n\n    Args:\n        client_id: Application ID. Defaults to the ProxyStore application ID.\n        app_name: Application name.\n\n    Returns:\n        Authorization client.\n    \"\"\"\n    return globus_sdk.NativeAppAuthClient(\n        client_id=client_id,\n        app_name=app_name,\n    )\n</code></pre>"},{"location":"api/globus/client/#proxystore.globus.client.is_client_login","title":"is_client_login()","text":"<pre><code>is_client_login() -&gt; bool\n</code></pre> <p>Check if Globus client identity environment variables are set.</p> <p>Based on the Globus Compute SDK's <code>is_client_login()</code>.</p> <p>Returns:</p> <ul> <li> <code>bool</code>         \u2013          <p><code>True</code> if <code>PROXYSTORE_GLOBUS_CLIENT_ID</code> and         <code>PROXYSTORE_GLOBUS_CLIENT_SECRET</code> are set.</p> </li> </ul> Source code in <code>proxystore/globus/client.py</code> <pre><code>def is_client_login() -&gt; bool:\n    \"\"\"Check if Globus client identity environment variables are set.\n\n    Based on the Globus Compute SDK's\n    [`is_client_login()`](https://github.com/funcx-faas/funcX/blob/8f5b59075ae6f8e8b8b13fe1b91430271f4e0c3c/compute_sdk/globus_compute_sdk/sdk/login_manager/client_login.py#L24-L38){target=_blank}.\n\n    Returns:\n        `True` if `PROXYSTORE_GLOBUS_CLIENT_ID` and \\\n        `PROXYSTORE_GLOBUS_CLIENT_SECRET` are set.\n    \"\"\"\n    try:\n        _get_client_credentials_from_env()\n    except ValueError:\n        return False\n    else:\n        return True\n</code></pre>"},{"location":"api/globus/manager/","title":"proxystore.globus.manager","text":"<code>proxystore/globus/manager.py</code> <p>Globus Auth credential managers.</p>"},{"location":"api/globus/manager/#proxystore.globus.manager.GlobusAuthManager","title":"GlobusAuthManager","text":"<p>             Bases: <code>Protocol</code></p> <p>Protocol for a Globus Auth manager.</p>"},{"location":"api/globus/manager/#proxystore.globus.manager.GlobusAuthManager.client","title":"client  <code>property</code>","text":"<pre><code>client: AuthLoginClient\n</code></pre> <p>Globus Auth client.</p>"},{"location":"api/globus/manager/#proxystore.globus.manager.GlobusAuthManager.logged_in","title":"logged_in  <code>property</code>","text":"<pre><code>logged_in: bool\n</code></pre> <p>User has valid refresh tokens for necessary scopes.</p>"},{"location":"api/globus/manager/#proxystore.globus.manager.GlobusAuthManager.get_authorizer","title":"get_authorizer()","text":"<pre><code>get_authorizer(resource_server: str) -&gt; GlobusAuthorizer\n</code></pre> <p>Get authorizer for a specific resource server.</p> <p>Raises:</p> <ul> <li> <code>LookupError</code>           \u2013          <p>if tokens for the resource server do not exist.</p> </li> </ul> Source code in <code>proxystore/globus/manager.py</code> <pre><code>def get_authorizer(\n    self,\n    resource_server: str,\n) -&gt; globus_sdk.authorizers.GlobusAuthorizer:\n    \"\"\"Get authorizer for a specific resource server.\n\n    Raises:\n        LookupError: if tokens for the resource server do not exist.\n    \"\"\"\n    ...\n</code></pre>"},{"location":"api/globus/manager/#proxystore.globus.manager.GlobusAuthManager.login","title":"login()","text":"<pre><code>login(*, additional_scopes: Iterable[str] = ()) -&gt; None\n</code></pre> <p>Perform the authentication flow.</p> <p>This method is idempotent meaning it will be a no-op if the user is already logged in.</p> <p>Parameters:</p> <ul> <li> <code>additional_scopes</code>             (<code>Iterable[str]</code>, default:                 <code>()</code> )         \u2013          <p>Additional scopes to request.</p> </li> </ul> Source code in <code>proxystore/globus/manager.py</code> <pre><code>def login(self, *, additional_scopes: Iterable[str] = ()) -&gt; None:\n    \"\"\"Perform the authentication flow.\n\n    This method is idempotent meaning it will be a no-op if the user\n    is already logged in.\n\n    Args:\n        additional_scopes: Additional scopes to request.\n    \"\"\"\n    ...\n</code></pre>"},{"location":"api/globus/manager/#proxystore.globus.manager.GlobusAuthManager.logout","title":"logout()","text":"<pre><code>logout() -&gt; None\n</code></pre> <p>Revoke and remove authentication tokens.</p> Source code in <code>proxystore/globus/manager.py</code> <pre><code>def logout(self) -&gt; None:\n    \"\"\"Revoke and remove authentication tokens.\"\"\"\n    ...\n</code></pre>"},{"location":"api/globus/manager/#proxystore.globus.manager.ConfidentialAppAuthManager","title":"ConfidentialAppAuthManager","text":"<pre><code>ConfidentialAppAuthManager(\n    *,\n    client: ConfidentialAppAuthClient | None = None,\n    storage: SQLiteAdapter | None = None,\n    resource_server_scopes: (\n        dict[str, list[str]] | None\n    ) = None\n)\n</code></pre> <p>Globus confidential app (client identity) credential manager.</p> <p>Parameters:</p> <ul> <li> <code>client</code>             (<code>ConfidentialAppAuthClient | None</code>, default:                 <code>None</code> )         \u2013          <p>Optionally override the standard ProxyStore auth client.</p> </li> <li> <code>storage</code>             (<code>SQLiteAdapter | None</code>, default:                 <code>None</code> )         \u2013          <p>Optionally override the default token storage.</p> </li> <li> <code>resource_server_scopes</code>             (<code>dict[str, list[str]] | None</code>, default:                 <code>None</code> )         \u2013          <p>Mapping of resource server URLs to a list of scopes for that resource server. If unspecified, all basic scopes needed by ProxyStore components will be requested. This parameter can be used to request scopes for many resource server when <code>login()</code> is invoked.</p> </li> </ul> Source code in <code>proxystore/globus/manager.py</code> <pre><code>def __init__(\n    self,\n    *,\n    client: globus_sdk.ConfidentialAppAuthClient | None = None,\n    storage: globus_sdk.tokenstorage.SQLiteAdapter | None = None,\n    resource_server_scopes: dict[str, list[str]] | None = None,\n) -&gt; None:\n    self._client = (\n        client\n        if client is not None\n        else get_confidential_app_auth_client()\n    )\n    self._storage = (\n        storage\n        if storage is not None\n        else get_token_storage_adapter(\n            namespace=f'client/{self._client.client_id}',\n        )\n    )\n    self._resource_server_scopes = (\n        resource_server_scopes\n        if resource_server_scopes is not None\n        else get_all_scopes_by_resource_server()\n    )\n</code></pre>"},{"location":"api/globus/manager/#proxystore.globus.manager.ConfidentialAppAuthManager.client","title":"client  <code>property</code>","text":"<pre><code>client: ConfidentialAppAuthClient\n</code></pre> <p>Globus Auth client.</p>"},{"location":"api/globus/manager/#proxystore.globus.manager.ConfidentialAppAuthManager.logged_in","title":"logged_in  <code>property</code>","text":"<pre><code>logged_in: bool\n</code></pre> <p>User has valid refresh tokens for necessary scopes.</p> <p>This is always true for client identities.</p>"},{"location":"api/globus/manager/#proxystore.globus.manager.ConfidentialAppAuthManager.get_authorizer","title":"get_authorizer()","text":"<pre><code>get_authorizer(resource_server: str) -&gt; GlobusAuthorizer\n</code></pre> <p>Get authorizer for a specific resource server.</p> Source code in <code>proxystore/globus/manager.py</code> <pre><code>def get_authorizer(\n    self,\n    resource_server: str,\n) -&gt; globus_sdk.authorizers.GlobusAuthorizer:\n    \"\"\"Get authorizer for a specific resource server.\"\"\"\n    scopes = []\n    for rs_name, rs_scopes in self._resource_server_scopes.items():\n        if rs_name == resource_server:\n            scopes.extend(rs_scopes)\n\n    tokens = self._storage.get_token_data(resource_server)\n    if tokens is None:\n        tokens = {}\n\n    return globus_sdk.ClientCredentialsAuthorizer(\n        confidential_client=self.client,\n        scopes=scopes,\n        access_token=tokens.get('access_token', None),\n        expires_at=tokens.get('expires_at_seconds', None),\n        on_refresh=self._storage.on_refresh,\n    )\n</code></pre>"},{"location":"api/globus/manager/#proxystore.globus.manager.ConfidentialAppAuthManager.login","title":"login()","text":"<pre><code>login(*, additional_scopes: Iterable[str] = ()) -&gt; None\n</code></pre> <p>Perform the authentication flow.</p> <p>Client identities do not require a login flow so this is a no-op.</p> <p>Parameters:</p> <ul> <li> <code>additional_scopes</code>             (<code>Iterable[str]</code>, default:                 <code>()</code> )         \u2013          <p>Additional scopes to request.</p> </li> </ul> Source code in <code>proxystore/globus/manager.py</code> <pre><code>def login(self, *, additional_scopes: Iterable[str] = ()) -&gt; None:\n    \"\"\"Perform the authentication flow.\n\n    Client identities do not require a login flow so this is a no-op.\n\n    Args:\n        additional_scopes: Additional scopes to request.\n    \"\"\"\n    return\n</code></pre>"},{"location":"api/globus/manager/#proxystore.globus.manager.ConfidentialAppAuthManager.logout","title":"logout()","text":"<pre><code>logout() -&gt; None\n</code></pre> <p>Revoke and remove authentication tokens.</p> Source code in <code>proxystore/globus/manager.py</code> <pre><code>def logout(self) -&gt; None:\n    \"\"\"Revoke and remove authentication tokens.\"\"\"\n    for server, data in self._storage.get_by_resource_server().items():\n        for key in ('access_token', 'refresh_token'):\n            token = data[key]\n            self.client.oauth2_revoke_token(token)\n        self._storage.remove_tokens_for_resource_server(server)\n</code></pre>"},{"location":"api/globus/manager/#proxystore.globus.manager.NativeAppAuthManager","title":"NativeAppAuthManager","text":"<pre><code>NativeAppAuthManager(\n    *,\n    client: NativeAppAuthClient | None = None,\n    storage: SQLiteAdapter | None = None,\n    resource_server_scopes: (\n        dict[str, list[str]] | None\n    ) = None\n)\n</code></pre> <p>Globus native app credential manager.</p> <p>Parameters:</p> <ul> <li> <code>client</code>             (<code>NativeAppAuthClient | None</code>, default:                 <code>None</code> )         \u2013          <p>Optionally override the standard ProxyStore auth client.</p> </li> <li> <code>storage</code>             (<code>SQLiteAdapter | None</code>, default:                 <code>None</code> )         \u2013          <p>Optionally override the default token storage.</p> </li> <li> <code>resource_server_scopes</code>             (<code>dict[str, list[str]] | None</code>, default:                 <code>None</code> )         \u2013          <p>Mapping of resource server URLs to a list of scopes for that resource server. If unspecified, all basic scopes needed by ProxyStore components will be requested. This parameter can be used to request scopes for many resource server when <code>login()</code> is invoked.</p> </li> </ul> Source code in <code>proxystore/globus/manager.py</code> <pre><code>def __init__(\n    self,\n    *,\n    client: globus_sdk.NativeAppAuthClient | None = None,\n    storage: globus_sdk.tokenstorage.SQLiteAdapter | None = None,\n    resource_server_scopes: dict[str, list[str]] | None = None,\n) -&gt; None:\n    self._client = (\n        client if client is not None else get_native_app_auth_client()\n    )\n    self._storage = (\n        storage\n        if storage is not None\n        else get_token_storage_adapter(\n            namespace=f'user/{self._client.client_id}',\n        )\n    )\n    self._resource_server_scopes = (\n        resource_server_scopes\n        if resource_server_scopes is not None\n        else get_all_scopes_by_resource_server()\n    )\n</code></pre>"},{"location":"api/globus/manager/#proxystore.globus.manager.NativeAppAuthManager.client","title":"client  <code>property</code>","text":"<pre><code>client: NativeAppAuthClient\n</code></pre> <p>Globus Auth client.</p>"},{"location":"api/globus/manager/#proxystore.globus.manager.NativeAppAuthManager.logged_in","title":"logged_in  <code>property</code>","text":"<pre><code>logged_in: bool\n</code></pre> <p>User has valid refresh tokens for necessary scopes.</p>"},{"location":"api/globus/manager/#proxystore.globus.manager.NativeAppAuthManager.get_authorizer","title":"get_authorizer()","text":"<pre><code>get_authorizer(resource_server: str) -&gt; GlobusAuthorizer\n</code></pre> <p>Get authorizer for a specific resource server.</p> <p>Raises:</p> <ul> <li> <code>LookupError</code>           \u2013          <p>if tokens for the resource server do not exist.</p> </li> </ul> Source code in <code>proxystore/globus/manager.py</code> <pre><code>def get_authorizer(\n    self,\n    resource_server: str,\n) -&gt; globus_sdk.authorizers.GlobusAuthorizer:\n    \"\"\"Get authorizer for a specific resource server.\n\n    Raises:\n        LookupError: if tokens for the resource server do not exist.\n    \"\"\"\n    tokens = self._storage.get_token_data(resource_server)\n    if tokens is None:\n        raise LookupError(f'Could not find tokens for {resource_server}.')\n    return globus_sdk.RefreshTokenAuthorizer(\n        tokens['refresh_token'],\n        self.client,\n        access_token=tokens['access_token'],\n        expires_at=tokens['expires_at_seconds'],\n        on_refresh=self._storage.on_refresh,\n    )\n</code></pre>"},{"location":"api/globus/manager/#proxystore.globus.manager.NativeAppAuthManager.login","title":"login()","text":"<pre><code>login(*, additional_scopes: Iterable[str] = ()) -&gt; None\n</code></pre> <p>Perform the authentication flow.</p> <p>This method is idempotent meaning it will be a no-op if the user is already logged in.</p> <p>On log in, the user will be prompted to follow a link to authenticate on globus.org.</p> <p>Parameters:</p> <ul> <li> <code>additional_scopes</code>             (<code>Iterable[str]</code>, default:                 <code>()</code> )         \u2013          <p>Additional scopes to request.</p> </li> </ul> Source code in <code>proxystore/globus/manager.py</code> <pre><code>def login(self, *, additional_scopes: Iterable[str] = ()) -&gt; None:\n    \"\"\"Perform the authentication flow.\n\n    This method is idempotent meaning it will be a no-op if the user\n    is already logged in.\n\n    On log in, the user will be prompted to follow a link to authenticate\n    on [globus.org](https://globus.org).\n\n    Args:\n        additional_scopes: Additional scopes to request.\n    \"\"\"\n    if not self.logged_in:\n        token = self._run_login_flow(additional_scopes=additional_scopes)\n        self._storage.store(token)\n</code></pre>"},{"location":"api/globus/manager/#proxystore.globus.manager.NativeAppAuthManager.logout","title":"logout()","text":"<pre><code>logout() -&gt; None\n</code></pre> <p>Revoke and remove authentication tokens.</p> Source code in <code>proxystore/globus/manager.py</code> <pre><code>def logout(self) -&gt; None:\n    \"\"\"Revoke and remove authentication tokens.\"\"\"\n    for server, data in self._storage.get_by_resource_server().items():\n        for key in ('access_token', 'refresh_token'):\n            token = data[key]\n            self.client.oauth2_revoke_token(token)\n        self._storage.remove_tokens_for_resource_server(server)\n</code></pre>"},{"location":"api/globus/scopes/","title":"proxystore.globus.scopes","text":"<code>proxystore/globus/scopes.py</code> <p>Build Globus Auth scopes.</p>"},{"location":"api/globus/scopes/#proxystore.globus.scopes.ProxyStoreRelayScopes","title":"ProxyStoreRelayScopes  <code>module-attribute</code>","text":"<pre><code>ProxyStoreRelayScopes = ScopeBuilder(\n    \"ebd5bbed-95e2-47cf-9c80-39e2064274bd\",\n    known_url_scopes=[\"relay_all\"],\n)\n</code></pre> <p>ProxyStore Relay Server scopes.</p> <p>Supported Scopes:</p> <ul> <li><code>relay_all</code></li> </ul>"},{"location":"api/globus/scopes/#proxystore.globus.scopes.get_all_scopes_by_resource_server","title":"get_all_scopes_by_resource_server()","text":"<pre><code>get_all_scopes_by_resource_server(\n    collections: Iterable[str] = (),\n) -&gt; dict[str, list[str]]\n</code></pre> <p>Get all scopes needed by the ProxyStore library by resource server.</p> <p>This returns scopes for three resource servers: Globus Auth, Globus Transfer, and the ProxyStore Relay Server.</p> <p>Parameters:</p> <ul> <li> <code>collections</code>             (<code>Iterable[str]</code>, default:                 <code>()</code> )         \u2013          <p>Iterable of collection UUIDs to request consent for. Passed to <code>get_transfer_scopes_by_resource_server</code>.</p> </li> </ul> Source code in <code>proxystore/globus/scopes.py</code> <pre><code>def get_all_scopes_by_resource_server(\n    collections: Iterable[str] = (),\n) -&gt; dict[str, list[str]]:\n    \"\"\"Get all scopes needed by the ProxyStore library by resource server.\n\n    This returns scopes for three resource servers: Globus Auth, Globus\n    Transfer, and the ProxyStore Relay Server.\n\n    Args:\n        collections: Iterable of collection UUIDs to request consent for.\n            Passed to\n            [`get_transfer_scopes_by_resource_server`][proxystore.globus.scopes.get_transfer_scopes_by_resource_server].\n    \"\"\"\n    return {\n        **get_auth_scopes_by_resource_server(),\n        **get_relay_scopes_by_resource_server(),\n        **get_transfer_scopes_by_resource_server(collections),\n    }\n</code></pre>"},{"location":"api/globus/scopes/#proxystore.globus.scopes.get_auth_scopes_by_resource_server","title":"get_auth_scopes_by_resource_server()","text":"<pre><code>get_auth_scopes_by_resource_server() -&gt; (\n    dict[str, list[str]]\n)\n</code></pre> <p>Get basic scopes for the auth API resource server.</p> Source code in <code>proxystore/globus/scopes.py</code> <pre><code>def get_auth_scopes_by_resource_server() -&gt; dict[str, list[str]]:\n    \"\"\"Get basic scopes for the auth API resource server.\"\"\"\n    return {AuthScopes.resource_server: [AuthScopes.openid, AuthScopes.email]}\n</code></pre>"},{"location":"api/globus/scopes/#proxystore.globus.scopes.get_relay_scopes_by_resource_server","title":"get_relay_scopes_by_resource_server()","text":"<pre><code>get_relay_scopes_by_resource_server() -&gt; (\n    dict[str, list[str]]\n)\n</code></pre> <p>Get all scopes for the relay server by resource server.</p> Source code in <code>proxystore/globus/scopes.py</code> <pre><code>def get_relay_scopes_by_resource_server() -&gt; dict[str, list[str]]:\n    \"\"\"Get all scopes for the relay server by resource server.\"\"\"\n    return {\n        ProxyStoreRelayScopes.resource_server: [\n            ProxyStoreRelayScopes.relay_all,\n        ],\n    }\n</code></pre>"},{"location":"api/globus/scopes/#proxystore.globus.scopes.get_transfer_scopes_by_resource_server","title":"get_transfer_scopes_by_resource_server()","text":"<pre><code>get_transfer_scopes_by_resource_server(\n    collections: Iterable[str] = (),\n) -&gt; dict[str, list[str]]\n</code></pre> <p>Get scopes for the transfer API resource server.</p> <p>Parameters:</p> <ul> <li> <code>collections</code>             (<code>Iterable[str]</code>, default:                 <code>()</code> )         \u2013          <p>Iterable of collection UUIDs to request consent for.</p> </li> </ul> Source code in <code>proxystore/globus/scopes.py</code> <pre><code>def get_transfer_scopes_by_resource_server(\n    collections: Iterable[str] = (),\n) -&gt; dict[str, list[str]]:\n    \"\"\"Get scopes for the transfer API resource server.\n\n    Args:\n        collections: Iterable of collection UUIDs to request consent for.\n    \"\"\"\n    transfer_scope = TransferScopes.make_mutable('all')\n\n    for collection in collections:\n        data_access_scope = GCSCollectionScopeBuilder(collection).make_mutable(\n            'data_access',\n        )\n        transfer_scope.add_dependency(data_access_scope)\n\n    return {TransferScopes.resource_server: [str(transfer_scope)]}\n</code></pre>"},{"location":"api/globus/storage/","title":"proxystore.globus.storage","text":"<code>proxystore/globus/storage.py</code> <p>Globus Auth token storage.</p>"},{"location":"api/globus/storage/#proxystore.globus.storage.get_token_storage_adapter","title":"get_token_storage_adapter()","text":"<pre><code>get_token_storage_adapter(\n    filepath: str | None = None,\n    *,\n    namespace: str = \"DEFAULT\"\n) -&gt; SQLiteAdapter\n</code></pre> <p>Create token storage adapter.</p> <p>Parameters:</p> <ul> <li> <code>filepath</code>             (<code>str | None</code>, default:                 <code>None</code> )         \u2013          <p>Name of the database file. This is passed to SQLite so <code>:memory:</code> is a valid option for an in-memory database. If not provided, defaults to a file in the ProxyStore home directory (see <code>home_dir()</code>).</p> </li> <li> <code>namespace</code>             (<code>str</code>, default:                 <code>'DEFAULT'</code> )         \u2013          <p>Optional namespace to use within the database. See <code>SQLiteAdapter</code> for more detauls.</p> </li> </ul> <p>Returns:</p> <ul> <li> <code>SQLiteAdapter</code>         \u2013          <p>Token storage adapter.</p> </li> </ul> Source code in <code>proxystore/globus/storage.py</code> <pre><code>def get_token_storage_adapter(\n    filepath: str | None = None,\n    *,\n    namespace: str = 'DEFAULT',\n) -&gt; SQLiteAdapter:\n    \"\"\"Create token storage adapter.\n\n    Args:\n        filepath: Name of the database file. This is passed to SQLite so\n            `:memory:` is a valid option for an in-memory database. If not\n            provided, defaults to a file in the ProxyStore home directory\n            (see [`home_dir()`][proxystore.utils.environment.home_dir]).\n        namespace: Optional namespace to use within the database. See\n            [`SQLiteAdapter`][globus_sdk.tokenstorage.SQLiteAdapter] for\n            more detauls.\n\n    Returns:\n        Token storage adapter.\n    \"\"\"\n    if filepath is None:\n        filepath = os.path.join(home_dir(), _TOKENS_FILE)\n    if filepath != ':memory:':\n        pathlib.Path(filepath).parent.mkdir(parents=True, exist_ok=True)\n    return SQLiteAdapter(filepath, namespace=namespace)\n</code></pre>"},{"location":"api/globus/transfer/","title":"proxystore.globus.transfer","text":"<code>proxystore/globus/transfer.py</code> <p>Create and authenticate a Globus Transfer client.</p>"},{"location":"api/globus/transfer/#proxystore.globus.transfer.get_transfer_client_flow","title":"get_transfer_client_flow()","text":"<pre><code>get_transfer_client_flow(\n    check_collections: Iterable[str] = (),\n) -&gt; TransferClient\n</code></pre> <p>Create a transfer client with consent handling.</p> <p>Performs a transfer client creation flow. The user is first prompted to authenticate with Globus if the user has not already authenticated. Then all collections in <code>check_collections</code> are checked to make sure that they are accessible. If any <code>ConsentRequired</code> errors are caught, the user is asked to re-authenticate with the required additional scopes.</p> <p>Parameters:</p> <ul> <li> <code>check_collections</code>             (<code>Iterable[str]</code>, default:                 <code>()</code> )         \u2013          <p>An iterable of collection UUIDs to ensure the user's tokens have consent for.</p> </li> </ul> <p>Returns:</p> <ul> <li> <code>TransferClient</code>         \u2013          <p>Transfer client.</p> </li> </ul> Source code in <code>proxystore/globus/transfer.py</code> <pre><code>def get_transfer_client_flow(\n    check_collections: Iterable[str] = (),\n) -&gt; globus_sdk.TransferClient:\n    \"\"\"Create a transfer client with consent handling.\n\n    Performs a transfer client creation flow. The user is first prompted to\n    authenticate with Globus if the user has not already authenticated.\n    Then all collections in `check_collections` are checked to make sure that\n    they are accessible. If any `ConsentRequired` errors are caught, the\n    user is asked to re-authenticate with the required additional scopes.\n\n    Args:\n        check_collections: An iterable of collection UUIDs to ensure the\n            user's tokens have consent for.\n\n    Returns:\n        Transfer client.\n    \"\"\"\n    scopes = get_transfer_scopes_by_resource_server()\n    manager = NativeAppAuthManager(resource_server_scopes=scopes)\n    manager.login()\n\n    authorizer = manager.get_authorizer(\n        globus_sdk.scopes.TransferScopes.resource_server,\n    )\n    transfer_client = globus_sdk.TransferClient(authorizer=authorizer)\n\n    consent_required_scopes: list[str] = []\n    for collection in check_collections:\n        try:\n            transfer_client.operation_ls(collection, path='/')\n        except globus_sdk.TransferAPIError as e:\n            if (\n                e.info.consent_required\n                and e.info.consent_required.required_scopes is not None\n            ):\n                consent_required_scopes.extend(\n                    e.info.consent_required.required_scopes,\n                )\n\n    if len(consent_required_scopes) == 0:\n        return transfer_client\n\n    click.echo(\n        'One or more collections require consent in order to be used. '\n        'Login again to to grant the remaining consents.',\n    )\n    manager.login(additional_scopes=consent_required_scopes)\n    authorizer = manager.get_authorizer(\n        globus_sdk.scopes.TransferScopes.resource_server,\n    )\n    return globus_sdk.TransferClient(authorizer=authorizer)\n</code></pre>"},{"location":"api/p2p/","title":"proxystore.p2p","text":"<code>proxystore/p2p/__init__.py</code> <p>Peer-to-peer communication and relaying.</p> <p>This module provides two main functionalities: the <code>PeerManager</code> and relay client/server implementations.</p> <ul> <li>The <code>PeerManager</code> enables   easy communication between arbitrary peers even if peers are behind separate   NATs. Peer connections are established using   aiortc, an asyncio WebRTC   implementation.</li> <li>The <code>proxystore.p2p.relay</code> module provides   implementations of the relay server and associated clients that are used by   peers to facilitate WebRTC peer connections.</li> </ul>"},{"location":"api/p2p/chunks/","title":"proxystore.p2p.chunks","text":"<code>proxystore/p2p/chunks.py</code> <p>Message chunking utilities.</p>"},{"location":"api/p2p/chunks/#proxystore.p2p.chunks.ChunkDType","title":"ChunkDType","text":"<p>             Bases: <code>Enum</code></p> <p>Data type contained in a Chunk.</p>"},{"location":"api/p2p/chunks/#proxystore.p2p.chunks.ChunkDType.BYTES","title":"BYTES  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>BYTES = 1\n</code></pre> <p>Data is bytes.</p>"},{"location":"api/p2p/chunks/#proxystore.p2p.chunks.ChunkDType.STRING","title":"STRING  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>STRING = 2\n</code></pre> <p>Data is a string.</p>"},{"location":"api/p2p/chunks/#proxystore.p2p.chunks.Chunk","title":"Chunk","text":"<pre><code>Chunk(\n    stream_id: int,\n    seq_id: int,\n    seq_len: int,\n    data: bytes | str,\n    dtype: ChunkDType | None = None,\n)\n</code></pre> <p>Representation of a chunk of a message.</p> <p>Parameters:</p> <ul> <li> <code>stream_id</code>             (<code>int</code>)         \u2013          <p>Unique ID for the stream of chunks.</p> </li> <li> <code>seq_id</code>             (<code>int</code>)         \u2013          <p>Sequence number for this chunk in the stream.</p> </li> <li> <code>seq_len</code>             (<code>int</code>)         \u2013          <p>Length of the stream.</p> </li> <li> <code>data</code>             (<code>bytes | str</code>)         \u2013          <p>Data for this chunk.</p> </li> <li> <code>dtype</code>             (<code>ChunkDType | None</code>, default:                 <code>None</code> )         \u2013          <p>Optionally specify data type otherwise inferred from data.</p> </li> </ul> <p>Raises:</p> <ul> <li> <code>ValueError</code>           \u2013          <p>if the sequence ID is not less than the sequence length.</p> </li> </ul> Source code in <code>proxystore/p2p/chunks.py</code> <pre><code>def __init__(\n    self,\n    stream_id: int,\n    seq_id: int,\n    seq_len: int,\n    data: bytes | str,\n    dtype: ChunkDType | None = None,\n) -&gt; None:\n    if seq_len &lt;= seq_id:\n        raise ValueError(\n            f'seq_id ({seq_id}) must be less than seq_len ({seq_len}).',\n        )\n    self.stream_id = stream_id\n    self.seq_id = seq_id\n    self.seq_len = seq_len\n    self.data = data\n    if dtype is None:\n        self.dtype = (\n            ChunkDType.BYTES\n            if isinstance(data, bytes)\n            else ChunkDType.STRING\n        )\n    else:\n        self.dtype = dtype\n</code></pre>"},{"location":"api/p2p/chunks/#proxystore.p2p.chunks.Chunk.__bytes__","title":"__bytes__()","text":"<pre><code>__bytes__() -&gt; bytes\n</code></pre> <p>Pack the chunk into bytes.</p> Source code in <code>proxystore/p2p/chunks.py</code> <pre><code>def __bytes__(self) -&gt; bytes:\n    \"\"\"Pack the chunk into bytes.\"\"\"\n    length = CHUNK_HEADER_LENGTH + len(self.data)\n    header = pack(\n        CHUNK_HEADER_FORMAT,\n        self.dtype.value,\n        length,\n        self.stream_id,\n        self.seq_id,\n        self.seq_len,\n    )\n    data = (\n        self.data.encode('utf8')\n        if isinstance(self.data, str)\n        else self.data\n    )\n    chunk = header + data\n\n    data += b'\\x00' * (len(chunk) % 4)\n    return chunk\n</code></pre>"},{"location":"api/p2p/chunks/#proxystore.p2p.chunks.Chunk.from_bytes","title":"from_bytes()  <code>classmethod</code>","text":"<pre><code>from_bytes(chunk: bytes) -&gt; Chunk\n</code></pre> <p>Decode bytes into a Chunk.</p> Source code in <code>proxystore/p2p/chunks.py</code> <pre><code>@classmethod\ndef from_bytes(cls, chunk: bytes) -&gt; Chunk:\n    \"\"\"Decode bytes into a Chunk.\"\"\"\n    (dtype_value, length, stream_id, seq_id, seq_len) = unpack_from(\n        CHUNK_HEADER_FORMAT,\n        chunk,\n    )\n    dtype = ChunkDType(dtype_value)\n    chunk_data = chunk[CHUNK_HEADER_LENGTH:length]\n    data: bytes | str\n    if dtype is ChunkDType.STRING:\n        data = chunk_data.decode('utf8')\n    else:\n        data = chunk_data\n    return cls(\n        stream_id=stream_id,\n        seq_id=seq_id,\n        seq_len=seq_len,\n        data=data,\n        dtype=dtype,\n    )\n</code></pre>"},{"location":"api/p2p/chunks/#proxystore.p2p.chunks.chunkify","title":"chunkify()","text":"<pre><code>chunkify(\n    data: bytes | str, size: int, stream_id: int\n) -&gt; Generator[Chunk, None, None]\n</code></pre> <p>Generate chunks from data.</p> <p>Parameters:</p> <ul> <li> <code>data</code>             (<code>bytes | str</code>)         \u2013          <p>Data to chunk.</p> </li> <li> <code>size</code>             (<code>int</code>)         \u2013          <p>Size of each chunk.</p> </li> <li> <code>stream_id</code>             (<code>int</code>)         \u2013          <p>Unique ID for the stream of chunks.</p> </li> </ul> <p>Yields:</p> <ul> <li> <code>Chunk</code>         \u2013          <p>Chunks of data.</p> </li> </ul> Source code in <code>proxystore/p2p/chunks.py</code> <pre><code>def chunkify(\n    data: bytes | str,\n    size: int,\n    stream_id: int,\n) -&gt; Generator[Chunk, None, None]:\n    \"\"\"Generate chunks from data.\n\n    Args:\n        data: Data to chunk.\n        size: Size of each chunk.\n        stream_id: Unique ID for the stream of chunks.\n\n    Yields:\n        Chunks of data.\n    \"\"\"\n    seq_len = math.ceil(len(data) / size)\n\n    for i, x in enumerate(range(0, len(data), size)):\n        chunk_data = data[x : min(x + size, len(data))]\n        yield Chunk(\n            stream_id=stream_id,\n            seq_id=i,\n            seq_len=seq_len,\n            data=chunk_data,\n        )\n</code></pre>"},{"location":"api/p2p/chunks/#proxystore.p2p.chunks.reconstruct","title":"reconstruct()","text":"<pre><code>reconstruct(chunks: list[Chunk]) -&gt; bytes | str\n</code></pre> <p>Reconstructs data from list of chunks.</p> <p>Parameters:</p> <ul> <li> <code>chunks</code>             (<code>list[Chunk]</code>)         \u2013          <p>List of chunks to order and join.</p> </li> </ul> <p>Returns:</p> <ul> <li> <code>bytes | str</code>         \u2013          <p>Reconstructed bytes or string.</p> </li> </ul> Source code in <code>proxystore/p2p/chunks.py</code> <pre><code>def reconstruct(chunks: list[Chunk]) -&gt; bytes | str:\n    \"\"\"Reconstructs data from list of chunks.\n\n    Args:\n        chunks: List of chunks to order and join.\n\n    Returns:\n        Reconstructed bytes or string.\n    \"\"\"\n    if len(chunks) == 0:\n        raise ValueError('Chunks list cannot be empty.')\n    seq_len = chunks[0].seq_len\n    if len(chunks) != seq_len:\n        raise ValueError(f'Got {len(chunks)} but expected {seq_len}.')\n    chunks = sorted(chunks, key=lambda c: c.seq_id)\n    if isinstance(chunks[0].data, bytes):\n        return b''.join(c.data for c in chunks)  # type: ignore\n    elif isinstance(chunks[0].data, str):\n        return ''.join(c.data for c in chunks)  # type: ignore\n    else:\n        raise AssertionError('Unreachable.')\n</code></pre>"},{"location":"api/p2p/connection/","title":"proxystore.p2p.connection","text":"<code>proxystore/p2p/connection.py</code> <p>Representation of peer-to-peer connection.</p>"},{"location":"api/p2p/connection/#proxystore.p2p.connection.PeerConnection","title":"PeerConnection","text":"<pre><code>PeerConnection(\n    relay_client: RelayClient, *, channels: int = 1\n)\n</code></pre> <p>Peer-to-peer connection.</p> <p>Interface for establishing a peer-to-peer connection via WebRTC aiortc and sending/receiving messages between the two peers. The peer-to-peer connection is established using a central and publicly accessible relay server.</p> Warning <p>Applications should prefer using the <code>PeerManager</code> rather than using the <code>PeerConnection</code> class.</p> Example <pre><code>from proxystore.p2p.connection import PeerConnection\nfrom proxystore.p2p.relay import BasicRelayClient\n\nclient1 = BasicRelayClient(relay_server_address)\nawait client1.connect()\nconnection1 = PeerConnection(client1)\n\nclient2 = BasicRelayClient(relay_server_address)\nawait client2.connect()\nconnection2 = PeerConnection(client2)\n\nawait connection1.send_offer(client2.uuid)\noffer = await client2.recv()\nawait connection2.handle_server_message(offer)\nanswer = await client1.recv()\nawait connection1.handle_server_message(answer)\n\nawait connection1.ready()\nawait connection2.ready()\n\nawait connection1.send('hello')\nassert await connection2.recv() == 'hello'\nawait connection2.send('hello hello')\nassert await connection1.recv() == 'hello hello'\n\nawait client1.close()\nawait client2.close()\nawait connection1.close()\nawait connection2.close()\n</code></pre> <p>Parameters:</p> <ul> <li> <code>relay_client</code>             (<code>RelayClient</code>)         \u2013          <p>Client connection to the relay server.</p> </li> <li> <code>channels</code>             (<code>int</code>, default:                 <code>1</code> )         \u2013          <p>Number of datachannels to open with peer.</p> </li> </ul> Source code in <code>proxystore/p2p/connection.py</code> <pre><code>def __init__(\n    self,\n    relay_client: RelayClient,\n    *,\n    channels: int = 1,\n) -&gt; None:\n    self._relay_client = relay_client\n    self._max_channels = channels\n\n    self._handshake_success: asyncio.Future[bool] = (\n        asyncio.get_running_loop().create_future()\n    )\n    self._pc = RTCPeerConnection()\n\n    self._incoming_queue: asyncio.Queue[bytes | str] = asyncio.Queue()\n    self._incoming_chunks: dict[int, list[Chunk]] = defaultdict(list)\n    # Max size of unsigned long (4 bytes) is 2^32 - 1\n    self._message_counter = AtomicCounter(size=2**32 - 1)\n\n    # Used by offerer to count how many of the channels it opened are ready\n    self._ready = 0\n    self._channels: dict[str, RTCDataChannel] = {}\n    self._channel_buffer_low: dict[str, asyncio.Event] = {}\n\n    self._peer_uuid: UUID | None = None\n    self._peer_name: str | None = None\n</code></pre>"},{"location":"api/p2p/connection/#proxystore.p2p.connection.PeerConnection.state","title":"state  <code>property</code>","text":"<pre><code>state: str\n</code></pre> <p>Get the current connection state.</p> <p>Returns:</p> <ul> <li> <code>str</code>         \u2013          <p>One of 'connected', 'connecting', 'closed', 'failed', or 'new'.</p> </li> </ul>"},{"location":"api/p2p/connection/#proxystore.p2p.connection.PeerConnection.close","title":"close()  <code>async</code>","text":"<pre><code>close() -&gt; None\n</code></pre> <p>Terminate the peer connection.</p> Note <p>This will not call <code>RelayClient.close()</code>.</p> Source code in <code>proxystore/p2p/connection.py</code> <pre><code>async def close(self) -&gt; None:\n    \"\"\"Terminate the peer connection.\n\n    Note:\n        This will not call\n        [`RelayClient.close()`][proxystore.p2p.relay.client.RelayClient].\n    \"\"\"\n    logger.info(f'{self._log_prefix}: closing connection')\n    # Flush send buffers before close\n    # https://github.com/aiortc/aiortc/issues/547\n    for channel in self._channels.values():\n        transport = channel._RTCDataChannel__transport\n        await transport._data_channel_flush()\n        await transport._transmit()\n        channel.close()\n    await self._pc.close()\n</code></pre>"},{"location":"api/p2p/connection/#proxystore.p2p.connection.PeerConnection.on_close_callback","title":"on_close_callback()","text":"<pre><code>on_close_callback(\n    callback: Callable[..., Awaitable[None]],\n    *args: Any,\n    **kwargs: Any\n) -&gt; None\n</code></pre> <p>Configure a callback for when the connection fails or closes.</p> <p>Parameters:</p> <ul> <li> <code>callback</code>             (<code>Callable[..., Awaitable[None]]</code>)         \u2013          <p>Callable to invoke when the peer connection state changes to closed or failed.</p> </li> <li> <code>args</code>             (<code>Any</code>, default:                 <code>()</code> )         \u2013          <p>Positional arguments to pass to the callback.</p> </li> <li> <code>kwargs</code>             (<code>Any</code>, default:                 <code>{}</code> )         \u2013          <p>Keyword arguments to pass to the callback.</p> </li> </ul> Source code in <code>proxystore/p2p/connection.py</code> <pre><code>def on_close_callback(\n    self,\n    callback: Callable[..., Awaitable[None]],\n    *args: Any,\n    **kwargs: Any,\n) -&gt; None:\n    \"\"\"Configure a callback for when the connection fails or closes.\n\n    Args:\n        callback: Callable to invoke when the peer connection state\n            changes to closed or failed.\n        args: Positional arguments to pass to the callback.\n        kwargs: Keyword arguments to pass to the callback.\n    \"\"\"\n\n    async def _on_close() -&gt; None:\n        if self.state in ('closed', 'failed'):\n            logger.info(\n                f'{self._log_prefix}: connection entered {self.state} '\n                'state, invoking callback',\n            )\n            await callback(*args, **kwargs)\n\n    self._pc.on('connectionstatechange', _on_close)\n</code></pre>"},{"location":"api/p2p/connection/#proxystore.p2p.connection.PeerConnection.send","title":"send()  <code>async</code>","text":"<pre><code>send(message: bytes | str, timeout: float = 30) -&gt; None\n</code></pre> <p>Send message to peer.</p> <p>Parameters:</p> <ul> <li> <code>message</code>             (<code>bytes | str</code>)         \u2013          <p>Message to send to peer.</p> </li> <li> <code>timeout</code>             (<code>float</code>, default:                 <code>30</code> )         \u2013          <p>Timeout to wait on peer connection to be ready.</p> </li> </ul> <p>Raises:</p> <ul> <li> <code>PeerConnectionTimeoutError</code>           \u2013          <p>If the peer connection is not established within the timeout.</p> </li> </ul> Source code in <code>proxystore/p2p/connection.py</code> <pre><code>async def send(self, message: bytes | str, timeout: float = 30) -&gt; None:\n    \"\"\"Send message to peer.\n\n    Args:\n        message: Message to send to peer.\n        timeout: Timeout to wait on peer connection to be ready.\n\n    Raises:\n        PeerConnectionTimeoutError: If the peer connection is not\n            established within the timeout.\n    \"\"\"\n    await self.ready(timeout)\n\n    chunk_size = (\n        MAX_CHUNK_SIZE_STRING\n        if isinstance(message, str)\n        else MAX_CHUNK_SIZE_BYTES\n    )\n\n    message_id = self._message_counter.increment()\n    channel_names = list(self._channels.keys())\n\n    for i, chunk in enumerate(chunkify(message, chunk_size, message_id)):\n        channel_name = channel_names[i % len(channel_names)]\n        channel = self._channels[channel_name]\n        buffer_low = self._channel_buffer_low[channel_name]\n        if channel.bufferedAmount &gt; channel.bufferedAmountLowThreshold:\n            await buffer_low.wait()\n            buffer_low.clear()\n        channel.send(bytes(chunk))\n\n    logger.debug(f'{self._log_prefix}: sending message to peer')\n</code></pre>"},{"location":"api/p2p/connection/#proxystore.p2p.connection.PeerConnection.recv","title":"recv()  <code>async</code>","text":"<pre><code>recv() -&gt; bytes | str\n</code></pre> <p>Receive next message from peer.</p> <p>Returns:</p> <ul> <li> <code>bytes | str</code>         \u2013          <p>Message received from peer.</p> </li> </ul> Source code in <code>proxystore/p2p/connection.py</code> <pre><code>async def recv(self) -&gt; bytes | str:\n    \"\"\"Receive next message from peer.\n\n    Returns:\n        Message received from peer.\n    \"\"\"\n    return await self._incoming_queue.get()\n</code></pre>"},{"location":"api/p2p/connection/#proxystore.p2p.connection.PeerConnection.send_offer","title":"send_offer()  <code>async</code>","text":"<pre><code>send_offer(peer_uuid: UUID) -&gt; None\n</code></pre> <p>Send offer for peering via relay server.</p> <p>Parameters:</p> <ul> <li> <code>peer_uuid</code>             (<code>UUID</code>)         \u2013          <p>UUID of peer client to establish connection with.</p> </li> </ul> Source code in <code>proxystore/p2p/connection.py</code> <pre><code>async def send_offer(self, peer_uuid: UUID) -&gt; None:\n    \"\"\"Send offer for peering via relay server.\n\n    Args:\n        peer_uuid: UUID of peer client to establish connection with.\n    \"\"\"\n\n    def _on_close(label: str) -&gt; Any:\n        # We use this factory method to avoid Flake8-BugBear B023\n        async def on_close() -&gt; None:\n            if self._channels[label].readyState in ('closed', 'failed'):\n                await self.close()\n\n        return on_close\n\n    for i in range(self._max_channels):\n        label = f'p2p-{i}-{self._max_channels}'\n        channel = self._pc.createDataChannel(label, ordered=False)\n        buffer_low = asyncio.Event()\n        channel.on('open', self._on_datachannel_open)\n        channel.on('bufferedamountlow', buffer_low.set)\n        channel.on('message', self._on_message)\n\n        self._channels[label] = channel\n        self._channel_buffer_low[label] = buffer_low\n\n        # We use the underlying RTCDtlsTransport as the channel status.\n        channel.transport.transport.on('statechange', _on_close(label))\n\n    await self._pc.setLocalDescription(await self._pc.createOffer())\n    message = PeerConnectionRequest(\n        source_uuid=self._relay_client.uuid,\n        source_name=self._relay_client.name,\n        peer_uuid=peer_uuid,\n        description_type='offer',\n        description=object_to_string(self._pc.localDescription),\n    )\n    logger.info(f'{self._log_prefix}: sending offer to {peer_uuid}')\n    await self._relay_client.send(message)\n</code></pre>"},{"location":"api/p2p/connection/#proxystore.p2p.connection.PeerConnection.send_answer","title":"send_answer()  <code>async</code>","text":"<pre><code>send_answer(peer_uuid: UUID) -&gt; None\n</code></pre> <p>Send answer to peering request via relay server.</p> <p>Parameters:</p> <ul> <li> <code>peer_uuid</code>             (<code>UUID</code>)         \u2013          <p>UUID of peer client that sent the initial offer.</p> </li> </ul> Source code in <code>proxystore/p2p/connection.py</code> <pre><code>async def send_answer(self, peer_uuid: UUID) -&gt; None:\n    \"\"\"Send answer to peering request via relay server.\n\n    Args:\n        peer_uuid: UUID of peer client that sent the initial offer.\n    \"\"\"\n\n    @self._pc.on('datachannel')\n    def on_datachannel(channel: RTCDataChannel) -&gt; None:\n        logger.info(f'{self._log_prefix}: peer channel established')\n        # TODO: note this is first channel opened\n        match = re.search(r'(\\d+)-(\\d+)$', channel.label)\n        if match is None:\n            raise AssertionError(\n                f'Got mislabled datachannel {channel.label}',\n            )\n        total = int(match.group(2))\n\n        buffer_low = asyncio.Event()\n        self._channels[channel.label] = channel\n        self._channel_buffer_low[channel.label] = buffer_low\n        channel.on('bufferedamountlow', buffer_low.set)\n        channel.on('message', self._on_message)\n\n        async def _on_close() -&gt; None:\n            if channel.readyState in ('closed', 'failed'):\n                await self.close()\n            else:\n                pass  # pragma: no cover\n\n        # We use the underlying RTCDtlsTransport as the channel status\n        channel.transport.transport.on('statechange', _on_close)\n\n        if len(self._channels) &gt;= total:\n            self._handshake_success.set_result(True)\n\n    await self._pc.setLocalDescription(await self._pc.createAnswer())\n    message = PeerConnectionRequest(\n        source_uuid=self._relay_client.uuid,\n        source_name=self._relay_client.name,\n        peer_uuid=peer_uuid,\n        description_type='answer',\n        description=object_to_string(self._pc.localDescription),\n    )\n    logger.info(f'{self._log_prefix}: sending answer to {peer_uuid}')\n    await self._relay_client.send(message)\n</code></pre>"},{"location":"api/p2p/connection/#proxystore.p2p.connection.PeerConnection.handle_server_message","title":"handle_server_message()  <code>async</code>","text":"<pre><code>handle_server_message(\n    message: PeerConnectionRequest,\n) -&gt; None\n</code></pre> <p>Handle message from the relay server.</p> <p>Parameters:</p> <ul> <li> <code>message</code>             (<code>PeerConnectionRequest</code>)         \u2013          <p>Message received from the relay server.</p> </li> </ul> Source code in <code>proxystore/p2p/connection.py</code> <pre><code>async def handle_server_message(\n    self,\n    message: PeerConnectionRequest,\n) -&gt; None:\n    \"\"\"Handle message from the relay server.\n\n    Args:\n        message: Message received from the relay server.\n    \"\"\"\n    if message.error is not None:\n        self._handshake_success.set_exception(\n            PeerConnectionError(\n                'Received error message from relay server: '\n                f'{message.error!s}',\n            ),\n        )\n        return\n\n    if message.description_type == 'offer':\n        logger.info(\n            f'{self._log_prefix}: received offer from '\n            f'{message.source_uuid} ({message.source_name})',\n        )\n        obj = object_from_string(message.description)\n    elif message.description_type == 'answer':\n        logger.info(\n            f'{self._log_prefix}: received answer from '\n            f'{message.source_uuid} ({message.source_name})',\n        )\n        obj = object_from_string(message.description)\n    else:\n        raise AssertionError(\n            'P2P connection message does not contain either an offer or '\n            'an answer',\n        )\n\n    if isinstance(obj, RTCSessionDescription):\n        await self._pc.setRemoteDescription(obj)\n        self._peer_uuid = message.source_uuid\n        self._peer_name = message.source_name\n        if obj.type == 'offer':\n            await self.send_answer(message.source_uuid)\n    elif isinstance(obj, RTCIceCandidate):  # pragma: no cover\n        # We should not receive an RTCIceCandidate message via the\n        # relay server but this is here following the aiortc example.\n        # https://github.com/aiortc/aiortc/blob/713fb644b95328f8ec1ac2cbb54def0424cc6645/examples/datachannel-cli/cli.py#L30  # noqa: E501\n        await self._pc.addIceCandidate(obj)\n    elif obj is BYE:  # pragma: no cover\n        raise AssertionError('received BYE message')\n    else:\n        raise AssertionError('received unknown message')\n</code></pre>"},{"location":"api/p2p/connection/#proxystore.p2p.connection.PeerConnection.ready","title":"ready()  <code>async</code>","text":"<pre><code>ready(timeout: float | None = None) -&gt; None\n</code></pre> <p>Wait for connection to be ready.</p> <p>Parameters:</p> <ul> <li> <code>timeout</code>             (<code>float | None</code>, default:                 <code>None</code> )         \u2013          <p>The maximum time in seconds to wait for the peer connection to establish. If None, block until the connection is established.</p> </li> </ul> <p>Raises:</p> <ul> <li> <code>PeerConnectionTimeoutError</code>           \u2013          <p>If the connection is not ready within the timeout.</p> </li> <li> <code>PeerConnectionError</code>           \u2013          <p>If there is an error establishing the peer connection.</p> </li> </ul> Source code in <code>proxystore/p2p/connection.py</code> <pre><code>async def ready(self, timeout: float | None = None) -&gt; None:\n    \"\"\"Wait for connection to be ready.\n\n    Args:\n        timeout: The maximum time in seconds to wait for\n            the peer connection to establish. If None, block until\n            the connection is established.\n\n    Raises:\n        PeerConnectionTimeoutError: If the connection is not ready within\n            the timeout.\n        PeerConnectionError: If there is an error establishing the peer\n            connection.\n    \"\"\"\n    try:\n        await asyncio.wait_for(self._handshake_success, timeout)\n    except asyncio.TimeoutError as e:\n        raise PeerConnectionTimeoutError(\n            'Timeout waiting for peer to peer connection to establish '\n            f'in {self._log_prefix}.',\n        ) from e\n</code></pre>"},{"location":"api/p2p/connection/#proxystore.p2p.connection.log_name","title":"log_name()","text":"<pre><code>log_name(uuid: UUID, name: str) -&gt; str\n</code></pre> <p>Return string formatted as <code>'name(uuid-prefix)'</code>.</p> Source code in <code>proxystore/p2p/connection.py</code> <pre><code>def log_name(uuid: UUID, name: str) -&gt; str:\n    \"\"\"Return string formatted as `#!python 'name(uuid-prefix)'`.\"\"\"\n    uuid_ = str(uuid)\n    return f'{name}({uuid_[:min(8,len(uuid_))]})'\n</code></pre>"},{"location":"api/p2p/exceptions/","title":"proxystore.p2p.exceptions","text":"<code>proxystore/p2p/exceptions.py</code> <p>Exception types for peering errors.</p>"},{"location":"api/p2p/exceptions/#proxystore.p2p.exceptions.PeerConnectionError","title":"PeerConnectionError","text":"<p>             Bases: <code>Exception</code></p> <p>Error connecting to peer.</p>"},{"location":"api/p2p/exceptions/#proxystore.p2p.exceptions.PeerConnectionTimeoutError","title":"PeerConnectionTimeoutError","text":"<p>             Bases: <code>PeerConnectionError</code></p> <p>Timeout waiting on peer to peer connection to establish.</p>"},{"location":"api/p2p/manager/","title":"proxystore.p2p.manager","text":"<code>proxystore/p2p/manager.py</code> <p>Manager of many peer-to-peer connections.</p>"},{"location":"api/p2p/manager/#proxystore.p2p.manager.PeerManager","title":"PeerManager","text":"<pre><code>PeerManager(\n    relay_client: RelayClient,\n    *,\n    timeout: int = 30,\n    peer_channels: int = 1\n)\n</code></pre> <p>Peer Connections Manager.</p> <p>Handles establishing peer connections via aiortc, responding to requests for new peer connections from the relay server, and sending and receiving data to/from existing peer connections.</p> Example <pre><code>from proxystore.p2p.manager import PeerManager\nfrom proxystore.p2p.relay import BasicRelayClient\n\nrelay_client = BasicRelayClient(relay_server_address)\n\npm1 = await PeerManager(relay_client)\npm2 = await PeerManager(relay_client)\n\nawait pm1.send(pm2.uuid, 'hello hello')\nsource_uuid, message = await pm2.recv()\nassert source_uuid == pm1.uuid\nassert message == 'hello hello'\n\nawait pm1.close()\nawait pm2.close()\n</code></pre> Note <p>The class can also be used as an asynchronous context manager.</p> <pre><code>async with PeerManager(..) as manager:\n    ...\n</code></pre> <p>Parameters:</p> <ul> <li> <code>relay_client</code>             (<code>RelayClient</code>)         \u2013          <p>Established client interface to a relay server.</p> </li> <li> <code>timeout</code>             (<code>int</code>, default:                 <code>30</code> )         \u2013          <p>Timeout in seconds when waiting for a peer connection to be established.</p> </li> <li> <code>peer_channels</code>             (<code>int</code>, default:                 <code>1</code> )         \u2013          <p>number of datachannels to split message sending over between each peer.</p> </li> </ul> <p>Raises:</p> <ul> <li> <code>ValueError</code>           \u2013          <p>If the relay server address does not start with \"ws://\" or \"wss://\".</p> </li> </ul> Source code in <code>proxystore/p2p/manager.py</code> <pre><code>def __init__(\n    self,\n    relay_client: RelayClient,\n    *,\n    timeout: int = 30,\n    peer_channels: int = 1,\n) -&gt; None:\n    self._relay_client = relay_client\n    self._timeout = timeout\n    self._peer_channels = peer_channels\n\n    self._peers_lock = asyncio.Lock()\n    self._peers: dict[frozenset[UUID], PeerConnection] = {}\n\n    self._message_queue: asyncio.Queue[tuple[UUID, bytes | str]] = (\n        asyncio.Queue()\n    )\n    self._server_task: asyncio.Task[None] | None = None\n    self._tasks: dict[frozenset[UUID], asyncio.Task[None]] = {}\n</code></pre>"},{"location":"api/p2p/manager/#proxystore.p2p.manager.PeerManager.name","title":"name  <code>property</code>","text":"<pre><code>name: str\n</code></pre> <p>Name of client as registered with relay server.</p>"},{"location":"api/p2p/manager/#proxystore.p2p.manager.PeerManager.uuid","title":"uuid  <code>property</code>","text":"<pre><code>uuid: UUID\n</code></pre> <p>UUID of client as registered with relay server.</p>"},{"location":"api/p2p/manager/#proxystore.p2p.manager.PeerManager.relay_client","title":"relay_client  <code>property</code>","text":"<pre><code>relay_client: RelayClient\n</code></pre> <p>Relay client interface.</p> <p>Raises:</p> <ul> <li> <code>RuntimeError</code>           \u2013          <p>if the manager is not initialized with <code>await</code> or <code>PeerManager.async_init()</code> has not been called.</p> </li> </ul>"},{"location":"api/p2p/manager/#proxystore.p2p.manager.PeerManager.async_init","title":"async_init()  <code>async</code>","text":"<pre><code>async_init() -&gt; None\n</code></pre> <p>Connect to relay server and being listening to incoming messages.</p> Source code in <code>proxystore/p2p/manager.py</code> <pre><code>async def async_init(self) -&gt; None:\n    \"\"\"Connect to relay server and being listening to incoming messages.\"\"\"\n    await self._relay_client.connect()\n    if self._server_task is None:\n        self._server_task = spawn_guarded_background_task(\n            self._handle_server_messages,\n        )\n        self._server_task.set_name('peer-manager-server-message-handler')\n</code></pre>"},{"location":"api/p2p/manager/#proxystore.p2p.manager.PeerManager.close","title":"close()  <code>async</code>","text":"<pre><code>close() -&gt; None\n</code></pre> <p>Close the connection manager.</p> Warning <p>This will close all create peer connections and close the connection to the relay server.</p> Source code in <code>proxystore/p2p/manager.py</code> <pre><code>async def close(self) -&gt; None:\n    \"\"\"Close the connection manager.\n\n    Warning:\n        This will close all create peer connections and close the\n        connection to the relay server.\n    \"\"\"\n    if self._server_task is not None:\n        self._server_task.cancel()\n        try:\n            await self._server_task\n        except (asyncio.CancelledError, SafeTaskExitError):\n            pass\n\n    for task in self._tasks.values():\n        task.cancel()\n        try:\n            await task\n        except (asyncio.CancelledError, SafeTaskExitError):\n            pass\n\n    async with self._peers_lock:\n        for connection in self._peers.values():\n            await connection.close()\n\n    await self.relay_client.close()\n    logger.info(f'{self._log_prefix}: peer manager closed')\n</code></pre>"},{"location":"api/p2p/manager/#proxystore.p2p.manager.PeerManager.close_connection","title":"close_connection()  <code>async</code>","text":"<pre><code>close_connection(peers: Iterable[UUID]) -&gt; None\n</code></pre> <p>Close a peer connection if it exists.</p> <p>This will close the associated <code>PeerConnection</code> and cancel the asyncio task handling peer messages. If the <code>PeerManager</code> is used to send a message from the peer again, a new connection will be established.</p> <p>Parameters:</p> <ul> <li> <code>peers</code>             (<code>Iterable[UUID]</code>)         \u2013          <p>Iterable containing the two peer UUIDs taking part in the connection that should be closed.</p> </li> </ul> Source code in <code>proxystore/p2p/manager.py</code> <pre><code>async def close_connection(self, peers: Iterable[UUID]) -&gt; None:\n    \"\"\"Close a peer connection if it exists.\n\n    This will close the associated\n    [`PeerConnection`][proxystore.p2p.connection.PeerConnection] and\n    cancel the asyncio task handling peer messages. If the\n    [`PeerManager`][proxystore.p2p.manager.PeerManager] is used to\n    send a message from the peer again, a new connection will be\n    established.\n\n    Args:\n        peers: Iterable containing the two peer UUIDs taking part in the\n            connection that should be closed.\n    \"\"\"\n    peers = frozenset(peers)\n    async with self._peers_lock:\n        connection = self._peers.pop(peers, None)\n    if connection is not None:\n        logger.info(\n            f'{self._log_prefix} Closing connection between peers: '\n            f'{\", \".join(str(peer) for peer in peers)}',\n        )\n        await connection.close()\n    task = self._tasks.pop(peers, None)\n    if task is not None:\n        task.cancel()\n        try:\n            await task\n        except (asyncio.CancelledError, SafeTaskExitError):\n            pass\n</code></pre>"},{"location":"api/p2p/manager/#proxystore.p2p.manager.PeerManager.recv","title":"recv()  <code>async</code>","text":"<pre><code>recv() -&gt; tuple[UUID, bytes | str]\n</code></pre> <p>Receive next message from a peer.</p> <p>Returns:</p> <ul> <li> <code>tuple[UUID, bytes | str]</code>         \u2013          <p>Tuple containing the UUID of the peer that sent the message             and the message itself.</p> </li> </ul> Source code in <code>proxystore/p2p/manager.py</code> <pre><code>async def recv(self) -&gt; tuple[UUID, bytes | str]:\n    \"\"\"Receive next message from a peer.\n\n    Returns:\n        Tuple containing the UUID of the peer that sent the message \\\n        and the message itself.\n    \"\"\"\n    return await self._message_queue.get()\n</code></pre>"},{"location":"api/p2p/manager/#proxystore.p2p.manager.PeerManager.send","title":"send()  <code>async</code>","text":"<pre><code>send(\n    peer_uuid: UUID,\n    message: bytes | str,\n    timeout: float = 30,\n) -&gt; None\n</code></pre> <p>Send message to peer.</p> <p>Parameters:</p> <ul> <li> <code>peer_uuid</code>             (<code>UUID</code>)         \u2013          <p>UUID of peer to send message to.</p> </li> <li> <code>message</code>             (<code>bytes | str</code>)         \u2013          <p>Message to send to peer.</p> </li> <li> <code>timeout</code>             (<code>float</code>, default:                 <code>30</code> )         \u2013          <p>Timeout to wait on peer connection to be ready.</p> </li> </ul> <p>Raises:</p> <ul> <li> <code>PeerConnectionTimeoutError</code>           \u2013          <p>If the peer connection is not established within the timeout.</p> </li> </ul> Source code in <code>proxystore/p2p/manager.py</code> <pre><code>async def send(\n    self,\n    peer_uuid: UUID,\n    message: bytes | str,\n    timeout: float = 30,\n) -&gt; None:\n    \"\"\"Send message to peer.\n\n    Args:\n        peer_uuid: UUID of peer to send message to.\n        message: Message to send to peer.\n        timeout: Timeout to wait on peer connection to be ready.\n\n    Raises:\n        PeerConnectionTimeoutError: If the peer connection is not\n            established within the timeout.\n    \"\"\"\n    connection = await self.get_connection(peer_uuid)\n    await connection.send(message, timeout)\n</code></pre>"},{"location":"api/p2p/manager/#proxystore.p2p.manager.PeerManager.get_connection","title":"get_connection()  <code>async</code>","text":"<pre><code>get_connection(peer_uuid: UUID) -&gt; PeerConnection\n</code></pre> <p>Get connection to the peer.</p> <p>Parameters:</p> <ul> <li> <code>peer_uuid</code>             (<code>UUID</code>)         \u2013          <p>UUID of peer to make connection with.</p> </li> </ul> <p>Returns:</p> <ul> <li> <code>PeerConnection</code>         \u2013          <p>The peer connection object.</p> </li> </ul> Source code in <code>proxystore/p2p/manager.py</code> <pre><code>async def get_connection(self, peer_uuid: UUID) -&gt; PeerConnection:\n    \"\"\"Get connection to the peer.\n\n    Args:\n        peer_uuid: UUID of peer to make connection with.\n\n    Returns:\n        The peer connection object.\n    \"\"\"\n    peers = frozenset({self.uuid, peer_uuid})\n\n    async with self._peers_lock:\n        if peers in self._peers:\n            return self._peers[peers]\n\n        connection = PeerConnection(\n            self.relay_client,\n            channels=self._peer_channels,\n        )\n        self._peers[peers] = connection\n\n    logger.info(\n        f'{self._log_prefix}: opening peer connection with '\n        f'{peer_uuid}',\n    )\n    await connection.send_offer(peer_uuid)\n\n    self._tasks[peers] = spawn_guarded_background_task(\n        self._handle_peer_messages,\n        peer_uuid,\n        connection,\n    )\n    self._tasks[peers].set_name(\n        f'handle-peer-messages-{self.uuid}-{peer_uuid}',\n    )\n\n    connection.on_close_callback(self.close_connection, peers)\n    return connection\n</code></pre>"},{"location":"api/p2p/nat/","title":"proxystore.p2p.nat","text":"<code>proxystore/p2p/nat.py</code> <p>Tools for getting the NAT type using STUN.</p> <p>This module is a wrapper around the tools provided by pystun3.</p>"},{"location":"api/p2p/nat/#proxystore.p2p.nat.NatType","title":"NatType","text":"<p>             Bases: <code>Enum</code></p> <p>NAT type.</p> <p>Learn more about NAT types at https://en.wikipedia.org/wiki/Network_address_translation.</p>"},{"location":"api/p2p/nat/#proxystore.p2p.nat.NatType.OpenInternet","title":"OpenInternet  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>OpenInternet = 'Open Internet (No NAT)'\n</code></pre> <p>Host is not behind a NAT.</p>"},{"location":"api/p2p/nat/#proxystore.p2p.nat.NatType.FullCone","title":"FullCone  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>FullCone = 'Full-cone NAT'\n</code></pre> <p>Host is behind a full-cone NAT.</p>"},{"location":"api/p2p/nat/#proxystore.p2p.nat.NatType.SymmetricUDPFirewall","title":"SymmetricUDPFirewall  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>SymmetricUDPFirewall = 'Symmetric UDP Firewall NAT'\n</code></pre> <p>Host is behind a symmetric UDP firewall.</p>"},{"location":"api/p2p/nat/#proxystore.p2p.nat.NatType.RestrictedCone","title":"RestrictedCone  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>RestrictedCone = 'Restricted-cone NAT'\n</code></pre> <p>Host is behind a restricted-cone NAT.</p>"},{"location":"api/p2p/nat/#proxystore.p2p.nat.NatType.PortRestrictedCone","title":"PortRestrictedCone  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>PortRestrictedCone = 'Port Restricted-cone NAT'\n</code></pre> <p>Host is behind a port-restricted-cone NAT.</p>"},{"location":"api/p2p/nat/#proxystore.p2p.nat.NatType.Symmetric","title":"Symmetric  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>Symmetric = 'Symmetric NAT'\n</code></pre> <p>Host is behind a symmetric NAT.</p>"},{"location":"api/p2p/nat/#proxystore.p2p.nat.Result","title":"Result","text":"<p>             Bases: <code>NamedTuple</code></p> <p>Result of NAT type check.</p> <p>Attributes:</p> <ul> <li> <code>nat_type</code>             (<code>NatType</code>)         \u2013          <p>Enum type of the found NAT this host is behind.</p> </li> <li> <code>external_ip</code>             (<code>str</code>)         \u2013          <p>External IP of this host.</p> </li> <li> <code>external_port</code>             (<code>int</code>)         \u2013          <p>External port of this host.</p> </li> </ul>"},{"location":"api/p2p/nat/#proxystore.p2p.nat.check_nat","title":"check_nat()","text":"<pre><code>check_nat(\n    source_ip: str = \"0.0.0.0\", source_port: int = 54320\n) -&gt; Result\n</code></pre> <p>Check the NAT type this host is behind.</p> <p>This function uses the STUN protocol (RFC 3489) to discover the presence and type of the NAT between this host and the open Internet.</p> <p>Parameters:</p> <ul> <li> <code>source_ip</code>             (<code>str</code>, default:                 <code>'0.0.0.0'</code> )         \u2013          <p>Address to bind to.</p> </li> <li> <code>source_port</code>             (<code>int</code>, default:                 <code>54320</code> )         \u2013          <p>Port to listen on.</p> </li> </ul> <p>Returns:</p> <ul> <li> <code>Result</code>         \u2013          <p>Result containing the NAT type and external IP/port of the host.</p> </li> </ul> <p>Raises:</p> <ul> <li> <code>RuntimeError</code>           \u2013          <p>if no STUN servers return a response or if the hosts IP or port changed during the STUN process.</p> </li> </ul> Source code in <code>proxystore/p2p/nat.py</code> <pre><code>def check_nat(\n    source_ip: str = '0.0.0.0',\n    source_port: int = 54320,\n) -&gt; Result:\n    \"\"\"Check the NAT type this host is behind.\n\n    This function uses the STUN protocol (RFC 3489) to discover the\n    presence and type of the NAT between this host and the open Internet.\n\n    Args:\n        source_ip: Address to bind to.\n        source_port: Port to listen on.\n\n    Returns:\n        Result containing the NAT type and external IP/port of the host.\n\n    Raises:\n        RuntimeError: if no STUN servers return a response or if the hosts\n            IP or port changed during the STUN process.\n    \"\"\"\n    with socket.socket(socket.AF_INET, socket.SOCK_DGRAM) as s:\n        s.settimeout(2)\n        s.setsockopt(socket.SOL_SOCKET, socket.SO_REUSEADDR, 1)\n        s.bind((source_ip, source_port))\n\n        for stun_server in _STUN_SERVERS:\n            stun_server_address, stun_server_port = stun_server.split(':')\n\n            _nat_type, external = stun.get_nat_type(\n                s,\n                source_ip,\n                source_port,\n                stun_host=stun_server_address,\n                stun_port=int(stun_server_port),\n            )\n\n            try:\n                nat_type = NatType._from_str(_nat_type)\n            except RuntimeError:\n                pass\n            else:\n                break\n        else:\n            raise RuntimeError(\n                'No STUN servers returned a valid response. '\n                'Enable debug level logging for more details.',\n            )\n\n    return Result(nat_type, external['ExternalIP'], external['ExternalPort'])\n</code></pre>"},{"location":"api/p2p/nat/#proxystore.p2p.nat.check_nat_and_log","title":"check_nat_and_log()","text":"<pre><code>check_nat_and_log(\n    source_ip: str = \"0.0.0.0\", source_port: int = 54320\n) -&gt; None\n</code></pre> <p>Check the NAT type this host is behind and log the results.</p> <p>Wrapper around <code>check_nat()</code> that logs the results rather than return them.</p> <p>Parameters:</p> <ul> <li> <code>source_ip</code>             (<code>str</code>, default:                 <code>'0.0.0.0'</code> )         \u2013          <p>Address to bind to.</p> </li> <li> <code>source_port</code>             (<code>int</code>, default:                 <code>54320</code> )         \u2013          <p>Port to listen on.</p> </li> </ul> Source code in <code>proxystore/p2p/nat.py</code> <pre><code>def check_nat_and_log(\n    source_ip: str = '0.0.0.0',\n    source_port: int = 54320,\n) -&gt; None:\n    \"\"\"Check the NAT type this host is behind and log the results.\n\n    Wrapper around [`check_nat()`][proxystore.p2p.nat.check_nat] that logs\n    the results rather than return them.\n\n    Args:\n        source_ip: Address to bind to.\n        source_port: Port to listen on.\n    \"\"\"\n    logger.info('Checking NAT type. This may take a moment...')\n    try:\n        nat_type, external_ip, external_port = check_nat(\n            source_ip=source_ip,\n            source_port=source_port,\n        )\n    except Exception as e:\n        logger.error(f'Failed to determine NAT type: {e}')\n    else:\n        logger.info(f'NAT Type:       {nat_type.value}')\n        logger.info(f'External IP:    {external_ip}')\n        logger.info(f'External Port:  {external_port}')\n\n        if nat_type == NatType.Symmetric:\n            logger.warning(\n                'NAT traversal (e.g., hole-punching) does not work reliably '\n                'across Symmetric NATs or poorly behaved legacy NATs. '\n                'Peer-to-peer methods may not work.',\n            )\n        else:\n            logger.info(\n                'NAT traversal for peer-to-peer methods (e.g., hole-punching) '\n                'is likely to work. (NAT traversal does not work reliably '\n                'across symmetric NATs or poorly behaved legacy NATs.)',\n            )\n</code></pre>"},{"location":"api/p2p/relay/","title":"proxystore.p2p.relay","text":"<code>proxystore/p2p/relay/__init__.py</code> <p>Relay client and server implementation.</p>"},{"location":"api/p2p/relay/authenticate/","title":"proxystore.p2p.relay.authenticate","text":"<code>proxystore/p2p/relay/authenticate.py</code> <p>Authenticate users from request headers.</p>"},{"location":"api/p2p/relay/authenticate/#proxystore.p2p.relay.authenticate.UserT","title":"UserT  <code>module-attribute</code>","text":"<pre><code>UserT = TypeVar('UserT', covariant=True)\n</code></pre> <p>Auth user generic type.</p>"},{"location":"api/p2p/relay/authenticate/#proxystore.p2p.relay.authenticate.Authenticator","title":"Authenticator","text":"<p>             Bases: <code>Protocol[UserT]</code></p> <p>Authenticate users from request headers.</p>"},{"location":"api/p2p/relay/authenticate/#proxystore.p2p.relay.authenticate.Authenticator.authenticate_user","title":"authenticate_user()","text":"<pre><code>authenticate_user(headers: Mapping[str, str]) -&gt; UserT\n</code></pre> <p>Authenticate user from request headers.</p> <p>Parameters:</p> <ul> <li> <code>headers</code>             (<code>Mapping[str, str]</code>)         \u2013          <p>Request headers.</p> </li> </ul> <p>Returns:</p> <ul> <li> <code>UserT</code>         \u2013          <p>User representation on authentication success.</p> </li> </ul> <p>Raises:</p> <ul> <li> <code>ForbiddenError</code>           \u2013          <p>user is authenticated but is missing permissions or accessing forbidden resources.</p> </li> <li> <code>UnauthorizedError</code>           \u2013          <p>user authentication fails.</p> </li> </ul> Source code in <code>proxystore/p2p/relay/authenticate.py</code> <pre><code>def authenticate_user(self, headers: Mapping[str, str]) -&gt; UserT:\n    \"\"\"Authenticate user from request headers.\n\n    Args:\n        headers: Request headers.\n\n    Returns:\n        User representation on authentication success.\n\n    Raises:\n        ForbiddenError: user is authenticated but is missing permissions\n            or accessing forbidden resources.\n        UnauthorizedError: user authentication fails.\n    \"\"\"\n    ...\n</code></pre>"},{"location":"api/p2p/relay/authenticate/#proxystore.p2p.relay.authenticate.NullUser","title":"NullUser","text":"<p>Null user that is always equal to another null user instance.</p>"},{"location":"api/p2p/relay/authenticate/#proxystore.p2p.relay.authenticate.NullAuthenticator","title":"NullAuthenticator","text":"<p>Authenticator that implements no authentication.</p>"},{"location":"api/p2p/relay/authenticate/#proxystore.p2p.relay.authenticate.NullAuthenticator.authenticate_user","title":"authenticate_user()","text":"<pre><code>authenticate_user(headers: Mapping[str, str]) -&gt; NullUser\n</code></pre> <p>Authenticate user from request headers.</p> <p>Parameters:</p> <ul> <li> <code>headers</code>             (<code>Mapping[str, str]</code>)         \u2013          <p>Request headers.</p> </li> </ul> <p>Returns:</p> <ul> <li> <code>NullUser</code>         \u2013          <p>Null user regardless of provided headers.</p> </li> </ul> Source code in <code>proxystore/p2p/relay/authenticate.py</code> <pre><code>def authenticate_user(self, headers: Mapping[str, str]) -&gt; NullUser:\n    \"\"\"Authenticate user from request headers.\n\n    Args:\n        headers: Request headers.\n\n    Returns:\n        Null user regardless of provided headers.\n    \"\"\"\n    return NullUser()\n</code></pre>"},{"location":"api/p2p/relay/authenticate/#proxystore.p2p.relay.authenticate.GlobusUser","title":"GlobusUser  <code>dataclass</code>","text":"<pre><code>GlobusUser(\n    username: str,\n    client_id: UUID,\n    email: str | None = None,\n    display_name: str | None = None,\n)\n</code></pre> <p>Globus Auth user information.</p> <p>Fields are retrieved via the token introspection API.</p> <p>Attributes:</p> <ul> <li> <code>username</code>             (<code>str</code>)         \u2013          <p>Identity username.</p> </li> <li> <code>client_id</code>             (<code>UUID</code>)         \u2013          <p>The Globus Auth issues client id of the client to which the introspected token was issued.</p> </li> <li> <code>email</code>             (<code>str | None</code>)         \u2013          <p>Email address associated with the effective identity of the introspected token. May be <code>None</code> if the user restricts their identity visibility.</p> </li> <li> <code>display_name</code>             (<code>str | None</code>)         \u2013          <p>Display name associated with the effective identity of the introspected token. May be <code>None</code> if the user restricts their identity visibility.</p> </li> </ul>"},{"location":"api/p2p/relay/authenticate/#proxystore.p2p.relay.authenticate.GlobusUser.__eq__","title":"__eq__()","text":"<pre><code>__eq__(other: object) -&gt; bool\n</code></pre> <p>Check equality using only Globus Auth client ID.</p> Source code in <code>proxystore/p2p/relay/authenticate.py</code> <pre><code>def __eq__(self, other: object) -&gt; bool:\n    \"\"\"Check equality using only Globus Auth client ID.\"\"\"\n    if isinstance(other, GlobusUser):\n        return self.client_id == other.client_id\n    else:\n        return False\n</code></pre>"},{"location":"api/p2p/relay/authenticate/#proxystore.p2p.relay.authenticate.GlobusAuthenticator","title":"GlobusAuthenticator","text":"<pre><code>GlobusAuthenticator(\n    client_id: str | None = None,\n    client_secret: str | None = None,\n    *,\n    audience: str = ProxyStoreRelayScopes.resource_server,\n    auth_client: ConfidentialAppAuthClient | None = None\n)\n</code></pre> <p>Globus Auth authorizer.</p> <p>Parameters:</p> <ul> <li> <code>client_id</code>             (<code>str | None</code>, default:                 <code>None</code> )         \u2013          <p>Globus application client ID. If either <code>client_id</code> or <code>client_secret</code> is <code>None</code>, the values will be read from the environment variables as described in <code>get_confidential_app_auth_client</code>. Ignored if <code>auth_client</code> is provided.</p> </li> <li> <code>client_secret</code>             (<code>str | None</code>, default:                 <code>None</code> )         \u2013          <p>Globus application client secret. See <code>client_id</code> for details. Ignored if <code>auth_client</code> is provided.</p> </li> <li> <code>audience</code>             (<code>str</code>, default:                 <code>resource_server</code> )         \u2013          <p>Intended audience of the token. This should typically be the resource server of the the token was issued for. E.g., the UUID of the ProxyStore Relay Server application.</p> </li> <li> <code>auth_client</code>             (<code>ConfidentialAppAuthClient | None</code>, default:                 <code>None</code> )         \u2013          <p>Optional confidential application authentication client which is used for introspecting client tokens.</p> </li> </ul> Source code in <code>proxystore/p2p/relay/authenticate.py</code> <pre><code>def __init__(\n    self,\n    client_id: str | None = None,\n    client_secret: str | None = None,\n    *,\n    audience: str = ProxyStoreRelayScopes.resource_server,\n    auth_client: globus_sdk.ConfidentialAppAuthClient | None = None,\n) -&gt; None:\n    self.auth_client = (\n        get_confidential_app_auth_client(client_id, client_secret)\n        if auth_client is None\n        else auth_client\n    )\n    self.audience = audience\n</code></pre>"},{"location":"api/p2p/relay/authenticate/#proxystore.p2p.relay.authenticate.GlobusAuthenticator.authenticate_user","title":"authenticate_user()","text":"<pre><code>authenticate_user(headers: Mapping[str, str]) -&gt; GlobusUser\n</code></pre> <p>Authenticate a Globus Auth user from request header.</p> <p>This follows from the Globus Sample Data Portal example.</p> <p>Parameters:</p> <ul> <li> <code>headers</code>             (<code>Mapping[str, str]</code>)         \u2013          <p>Request headers to extract tokens from.</p> </li> </ul> <p>Returns:</p> <ul> <li> <code>GlobusUser</code>         \u2013          <p>Globus Auth identity returned via             token introspection.</p> </li> </ul> <p>Raises:</p> <ul> <li> <code>UnauthorizedError</code>           \u2013          <p>if the authorization header is missing or the header is malformed.</p> </li> <li> <code>ForbiddenError</code>           \u2013          <p>if the tokens have expired or been revoked.</p> </li> <li> <code>ForbiddenError</code>           \u2013          <p>if <code>audience</code> is not included in the token's audience.</p> </li> </ul> Source code in <code>proxystore/p2p/relay/authenticate.py</code> <pre><code>def authenticate_user(self, headers: Mapping[str, str]) -&gt; GlobusUser:\n    \"\"\"Authenticate a Globus Auth user from request header.\n\n    This follows from the [Globus Sample Data Portal](https://github.com/globus/globus-sample-data-portal/blob/30e30cd418ee9b103e04916e19deb9902d3aafd8/service/decorators.py)\n    example.\n\n    Args:\n        headers: Request headers to extract tokens from.\n\n    Returns:\n        Globus Auth identity returned via \\\n        [token introspection](https://docs.globus.org/api/auth/reference/#token-introspect).\n\n    Raises:\n        UnauthorizedError: if the authorization header is missing or\n            the header is malformed.\n        ForbiddenError: if the tokens have expired or been revoked.\n        ForbiddenError: if `audience` is not included in the token's\n            audience.\n    \"\"\"\n    token = get_token_from_headers(headers)\n    token_meta = self.auth_client.oauth2_token_introspect(token)\n\n    if not token_meta.get('active'):\n        raise ForbiddenError('Token is expired or has been revoked.')\n\n    if self.audience is not None and self.audience not in token_meta.get(\n        'aud',\n        [],\n    ):\n        raise ForbiddenError(\n            f'Token audience does not include \"{self.audience}\". This '\n            'could result in a confused deputy attack. Ensure the correct '\n            'scopes are requested when the token is created.',\n        )\n\n    return GlobusUser(\n        username=token_meta.get('username'),\n        client_id=uuid.UUID(token_meta.get('client_id')),\n        email=token_meta.get('email', None),\n        display_name=token_meta.get('name', None),\n    )\n</code></pre>"},{"location":"api/p2p/relay/authenticate/#proxystore.p2p.relay.authenticate.get_authenticator","title":"get_authenticator()","text":"<pre><code>get_authenticator(\n    config: RelayAuthConfig,\n) -&gt; Authenticator[Any]\n</code></pre> <p>Create an authenticator from a configuration.</p> <p>Parameters:</p> <ul> <li> <code>config</code>             (<code>RelayAuthConfig</code>)         \u2013          <p>Configuration.</p> </li> </ul> <p>Returns:</p> <ul> <li> <code>Authenticator[Any]</code>         \u2013          <p>Authenticator.</p> </li> </ul> <p>Raises:</p> <ul> <li> <code>ValueError</code>           \u2013          <p>if the authentication method in the config is unknown.</p> </li> </ul> Source code in <code>proxystore/p2p/relay/authenticate.py</code> <pre><code>def get_authenticator(config: RelayAuthConfig) -&gt; Authenticator[Any]:\n    \"\"\"Create an authenticator from a configuration.\n\n    Args:\n        config: Configuration.\n\n    Returns:\n        Authenticator.\n\n    Raises:\n        ValueError: if the authentication method in the config is unknown.\n    \"\"\"\n    if config.method is None:\n        return NullAuthenticator()\n    elif config.method == 'globus':\n        return GlobusAuthenticator(**config.kwargs)\n    else:\n        raise ValueError(f'Unknown authentication method \"{config.method}.\"')\n</code></pre>"},{"location":"api/p2p/relay/authenticate/#proxystore.p2p.relay.authenticate.get_token_from_headers","title":"get_token_from_headers()","text":"<pre><code>get_token_from_headers(headers: Mapping[str, str]) -&gt; str\n</code></pre> <p>Extract token from websockets headers.</p> <p>The header is expected to have the format <code>Authorization: Bearer &lt;TOKEN&gt;</code>.</p> <p>Parameters:</p> <ul> <li> <code>headers</code>             (<code>Mapping[str, str]</code>)         \u2013          <p>Request headers to extract tokens from.</p> </li> </ul> <p>Returns:</p> <ul> <li> <code>str</code>         \u2013          <p>String token.</p> </li> </ul> <p>Raises:</p> <ul> <li> <code>UnauthorizedError</code>           \u2013          <p>if the authorization header is missing.</p> </li> <li> <code>UnauthorizedError</code>           \u2013          <p>if the authorization header is malformed.</p> </li> </ul> Source code in <code>proxystore/p2p/relay/authenticate.py</code> <pre><code>def get_token_from_headers(headers: Mapping[str, str]) -&gt; str:\n    \"\"\"Extract token from websockets headers.\n\n    The header is expected to have the format `Authorization: Bearer &lt;TOKEN&gt;`.\n\n    Args:\n         headers: Request headers to extract tokens from.\n\n    Returns:\n        String token.\n\n    Raises:\n        UnauthorizedError: if the authorization header is missing.\n        UnauthorizedError: if the authorization header is malformed.\n    \"\"\"\n    if 'Authorization' not in headers:\n        raise UnauthorizedError(\n            'Request headers are missing authorization header.',\n        )\n\n    auth_header_parts = headers['Authorization'].split(' ')\n\n    if len(auth_header_parts) != 2 or auth_header_parts[0] != 'Bearer':\n        raise UnauthorizedError(\n            'Bearer token in authorization header is malformed.',\n        )\n\n    return auth_header_parts[1]\n</code></pre>"},{"location":"api/p2p/relay/client/","title":"proxystore.p2p.relay.client","text":"<code>proxystore/p2p/relay/client.py</code> <p>Client interface to a relay server.</p>"},{"location":"api/p2p/relay/client/#proxystore.p2p.relay.client.RelayClient","title":"RelayClient","text":"<pre><code>RelayClient(\n    address: str,\n    *,\n    client_name: str | None = None,\n    client_uuid: UUID | None = None,\n    extra_headers: dict[str, str] | None = None,\n    reconnect_task: bool = True,\n    ssl_context: SSLContext | None = None,\n    timeout: float = 10,\n    verify_certificate: bool = True\n)\n</code></pre> <p>Client interface to a relay server.</p> <p>This interface abstracts the low-level WebSocket connection to a relay server to provide automatic reconnection.</p> Tip <p>This class can be used as an async context manager! <pre><code>from proxystore.p2p.relay.client import RelayClient\n\nasync with RelayClient(...) as client:\n    await client.send(...)\n    message = await client.recv(...)\n</code></pre></p> Note <p>WebSocket connections are not opened until a message is sent, a message is received, or <code>connect()</code> is called. Initializing the client with <code>await</code> will call <code>connect()</code>. <pre><code>client = await RelayClient(...)\n</code></pre></p> <p>Parameters:</p> <ul> <li> <code>address</code>             (<code>str</code>)         \u2013          <p>Address of the relay server. Should start with <code>ws://</code> or <code>wss://</code>.</p> </li> <li> <code>client_name</code>             (<code>str | None</code>, default:                 <code>None</code> )         \u2013          <p>Optional name of the client to use when registering with the relay server. If <code>None</code>, the hostname will be used.</p> </li> <li> <code>client_uuid</code>             (<code>UUID | None</code>, default:                 <code>None</code> )         \u2013          <p>Optional UUID of the client to use when registering with the relay server. If <code>None</code>, one will be generated.</p> </li> <li> <code>extra_headers</code>             (<code>dict[str, str] | None</code>, default:                 <code>None</code> )         \u2013          <p>Arbitrary HTTP headers to add to the handshake request. If connecting to a relay server with authentication, such as one using the <code>GlobusAuthenticator</code>, the headers should include the <code>Authorization</code> header containing the bearer token.</p> </li> <li> <code>reconnect_task</code>             (<code>bool</code>, default:                 <code>True</code> )         \u2013          <p>Spawn a background task which will automatically reconnect to the relay server when the websocket client closes. Otherwise, reconnections will only be attempted when sending or receiving a message.</p> </li> <li> <code>ssl_context</code>             (<code>SSLContext | None</code>, default:                 <code>None</code> )         \u2013          <p>Custom SSL context to pass to <code>websockets.connect()</code>. A TLS context is created with <code>ssl.create_default_context()</code> when connecting to a <code>wss://</code> URI and <code>ssl_context</code> is not provided.</p> </li> <li> <code>timeout</code>             (<code>float</code>, default:                 <code>10</code> )         \u2013          <p>Time to wait in seconds on relay server connection.</p> </li> <li> <code>verify_certificate</code>             (<code>bool</code>, default:                 <code>True</code> )         \u2013          <p>Verify the relay server's SSL certificate. Only used if <code>ssl_context</code> is <code>None</code> and connecting to a <code>wss://</code> URI.</p> </li> </ul> <p>Raises:</p> <ul> <li> <code>RelayRegistrationError</code>           \u2013          <p>If the connection to the relay server is closed, does not reply to the registration request within the timeout, or replies with an error.</p> </li> <li> <code>ValueError</code>           \u2013          <p>If address does not start with <code>ws://</code> or <code>wss://</code>.</p> </li> </ul> Source code in <code>proxystore/p2p/relay/client.py</code> <pre><code>def __init__(\n    self,\n    address: str,\n    *,\n    client_name: str | None = None,\n    client_uuid: uuid.UUID | None = None,\n    extra_headers: dict[str, str] | None = None,\n    reconnect_task: bool = True,\n    ssl_context: ssl.SSLContext | None = None,\n    timeout: float = 10,\n    verify_certificate: bool = True,\n) -&gt; None:\n    if not (address.startswith('ws://') or address.startswith('wss://')):\n        raise ValueError(\n            'Relay server address must start with ws:// or wss://.'\n            f'Got {address}.',\n        )\n\n    self._address = address\n    self._name = hostname() if client_name is None else client_name\n    self._uuid = uuid.uuid4() if client_uuid is None else client_uuid\n    self._timeout = timeout\n\n    if self._address.startswith('wss://') and ssl_context is None:\n        ssl_context = ssl.create_default_context()\n        if not verify_certificate:\n            ssl_context.check_hostname = False\n            ssl_context.verify_mode = ssl.CERT_NONE\n\n    self._extra_headers = extra_headers\n    self._ssl_context = ssl_context\n    self._create_reconnect_task = reconnect_task\n\n    self._initial_backoff_seconds = 1.0\n\n    self._connect_lock = asyncio.Lock()\n    self._reconnect_task: asyncio.Task[None] | None = None\n    self._websocket: WebSocketClientProtocol | None = None\n</code></pre>"},{"location":"api/p2p/relay/client/#proxystore.p2p.relay.client.RelayClient.name","title":"name  <code>property</code>","text":"<pre><code>name: str\n</code></pre> <p>Name of client as registered with relay server.</p>"},{"location":"api/p2p/relay/client/#proxystore.p2p.relay.client.RelayClient.uuid","title":"uuid  <code>property</code>","text":"<pre><code>uuid: UUID\n</code></pre> <p>UUID of client as registered with relay server.</p>"},{"location":"api/p2p/relay/client/#proxystore.p2p.relay.client.RelayClient.websocket","title":"websocket  <code>property</code>","text":"<pre><code>websocket: WebSocketClientProtocol\n</code></pre> <p>Websocket connection to the relay server.</p> <p>Raises:</p> <ul> <li> <code>RelayNotConnectedError</code>           \u2013          <p>if the websocket connection to the relay server is not open. This usually indicates that <code>connect()</code> needs to be called.</p> </li> </ul>"},{"location":"api/p2p/relay/client/#proxystore.p2p.relay.client.RelayClient.connect","title":"connect()  <code>async</code>","text":"<pre><code>connect(retry: bool = True) -&gt; None\n</code></pre> <p>Connect to the relay server.</p> Note <p>Typically this does not need to be called because the send and receive methods will automatically call this.</p> Note <p>This method is a no-op if a connection is already established. Otherwise, a new connection will be attempted with exponential backoff when <code>retry</code> is True for connection failures.</p> <p>Parameters:</p> <ul> <li> <code>retry</code>             (<code>bool</code>, default:                 <code>True</code> )         \u2013          <p>Retry the connection with exponential backoff starting at one second and increasing to a max of 60 seconds.</p> </li> </ul> Source code in <code>proxystore/p2p/relay/client.py</code> <pre><code>async def connect(self, retry: bool = True) -&gt; None:\n    \"\"\"Connect to the relay server.\n\n    Note:\n        Typically this does not need to be called because the\n        send and receive methods will automatically call this.\n\n    Note:\n        This method is a no-op if a connection is already established.\n        Otherwise, a new connection will be attempted with\n        exponential backoff when `retry` is True for connection failures.\n\n    Args:\n        retry: Retry the connection with exponential backoff starting at\n            one second and increasing to a max of 60 seconds.\n    \"\"\"\n    async with self._connect_lock:\n        if self._websocket is not None and self._websocket.open:\n            return\n\n        backoff_seconds = self._initial_backoff_seconds\n        while True:\n            try:\n                self._websocket = await self._register(\n                    timeout=self._timeout,\n                )\n                if (\n                    self._reconnect_task is None\n                    and self._create_reconnect_task\n                ):\n                    self._reconnect_task = spawn_guarded_background_task(\n                        self._reconnect_on_close,\n                    )\n                    self._reconnect_task.set_name('relay-client-reconnect')\n            except (\n                # Exceptions that we should wait and retry again for\n                ConnectionRefusedError,\n                asyncio.TimeoutError,\n                websockets.exceptions.ConnectionClosed,\n            ) as e:\n                if not retry:\n                    raise\n\n                logger.warning(\n                    f'Registration with relay server at {self._address} '\n                    f'failed because of {e}. Retrying connection in '\n                    f'{backoff_seconds} seconds',\n                )\n                await asyncio.sleep(backoff_seconds)\n                backoff_seconds = min(backoff_seconds * 2, 60)\n            else:\n                # Coverage doesn't detect the singular break but it does\n                # get executed to break from the loop\n                break  # pragma: no cover\n</code></pre>"},{"location":"api/p2p/relay/client/#proxystore.p2p.relay.client.RelayClient.close","title":"close()  <code>async</code>","text":"<pre><code>close() -&gt; None\n</code></pre> <p>Close the connection to the relay server.</p> Source code in <code>proxystore/p2p/relay/client.py</code> <pre><code>async def close(self) -&gt; None:\n    \"\"\"Close the connection to the relay server.\"\"\"\n    if self._reconnect_task is not None:\n        self._reconnect_task.cancel()\n        try:\n            await self._reconnect_task\n        except asyncio.CancelledError:\n            pass\n\n    if self._websocket is not None:\n        await self._websocket.close()\n</code></pre>"},{"location":"api/p2p/relay/client/#proxystore.p2p.relay.client.RelayClient.recv","title":"recv()  <code>async</code>","text":"<pre><code>recv() -&gt; RelayMessage\n</code></pre> <p>Receive the next message.</p> <p>Returns:</p> <ul> <li> <code>RelayMessage</code>         \u2013          <p>The message received from the relay server.</p> </li> </ul> <p>Raises:</p> <ul> <li> <code>RelayMessageDecodeError</code>           \u2013          <p>If the message received cannot be decoded into the appropriate message type.</p> </li> </ul> Source code in <code>proxystore/p2p/relay/client.py</code> <pre><code>async def recv(self) -&gt; RelayMessage:\n    \"\"\"Receive the next message.\n\n    Returns:\n        The message received from the relay server.\n\n    Raises:\n        RelayMessageDecodeError: If the message received cannot\n            be decoded into the appropriate message type.\n    \"\"\"\n    try:\n        websocket = self.websocket\n    except RelayNotConnectedError:\n        await self.connect()\n        websocket = self.websocket\n\n    message_str = await websocket.recv()\n    if not isinstance(message_str, str):\n        raise AssertionError('Received non-string from websocket.')\n    return decode_relay_message(message_str)\n</code></pre>"},{"location":"api/p2p/relay/client/#proxystore.p2p.relay.client.RelayClient.send","title":"send()  <code>async</code>","text":"<pre><code>send(message: RelayMessage) -&gt; None\n</code></pre> <p>Send a message.</p> <p>Parameters:</p> <ul> <li> <code>message</code>             (<code>RelayMessage</code>)         \u2013          <p>The message to send to the relay server.</p> </li> </ul> Source code in <code>proxystore/p2p/relay/client.py</code> <pre><code>async def send(self, message: RelayMessage) -&gt; None:\n    \"\"\"Send a message.\n\n    Args:\n        message: The message to send to the relay server.\n    \"\"\"\n    message_str = encode_relay_message(message)\n\n    try:\n        websocket = self.websocket\n    except RelayNotConnectedError:\n        await self.connect()\n        websocket = self.websocket\n\n    await websocket.send(message_str)\n</code></pre>"},{"location":"api/p2p/relay/config/","title":"proxystore.p2p.relay.config","text":"<code>proxystore/p2p/relay/config.py</code> <p>Relay server configuration file parsing.</p>"},{"location":"api/p2p/relay/config/#proxystore.p2p.relay.config.RelayAuthConfig","title":"RelayAuthConfig","text":"<p>             Bases: <code>BaseModel</code></p> <p>Relay authentication configuration.</p> <p>Attributes:</p> <ul> <li> <code>method</code>             (<code>Optional[Literal['globus']]</code>)         \u2013          <p>Authentication method.</p> </li> <li> <code>kwargs</code>             (<code>Dict[str, Any]</code>)         \u2013          <p>Arbitrary keyword arguments to pass to the authenticator. The kwargs are excluded from the <code>repr()</code> of this class because they often contain secrets.</p> </li> </ul>"},{"location":"api/p2p/relay/config/#proxystore.p2p.relay.config.RelayLoggingConfig","title":"RelayLoggingConfig","text":"<p>             Bases: <code>BaseModel</code></p> <p>Relay logging configuration.</p> <p>Attributes:</p> <ul> <li> <code>log_dir</code>             (<code>Optional[str]</code>)         \u2013          <p>Default logging directory.</p> </li> <li> <code>default_level</code>             (<code>Union[int, str]</code>)         \u2013          <p>Default logging level for the root logger.</p> </li> <li> <code>websockets_level</code>             (<code>Union[int, str]</code>)         \u2013          <p>Log level for the <code>websockets</code> logger. Websockets logs with much higher frequency so it is suggested to set this to <code>WARNING</code> or higher.</p> </li> <li> <code>current_clients_interval</code>             (<code>Union[int, str]</code>)         \u2013          <p>Optional seconds between logging the number of currently connected clients and user.</p> </li> <li> <code>current_client_limit</code>             (<code>Optional[int]</code>)         \u2013          <p>Max threshold for enumerating the detailed list of connected clients. If <code>None</code>, no detailed list will be logged.</p> </li> </ul>"},{"location":"api/p2p/relay/config/#proxystore.p2p.relay.config.RelayServingConfig","title":"RelayServingConfig","text":"<p>             Bases: <code>BaseModel</code></p> <p>Relay serving configuration.</p> <p>Attributes:</p> <ul> <li> <code>host</code>             (<code>Optional[str]</code>)         \u2013          <p>Network interface the server binds to.</p> </li> <li> <code>port</code>             (<code>int</code>)         \u2013          <p>Network port the server binds to.</p> </li> <li> <code>certfile</code>             (<code>Optional[str]</code>)         \u2013          <p>Certificate file (PEM format) use to enable TLS.</p> </li> <li> <code>keyfile</code>             (<code>Optional[str]</code>)         \u2013          <p>Private key file. If not specified, the key will be taken from the certfile.</p> </li> <li> <code>auth</code>             (<code>RelayAuthConfig</code>)         \u2013          <p>Authentication configuration.</p> </li> <li> <code>logging</code>             (<code>RelayLoggingConfig</code>)         \u2013          <p>Logging configuration.</p> </li> <li> <code>max_message_bytes</code>             (<code>Optional[int]</code>)         \u2013          <p>Maximum size in bytes of messages received by the relay server.</p> </li> </ul>"},{"location":"api/p2p/relay/config/#proxystore.p2p.relay.config.RelayServingConfig.from_toml","title":"from_toml()  <code>classmethod</code>","text":"<pre><code>from_toml(filepath: str | Path) -&gt; Self\n</code></pre> <p>Parse an TOML config file.</p> Example <p>Minimal config without SSL and without authentication. relay.toml<pre><code>port = 8700\n\n[logging]\nlog_dir = \"/path/to/log/dir\"\ndefault_log_level = \"INFO\"\nwebsockets_log_level = \"WARNING\"\nconnected_client_logging_interval = 60\nconnected_client_logging_limit = 32\n</code></pre></p> <pre><code>from proxystore.p2p.relay.globus.config\n\nconfig = RelayServingConfig.from_toml('relay.toml')\n</code></pre> Example <p>Serve with SSL and Globus Auth. relay.toml<pre><code>host = \"0.0.0.0\"\nport = 8700\ncertfile = \"/path/to/cert.pem\"\nkeyfile = \"/path/to/privkey.pem\"\n\n[auth]\nmethod = \"globus\"\n\n[auth.kwargs]\nclient_id = \"...\"\nclient_secret = \"...\"\n\n[logging]\nlog_dir = \"/path/to/log/dir\"\ndefault_log_level = \"INFO\"\nwebsockets_log_level = \"WARNING\"\nconnected_client_logging_interval = 60\nconnected_client_logging_limit = 32\n</code></pre></p> Note <p>Omitted values will be set to their defaults (if they are an optional value with a default). relay.toml<pre><code>[serving]\ncertfile = \"/path/to/cert.pem\"\n</code></pre></p> <pre><code>from proxystore.p2p.relay.config import RelayServingConfig\n\nconfig = RelayServingConfig.from_config('relay.toml')\nassert config.certfile == '/path/to/cert.pem'\nassert config.keyfile is None\n</code></pre> Source code in <code>proxystore/p2p/relay/config.py</code> <pre><code>@classmethod\ndef from_toml(cls, filepath: str | pathlib.Path) -&gt; Self:\n    \"\"\"Parse an TOML config file.\n\n    Example:\n        Minimal config without SSL and without authentication.\n        ```toml title=\"relay.toml\"\n        port = 8700\n\n        [logging]\n        log_dir = \"/path/to/log/dir\"\n        default_log_level = \"INFO\"\n        websockets_log_level = \"WARNING\"\n        connected_client_logging_interval = 60\n        connected_client_logging_limit = 32\n        ```\n\n        ```python\n        from proxystore.p2p.relay.globus.config\n\n        config = RelayServingConfig.from_toml('relay.toml')\n        ```\n\n    Example:\n        Serve with SSL and Globus Auth.\n        ```toml title=\"relay.toml\"\n        host = \"0.0.0.0\"\n        port = 8700\n        certfile = \"/path/to/cert.pem\"\n        keyfile = \"/path/to/privkey.pem\"\n\n        [auth]\n        method = \"globus\"\n\n        [auth.kwargs]\n        client_id = \"...\"\n        client_secret = \"...\"\n\n        [logging]\n        log_dir = \"/path/to/log/dir\"\n        default_log_level = \"INFO\"\n        websockets_log_level = \"WARNING\"\n        connected_client_logging_interval = 60\n        connected_client_logging_limit = 32\n        ```\n\n    Note:\n        Omitted values will be set to their defaults (if they are an\n        optional value with a default).\n        ```toml title=\"relay.toml\"\n        [serving]\n        certfile = \"/path/to/cert.pem\"\n        ```\n\n        ```python\n        from proxystore.p2p.relay.config import RelayServingConfig\n\n        config = RelayServingConfig.from_config('relay.toml')\n        assert config.certfile == '/path/to/cert.pem'\n        assert config.keyfile is None\n        ```\n    \"\"\"\n    with open(filepath, 'rb') as f:\n        return load(cls, f)\n</code></pre>"},{"location":"api/p2p/relay/exceptions/","title":"proxystore.p2p.relay.exceptions","text":"<code>proxystore/p2p/relay/exceptions.py</code> <p>Exception types raised by relay clients and servers.</p>"},{"location":"api/p2p/relay/exceptions/#proxystore.p2p.relay.exceptions.RelayClientError","title":"RelayClientError","text":"<p>             Bases: <code>Exception</code></p> <p>Base exception type for exceptions raised by relay clients.</p>"},{"location":"api/p2p/relay/exceptions/#proxystore.p2p.relay.exceptions.RelayNotConnectedError","title":"RelayNotConnectedError","text":"<p>             Bases: <code>RelayClientError</code></p> <p>Exception raised if a client is not connected to a relay server.</p>"},{"location":"api/p2p/relay/exceptions/#proxystore.p2p.relay.exceptions.RelayRegistrationError","title":"RelayRegistrationError","text":"<p>             Bases: <code>RelayClientError</code></p> <p>Exception raised by client if unable to register with relay server.</p>"},{"location":"api/p2p/relay/exceptions/#proxystore.p2p.relay.exceptions.RelayServerError","title":"RelayServerError","text":"<p>             Bases: <code>Exception</code></p> <p>Base exception type for exceptions raised by relay server.</p>"},{"location":"api/p2p/relay/exceptions/#proxystore.p2p.relay.exceptions.BadRequestError","title":"BadRequestError","text":"<p>             Bases: <code>RelayServerError</code></p> <p>A runtime exception indicating a bad client request.</p>"},{"location":"api/p2p/relay/exceptions/#proxystore.p2p.relay.exceptions.ForbiddenError","title":"ForbiddenError","text":"<p>             Bases: <code>RelayServerError</code></p> <p>Client does not have correct permissions after authentication.</p>"},{"location":"api/p2p/relay/exceptions/#proxystore.p2p.relay.exceptions.InternalServerError","title":"InternalServerError","text":"<p>             Bases: <code>RelayServerError</code></p> <p>Server encountered an unexpected condition.</p>"},{"location":"api/p2p/relay/exceptions/#proxystore.p2p.relay.exceptions.UnauthorizedError","title":"UnauthorizedError","text":"<p>             Bases: <code>RelayServerError</code></p> <p>Client is missing authentication tokens.</p>"},{"location":"api/p2p/relay/manager/","title":"proxystore.p2p.relay.manager","text":"<code>proxystore/p2p/relay/manager.py</code> <p>Helper classes for managing clients connected to a relay server.</p>"},{"location":"api/p2p/relay/manager/#proxystore.p2p.relay.manager.Client","title":"Client  <code>dataclass</code>","text":"<pre><code>Client(\n    name: str,\n    uuid: UUID,\n    user: UserT,\n    websocket: WebSocketServerProtocol,\n    created: datetime = _utc_current_time(),\n)\n</code></pre> <p>             Bases: <code>Generic[UserT]</code></p> <p>Representation of client connection owned by a user.</p> <p>Attributes:</p> <ul> <li> <code>name</code>             (<code>str</code>)         \u2013          <p>Name of client.</p> </li> <li> <code>uuid</code>             (<code>UUID</code>)         \u2013          <p>UUID of client.</p> </li> <li> <code>user</code>             (<code>UserT</code>)         \u2013          <p>Auth user information.</p> </li> <li> <code>websocket</code>             (<code>WebSocketServerProtocol</code>)         \u2013          <p>WebSocket connection to the client.</p> </li> <li> <code>created</code>             (<code>datetime</code>)         \u2013          <p>Time the client was created at.</p> </li> </ul>"},{"location":"api/p2p/relay/manager/#proxystore.p2p.relay.manager.ClientManager","title":"ClientManager","text":"<pre><code>ClientManager()\n</code></pre> <p>             Bases: <code>Generic[UserT]</code></p> <p>Manages active connections with authenticated clients.</p> Warning <p>This class is intended for internal use by the <code>RelayServer</code>.</p> Source code in <code>proxystore/p2p/relay/manager.py</code> <pre><code>def __init__(self) -&gt; None:\n    self._clients_by_uuid: dict[uuid.UUID, Client[UserT]] = {}\n    self._clients_by_websocket: dict[\n        WebSocketServerProtocol,\n        Client[UserT],\n    ] = {}\n</code></pre>"},{"location":"api/p2p/relay/manager/#proxystore.p2p.relay.manager.ClientManager.add_client","title":"add_client()","text":"<pre><code>add_client(client: Client[UserT]) -&gt; None\n</code></pre> <p>Add a new authenticated client.</p> Source code in <code>proxystore/p2p/relay/manager.py</code> <pre><code>def add_client(self, client: Client[UserT]) -&gt; None:\n    \"\"\"Add a new authenticated client.\"\"\"\n    self._clients_by_uuid[client.uuid] = client\n    self._clients_by_websocket[client.websocket] = client\n</code></pre>"},{"location":"api/p2p/relay/manager/#proxystore.p2p.relay.manager.ClientManager.get_clients","title":"get_clients()","text":"<pre><code>get_clients() -&gt; list[Client[UserT]]\n</code></pre> <p>Get a list of all clients.</p> Source code in <code>proxystore/p2p/relay/manager.py</code> <pre><code>def get_clients(self) -&gt; list[Client[UserT]]:\n    \"\"\"Get a list of all clients.\"\"\"\n    return list(self._clients_by_uuid.values())\n</code></pre>"},{"location":"api/p2p/relay/manager/#proxystore.p2p.relay.manager.ClientManager.get_client_by_uuid","title":"get_client_by_uuid()","text":"<pre><code>get_client_by_uuid(uuid: UUID) -&gt; Client[UserT] | None\n</code></pre> <p>Get a client by the client's UUID.</p> Source code in <code>proxystore/p2p/relay/manager.py</code> <pre><code>def get_client_by_uuid(self, uuid: uuid.UUID) -&gt; Client[UserT] | None:\n    \"\"\"Get a client by the client's UUID.\"\"\"\n    return self._clients_by_uuid.get(uuid, None)\n</code></pre>"},{"location":"api/p2p/relay/manager/#proxystore.p2p.relay.manager.ClientManager.get_client_by_websocket","title":"get_client_by_websocket()","text":"<pre><code>get_client_by_websocket(\n    websocket: WebSocketServerProtocol,\n) -&gt; Client[UserT] | None\n</code></pre> <p>Get a client by the current websocket connection.</p> Source code in <code>proxystore/p2p/relay/manager.py</code> <pre><code>def get_client_by_websocket(\n    self,\n    websocket: WebSocketServerProtocol,\n) -&gt; Client[UserT] | None:\n    \"\"\"Get a client by the current websocket connection.\"\"\"\n    return self._clients_by_websocket.get(websocket, None)\n</code></pre>"},{"location":"api/p2p/relay/manager/#proxystore.p2p.relay.manager.ClientManager.remove_client","title":"remove_client()","text":"<pre><code>remove_client(client: Client[UserT]) -&gt; None\n</code></pre> <p>Remove a client.</p> Source code in <code>proxystore/p2p/relay/manager.py</code> <pre><code>def remove_client(self, client: Client[UserT]) -&gt; None:\n    \"\"\"Remove a client.\"\"\"\n    self._clients_by_uuid.pop(client.uuid, None)\n    self._clients_by_websocket.pop(client.websocket, None)\n</code></pre>"},{"location":"api/p2p/relay/messages/","title":"proxystore.p2p.relay.messages","text":"<code>proxystore/p2p/relay/messages.py</code> <p>Message types for relay client and relay server communication.</p>"},{"location":"api/p2p/relay/messages/#proxystore.p2p.relay.messages.RelayMessageType","title":"RelayMessageType","text":"<p>             Bases: <code>Enum</code></p> <p>Types of messages supported.</p>"},{"location":"api/p2p/relay/messages/#proxystore.p2p.relay.messages.RelayMessageType.relay_response","title":"relay_response  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>relay_response = 'RelayResponse'\n</code></pre> <p>Relay response message.</p>"},{"location":"api/p2p/relay/messages/#proxystore.p2p.relay.messages.RelayMessageType.relay_registration","title":"relay_registration  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>relay_registration = 'RelayRegistrationRequest'\n</code></pre> <p>Relay registration request message.</p>"},{"location":"api/p2p/relay/messages/#proxystore.p2p.relay.messages.RelayMessageType.peer_connection","title":"peer_connection  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>peer_connection = 'PeerConnectionRequest'\n</code></pre> <p>Peer connection request message.</p>"},{"location":"api/p2p/relay/messages/#proxystore.p2p.relay.messages.RelayMessage","title":"RelayMessage  <code>dataclass</code>","text":"<pre><code>RelayMessage()\n</code></pre> <p>Base message.</p>"},{"location":"api/p2p/relay/messages/#proxystore.p2p.relay.messages.RelayRegistrationRequest","title":"RelayRegistrationRequest  <code>dataclass</code>","text":"<pre><code>RelayRegistrationRequest(\n    name: str,\n    uuid: UUID,\n    message_type: str = RelayMessageType.relay_registration.name,\n)\n</code></pre> <p>             Bases: <code>RelayMessage</code></p> <p>Register with relay server as peer.</p> <p>Attributes:</p> <ul> <li> <code>name</code>             (<code>str</code>)         \u2013          <p>Name of peer requesting to register.</p> </li> <li> <code>uuid</code>             (<code>UUID</code>)         \u2013          <p>UUID of peer requesting to register.</p> </li> </ul>"},{"location":"api/p2p/relay/messages/#proxystore.p2p.relay.messages.RelayResponse","title":"RelayResponse  <code>dataclass</code>","text":"<pre><code>RelayResponse(\n    success: bool = True,\n    message: str | None = None,\n    error: bool = False,\n    message_type: str = RelayMessageType.relay_response.name,\n)\n</code></pre> <p>             Bases: <code>RelayMessage</code></p> <p>Message returned by relay server on success or error.</p> <p>Attributes:</p> <ul> <li> <code>success</code>             (<code>bool</code>)         \u2013          <p>If the registration was successful.</p> </li> <li> <code>message</code>             (<code>str | None</code>)         \u2013          <p>Message from server.</p> </li> <li> <code>error</code>             (<code>bool</code>)         \u2013          <p>If <code>message</code> is an error message.</p> </li> </ul>"},{"location":"api/p2p/relay/messages/#proxystore.p2p.relay.messages.PeerConnectionRequest","title":"PeerConnectionRequest  <code>dataclass</code>","text":"<pre><code>PeerConnectionRequest(\n    source_uuid: UUID,\n    source_name: str,\n    peer_uuid: UUID,\n    description_type: Literal[\"answer\", \"offer\"],\n    description: str,\n    error: str | None = None,\n    message_type: str = RelayMessageType.peer_connection.name,\n)\n</code></pre> <p>             Bases: <code>RelayMessage</code></p> <p>Message used to request a peer-to-peer connection from a relay.</p> <p>Attributes:</p> <ul> <li> <code>source_uuid</code>             (<code>UUID</code>)         \u2013          <p>UUID of sending peer.</p> </li> <li> <code>source_name</code>             (<code>str</code>)         \u2013          <p>Name of sending peer.</p> </li> <li> <code>peer_uuid</code>             (<code>UUID</code>)         \u2013          <p>UUID of destination peer.</p> </li> <li> <code>description_type</code>             (<code>Literal['answer', 'offer']</code>)         \u2013          <p>One of <code>'answer'</code> or <code>'offer'</code> indicating the type of message being sent.</p> </li> <li> <code>description</code>             (<code>str</code>)         \u2013          <p>Session description protocol message.</p> </li> <li> <code>error</code>             (<code>str | None</code>)         \u2013          <p>Error string if a problem occurs.</p> </li> </ul>"},{"location":"api/p2p/relay/messages/#proxystore.p2p.relay.messages.RelayMessageError","title":"RelayMessageError","text":"<p>             Bases: <code>Exception</code></p> <p>Base exception type for relay messages.</p>"},{"location":"api/p2p/relay/messages/#proxystore.p2p.relay.messages.RelayMessageDecodeError","title":"RelayMessageDecodeError","text":"<p>             Bases: <code>RelayMessageError</code></p> <p>Exception raised when a message cannot be decoded.</p>"},{"location":"api/p2p/relay/messages/#proxystore.p2p.relay.messages.RelayMessageEncodeError","title":"RelayMessageEncodeError","text":"<p>             Bases: <code>RelayMessageError</code></p> <p>Exception raised when an message cannot be encoded.</p>"},{"location":"api/p2p/relay/messages/#proxystore.p2p.relay.messages.uuid_to_str","title":"uuid_to_str()","text":"<pre><code>uuid_to_str(data: dict[str, Any]) -&gt; dict[str, Any]\n</code></pre> <p>Cast any UUIDs to strings.</p> <p>Scans the input dictionary for any values where the associated key contains 'uuid' and value is a UUID instance and converts it to a string for jsonification.</p> <p>Returns:</p> <ul> <li> <code>dict[str, Any]</code>         \u2013          <p>Shallow copy of the input dictionary with values cast from UUID         to str if their key also contains UUID.</p> </li> </ul> Source code in <code>proxystore/p2p/relay/messages.py</code> <pre><code>def uuid_to_str(data: dict[str, Any]) -&gt; dict[str, Any]:\n    \"\"\"Cast any UUIDs to strings.\n\n    Scans the input dictionary for any values where the associated key\n    contains 'uuid' and value is a UUID instance and converts it to a\n    string for jsonification.\n\n    Returns:\n        Shallow copy of the input dictionary with values cast from UUID \\\n        to str if their key also contains UUID.\n    \"\"\"\n    data = data.copy()\n    for key in data:\n        if 'uuid' in key.lower() and isinstance(data[key], uuid.UUID):\n            data[key] = str(data[key])\n    return data\n</code></pre>"},{"location":"api/p2p/relay/messages/#proxystore.p2p.relay.messages.str_to_uuid","title":"str_to_uuid()","text":"<pre><code>str_to_uuid(data: dict[str, Any]) -&gt; dict[str, Any]\n</code></pre> <p>Cast any possible UUID strings to UUID objects.</p> <p>The inverse operation of uuid_to_str().</p> <p>Returns:</p> <ul> <li> <code>dict[str, Any]</code>         \u2013          <p>Shallow copy of the input dictionary with values cast from         str to UUID if the key also contains UUID.</p> </li> </ul> <p>Raises:</p> <ul> <li> <code>RelayMessageDecodeError</code>           \u2013          <p>If a key contains 'uuid' but the value cannot be cast to a UUID.</p> </li> </ul> Source code in <code>proxystore/p2p/relay/messages.py</code> <pre><code>def str_to_uuid(data: dict[str, Any]) -&gt; dict[str, Any]:\n    \"\"\"Cast any possible UUID strings to UUID objects.\n\n    The inverse operation of\n    [uuid_to_str()][proxystore.p2p.relay.messages.uuid_to_str].\n\n    Returns:\n        Shallow copy of the input dictionary with values cast from \\\n        str to UUID if the key also contains UUID.\n\n    Raises:\n        RelayMessageDecodeError: If a key contains 'uuid' but the value cannot\n            be cast to a UUID.\n    \"\"\"\n    data = data.copy()\n    for key in data:\n        if 'uuid' in key.lower():\n            try:\n                data[key] = uuid.UUID(data[key])\n            except (AttributeError, TypeError, ValueError) as e:\n                raise RelayMessageDecodeError(\n                    f'Failed to convert key {key} to UUID.',\n                ) from e\n    return data\n</code></pre>"},{"location":"api/p2p/relay/messages/#proxystore.p2p.relay.messages.decode_relay_message","title":"decode_relay_message()","text":"<pre><code>decode_relay_message(message: str) -&gt; RelayMessage\n</code></pre> <p>Decode JSON string into correct relay message type.</p> <p>Parameters:</p> <ul> <li> <code>message</code>             (<code>str</code>)         \u2013          <p>JSON string to decode.</p> </li> </ul> <p>Returns:</p> <ul> <li> <code>RelayMessage</code>         \u2013          <p>Parsed message.</p> </li> </ul> <p>Raises:</p> <ul> <li> <code>RelayMessageDecodeError</code>           \u2013          <p>If the message cannot be decoded.</p> </li> </ul> Source code in <code>proxystore/p2p/relay/messages.py</code> <pre><code>def decode_relay_message(message: str) -&gt; RelayMessage:\n    \"\"\"Decode JSON string into correct relay message type.\n\n    Args:\n        message: JSON string to decode.\n\n    Returns:\n        Parsed message.\n\n    Raises:\n        RelayMessageDecodeError: If the message cannot be decoded.\n    \"\"\"\n    try:\n        data = json.loads(message)\n    except json.JSONDecodeError as e:\n        raise RelayMessageDecodeError('Failed to load string as JSON.') from e\n\n    try:\n        message_type_name = data.pop('message_type')\n    except KeyError as e:\n        raise RelayMessageDecodeError(\n            'Message does not contain a message_type key.',\n        ) from e\n\n    try:\n        message_type = getattr(\n            sys.modules[__name__],\n            RelayMessageType[message_type_name].value,\n        )\n    except (AttributeError, KeyError) as e:\n        raise RelayMessageDecodeError(\n            'The message is of an unknown message type: '\n            f'{message_type_name}.',\n        ) from e\n\n    data = str_to_uuid(data)\n\n    try:\n        return message_type(**data)\n    except TypeError as e:\n        raise RelayMessageDecodeError(\n            f'Failed to convert message to {message_type.__name__}: {e}',\n        ) from e\n</code></pre>"},{"location":"api/p2p/relay/messages/#proxystore.p2p.relay.messages.encode_relay_message","title":"encode_relay_message()","text":"<pre><code>encode_relay_message(message: RelayMessage) -&gt; str\n</code></pre> <p>Encode message as JSON string.</p> <p>Parameters:</p> <ul> <li> <code>message</code>             (<code>RelayMessage</code>)         \u2013          <p>Message to JSON encode.</p> </li> </ul> <p>Raises:</p> <ul> <li> <code>RelayMessageEncodeError</code>           \u2013          <p>If the message cannot be JSON encoded.</p> </li> </ul> Source code in <code>proxystore/p2p/relay/messages.py</code> <pre><code>def encode_relay_message(message: RelayMessage) -&gt; str:\n    \"\"\"Encode message as JSON string.\n\n    Args:\n        message: Message to JSON encode.\n\n    Raises:\n        RelayMessageEncodeError: If the message cannot be JSON encoded.\n    \"\"\"\n    if not isinstance(message, RelayMessage):\n        raise RelayMessageEncodeError(\n            f'Message is not an instance of {RelayMessage.__name__}. '\n            f'Got {type(message).__name__}.',\n        )\n\n    data = dataclasses.asdict(message)\n    data = uuid_to_str(data)\n\n    try:\n        return json.dumps(data)\n    except TypeError as e:\n        raise RelayMessageEncodeError('Error encoding message.') from e\n</code></pre>"},{"location":"api/p2p/relay/run/","title":"proxystore.p2p.relay.run","text":"<code>proxystore/p2p/relay/run.py</code> <p>CLI and serving functions for running a Globus Auth relay server.</p>"},{"location":"api/p2p/relay/run/#proxystore.p2p.relay.run.periodic_client_logger","title":"periodic_client_logger()","text":"<pre><code>periodic_client_logger(\n    server: RelayServer[UserT],\n    interval: float = 60,\n    limit: float | None = 60,\n    level: int = logging.INFO,\n) -&gt; Task[None]\n</code></pre> <p>Create an asyncio task which logs currently connected clients.</p> <p>Parameters:</p> <ul> <li> <code>server</code>             (<code>RelayServer[UserT]</code>)         \u2013          <p>Relay server instance to log connected clients of.</p> </li> <li> <code>interval</code>             (<code>float</code>, default:                 <code>60</code> )         \u2013          <p>Seconds between logging connected clients.</p> </li> <li> <code>limit</code>             (<code>float | None</code>, default:                 <code>60</code> )         \u2013          <p>Only log detailed client list if the number of clients is less than this number. Useful for debugging or avoiding clobbering the logs by printing thousands of clients.</p> </li> <li> <code>level</code>             (<code>int</code>, default:                 <code>INFO</code> )         \u2013          <p>Logging level.</p> </li> </ul> <p>Returns:</p> <ul> <li> <code>Task[None]</code>         \u2013          <p>Asyncio task.</p> </li> </ul> Source code in <code>proxystore/p2p/relay/run.py</code> <pre><code>def periodic_client_logger(\n    server: RelayServer[UserT],\n    interval: float = 60,\n    limit: float | None = 60,\n    level: int = logging.INFO,\n) -&gt; asyncio.Task[None]:\n    \"\"\"Create an asyncio task which logs currently connected clients.\n\n    Args:\n        server: Relay server instance to log connected clients of.\n        interval: Seconds between logging connected clients.\n        limit: Only log detailed client list if the number of clients is\n            less than this number. Useful for debugging or avoiding\n            clobbering the logs by printing thousands of clients.\n        level: Logging level.\n\n    Returns:\n        Asyncio task.\n    \"\"\"\n\n    async def _log() -&gt; None:\n        while True:\n            await asyncio.sleep(interval)\n            clients = server.client_manager.get_clients()\n            clients = sorted(clients, key=lambda client: client.name)\n            clients_repr = (\n                '\\n'.join(repr(client) for client in clients)\n                if limit is not None\n                else None\n            )\n            message = f'Connected clients: {len(clients)}'\n            message = (\n                f'{message}\\n{clients_repr}'\n                if (\n                    clients_repr is not None\n                    and limit is not None\n                    and 0 &lt; len(clients) &lt; limit\n                )\n                else message\n            )\n            logger.log(level, message)\n\n    task = spawn_guarded_background_task(_log)\n    task.set_name('relay-server-client-logger')\n\n    return task\n</code></pre>"},{"location":"api/p2p/relay/run/#proxystore.p2p.relay.run.serve","title":"serve()  <code>async</code>","text":"<pre><code>serve(config: RelayServingConfig) -&gt; None\n</code></pre> <p>Run the relay server.</p> <p>Initializes a <code>RelayServer</code> and starts a websocket server listening for new connections and incoming messages.</p> Note <p>This function will not configure any logging. Configuring logging according to <code>RelayServingConfig.logging</code> is the responsibility of the caller.</p> <p>Parameters:</p> <ul> <li> <code>config</code>             (<code>RelayServingConfig</code>)         \u2013          <p>Serving configuration.</p> </li> </ul> Source code in <code>proxystore/p2p/relay/run.py</code> <pre><code>async def serve(config: RelayServingConfig) -&gt; None:\n    \"\"\"Run the relay server.\n\n    Initializes a\n    [`RelayServer`][proxystore.p2p.relay.server.RelayServer]\n    and starts a websocket server listening for new connections\n    and incoming messages.\n\n    Note:\n        This function will not configure any logging. Configuring logging\n        according to\n        [`RelayServingConfig.logging`][proxystore.p2p.relay.config.RelayServingConfig]\n        is the responsibility of the caller.\n\n    Args:\n        config: Serving configuration.\n    \"\"\"\n    authenticator = get_authenticator(config.auth)\n    server = RelayServer(\n        authenticator,\n        max_message_bytes=config.max_message_bytes,\n    )\n\n    # Set the stop condition when receiving SIGINT (ctrl-C) and SIGTERM.\n    loop = asyncio.get_running_loop()\n    stop = loop.create_future()\n    loop.add_signal_handler(signal.SIGINT, stop.set_result, None)\n    loop.add_signal_handler(signal.SIGTERM, stop.set_result, None)\n\n    ssl_context: ssl.SSLContext | None = None\n    if config.certfile is not None:\n        ssl_context = ssl.SSLContext(ssl.PROTOCOL_TLS_SERVER)\n        ssl_context.load_cert_chain(config.certfile, keyfile=config.keyfile)\n\n    client_logger_task: asyncio.Task[None] | None = None\n    if config.logging.current_client_interval is not None:  # pragma: no branch\n        level = (\n            config.logging.default_level\n            if isinstance(config.logging.default_level, int)\n            else logging.getLevelName(config.logging.default_level)\n        )\n        client_logger_task = periodic_client_logger(\n            server,\n            config.logging.current_client_interval,\n            config.logging.current_client_limit,\n            level=level,\n        )\n\n    config_repr = pprint.pformat(config, indent=2)\n    logger.info(f'Relay serving configuration:\\n{config_repr}')\n\n    async with websockets.server.serve(\n        server.handler,\n        config.host,\n        config.port,\n        logger=None,\n        ssl=ssl_context,\n    ):\n        logger.info(f'Relay server listening on port {config.port}')\n        logger.info('Use ctrl-C to stop')\n        await stop\n\n    if client_logger_task is not None:  # pragma: no branch\n        client_logger_task.cancel()\n        try:\n            await client_logger_task\n        except asyncio.CancelledError:\n            pass\n\n    loop.remove_signal_handler(signal.SIGINT)\n    loop.remove_signal_handler(signal.SIGTERM)\n\n    logger.info('Relay server shutdown')\n</code></pre>"},{"location":"api/p2p/relay/run/#proxystore.p2p.relay.run.cli","title":"cli()","text":"<pre><code>cli(\n    config_path: str | None,\n    host: str | None,\n    port: int | None,\n    log_dir: str | None,\n    log_level: str | None,\n) -&gt; None\n</code></pre> <p>Run a relay server instance.</p> <p>The relay server is used by clients to establish peer-to-peer WebRTC connections. If no configuration file is provided, a default configuration will be created from <code>RelayServingConfig()</code>. The remaining CLI options will override the options provided in the configuration object.</p> Source code in <code>proxystore/p2p/relay/run.py</code> <pre><code>@click.command()\n@click.option('--config', '-c', 'config_path', help='Configuration file.')\n@click.option('--host', metavar='ADDR', help='Interface to bind to.')\n@click.option('--port', type=int, metavar='PORT', help='Port to bind to.')\n@click.option('--log-dir', metavar='PATH', help='Logging directoryy.')\n@click.option(\n    '--log-level',\n    type=click.Choice(\n        ['CRITICAL', 'ERROR', 'WARNING', 'INFO', 'DEBUG'],\n        case_sensitive=False,\n    ),\n    help='Minimum logging level.',\n)\ndef cli(\n    config_path: str | None,\n    host: str | None,\n    port: int | None,\n    log_dir: str | None,\n    log_level: str | None,\n) -&gt; None:\n    \"\"\"Run a relay server instance.\n\n    The relay server is used by clients to establish peer-to-peer\n    WebRTC connections. If no configuration file is provided, a default\n    configuration will be created from\n    [`RelayServingConfig()`][proxystore.p2p.relay.config.RelayServingConfig].\n    The remaining CLI options will override the options provided in the\n    configuration object.\n    \"\"\"\n    config = (\n        RelayServingConfig()\n        if config_path is None\n        else RelayServingConfig.from_toml(config_path)\n    )\n\n    # Override config with CLI options if given\n    if host is not None:\n        config.host = host\n    if port is not None:\n        config.port = port\n    if log_dir is not None:\n        config.logging.log_dir = log_dir\n    if log_level is not None:\n        config.logging.default_level = logging.getLevelName(log_level)\n\n    handlers: list[logging.Handler] = [logging.StreamHandler(sys.stdout)]\n    if config.logging.log_dir is not None:\n        os.makedirs(config.logging.log_dir, exist_ok=True)\n        handlers.append(\n            logging.handlers.TimedRotatingFileHandler(\n                os.path.join(config.logging.log_dir, 'server.log'),\n                # Rotate logs Sunday at midnight\n                when='W6',\n                atTime=datetime.time(hour=0, minute=0, second=0),\n            ),\n        )\n\n    logging.basicConfig(\n        format=(\n            '[%(asctime)s.%(msecs)03d] %(levelname)-5s (%(name)s) :: '\n            '%(message)s'\n        ),\n        datefmt='%Y-%m-%d %H:%M:%S',\n        level=config.logging.default_level,\n        handlers=handlers,\n    )\n\n    logging.getLogger('websockets').setLevel(config.logging.websockets_level)\n\n    asyncio.run(serve(config))\n</code></pre>"},{"location":"api/p2p/relay/server/","title":"proxystore.p2p.relay.server","text":"<code>proxystore/p2p/relay/server.py</code> <p>Relay server implementation for facilitating WebRTC peer connections.</p> <p>The relay server (or signaling server) is a lightweight server accessible by all peers (e.g., has a public IP address) that facilitates the establishment of peer WebRTC connections.</p>"},{"location":"api/p2p/relay/server/#proxystore.p2p.relay.server.RelayServer","title":"RelayServer","text":"<pre><code>RelayServer(\n    authenticator: Authenticator[UserT],\n    max_message_bytes: int | None = None,\n)\n</code></pre> <p>             Bases: <code>Generic[UserT]</code></p> <p>WebRTC relay server.</p> <p>The relay server acts as a public third-party that helps two peers (endpoints) establish a peer-to-peer connection during the WebRTC peer connection initiation process. The relay server's responsibility is just to forward session descriptions between two peers, so the server can be relatively lightweight and typically only needs to transfer two messages to establish a peer connection, after which the peers no longer need the relay server.</p> <p>To learn more about the WebRTC peer connection process, check out https://webrtc.org/getting-started/peer-connections.</p> <p>The relay server is built on websockets and designed to be served using <code>serve()</code>.</p> <p>Parameters:</p> <ul> <li> <code>authenticator</code>             (<code>Authenticator[UserT]</code>)         \u2013          <p>Authenticator used to identify users from the opening websocket headers.</p> </li> <li> <code>max_message_bytes</code>             (<code>int | None</code>, default:                 <code>None</code> )         \u2013          <p>Optional maximum size of client messages in bytes. Clients that send oversized messages will have their connections closed. Note that message size is computed using <code>sys.getsizeof()</code> so will also include the PyObject overhead.</p> </li> </ul> Source code in <code>proxystore/p2p/relay/server.py</code> <pre><code>def __init__(\n    self,\n    authenticator: Authenticator[UserT],\n    max_message_bytes: int | None = None,\n) -&gt; None:\n    self._authenticator = authenticator\n    self._client_manager: ClientManager[UserT] = ClientManager()\n    self._max_message_bytes = max_message_bytes\n</code></pre>"},{"location":"api/p2p/relay/server/#proxystore.p2p.relay.server.RelayServer.authenticator","title":"authenticator  <code>property</code>","text":"<pre><code>authenticator: Authenticator[UserT]\n</code></pre> <p>User authenticator.</p>"},{"location":"api/p2p/relay/server/#proxystore.p2p.relay.server.RelayServer.client_manager","title":"client_manager  <code>property</code>","text":"<pre><code>client_manager: ClientManager[UserT]\n</code></pre> <p>Manager of user clients.</p>"},{"location":"api/p2p/relay/server/#proxystore.p2p.relay.server.RelayServer.send","title":"send()  <code>async</code>","text":"<pre><code>send(client: Client[UserT], message: RelayMessage) -&gt; None\n</code></pre> <p>Send message on the socket.</p> Note <p>Messages are JSON string encoded using <code>encode_relay_message()</code>.</p> <p>Parameters:</p> <ul> <li> <code>client</code>             (<code>Client[UserT]</code>)         \u2013          <p>Client to send message to.</p> </li> <li> <code>message</code>             (<code>RelayMessage</code>)         \u2013          <p>Message to encode and send via the websocket connection to the client.</p> </li> </ul> Source code in <code>proxystore/p2p/relay/server.py</code> <pre><code>async def send(self, client: Client[UserT], message: RelayMessage) -&gt; None:\n    \"\"\"Send message on the socket.\n\n    Note:\n        Messages are JSON string encoded using\n        [`encode_relay_message()`][proxystore.p2p.relay.messages.encode_relay_message].\n\n    Args:\n        client: Client to send message to.\n        message: Message to encode and send via the websocket connection\n            to the client.\n    \"\"\"\n    try:\n        message_str = encode_relay_message(message)\n    except RelayMessageEncodeError as e:\n        logger.error(f'Failed to encode message: {e}')\n        return\n\n    try:\n        await client.websocket.send(message_str)\n    except websockets.exceptions.ConnectionClosed:\n        logger.error('Connection closed while attempting to send message')\n</code></pre>"},{"location":"api/p2p/relay/server/#proxystore.p2p.relay.server.RelayServer.register","title":"register()  <code>async</code>","text":"<pre><code>register(\n    websocket: WebSocketServerProtocol,\n    request: RelayRegistrationRequest,\n) -&gt; None\n</code></pre> <p>Register client with relay server.</p> <p>Parameters:</p> <ul> <li> <code>websocket</code>             (<code>WebSocketServerProtocol</code>)         \u2013          <p>Websocket connection with client wanting to register.</p> </li> <li> <code>request</code>             (<code>RelayRegistrationRequest</code>)         \u2013          <p>Registration request message.</p> </li> </ul> <p>Raises:</p> <ul> <li> <code>UnauthorizedError</code>           \u2013          <p>if the websocket request headers are missing the authorization headers.</p> </li> <li> <code>ForbiddenError</code>           \u2013          <p>if Globus authentication fails.</p> </li> <li> <code>ForbiddenError</code>           \u2013          <p>if the requested client UUID is already registered by another user.</p> </li> </ul> Source code in <code>proxystore/p2p/relay/server.py</code> <pre><code>async def register(\n    self,\n    websocket: WebSocketServerProtocol,\n    request: RelayRegistrationRequest,\n) -&gt; None:\n    \"\"\"Register client with relay server.\n\n    Args:\n        websocket: Websocket connection with client wanting to register.\n        request: Registration request message.\n\n    Raises:\n        UnauthorizedError: if the websocket request headers are missing\n            the authorization headers.\n        ForbiddenError: if Globus authentication fails.\n        ForbiddenError: if the requested client UUID is already\n            registered by another user.\n    \"\"\"\n    try:\n        auth_user = self.authenticator.authenticate_user(\n            websocket.request_headers,\n        )\n    except RelayServerError as e:\n        logging.warning(\n            'Failed to authenticate connection request from '\n            f'{websocket.remote_address}. {e.__class__.__name__}: {e}',\n        )\n        raise\n\n    existing_client = self.client_manager.get_client_by_uuid(request.uuid)\n    if existing_client is not None:\n        if (\n            existing_client.user == auth_user\n            and existing_client.websocket != websocket\n        ):\n            logger.info(\n                f'Previously registered client {request.uuid} attempting '\n                'to reregister on new socket so old socket associated '\n                'with existing registration will be closed',\n            )\n            await self.unregister(existing_client, False)\n        elif existing_client.user != auth_user:\n            logger.warning(\n                f'User {auth_user} is attempting to register with a UUID'\n                f' ({request.uuid}) that is owned by a different user.',\n            )\n            raise ForbiddenError(\n                f'The client UUID {request.uuid} is already registered '\n                'to another user.',\n            )\n\n    client = Client(\n        name=request.name,\n        uuid=request.uuid,\n        user=auth_user,\n        websocket=websocket,\n    )\n    self.client_manager.add_client(client)\n    logger.info(f'Registered client: {client}')\n\n    await self.send(client, RelayResponse(success=True))\n</code></pre>"},{"location":"api/p2p/relay/server/#proxystore.p2p.relay.server.RelayServer.unregister","title":"unregister()  <code>async</code>","text":"<pre><code>unregister(client: Client[UserT], expected: bool) -&gt; None\n</code></pre> <p>Unregister the endpoint.</p> <p>Parameters:</p> <ul> <li> <code>client</code>             (<code>Client[UserT]</code>)         \u2013          <p>Client to unregister.</p> </li> <li> <code>expected</code>             (<code>bool</code>)         \u2013          <p>If the connection was closed intentionally or due to an error.</p> </li> </ul> Source code in <code>proxystore/p2p/relay/server.py</code> <pre><code>async def unregister(self, client: Client[UserT], expected: bool) -&gt; None:\n    \"\"\"Unregister the endpoint.\n\n    Args:\n        client: Client to unregister.\n        expected: If the connection was closed intentionally or due to an\n            error.\n    \"\"\"\n    reason = 'ok' if expected else 'unexpected'\n    logger.info(\n        f'Unregistering client {client.uuid} ({client.name}) '\n        f'for {reason} reason',\n    )\n    self.client_manager.remove_client(client)\n    await client.websocket.close(code=1000 if expected else 1001)\n</code></pre>"},{"location":"api/p2p/relay/server/#proxystore.p2p.relay.server.RelayServer.forward","title":"forward()  <code>async</code>","text":"<pre><code>forward(\n    source_client: Client[UserT],\n    request: PeerConnectionRequest,\n) -&gt; None\n</code></pre> <p>Forward peer connection request between two clients.</p> <p>If an error is encountered, the relay server replies to the source client with an error message set in <code>message.error</code>.</p> <p>Parameters:</p> <ul> <li> <code>source_client</code>             (<code>Client[UserT]</code>)         \u2013          <p>Client making forwarding request.</p> </li> <li> <code>request</code>             (<code>PeerConnectionRequest</code>)         \u2013          <p>Peer connection request to forward.</p> </li> </ul> Source code in <code>proxystore/p2p/relay/server.py</code> <pre><code>async def forward(\n    self,\n    source_client: Client[UserT],\n    request: PeerConnectionRequest,\n) -&gt; None:\n    \"\"\"Forward peer connection request between two clients.\n\n    If an error is encountered, the relay server replies to the source\n    client with an error message set in `message.error`.\n\n    Args:\n        source_client: Client making forwarding request.\n        request: Peer connection request to forward.\n    \"\"\"\n    target_client = self.client_manager.get_client_by_uuid(\n        request.peer_uuid,\n    )\n    if target_client is None:\n        logger.warning(\n            f'Client {source_client.uuid} ({source_client.name}) '\n            'attempting to send message to unknown peer '\n            f'{request.peer_uuid}',\n        )\n        request.error = (\n            'Cannot forward peer connection message to peer '\n            f'{request.peer_uuid} because this peer is not registered '\n            'this relay server.'\n        )\n        await self.send(source_client, request)\n        return\n\n    if source_client.user != target_client.user:\n        logger.warning(\n            f'Client {source_client.uuid} ({source_client.name}) '\n            'attempting to send message to peer '\n            f'{request.peer_uuid} owned by another user',\n        )\n        request.error = (\n            f'The requested peer {request.peer_uuid} is owned by a '\n            'different user.'\n        )\n        await self.send(source_client, request)\n    else:\n        logger.info(\n            f'Transmitting message from {source_client.uuid} '\n            f'({source_client.name}) to {target_client.uuid} '\n            f'({target_client.name})',\n        )\n        await self.send(target_client, request)\n</code></pre>"},{"location":"api/p2p/relay/server/#proxystore.p2p.relay.server.RelayServer.handler","title":"handler()  <code>async</code>","text":"<pre><code>handler(\n    websocket: WebSocketServerProtocol, uri: str\n) -&gt; None\n</code></pre> <p>Websocket server message handler.</p> <p>The handler will close the connection for the following reasons.</p> <ul> <li>An unexpected message type is received (code 4000).</li> <li>The client can not be authenticated (code 4001).</li> <li>The client attempts to access forbidden resources (code 4002).</li> <li>The client sends a message larger than the allowed size (code 4003).</li> </ul> <p>Parameters:</p> <ul> <li> <code>websocket</code>             (<code>WebSocketServerProtocol</code>)         \u2013          <p>Websocket message was received on.</p> </li> <li> <code>uri</code>             (<code>str</code>)         \u2013          <p>URI message was sent to.</p> </li> </ul> Source code in <code>proxystore/p2p/relay/server.py</code> <pre><code>async def handler(  # noqa: C901\n    self,\n    websocket: WebSocketServerProtocol,\n    uri: str,\n) -&gt; None:\n    \"\"\"Websocket server message handler.\n\n    The handler will close the connection for the following reasons.\n\n    - An unexpected message type is received (code 4000).\n    - The client can not be authenticated (code 4001).\n    - The client attempts to access forbidden resources (code 4002).\n    - The client sends a message larger than the allowed size (code 4003).\n\n    Args:\n        websocket: Websocket message was received on.\n        uri: URI message was sent to.\n    \"\"\"\n    while True:\n        try:\n            message_str = await websocket.recv()\n        except websockets.exceptions.ConnectionClosedOK:\n            client = self.client_manager.get_client_by_websocket(websocket)\n            if client is not None:\n                await self.unregister(client, expected=True)\n            break\n        except websockets.exceptions.ConnectionClosedError:\n            client = self.client_manager.get_client_by_websocket(websocket)\n            if client is not None:\n                await self.unregister(client, expected=False)\n            break\n\n        if (\n            self._max_message_bytes is not None\n            and sys.getsizeof(message_str) &gt; self._max_message_bytes\n        ):\n            await websocket.close(\n                4003,\n                reason='Message length exceeds limit.',\n            )\n            logger.warning(\n                f'Client at {websocket.remote_address} sent message with '\n                f'size {sys.getsizeof(message_str)} bytes which exceeds '\n                f'the max configured size of {self._max_message_bytes} '\n                'bytes. Connection closed with error code 4003',\n            )\n            break\n\n        try:\n            if isinstance(message_str, bytes):\n                raise RelayMessageDecodeError(\n                    'Got message as bytes but expected str.',\n                )\n            message = decode_relay_message(message_str)\n        except RelayMessageDecodeError as e:\n            logger.error(\n                'Closing websocket because deserialization error was '\n                'caught on message received from '\n                f'{websocket.remote_address}. {e}',\n            )\n            await websocket.close(4000, reason='Unknown message type.')\n            break\n\n        try:\n            await self._process_message(websocket, message)\n        except UnauthorizedError as e:\n            await websocket.close(\n                code=4001,\n                reason=f'{e.__class__.__name__}: {e}',\n            )\n        except ForbiddenError as e:\n            await websocket.close(\n                code=4002,\n                reason=f'{e.__class__.__name__}: {e}',\n            )\n        except RelayServerError as e:\n            response = RelayResponse(\n                success=False,\n                message=f'{e.__class__.__name__}: {e}',\n                error=True,\n            )\n            await websocket.send(encode_relay_message(response))\n</code></pre>"},{"location":"api/proxy/","title":"proxystore.proxy","text":"<code>proxystore/proxy/__init__.py</code> <p>Proxy implementation and helpers.</p>"},{"location":"api/proxy/#proxystore.proxy.ProxyOr","title":"ProxyOr  <code>module-attribute</code>","text":"<pre><code>ProxyOr = TypeAliasType(\n    \"ProxyOr\", Union[Proxy[T], T], type_params=(T)\n)\n</code></pre> <p>Type alias for a union of a type <code>T</code> or a <code>Proxy[T]</code>.</p> <p>This type alias is useful for typing functions that operate on or return mixed types involving proxies.</p> Example <pre><code>from typing import TypeVar\nfrom proxystore.proxy import Proxy, ProxyOr, extract\n\nT = TypeVar('T')\n\ndef extract_if_proxy(value: ProxyOr[T]) -&gt; T:\n    return extract(value) if isinstance(value, Proxy) else value\n</code></pre>"},{"location":"api/proxy/#proxystore.proxy.Proxy","title":"Proxy","text":"<pre><code>Proxy(\n    factory: FactoryType[T],\n    *,\n    cache_defaults: bool = False,\n    target: T | None = None\n)\n</code></pre> <p>             Bases: <code>as_metaclass(ProxyMetaType)</code>, <code>Generic[T]</code></p> <p>Lazy object proxy.</p> <p>An extension of the Proxy from lazy-object-proxy with modified attribute lookup and pickling behavior.</p> <p>An object proxy acts as a thin wrapper around a Python object, i.e. the proxy behaves identically to the underlying object. The proxy is initialized with a callable factory object. The factory returns the underlying object when called, i.e. resolves the proxy. This means a proxy performs lazy/just-in-time resolution, i.e., the proxy does not call the factory until the first access to the proxy.</p> <pre><code>from proxystore.proxy import Proxy\n\ndef factory() -&gt; list[int]:\n    return [1, 2, 3]\n\nproxy = Proxy(factory)\nassert isinstance(proxy, list)\nassert proxy == [1, 2, 3]\n</code></pre> Note <p>The <code>factory</code>, by default, is only ever called once during the lifetime of a proxy instance.</p> Note <p>When a proxy instance is pickled, only the <code>factory</code> is pickled, not the wrapped object. Thus, proxy instances can be pickled and passed around cheaply, and once the proxy is unpickled and used, the <code>factory</code> will be called again to resolve the object.</p> Tip <p>Common data structures (e.g., <code>dict</code> or <code>set</code>) and operations (e.g., <code>isinstance</code>) will resolve an unresolved proxy. This can result in unintentional performance degradation for expensive factories, such as those that require significant I/O or produce target objects that require a lot of memory. The <code>target</code> and <code>cache_defaults</code> parameters of <code>Proxy</code> can prevent these unintenional proxy resolves by caching the <code>__class__</code> and <code>__hash__</code> values of the target object in the proxy.</p> <pre><code>from proxystore.proxy import Proxy\nfrom proxystore.proxy import is_resolved\n\nproxy = Proxy(lambda: 'value')\nassert not is_resolved(proxy)\n\nassert isinstance(proxy, str)  # (1)!\nassert is_resolved(proxy)\n\nvalue = 'value'\nproxy = Proxy(lambda: value, cache_defaults=True, target=value)  # (2)!\nassert not is_resolved(proxy)\n\nassert isinstance(proxy, str)  # (3)!\nassert not is_resolved(proxy)\n</code></pre> <ol> <li>Using <code>isinstance</code> calls <code>__class__</code> on the target    object which requires the proxy to be resolved. In many cases,    it may be desirable to check the type of a proxy's target object    without incurring the cost of resolving the target.</li> <li>If the target is available when constructing the proxy, the    proxy can precompute and cache the <code>__class__</code> and <code>__hash__</code> values    of the target.</li> <li>Using <code>isinstance</code> no longer requires the proxy    to be resolved, instead using the precomputed value.</li> </ol> Warning <p>A proxy of a singleton type (e.g., <code>True</code>, <code>False</code>, and <code>None</code>) will not behave exactly as a singleton type would. This is because the proxy itself is not a singleton.</p> <pre><code>&gt;&gt;&gt; from proxystore.proxy import Proxy\n&gt;&gt;&gt; p = Proxy(lambda: True)\n&gt;&gt;&gt; p == True\nTrue\n&gt;&gt;&gt; p is True\nFalse\n</code></pre> Warning <p>Python bindings to other languages (e.g., C, C++) may throw type errors when receiving a <code>Proxy</code> instance. Casting the proxy or extracting the target object may be needed.</p> <pre><code>&gt;&gt;&gt; import io\n&gt;&gt;&gt; from proxystore.proxy import Proxy\n&gt;&gt;&gt; s = 'mystring'\n&gt;&gt;&gt; p = Proxy(lambda: s)\n&gt;&gt;&gt; io.StringIO(p)\nTraceback (most recent call last):\n  File \"&lt;stdin&gt;\", line 1, in &lt;module&gt;\nTypeError: initial_value must be str or None, not Proxy\n&gt;&gt;&gt; io.StringIO(str(p))  # succeeds\n</code></pre> <p>Attributes:</p> <ul> <li> <code>__proxy_factory__</code>             (<code>FactoryType[T]</code>)         \u2013          <p>Factory function which resolves to the target object.</p> </li> <li> <code>__proxy_target__</code>             (<code>T</code>)         \u2013          <p>The target object once resolved.</p> </li> <li> <code>__proxy_resolved__</code>             (<code>bool</code>)         \u2013          <p><code>True</code> if <code>__proxy_target__</code> is set.</p> </li> <li> <code>__proxy_wrapped__</code>             (<code>T</code>)         \u2013          <p>A property that either returns <code>__proxy_target__</code> if it exists else calls <code>__proxy_factory__</code>, saving the result to <code>__proxy_target__</code> and returning said result.</p> </li> <li> <code>__proxy_default_class__</code>             (<code>DefaultClassType</code>)         \u2013          <p>Optional default class type value to use when a proxy is in the unresolved state. This avoids needing to resolve the proxy to perform <code>isinstance</code> checks. This value is always ignored while the proxy is resolved because <code>__class__</code> is a writable property of the cached target and could be altered.</p> </li> <li> <code>__proxy_default_hash__</code>             (<code>DefaultHashType</code>)         \u2013          <p>Optional default hash value to use when a proxy is in the unresolved state and <code>hash()</code> is called. This avoids needing to resolve the proxy for simple operations like dictionary updates. This value is always ignored while the proxy is resolved because the cached target may be modified which can alter the value of the hash.</p> </li> </ul> <p>Parameters:</p> <ul> <li> <code>factory</code>             (<code>FactoryType[T]</code>)         \u2013          <p>Callable object that returns the underlying object when called. The factory should be pure meaning that every call of the factory returns the same object.</p> </li> <li> <code>cache_defaults</code>             (<code>bool</code>, default:                 <code>False</code> )         \u2013          <p>Precompute and cache the <code>__proxy_default_class__</code> and <code>__proxy_default_hash__</code> attributes of the proxy instance from <code>target</code>. Ignored if <code>target</code> is not provided.</p> </li> <li> <code>target</code>             (<code>T | None</code>, default:                 <code>None</code> )         \u2013          <p>Optionally preset the target object.</p> </li> </ul> <p>Raises:</p> <ul> <li> <code>TypeError</code>           \u2013          <p>If <code>factory</code> is not callable.</p> </li> </ul> Source code in <code>proxystore/proxy/__init__.py</code> <pre><code>def __init__(\n    self,\n    factory: FactoryType[T],\n    *,\n    cache_defaults: bool = False,\n    target: T | None = None,\n) -&gt; None:\n    if not callable(factory):\n        raise TypeError('Factory must be callable.')\n    object.__setattr__(self, '__proxy_factory__', factory)\n\n    default_class: DefaultClassType = None\n    default_hash: DefaultHashType = None\n\n    if target is not None:\n        object.__setattr__(self, '__proxy_target__', target)\n        if cache_defaults:\n            default_class = target.__class__\n            try:\n                default_hash = hash(target)\n            except TypeError as e:\n                default_hash = e\n\n    object.__setattr__(self, '__proxy_default_class__', default_class)\n    object.__setattr__(self, '__proxy_default_hash__', default_hash)\n</code></pre>"},{"location":"api/proxy/#proxystore.proxy.ProxyLocker","title":"ProxyLocker","text":"<pre><code>ProxyLocker(proxy: Proxy[T])\n</code></pre> <p>             Bases: <code>Generic[T]</code></p> <p>Proxy locker that prevents resolution of wrapped proxies.</p> <p>The class prevents unintended access to a wrapped proxy to ensure a proxy is not resolved. The wrapped proxy can be retrieved with <code>proxy = ProxyLocker(proxy).unlock()</code>.</p> <p>Parameters:</p> <ul> <li> <code>proxy</code>             (<code>Proxy[T]</code>)         \u2013          <p>Proxy to lock.</p> </li> </ul> Source code in <code>proxystore/proxy/__init__.py</code> <pre><code>def __init__(self, proxy: Proxy[T]) -&gt; None:\n    self._proxy = proxy\n</code></pre>"},{"location":"api/proxy/#proxystore.proxy.ProxyLocker.unlock","title":"unlock()","text":"<pre><code>unlock() -&gt; Proxy[T]\n</code></pre> <p>Retrieve the locked proxy.</p> <p>Returns:</p> <ul> <li> <code>Proxy[T]</code>         \u2013          <p>Proxy object.</p> </li> </ul> Source code in <code>proxystore/proxy/__init__.py</code> <pre><code>def unlock(self) -&gt; Proxy[T]:\n    \"\"\"Retrieve the locked proxy.\n\n    Returns:\n        Proxy object.\n    \"\"\"\n    return super().__getattribute__('_proxy')\n</code></pre>"},{"location":"api/proxy/#proxystore.proxy.get_factory","title":"get_factory()","text":"<pre><code>get_factory(proxy: Proxy[T]) -&gt; FactoryType[T]\n</code></pre> <p>Get the factory contained in a proxy.</p> <p>Parameters:</p> <ul> <li> <code>proxy</code>             (<code>Proxy[T]</code>)         \u2013          <p>Proxy instance to get the factory from.</p> </li> </ul> <p>Returns:</p> <ul> <li> <code>FactoryType[T]</code>         \u2013          <p>The factory, a callable object which, when invoked, returns an object</p> </li> <li> <code>FactoryType[T]</code>         \u2013          <p>of type <code>T</code>.</p> </li> </ul> Source code in <code>proxystore/proxy/__init__.py</code> <pre><code>def get_factory(proxy: Proxy[T]) -&gt; FactoryType[T]:\n    \"\"\"Get the factory contained in a proxy.\n\n    Args:\n        proxy: Proxy instance to get the factory from.\n\n    Returns:\n        The factory, a callable object which, when invoked, returns an object\n        of type `T`.\n    \"\"\"\n    return proxy.__proxy_factory__\n</code></pre>"},{"location":"api/proxy/#proxystore.proxy.extract","title":"extract()","text":"<pre><code>extract(proxy: Proxy[T]) -&gt; T\n</code></pre> <p>Return object wrapped by proxy.</p> <p>If the proxy has not been resolved yet, this will force the proxy to be resolved prior.</p> <p>Parameters:</p> <ul> <li> <code>proxy</code>             (<code>Proxy[T]</code>)         \u2013          <p>Proxy instance to extract from.</p> </li> </ul> <p>Returns:</p> <ul> <li> <code>T</code>         \u2013          <p>Object wrapped by proxy.</p> </li> </ul> Source code in <code>proxystore/proxy/__init__.py</code> <pre><code>def extract(proxy: Proxy[T]) -&gt; T:\n    \"\"\"Return object wrapped by proxy.\n\n    If the proxy has not been resolved yet, this will force\n    the proxy to be resolved prior.\n\n    Args:\n        proxy: Proxy instance to extract from.\n\n    Returns:\n        Object wrapped by proxy.\n    \"\"\"\n    return proxy.__proxy_wrapped__\n</code></pre>"},{"location":"api/proxy/#proxystore.proxy.is_resolved","title":"is_resolved()","text":"<pre><code>is_resolved(proxy: Proxy[T]) -&gt; bool\n</code></pre> <p>Check if a proxy is resolved.</p> <p>Parameters:</p> <ul> <li> <code>proxy</code>             (<code>Proxy[T]</code>)         \u2013          <p>Proxy instance to check.</p> </li> </ul> <p>Returns:</p> <ul> <li> <code>bool</code>         \u2013          <p><code>True</code> if <code>proxy</code> is resolved (i.e., the <code>factory</code> has been called)         and <code>False</code> otherwise.</p> </li> </ul> Source code in <code>proxystore/proxy/__init__.py</code> <pre><code>def is_resolved(proxy: Proxy[T]) -&gt; bool:\n    \"\"\"Check if a proxy is resolved.\n\n    Args:\n        proxy: Proxy instance to check.\n\n    Returns:\n        `True` if `proxy` is resolved (i.e., the `factory` has been called) \\\n        and `False` otherwise.\n    \"\"\"\n    return proxy.__proxy_resolved__\n</code></pre>"},{"location":"api/proxy/#proxystore.proxy.resolve","title":"resolve()","text":"<pre><code>resolve(proxy: Proxy[T]) -&gt; None\n</code></pre> <p>Force a proxy to resolve itself.</p> <p>Parameters:</p> <ul> <li> <code>proxy</code>             (<code>Proxy[T]</code>)         \u2013          <p>Proxy instance to force resolve.</p> </li> </ul> Source code in <code>proxystore/proxy/__init__.py</code> <pre><code>def resolve(proxy: Proxy[T]) -&gt; None:\n    \"\"\"Force a proxy to resolve itself.\n\n    Args:\n        proxy: Proxy instance to force resolve.\n    \"\"\"\n    proxy.__proxy_wrapped__  # noqa: B018\n</code></pre>"},{"location":"api/store/","title":"proxystore.store","text":"<code>proxystore/store/__init__.py</code> <p>The ProxyStore <code>Store</code> interface.</p>"},{"location":"api/store/#proxystore.store.Store","title":"Store","text":"<pre><code>Store(\n    name: str,\n    connector: ConnectorT,\n    *,\n    serializer: SerializerT | None = None,\n    deserializer: DeserializerT | None = None,\n    cache_size: int = 16,\n    metrics: bool = False,\n    populate_target: bool = True,\n    register: bool = False\n)\n</code></pre> <p>             Bases: <code>Generic[ConnectorT]</code></p> <p>Key-value store interface for proxies.</p> Tip <p>A <code>Store</code> instance can be used as a context manager which will automatically call <code>close()</code> on exit.</p> <pre><code>with Store('my-store', connector=...) as store:\n    key = store.put('value')\n    store.get(key)\n</code></pre> Warning <p>The default value of <code>populate_target=True</code> can cause unexpected behavior when providing custom serializer/deserializers because neither the serializer nor deserializer will be applied to the target object being cached in the resulting <code>Proxy</code>.</p> <pre><code>import pickle\nfrom proxystore.store import Store\nfrom proxystore.connectors.local import LocalConnector\n\nwith Store('example', LocalConnector(), register=True) as store:\n    data = [1, 2, 3]\n    data_bytes = pickle.dumps(data)\n\n    data_proxy = store.proxy(\n        data_bytes,\n        serializer=lambda s: s,\n        deserializer=pickle.loads,\n        populate_target=True,\n    )\n\n    print(data_proxy)\n    # b'\\x80\\x04\\x95\\x0b\\x00\\x00\\x00\\x00\\x00\\x00\\x00]\\x94(K\\x01K\\x02K\\x03e.'\n</code></pre> <p>In this example, the serialized <code>data_bytes</code> was populated as the target object in the resulting proxy so the proxy looks like a proxy of bytes rather than the intended list of integers. To fix this, set <code>populate_target=False</code> so the custom deserializer is correctly applied to <code>data_bytes</code> when the proxy is resolved.</p> <p>Parameters:</p> <ul> <li> <code>name</code>             (<code>str</code>)         \u2013          <p>Name of the store instance.</p> </li> <li> <code>connector</code>             (<code>ConnectorT</code>)         \u2013          <p>Connector instance to use for object storage.</p> </li> <li> <code>serializer</code>             (<code>SerializerT | None</code>, default:                 <code>None</code> )         \u2013          <p>Optional callable which serializes the object. If <code>None</code>, the default serializer (<code>serialize()</code>) will be used.</p> </li> <li> <code>deserializer</code>             (<code>DeserializerT | None</code>, default:                 <code>None</code> )         \u2013          <p>Optional callable used by the factory to deserialize the byte string. If <code>None</code>, the default deserializer (<code>deserialize()</code>) will be used.</p> </li> <li> <code>cache_size</code>             (<code>int</code>, default:                 <code>16</code> )         \u2013          <p>Size of LRU cache (in # of objects). If 0, the cache is disabled. The cache is local to the Python process.</p> </li> <li> <code>metrics</code>             (<code>bool</code>, default:                 <code>False</code> )         \u2013          <p>Enable recording operation metrics.</p> </li> <li> <code>populate_target</code>             (<code>bool</code>, default:                 <code>True</code> )         \u2013          <p>Set the default value of <code>populate_target</code> for proxy methods of the store.</p> </li> <li> <code>register</code>             (<code>bool</code>, default:                 <code>False</code> )         \u2013          <p>Register the store instance after initialization.</p> </li> </ul> <p>Raises:</p> <ul> <li> <code>ValueError</code>           \u2013          <p>If <code>cache_size</code> is less than zero.</p> </li> <li> <code>StoreExistsError</code>           \u2013          <p>If <code>register=True</code> and a store with <code>name</code> already exists.</p> </li> </ul> Source code in <code>proxystore/store/base.py</code> <pre><code>def __init__(\n    self,\n    name: str,\n    connector: ConnectorT,\n    *,\n    serializer: SerializerT | None = None,\n    deserializer: DeserializerT | None = None,\n    cache_size: int = 16,\n    metrics: bool = False,\n    populate_target: bool = True,\n    register: bool = False,\n) -&gt; None:\n    if cache_size &lt; 0:\n        raise ValueError(\n            f'Cache size cannot be negative. Got {cache_size}.',\n        )\n\n    self.connector = connector\n    self.cache: LRUCache[ConnectorKeyT, Any] = LRUCache(cache_size)\n    self._name = name\n    self._metrics = StoreMetrics() if metrics else None\n    self._cache_size = cache_size\n    self._serializer = serializer\n    self._deserializer = deserializer\n    self._populate_target = populate_target\n    self._register = register\n\n    if self._register:\n        try:\n            proxystore.store.register_store(self)\n        except StoreExistsError as e:\n            if sys.version_info &gt;= (3, 11):  # pragma: &gt;=3.11 cover\n                e.add_note(\n                    'Consider using get_store(name) rather than '\n                    'initializing a new instance with register=True.',\n                )\n            else:  # pragma: &lt;3.11 cover\n                pass\n            raise\n\n    logger.info(f'Initialized {self}')\n</code></pre>"},{"location":"api/store/#proxystore.store.Store.name","title":"name  <code>property</code>","text":"<pre><code>name: str\n</code></pre> <p>Name of this <code>Store</code> instance.</p>"},{"location":"api/store/#proxystore.store.Store.metrics","title":"metrics  <code>property</code>","text":"<pre><code>metrics: StoreMetrics | None\n</code></pre> <p>Optional metrics for this instance.</p>"},{"location":"api/store/#proxystore.store.Store.serializer","title":"serializer  <code>property</code>","text":"<pre><code>serializer: SerializerT\n</code></pre> <p>Serializer for this instance.</p>"},{"location":"api/store/#proxystore.store.Store.deserializer","title":"deserializer  <code>property</code>","text":"<pre><code>deserializer: DeserializerT\n</code></pre> <p>Deserializer for this instance.</p>"},{"location":"api/store/#proxystore.store.Store.close","title":"close()","text":"<pre><code>close(*args: Any, **kwargs: Any) -&gt; None\n</code></pre> <p>Close the connector associated with the store.</p> <p>This will (1) close the connector and (2) unregister the store if <code>register=True</code> was set during initialization.</p> Warning <p>This method should only be called at the end of the program when the store will no longer be used, for example once all proxies have been resolved.</p> <p>Parameters:</p> <ul> <li> <code>args</code>             (<code>Any</code>, default:                 <code>()</code> )         \u2013          <p>Positional arguments to pass to <code>Connector.close()</code>.</p> </li> <li> <code>kwargs</code>             (<code>Any</code>, default:                 <code>{}</code> )         \u2013          <p>Keyword arguments to pass to <code>Connector.close()</code>.</p> </li> </ul> Source code in <code>proxystore/store/base.py</code> <pre><code>def close(self, *args: Any, **kwargs: Any) -&gt; None:\n    \"\"\"Close the connector associated with the store.\n\n    This will (1) close the connector and (2) unregister the store if\n    `register=True` was set during initialization.\n\n    Warning:\n        This method should only be called at the end of the program\n        when the store will no longer be used, for example once all\n        proxies have been resolved.\n\n    Args:\n        args: Positional arguments to pass to\n            [`Connector.close()`][proxystore.connectors.protocols.Connector.close].\n        kwargs: Keyword arguments to pass to\n            [`Connector.close()`][proxystore.connectors.protocols.Connector.close].\n    \"\"\"\n    if self._register:\n        proxystore.store.unregister_store(self.name)\n    self.connector.close(*args, **kwargs)\n</code></pre>"},{"location":"api/store/#proxystore.store.Store.config","title":"config()","text":"<pre><code>config() -&gt; StoreConfig\n</code></pre> <p>Get the store configuration.</p> Example <pre><code>&gt;&gt;&gt; store = Store(...)\n&gt;&gt;&gt; config = store.config()\n&gt;&gt;&gt; store = Store.from_config(config)\n</code></pre> <p>Returns:</p> <ul> <li> <code>StoreConfig</code>         \u2013          <p>Store configuration.</p> </li> </ul> Source code in <code>proxystore/store/base.py</code> <pre><code>def config(self) -&gt; StoreConfig:\n    \"\"\"Get the store configuration.\n\n    Example:\n        ```python\n        &gt;&gt;&gt; store = Store(...)\n        &gt;&gt;&gt; config = store.config()\n        &gt;&gt;&gt; store = Store.from_config(config)\n        ```\n\n    Returns:\n        Store configuration.\n    \"\"\"\n    return StoreConfig(\n        name=self.name,\n        connector=ConnectorConfig(\n            kind=get_object_path(type(self.connector)),\n            options=self.connector.config(),\n        ),\n        serializer=self._serializer,\n        deserializer=self._deserializer,\n        cache_size=self._cache_size,\n        metrics=self.metrics is not None,\n        populate_target=self._populate_target,\n        auto_register=self._register,\n    )\n</code></pre>"},{"location":"api/store/#proxystore.store.Store.from_config","title":"from_config()  <code>classmethod</code>","text":"<pre><code>from_config(config: StoreConfig) -&gt; Store[Any]\n</code></pre> <p>Create a new store instance from a configuration.</p> <p>Parameters:</p> <ul> <li> <code>config</code>             (<code>StoreConfig</code>)         \u2013          <p>Configuration returned by <code>.config()</code>.</p> </li> </ul> <p>Returns:</p> <ul> <li> <code>Store[Any]</code>         \u2013          <p>Store instance.</p> </li> </ul> Source code in <code>proxystore/store/base.py</code> <pre><code>@classmethod\ndef from_config(cls, config: StoreConfig) -&gt; Store[Any]:\n    \"\"\"Create a new store instance from a configuration.\n\n    Args:\n        config: Configuration returned by `#!python .config()`.\n\n    Returns:\n        Store instance.\n    \"\"\"\n    connector = cast(ConnectorT, config.connector.get_connector())\n    return cls(\n        name=config.name,\n        connector=connector,\n        serializer=config.serializer,\n        deserializer=config.deserializer,\n        cache_size=config.cache_size,\n        metrics=config.metrics,\n        populate_target=config.populate_target,\n        register=config.auto_register,\n    )\n</code></pre>"},{"location":"api/store/#proxystore.store.Store.future","title":"future()","text":"<pre><code>future(\n    *,\n    evict: bool = False,\n    serializer: SerializerT | None = None,\n    deserializer: DeserializerT | None = None,\n    polling_interval: float = 1,\n    polling_backoff_factor: float = 1,\n    polling_interval_limit: float | None = None,\n    polling_timeout: float | None = None\n) -&gt; Future[T]\n</code></pre> <p>Create a future to an object.</p> Example <pre><code>from proxystore.connectors.file import FileConnector\nfrom proxystore.store import Store\nfrom proxystore.store.future import Future\n\ndef remote_foo(future: Future) -&gt; None:\n    # Computation that generates a result value needed by\n    # the remote_bar function.\n    future.set_result(...)\n\ndef remote_bar(data: Any) -&gt; None:\n    # Function uses data, which is a proxy, as normal, blocking\n    # until the remote_foo function has called set_result.\n    ...\n\nwith Store('future-example', FileConnector(...)) as store:\n    future = store.future()\n\n    # The invoke_remove function invokes a provided function\n    # on a remote process. For example, this could be a serverless\n    # function execution.\n    foo_result_future = invoke_remote(remote_foo, future)\n    bar_result_future = invoke_remote(remote_bar, future.proxy())\n\n    foo_result_future.result()\n    bar_result_future.result()\n</code></pre> Warning <p>This method only works if the <code>connector</code> is of type <code>DeferrableConnector</code>.</p> Warning <p>This method and the <code>Future.proxy()</code> are experimental features and may change in future releases.</p> <p>Parameters:</p> <ul> <li> <code>evict</code>             (<code>bool</code>, default:                 <code>False</code> )         \u2013          <p>If a proxy returned by <code>Future.proxy()</code> should evict the object once resolved.</p> </li> <li> <code>serializer</code>             (<code>SerializerT | None</code>, default:                 <code>None</code> )         \u2013          <p>Optionally override the default serializer for the store instance.</p> </li> <li> <code>deserializer</code>             (<code>DeserializerT | None</code>, default:                 <code>None</code> )         \u2013          <p>Optionally override the default deserializer for the store instance.</p> </li> <li> <code>polling_interval</code>             (<code>float</code>, default:                 <code>1</code> )         \u2013          <p>Initial seconds to sleep between polling the store for the object.</p> </li> <li> <code>polling_backoff_factor</code>             (<code>float</code>, default:                 <code>1</code> )         \u2013          <p>Multiplicative factor applied to the polling_interval applied after each unsuccessful poll.</p> </li> <li> <code>polling_interval_limit</code>             (<code>float | None</code>, default:                 <code>None</code> )         \u2013          <p>Maximum polling interval allowed. Prevents the backoff factor from increasing the current polling interval to unreasonable values.</p> </li> <li> <code>polling_timeout</code>             (<code>float | None</code>, default:                 <code>None</code> )         \u2013          <p>Optional maximum number of seconds to poll for. If the timeout is reached an error is raised.</p> </li> </ul> <p>Returns:</p> <ul> <li> <code>Future[T]</code>         \u2013          <p>Future which can be used to get the result object at a later time             or create a proxy which will resolve to the result of the future.</p> </li> </ul> <p>Raises:</p> <ul> <li> <code>NotImplementedError</code>           \u2013          <p>If the <code>connector</code> is not of type <code>DeferrableConnector</code>.</p> </li> </ul> Source code in <code>proxystore/store/base.py</code> <pre><code>def future(\n    self,\n    *,\n    evict: bool = False,\n    serializer: SerializerT | None = None,\n    deserializer: DeserializerT | None = None,\n    polling_interval: float = 1,\n    polling_backoff_factor: float = 1,\n    polling_interval_limit: float | None = None,\n    polling_timeout: float | None = None,\n) -&gt; Future[T]:\n    \"\"\"Create a future to an object.\n\n    Example:\n        ```python\n        from proxystore.connectors.file import FileConnector\n        from proxystore.store import Store\n        from proxystore.store.future import Future\n\n        def remote_foo(future: Future) -&gt; None:\n            # Computation that generates a result value needed by\n            # the remote_bar function.\n            future.set_result(...)\n\n        def remote_bar(data: Any) -&gt; None:\n            # Function uses data, which is a proxy, as normal, blocking\n            # until the remote_foo function has called set_result.\n            ...\n\n        with Store('future-example', FileConnector(...)) as store:\n            future = store.future()\n\n            # The invoke_remove function invokes a provided function\n            # on a remote process. For example, this could be a serverless\n            # function execution.\n            foo_result_future = invoke_remote(remote_foo, future)\n            bar_result_future = invoke_remote(remote_bar, future.proxy())\n\n            foo_result_future.result()\n            bar_result_future.result()\n        ```\n\n    Warning:\n        This method only works if the `connector` is of type\n        [`DeferrableConnector`][proxystore.connectors.protocols.DeferrableConnector].\n\n    Warning:\n        This method and the\n        [`Future.proxy()`][proxystore.store.future.Future.proxy]\n        are experimental features and may change in future releases.\n\n    Args:\n        evict: If a proxy returned by\n            [`Future.proxy()`][proxystore.store.future.Future.proxy]\n            should evict the object once resolved.\n        serializer: Optionally override the default serializer for the\n            store instance.\n        deserializer: Optionally override the default deserializer for the\n            store instance.\n        polling_interval: Initial seconds to sleep between polling the\n            store for the object.\n        polling_backoff_factor: Multiplicative factor applied to the\n            polling_interval applied after each unsuccessful poll.\n        polling_interval_limit: Maximum polling interval allowed. Prevents\n            the backoff factor from increasing the current polling interval\n            to unreasonable values.\n        polling_timeout: Optional maximum number of seconds to poll for. If\n            the timeout is reached an error is raised.\n\n    Returns:\n        Future which can be used to get the result object at a later time \\\n        or create a proxy which will resolve to the result of the future.\n\n    Raises:\n        NotImplementedError: If the `connector` is not of type\n            [`DeferrableConnector`][proxystore.connectors.protocols.DeferrableConnector].\n    \"\"\"\n    timer = Timer()\n    timer.start()\n\n    if not isinstance(self.connector, DeferrableConnector):\n        raise NotImplementedError(\n            'The provided connector is type '\n            f'{type(self.connector).__name__} which does not implement '\n            f'the {DeferrableConnector.__name__} necessary to use the '\n            f'{Future.__name__} interface.',\n        )\n\n    with Timer() as connector_timer:\n        key = self.connector.new_key()\n\n    if self.metrics is not None:\n        ctime = connector_timer.elapsed_ms\n        self.metrics.add_time('store.future.connector', key, ctime)\n\n    factory: PollingStoreFactory[ConnectorT, T] = PollingStoreFactory(\n        key,\n        store_config=self.config(),\n        deserializer=deserializer,\n        evict=evict,\n        polling_interval=polling_interval,\n        polling_backoff_factor=polling_backoff_factor,\n        polling_interval_limit=polling_interval_limit,\n        polling_timeout=polling_timeout,\n    )\n    future = Future(factory, serializer=serializer)\n\n    timer.stop()\n    if self.metrics is not None:\n        self.metrics.add_time('store.future', key, timer.elapsed_ms)\n\n    logger.debug(\n        f'Store(name=\"{self.name}\"): FUTURE {key} in '\n        f'{timer.elapsed_ms:.3f} ms',\n    )\n    return future\n</code></pre>"},{"location":"api/store/#proxystore.store.Store.evict","title":"evict()","text":"<pre><code>evict(key: ConnectorKeyT) -&gt; None\n</code></pre> <p>Evict the object associated with the key.</p> <p>Parameters:</p> <ul> <li> <code>key</code>             (<code>ConnectorKeyT</code>)         \u2013          <p>Key associated with object to evict.</p> </li> </ul> Source code in <code>proxystore/store/base.py</code> <pre><code>def evict(self, key: ConnectorKeyT) -&gt; None:\n    \"\"\"Evict the object associated with the key.\n\n    Args:\n        key: Key associated with object to evict.\n    \"\"\"\n    with Timer() as timer:\n        with Timer() as connector_timer:\n            self.connector.evict(key)\n\n        if self.metrics is not None:\n            ctime = connector_timer.elapsed_ms\n            self.metrics.add_time('store.evict.connector', key, ctime)\n\n        self.cache.evict(key)\n\n    if self.metrics is not None:\n        self.metrics.add_time('store.evict', key, timer.elapsed_ms)\n\n    logger.debug(\n        f'Store(name=\"{self.name}\"): EVICT {key} in '\n        f'{timer.elapsed_ms:.3f} ms',\n    )\n</code></pre>"},{"location":"api/store/#proxystore.store.Store.exists","title":"exists()","text":"<pre><code>exists(key: ConnectorKeyT) -&gt; bool\n</code></pre> <p>Check if an object associated with the key exists.</p> <p>Parameters:</p> <ul> <li> <code>key</code>             (<code>ConnectorKeyT</code>)         \u2013          <p>Key potentially associated with stored object.</p> </li> </ul> <p>Returns:</p> <ul> <li> <code>bool</code>         \u2013          <p>If an object associated with the key exists.</p> </li> </ul> Source code in <code>proxystore/store/base.py</code> <pre><code>def exists(self, key: ConnectorKeyT) -&gt; bool:\n    \"\"\"Check if an object associated with the key exists.\n\n    Args:\n        key: Key potentially associated with stored object.\n\n    Returns:\n        If an object associated with the key exists.\n    \"\"\"\n    with Timer() as timer:\n        res = self.cache.exists(key)\n        if not res:\n            with Timer() as connector_timer:\n                res = self.connector.exists(key)\n\n            if self.metrics is not None:\n                ctime = connector_timer.elapsed_ms\n                self.metrics.add_time('store.exists.connector', key, ctime)\n\n    if self.metrics is not None:\n        self.metrics.add_time('store.exists', key, timer.elapsed_ms)\n\n    logger.debug(\n        f'Store(name=\"{self.name}\"): EXISTS {key} in '\n        f'{timer.elapsed_ms:.3f} ms',\n    )\n    return res\n</code></pre>"},{"location":"api/store/#proxystore.store.Store.get","title":"get()","text":"<pre><code>get(\n    key: ConnectorKeyT,\n    *,\n    deserializer: DeserializerT | None = None,\n    default: object | None = None\n) -&gt; Any | None\n</code></pre> <p>Get the object associated with the key.</p> <p>Parameters:</p> <ul> <li> <code>key</code>             (<code>ConnectorKeyT</code>)         \u2013          <p>Key associated with the object to retrieve.</p> </li> <li> <code>deserializer</code>             (<code>DeserializerT | None</code>, default:                 <code>None</code> )         \u2013          <p>Optionally override the default deserializer for the store instance.</p> </li> <li> <code>default</code>             (<code>object | None</code>, default:                 <code>None</code> )         \u2013          <p>An optional value to be returned if an object associated with the key does not exist.</p> </li> </ul> <p>Returns:</p> <ul> <li> <code>Any | None</code>         \u2013          <p>Object or <code>None</code> if the object does not exist.</p> </li> </ul> <p>Raises:</p> <ul> <li> <code>SerializationError</code>           \u2013          <p>If an exception is caught when deserializing the object associated with the key.</p> </li> </ul> Source code in <code>proxystore/store/base.py</code> <pre><code>def get(\n    self,\n    key: ConnectorKeyT,\n    *,\n    deserializer: DeserializerT | None = None,\n    default: object | None = None,\n) -&gt; Any | None:\n    \"\"\"Get the object associated with the key.\n\n    Args:\n        key: Key associated with the object to retrieve.\n        deserializer: Optionally override the default deserializer for the\n            store instance.\n        default: An optional value to be returned if an object\n            associated with the key does not exist.\n\n    Returns:\n        Object or `None` if the object does not exist.\n\n    Raises:\n        SerializationError: If an exception is caught when deserializing\n            the object associated with the key.\n    \"\"\"\n    timer = Timer()\n    timer.start()\n\n    if self.is_cached(key):\n        value = self.cache.get(key)\n\n        timer.stop()\n        if self.metrics is not None:\n            self.metrics.add_counter('store.get.cache_hits', key, 1)\n            self.metrics.add_time('store.get', key, timer.elapsed_ms)\n\n        logger.debug(\n            f'Store(name=\"{self.name}\"): GET {key} in '\n            f'{timer.elapsed_ms:.3f} ms (cached=True)',\n        )\n        return value\n\n    with Timer() as connector_timer:\n        value = self.connector.get(key)\n\n    if self.metrics is not None:\n        ctime = connector_timer.elapsed_ms\n        self.metrics.add_counter('store.get.cache_misses', key, 1)\n        self.metrics.add_time('store.get.connector', key, ctime)\n\n    if value is not None:\n        with Timer() as deserializer_timer:\n            deserializer = (\n                deserializer\n                if deserializer is not None\n                else self.deserializer\n            )\n            try:\n                result = deserializer(value)\n            except Exception as e:\n                name = get_object_path(deserializer)\n                raise SerializationError(\n                    'Failed to deserialize object '\n                    f'(deserializer={name}, key={key}).',\n                ) from e\n\n        if self.metrics is not None:\n            dtime = deserializer_timer.elapsed_ms\n            obj_size = len(value)\n            self.metrics.add_time('store.get.deserialize', key, dtime)\n            self.metrics.add_attribute(\n                'store.get.object_size',\n                key,\n                obj_size,\n            )\n\n        self.cache.set(key, result)\n    else:\n        result = default\n\n    timer.stop()\n    if self.metrics is not None:\n        self.metrics.add_time('store.get', key, timer.elapsed_ms)\n\n    logger.debug(\n        f'Store(name=\"{self.name}\"): GET {key} in '\n        f'{timer.elapsed_ms:.3f} ms (cached=False)',\n    )\n    return result\n</code></pre>"},{"location":"api/store/#proxystore.store.Store.is_cached","title":"is_cached()","text":"<pre><code>is_cached(key: ConnectorKeyT) -&gt; bool\n</code></pre> <p>Check if an object associated with the key is cached locally.</p> <p>Parameters:</p> <ul> <li> <code>key</code>             (<code>ConnectorKeyT</code>)         \u2013          <p>Key potentially associated with stored object.</p> </li> </ul> <p>Returns:</p> <ul> <li> <code>bool</code>         \u2013          <p>If the object is cached.</p> </li> </ul> Source code in <code>proxystore/store/base.py</code> <pre><code>def is_cached(self, key: ConnectorKeyT) -&gt; bool:\n    \"\"\"Check if an object associated with the key is cached locally.\n\n    Args:\n        key: Key potentially associated with stored object.\n\n    Returns:\n        If the object is cached.\n    \"\"\"\n    return self.cache.exists(key)\n</code></pre>"},{"location":"api/store/#proxystore.store.Store.proxy","title":"proxy()","text":"<pre><code>proxy(\n    obj: T | NonProxiableT,\n    *,\n    evict: bool = False,\n    lifetime: Lifetime | None = None,\n    serializer: SerializerT | None = None,\n    deserializer: DeserializerT | None = None,\n    populate_target: bool | None = None,\n    skip_nonproxiable: bool = False,\n    **kwargs: Any\n) -&gt; Proxy[T] | NonProxiableT\n</code></pre> <p>Create a proxy that will resolve to an object in the store.</p> <p>Parameters:</p> <ul> <li> <code>obj</code>             (<code>T | NonProxiableT</code>)         \u2013          <p>The object to place in store and return a proxy for.</p> </li> <li> <code>evict</code>             (<code>bool</code>, default:                 <code>False</code> )         \u2013          <p>If the proxy should evict the object once resolved. Mutually exclusive with the <code>lifetime</code> parameter.</p> </li> <li> <code>lifetime</code>             (<code>Lifetime | None</code>, default:                 <code>None</code> )         \u2013          <p>Attach the proxy to this lifetime. The object associated with the proxy will be evicted when the lifetime ends. Mutually exclusive with the <code>evict</code> parameter.</p> </li> <li> <code>serializer</code>             (<code>SerializerT | None</code>, default:                 <code>None</code> )         \u2013          <p>Optionally override the default serializer for the store instance.</p> </li> <li> <code>deserializer</code>             (<code>DeserializerT | None</code>, default:                 <code>None</code> )         \u2013          <p>Optionally override the default deserializer for the store instance.</p> </li> <li> <code>populate_target</code>             (<code>bool | None</code>, default:                 <code>None</code> )         \u2013          <p>Pass <code>cache_defaults=True</code> and <code>target=obj</code> to the <code>Proxy</code> constructor. I.e., return a proxy that (1) is already resolved, (2) can be used in <code>isinstance</code> checks without resolving, and (3) is hashable without resolving if <code>obj</code> is a hashable type. This is <code>False</code> by default because the returned proxy will hold a reference to <code>obj</code> which will prevent garbage collecting <code>obj</code>. If <code>None</code>, defaults to the store-wide setting.</p> </li> <li> <code>skip_nonproxiable</code>             (<code>bool</code>, default:                 <code>False</code> )         \u2013          <p>Return non-proxiable types (e.g., built-in constants like <code>bool</code> or <code>None</code>) rather than raising a <code>NonProxiableTypeError</code>.</p> </li> <li> <code>kwargs</code>             (<code>Any</code>, default:                 <code>{}</code> )         \u2013          <p>Additional keyword arguments to pass to <code>Connector.put()</code>.</p> </li> </ul> <p>Returns:</p> <ul> <li> <code>Proxy[T] | NonProxiableT</code>         \u2013          <p>A proxy of the object unless <code>obj</code> is a non-proxiable type             <code>skip_nonproxiable is True</code> in which case <code>obj</code> is             returned directly.</p> </li> </ul> <p>Raises:</p> <ul> <li> <code>NonProxiableTypeError</code>           \u2013          <p>If <code>obj</code> is a non-proxiable type. This behavior can be overridden by setting <code>skip_nonproxiable=True</code>.</p> </li> <li> <code>ValueError</code>           \u2013          <p>If <code>evict</code> is <code>True</code> and <code>lifetime</code> is not <code>None</code> because these parameters are mutually exclusive.</p> </li> </ul> Source code in <code>proxystore/store/base.py</code> <pre><code>def proxy(\n    self,\n    obj: T | NonProxiableT,\n    *,\n    evict: bool = False,\n    lifetime: Lifetime | None = None,\n    serializer: SerializerT | None = None,\n    deserializer: DeserializerT | None = None,\n    populate_target: bool | None = None,\n    skip_nonproxiable: bool = False,\n    **kwargs: Any,\n) -&gt; Proxy[T] | NonProxiableT:\n    \"\"\"Create a proxy that will resolve to an object in the store.\n\n    Args:\n        obj: The object to place in store and return a proxy for.\n        evict: If the proxy should evict the object once resolved.\n            Mutually exclusive with the `lifetime` parameter.\n        lifetime: Attach the proxy to this lifetime. The object associated\n            with the proxy will be evicted when the lifetime ends.\n            Mutually exclusive with the `evict` parameter.\n        serializer: Optionally override the default serializer for the\n            store instance.\n        deserializer: Optionally override the default deserializer for the\n            store instance.\n        populate_target: Pass `cache_defaults=True` and `target=obj` to\n            the [`Proxy`][proxystore.proxy.Proxy] constructor. I.e.,\n            return a proxy that (1) is already resolved, (2) can be used\n            in [`isinstance`][isinstance] checks without resolving, and (3)\n            is hashable without resolving if `obj` is a hashable type.\n            This is `False` by default because the returned proxy will\n            hold a reference to `obj` which will prevent garbage\n            collecting `obj`. If `None`, defaults to the store-wide\n            setting.\n        skip_nonproxiable: Return non-proxiable types (e.g., built-in\n            constants like `bool` or `None`) rather than raising a\n            [`NonProxiableTypeError`][proxystore.store.exceptions.NonProxiableTypeError].\n        kwargs: Additional keyword arguments to pass to\n            [`Connector.put()`][proxystore.connectors.protocols.Connector.put].\n\n    Returns:\n        A proxy of the object unless `obj` is a non-proxiable type \\\n        `#!python skip_nonproxiable is True` in which case `obj` is \\\n        returned directly.\n\n    Raises:\n        NonProxiableTypeError: If `obj` is a non-proxiable type. This\n            behavior can be overridden by setting\n            `#!python skip_nonproxiable=True`.\n        ValueError: If `evict` is `True` and `lifetime` is not `None`\n            because these parameters are mutually exclusive.\n    \"\"\"\n    if evict and lifetime is not None:\n        raise ValueError(\n            'The evict and lifetime parameters are mutually exclusive. '\n            'Only set one of evict or lifetime.',\n        )\n\n    if isinstance(obj, _NON_PROXIABLE_TYPES):\n        if skip_nonproxiable:\n            # MyPy raises the following error which is not correct:\n            #     Incompatible return value type (got \"Optional[bool]\",\n            #     expected \"Optional[Proxy[T]]\")  [return-value]\n            return obj  # type: ignore[return-value]\n        else:\n            raise NonProxiableTypeError(\n                f'Object of {type(obj)} is not proxiable.',\n            )\n\n    with Timer() as timer:\n        key = self.put(obj, serializer=serializer, **kwargs)\n        factory: StoreFactory[ConnectorT, T] = StoreFactory(\n            key,\n            store_config=self.config(),\n            deserializer=deserializer,\n            evict=evict,\n        )\n        populate_target = (\n            self._populate_target\n            if populate_target is None\n            else populate_target\n        )\n        if populate_target:\n            # If obj were None, we would have escaped early when\n            # checking _NON_PROXIABLE_TYPES.\n            assert obj is not None\n            proxy = Proxy(factory, cache_defaults=True, target=obj)\n        else:\n            proxy = Proxy(factory)\n\n        if lifetime is not None:\n            lifetime.add_proxy(proxy)\n\n    if self.metrics is not None:\n        self.metrics.add_time('store.proxy', key, timer.elapsed_ms)\n\n    logger.debug(\n        f'Store(name=\"{self.name}\"): PROXY {key} in '\n        f'{timer.elapsed_ms:.3f} ms',\n    )\n    return proxy\n</code></pre>"},{"location":"api/store/#proxystore.store.Store.proxy_batch","title":"proxy_batch()","text":"<pre><code>proxy_batch(\n    objs: Sequence[T | NonProxiableT],\n    *,\n    evict: bool = False,\n    lifetime: Lifetime | None = None,\n    serializer: SerializerT | None = None,\n    deserializer: DeserializerT | None = None,\n    populate_target: bool | None = None,\n    skip_nonproxiable: bool = False,\n    **kwargs: Any\n) -&gt; list[Proxy[T] | NonProxiableT]\n</code></pre> <p>Create proxies that will resolve to an object in the store.</p> <p>Parameters:</p> <ul> <li> <code>objs</code>             (<code>Sequence[T | NonProxiableT]</code>)         \u2013          <p>The objects to place in store and return a proxies for.</p> </li> <li> <code>evict</code>             (<code>bool</code>, default:                 <code>False</code> )         \u2013          <p>If a proxy should evict its object once resolved. Mutually exclusive with the <code>lifetime</code> parameter.</p> </li> <li> <code>lifetime</code>             (<code>Lifetime | None</code>, default:                 <code>None</code> )         \u2013          <p>Attach the proxies to this lifetime. The objects associated with each proxy will be evicted when the lifetime ends. Mutually exclusive with the <code>evict</code> parameter.</p> </li> <li> <code>serializer</code>             (<code>SerializerT | None</code>, default:                 <code>None</code> )         \u2013          <p>Optionally override the default serializer for the store instance.</p> </li> <li> <code>deserializer</code>             (<code>DeserializerT | None</code>, default:                 <code>None</code> )         \u2013          <p>Optionally override the default deserializer for the store instance.</p> </li> <li> <code>populate_target</code>             (<code>bool | None</code>, default:                 <code>None</code> )         \u2013          <p>Pass <code>cache_defaults=True</code> and <code>target=obj</code> to the <code>Proxy</code> constructor. I.e., return a proxy that (1) is already resolved, (2) can be used in <code>isinstance</code> checks without resolving, and (3) is hashable without resolving if <code>obj</code> is a hashable type. If <code>None</code>, defaults to the store-wide setting.</p> </li> <li> <code>skip_nonproxiable</code>             (<code>bool</code>, default:                 <code>False</code> )         \u2013          <p>Return non-proxiable types (e.g., built-in constants like <code>bool</code> or <code>None</code>) rather than raising a <code>NonProxiableTypeError</code>.</p> </li> <li> <code>kwargs</code>             (<code>Any</code>, default:                 <code>{}</code> )         \u2013          <p>Additional keyword arguments to pass to <code>Connector.put_batch()</code>.</p> </li> </ul> <p>Returns:</p> <ul> <li> <code>list[Proxy[T] | NonProxiableT]</code>         \u2013          <p>A list of proxies of each object or the object itself if said             object is not proxiable and <code>skip_nonproxiable is True</code>.</p> </li> </ul> <p>Raises:</p> <ul> <li> <code>NonProxiableTypeError</code>           \u2013          <p>If <code>obj</code> is a non-proxiable type. This behavior can be overridden by setting <code>skip_nonproxiable=True</code>.</p> </li> <li> <code>ValueError</code>           \u2013          <p>If <code>evict</code> is <code>True</code> and <code>lifetime</code> is not <code>None</code> because these parameters are mutually exclusive.</p> </li> </ul> Source code in <code>proxystore/store/base.py</code> <pre><code>def proxy_batch(  # type: ignore[misc]\n    self,\n    objs: Sequence[T | NonProxiableT],\n    *,\n    evict: bool = False,\n    lifetime: Lifetime | None = None,\n    serializer: SerializerT | None = None,\n    deserializer: DeserializerT | None = None,\n    populate_target: bool | None = None,\n    skip_nonproxiable: bool = False,\n    **kwargs: Any,\n) -&gt; list[Proxy[T] | NonProxiableT]:\n    \"\"\"Create proxies that will resolve to an object in the store.\n\n    Args:\n        objs: The objects to place in store and return a proxies for.\n        evict: If a proxy should evict its object once resolved.\n            Mutually exclusive with the `lifetime` parameter.\n        lifetime: Attach the proxies to this lifetime. The objects\n            associated with each proxy will be evicted when the lifetime\n            ends. Mutually exclusive with the `evict` parameter.\n        serializer: Optionally override the default serializer for the\n            store instance.\n        deserializer: Optionally override the default deserializer for the\n            store instance.\n        populate_target: Pass `cache_defaults=True` and `target=obj` to\n            the [`Proxy`][proxystore.proxy.Proxy] constructor. I.e.,\n            return a proxy that (1) is already resolved, (2) can be used\n            in [`isinstance`][isinstance] checks without resolving, and (3)\n            is hashable without resolving if `obj` is a hashable type.\n            If `None`, defaults to the store-wide setting.\n        skip_nonproxiable: Return non-proxiable types (e.g., built-in\n            constants like `bool` or `None`) rather than raising a\n            [`NonProxiableTypeError`][proxystore.store.exceptions.NonProxiableTypeError].\n        kwargs: Additional keyword arguments to pass to\n            [`Connector.put_batch()`][proxystore.connectors.protocols.Connector.put_batch].\n\n    Returns:\n        A list of proxies of each object or the object itself if said \\\n        object is not proxiable and `#!python skip_nonproxiable is True`.\n\n    Raises:\n        NonProxiableTypeError: If `obj` is a non-proxiable type. This\n            behavior can be overridden by setting\n            `#!python skip_nonproxiable=True`.\n        ValueError: If `evict` is `True` and `lifetime` is not `None`\n            because these parameters are mutually exclusive.\n    \"\"\"\n    if evict and lifetime is not None:\n        raise ValueError(\n            'The evict and lifetime parameters are mutually exclusive. '\n            'Only set one of evict or lifetime.',\n        )\n\n    with Timer() as timer:\n        # Find if there are non-proxiable types and if that's okay\n        non_proxiable: list[tuple[int, Any]] = []\n        for i, obj in enumerate(objs):\n            if isinstance(obj, _NON_PROXIABLE_TYPES):\n                non_proxiable.append((i, obj))\n\n        if len(non_proxiable) &gt; 0 and not skip_nonproxiable:\n            raise NonProxiableTypeError(\n                f'Input sequence contains {len(non_proxiable)} '\n                'objects that are not proxiable.',\n            )\n\n        # Pop non-proxiable types so we can batch proxy the proxiable ones\n        non_proxiable_indicies = [i for i, _ in non_proxiable]\n        proxiable_objs = [\n            obj\n            for i, obj in enumerate(objs)\n            if i not in non_proxiable_indicies\n        ]\n\n        keys = self.put_batch(\n            proxiable_objs,\n            serializer=serializer,\n            **kwargs,\n        )\n        factories: list[StoreFactory[ConnectorT, T]] = [\n            StoreFactory(\n                key,\n                store_config=self.config(),\n                evict=evict,\n                deserializer=deserializer,\n            )\n            for key in keys\n        ]\n\n        populate_target = (\n            self._populate_target\n            if populate_target is None\n            else populate_target\n        )\n\n        proxies: list[Proxy[T]] = []\n        for factory, obj in zip(factories, proxiable_objs):\n            if populate_target:\n                proxy = Proxy(factory, cache_defaults=True, target=obj)\n            else:\n                proxy = Proxy(factory)\n            proxies.append(proxy)\n\n        if lifetime is not None:\n            lifetime.add_proxy(*proxies)\n\n        # Put non-proxiable objects back in their original positions.\n        # The indices of non_proxiable must still be sorted\n        for original_index, original_object in non_proxiable:\n            proxies.insert(original_index, original_object)\n\n    if self.metrics is not None:\n        self.metrics.add_time('store.proxy_batch', keys, timer.elapsed_ms)\n\n    logger.debug(\n        f'Store(name=\"{self.name}\"): PROXY_BATCH ({len(proxies)} items) '\n        f'in {timer.elapsed_ms:.3f} ms',\n    )\n    return cast(List[Union[Proxy[T], NonProxiableT]], proxies)\n</code></pre>"},{"location":"api/store/#proxystore.store.Store.proxy_from_key","title":"proxy_from_key()","text":"<pre><code>proxy_from_key(\n    key: ConnectorKeyT,\n    *,\n    evict: bool = False,\n    lifetime: Lifetime | None = None,\n    deserializer: DeserializerT | None = None\n) -&gt; Proxy[T]\n</code></pre> <p>Create a proxy that will resolve to an object already in the store.</p> <p>Parameters:</p> <ul> <li> <code>key</code>             (<code>ConnectorKeyT</code>)         \u2013          <p>The key associated with an object already in the store.</p> </li> <li> <code>evict</code>             (<code>bool</code>, default:                 <code>False</code> )         \u2013          <p>If the proxy should evict the object once resolved. Mutually exclusive with the <code>lifetime</code> parameter.</p> </li> <li> <code>lifetime</code>             (<code>Lifetime | None</code>, default:                 <code>None</code> )         \u2013          <p>Attach the proxy to this lifetime. The object associated with the proxy will be evicted when the lifetime ends. Mutually exclusive with the <code>evict</code> parameter.</p> </li> <li> <code>deserializer</code>             (<code>DeserializerT | None</code>, default:                 <code>None</code> )         \u2013          <p>Optionally override the default deserializer for the store instance.</p> </li> </ul> <p>Returns:</p> <ul> <li> <code>Proxy[T]</code>         \u2013          <p>A proxy of the object.</p> </li> </ul> <p>Raises:</p> <ul> <li> <code>ValueError</code>           \u2013          <p>If <code>evict</code> is <code>True</code> and <code>lifetime</code> is not <code>None</code> because these parameters are mutually exclusive.</p> </li> </ul> Source code in <code>proxystore/store/base.py</code> <pre><code>def proxy_from_key(\n    self,\n    key: ConnectorKeyT,\n    *,\n    evict: bool = False,\n    lifetime: Lifetime | None = None,\n    deserializer: DeserializerT | None = None,\n) -&gt; Proxy[T]:\n    \"\"\"Create a proxy that will resolve to an object already in the store.\n\n    Args:\n        key: The key associated with an object already in the store.\n        evict: If the proxy should evict the object once resolved.\n            Mutually exclusive with the `lifetime` parameter.\n        lifetime: Attach the proxy to this lifetime. The object associated\n            with the proxy will be evicted when the lifetime ends.\n            Mutually exclusive with the `evict` parameter.\n        deserializer: Optionally override the default deserializer for the\n            store instance.\n\n    Returns:\n        A proxy of the object.\n\n    Raises:\n        ValueError: If `evict` is `True` and `lifetime` is not `None`\n            because these parameters are mutually exclusive.\n    \"\"\"\n    if evict and lifetime is not None:\n        raise ValueError(\n            'The evict and lifetime parameters are mutually exclusive. '\n            'Only set one of evict or lifetime.',\n        )\n\n    factory: StoreFactory[ConnectorT, T] = StoreFactory(\n        key,\n        store_config=self.config(),\n        deserializer=deserializer,\n        evict=evict,\n    )\n    proxy = Proxy(factory)\n\n    logger.debug(f'Store(name=\"{self.name}\"): PROXY_FROM_KEY {key}')\n\n    if lifetime is not None:\n        lifetime.add_proxy(proxy)\n\n    return proxy\n</code></pre>"},{"location":"api/store/#proxystore.store.Store.locked_proxy","title":"locked_proxy()","text":"<pre><code>locked_proxy(\n    obj: T | NonProxiableT,\n    *,\n    evict: bool = False,\n    lifetime: Lifetime | None = None,\n    serializer: SerializerT | None = None,\n    deserializer: DeserializerT | None = None,\n    populate_target: bool | None = None,\n    skip_nonproxiable: bool = True,\n    **kwargs: Any\n) -&gt; ProxyLocker[T] | NonProxiableT\n</code></pre> <p>Proxy an object and return <code>ProxyLocker</code>.</p> <p>Parameters:</p> <ul> <li> <code>obj</code>             (<code>T | NonProxiableT</code>)         \u2013          <p>The object to place in store and return a proxy for.</p> </li> <li> <code>evict</code>             (<code>bool</code>, default:                 <code>False</code> )         \u2013          <p>If the proxy should evict the object once resolved. Mutually exclusive with the <code>lifetime</code> parameter.</p> </li> <li> <code>lifetime</code>             (<code>Lifetime | None</code>, default:                 <code>None</code> )         \u2013          <p>Attach the proxy to this lifetime. The object associated with the proxy will be evicted when the lifetime ends. Mutually exclusive with the <code>evict</code> parameter.</p> </li> <li> <code>serializer</code>             (<code>SerializerT | None</code>, default:                 <code>None</code> )         \u2013          <p>Optionally override the default serializer for the store instance.</p> </li> <li> <code>deserializer</code>             (<code>DeserializerT | None</code>, default:                 <code>None</code> )         \u2013          <p>Optionally override the default deserializer for the store instance.</p> </li> <li> <code>populate_target</code>             (<code>bool | None</code>, default:                 <code>None</code> )         \u2013          <p>Pass <code>cache_defaults=True</code> and <code>target=obj</code> to the <code>Proxy</code> constructor. I.e., return a proxy that (1) is already resolved, (2) can be used in <code>isinstance</code> checks without resolving, and (3) is hashable without resolving if <code>obj</code> is a hashable type. If <code>None</code>, defaults to the store-wide setting.</p> </li> <li> <code>skip_nonproxiable</code>             (<code>bool</code>, default:                 <code>True</code> )         \u2013          <p>Return non-proxiable types (e.g., built-in constants like <code>bool</code> or <code>None</code>) rather than raising a <code>NonProxiableTypeError</code>.</p> </li> <li> <code>kwargs</code>             (<code>Any</code>, default:                 <code>{}</code> )         \u2013          <p>Additional keyword arguments to pass to <code>Connector.put()</code>.</p> </li> </ul> <p>Returns:</p> <ul> <li> <code>ProxyLocker[T] | NonProxiableT</code>         \u2013          <p>A proxy wrapped in a             <code>ProxyLocker</code> unless <code>obj</code> is a             non-proxiable type <code>skip_nonproxiable is True</code> in which             case <code>obj</code> is returned directly.</p> </li> </ul> <p>Raises:</p> <ul> <li> <code>NonProxiableTypeError</code>           \u2013          <p>If <code>obj</code> is a non-proxiable type. This behavior can be overridden by setting <code>skip_nonproxiable=True</code>.</p> </li> <li> <code>ValueError</code>           \u2013          <p>If <code>evict</code> is <code>True</code> and <code>lifetime</code> is not <code>None</code> because these parameters are mutually exclusive.</p> </li> </ul> Source code in <code>proxystore/store/base.py</code> <pre><code>def locked_proxy(\n    self,\n    obj: T | NonProxiableT,\n    *,\n    evict: bool = False,\n    lifetime: Lifetime | None = None,\n    serializer: SerializerT | None = None,\n    deserializer: DeserializerT | None = None,\n    populate_target: bool | None = None,\n    skip_nonproxiable: bool = True,\n    **kwargs: Any,\n) -&gt; ProxyLocker[T] | NonProxiableT:\n    \"\"\"Proxy an object and return [`ProxyLocker`][proxystore.proxy.ProxyLocker].\n\n    Args:\n        obj: The object to place in store and return a proxy for.\n        evict: If the proxy should evict the object once resolved.\n            Mutually exclusive with the `lifetime` parameter.\n        lifetime: Attach the proxy to this lifetime. The object associated\n            with the proxy will be evicted when the lifetime ends.\n            Mutually exclusive with the `evict` parameter.\n        serializer: Optionally override the default serializer for the\n            store instance.\n        deserializer: Optionally override the default deserializer for the\n            store instance.\n        populate_target: Pass `cache_defaults=True` and `target=obj` to\n            the [`Proxy`][proxystore.proxy.Proxy] constructor. I.e.,\n            return a proxy that (1) is already resolved, (2) can be used\n            in [`isinstance`][isinstance] checks without resolving, and (3)\n            is hashable without resolving if `obj` is a hashable type.\n            If `None`, defaults to the store-wide setting.\n        skip_nonproxiable: Return non-proxiable types (e.g., built-in\n            constants like `bool` or `None`) rather than raising a\n            [`NonProxiableTypeError`][proxystore.store.exceptions.NonProxiableTypeError].\n        kwargs: Additional keyword arguments to pass to\n            [`Connector.put()`][proxystore.connectors.protocols.Connector.put].\n\n    Returns:\n        A proxy wrapped in a \\\n        [`ProxyLocker`][proxystore.proxy.ProxyLocker] unless `obj` is a \\\n        non-proxiable type `#!python skip_nonproxiable is True` in which \\\n        case `obj` is returned directly.\n\n    Raises:\n        NonProxiableTypeError: If `obj` is a non-proxiable type. This\n            behavior can be overridden by setting\n            `#!python skip_nonproxiable=True`.\n        ValueError: If `evict` is `True` and `lifetime` is not `None`\n            because these parameters are mutually exclusive.\n    \"\"\"  # noqa: E501\n    possible_proxy = self.proxy(\n        obj,\n        evict=evict,\n        lifetime=lifetime,\n        serializer=serializer,\n        deserializer=deserializer,\n        populate_target=populate_target,\n        skip_nonproxiable=skip_nonproxiable,\n        **kwargs,\n    )\n\n    if isinstance(possible_proxy, Proxy):\n        return ProxyLocker(possible_proxy)\n    return possible_proxy\n</code></pre>"},{"location":"api/store/#proxystore.store.Store.owned_proxy","title":"owned_proxy()","text":"<pre><code>owned_proxy(\n    obj: T | NonProxiableT,\n    *,\n    serializer: SerializerT | None = None,\n    deserializer: DeserializerT | None = None,\n    populate_target: bool | None = None,\n    skip_nonproxiable: bool = True,\n    **kwargs: Any\n) -&gt; OwnedProxy[T] | NonProxiableT\n</code></pre> <p>Create a proxy that will enforce ownership rules over the object.</p> <p>An <code>OwnedProxy</code> will auto-evict the object once it goes out of scope. This proxy type can also be borrowed.</p> <p>Parameters:</p> <ul> <li> <code>obj</code>             (<code>T | NonProxiableT</code>)         \u2013          <p>The object to place in store and return a proxy for.</p> </li> <li> <code>serializer</code>             (<code>SerializerT | None</code>, default:                 <code>None</code> )         \u2013          <p>Optionally override the default serializer for the store instance.</p> </li> <li> <code>deserializer</code>             (<code>DeserializerT | None</code>, default:                 <code>None</code> )         \u2013          <p>Optionally override the default deserializer for the store instance.</p> </li> <li> <code>populate_target</code>             (<code>bool | None</code>, default:                 <code>None</code> )         \u2013          <p>Pass <code>cache_defaults=True</code> and <code>target=obj</code> to the <code>Proxy</code> constructor. I.e., return a proxy that (1) is already resolved, (2) can be used in <code>isinstance</code> checks without resolving, and (3) is hashable without resolving if <code>obj</code> is a hashable type. If <code>None</code>, defaults to the store-wide setting.</p> </li> <li> <code>skip_nonproxiable</code>             (<code>bool</code>, default:                 <code>True</code> )         \u2013          <p>Return non-proxiable types (e.g., built-in constants like <code>bool</code> or <code>None</code>) rather than raising a <code>NonProxiableTypeError</code>.</p> </li> <li> <code>kwargs</code>             (<code>Any</code>, default:                 <code>{}</code> )         \u2013          <p>Additional keyword arguments to pass to <code>Connector.put()</code>.</p> </li> </ul> <p>Returns:</p> <ul> <li> <code>OwnedProxy[T] | NonProxiableT</code>         \u2013          <p>A proxy of the object unless <code>obj</code> is a non-proxiable type             <code>skip_nonproxiable is True</code> in which case <code>obj</code> is             returned directly.</p> </li> </ul> <p>Raises:</p> <ul> <li> <code>NonProxiableTypeError</code>           \u2013          <p>If <code>obj</code> is a non-proxiable type. This behavior can be overridden by setting <code>skip_nonproxiable=True</code>.</p> </li> </ul> Source code in <code>proxystore/store/base.py</code> <pre><code>def owned_proxy(\n    self,\n    obj: T | NonProxiableT,\n    *,\n    serializer: SerializerT | None = None,\n    deserializer: DeserializerT | None = None,\n    populate_target: bool | None = None,\n    skip_nonproxiable: bool = True,\n    **kwargs: Any,\n) -&gt; OwnedProxy[T] | NonProxiableT:\n    \"\"\"Create a proxy that will enforce ownership rules over the object.\n\n    An [`OwnedProxy`][proxystore.store.ref.OwnedProxy] will auto-evict\n    the object once it goes out of scope. This proxy type can also\n    be borrowed.\n\n    Args:\n        obj: The object to place in store and return a proxy for.\n        serializer: Optionally override the default serializer for the\n            store instance.\n        deserializer: Optionally override the default deserializer for the\n            store instance.\n        populate_target: Pass `cache_defaults=True` and `target=obj` to\n            the [`Proxy`][proxystore.proxy.Proxy] constructor. I.e.,\n            return a proxy that (1) is already resolved, (2) can be used\n            in [`isinstance`][isinstance] checks without resolving, and (3)\n            is hashable without resolving if `obj` is a hashable type.\n            If `None`, defaults to the store-wide setting.\n        skip_nonproxiable: Return non-proxiable types (e.g., built-in\n            constants like `bool` or `None`) rather than raising a\n            [`NonProxiableTypeError`][proxystore.store.exceptions.NonProxiableTypeError].\n        kwargs: Additional keyword arguments to pass to\n            [`Connector.put()`][proxystore.connectors.protocols.Connector.put].\n\n    Returns:\n        A proxy of the object unless `obj` is a non-proxiable type \\\n        `#!python skip_nonproxiable is True` in which case `obj` is \\\n        returned directly.\n\n    Raises:\n        NonProxiableTypeError: If `obj` is a non-proxiable type. This\n            behavior can be overridden by setting\n            `#!python skip_nonproxiable=True`.\n    \"\"\"\n    possible_proxy = self.proxy(\n        obj,\n        evict=False,\n        serializer=serializer,\n        deserializer=deserializer,\n        populate_target=populate_target,\n        skip_nonproxiable=skip_nonproxiable,\n        **kwargs,\n    )\n\n    if isinstance(possible_proxy, Proxy):\n        populate_target = (\n            self._populate_target\n            if populate_target is None\n            else populate_target\n        )\n        return into_owned(possible_proxy, populate_target=populate_target)\n    return possible_proxy\n</code></pre>"},{"location":"api/store/#proxystore.store.Store.put","title":"put()","text":"<pre><code>put(\n    obj: Any,\n    *,\n    lifetime: Lifetime | None = None,\n    serializer: SerializerT | None = None,\n    **kwargs: Any\n) -&gt; ConnectorKeyT\n</code></pre> <p>Put an object in the store.</p> <p>Parameters:</p> <ul> <li> <code>obj</code>             (<code>Any</code>)         \u2013          <p>Object to put in the store.</p> </li> <li> <code>serializer</code>             (<code>SerializerT | None</code>, default:                 <code>None</code> )         \u2013          <p>Optionally override the default serializer for the store instance.</p> </li> <li> <code>lifetime</code>             (<code>Lifetime | None</code>, default:                 <code>None</code> )         \u2013          <p>Attach the key to this lifetime. The object associated with the key will be evicted when the lifetime ends.</p> </li> <li> <code>kwargs</code>             (<code>Any</code>, default:                 <code>{}</code> )         \u2013          <p>Additional keyword arguments to pass to <code>Connector.put()</code>.</p> </li> </ul> <p>Returns:</p> <ul> <li> <code>ConnectorKeyT</code>         \u2013          <p>A key which can be used to retrieve the object.</p> </li> </ul> <p>Raises:</p> <ul> <li> <code>TypeError</code>           \u2013          <p>If the output of <code>serializer</code> is not bytes.</p> </li> </ul> Source code in <code>proxystore/store/base.py</code> <pre><code>def put(\n    self,\n    obj: Any,\n    *,\n    lifetime: Lifetime | None = None,\n    serializer: SerializerT | None = None,\n    **kwargs: Any,\n) -&gt; ConnectorKeyT:\n    \"\"\"Put an object in the store.\n\n    Args:\n        obj: Object to put in the store.\n        serializer: Optionally override the default serializer for the\n            store instance.\n        lifetime: Attach the key to this lifetime. The object associated\n            with the key will be evicted when the lifetime ends.\n        kwargs: Additional keyword arguments to pass to\n            [`Connector.put()`][proxystore.connectors.protocols.Connector.put].\n\n    Returns:\n        A key which can be used to retrieve the object.\n\n    Raises:\n        TypeError: If the output of `serializer` is not bytes.\n    \"\"\"\n    timer = Timer()\n    timer.start()\n\n    with Timer() as serialize_timer:\n        if serializer is not None:\n            obj = serializer(obj)\n        else:\n            obj = self.serializer(obj)\n\n    if not isinstance(obj, bytes):\n        raise TypeError('Serializer must produce bytes.')\n\n    with Timer() as connector_timer:\n        key = self.connector.put(obj, **kwargs)\n\n    if lifetime is not None:\n        lifetime.add_key(key, store=self)\n\n    timer.stop()\n    if self.metrics is not None:\n        ctime = connector_timer.elapsed_ms\n        stime = serialize_timer.elapsed_ms\n        self.metrics.add_attribute('store.put.object_size', key, len(obj))\n        self.metrics.add_time('store.put.serialize', key, stime)\n        self.metrics.add_time('store.put.connector', key, ctime)\n        self.metrics.add_time('store.put', key, timer.elapsed_ms)\n\n    logger.debug(\n        f'Store(name=\"{self.name}\"): PUT {key} in '\n        f'{timer.elapsed_ms:.3f} ms',\n    )\n    return key\n</code></pre>"},{"location":"api/store/#proxystore.store.Store.put_batch","title":"put_batch()","text":"<pre><code>put_batch(\n    objs: Sequence[Any],\n    *,\n    lifetime: Lifetime | None = None,\n    serializer: SerializerT | None = None,\n    **kwargs: Any\n) -&gt; list[ConnectorKeyT]\n</code></pre> <p>Put multiple objects in the store.</p> <p>Parameters:</p> <ul> <li> <code>objs</code>             (<code>Sequence[Any]</code>)         \u2013          <p>Sequence of objects to put in the store.</p> </li> <li> <code>serializer</code>             (<code>SerializerT | None</code>, default:                 <code>None</code> )         \u2013          <p>Optionally override the default serializer for the store instance.</p> </li> <li> <code>lifetime</code>             (<code>Lifetime | None</code>, default:                 <code>None</code> )         \u2013          <p>Attach the keys to this lifetime. The objects associated with each key will be evicted when the lifetime ends.</p> </li> <li> <code>kwargs</code>             (<code>Any</code>, default:                 <code>{}</code> )         \u2013          <p>Additional keyword arguments to pass to <code>Connector.put_batch()</code>.</p> </li> </ul> <p>Returns:</p> <ul> <li> <code>list[ConnectorKeyT]</code>         \u2013          <p>A list of keys which can be used to retrieve the objects.</p> </li> </ul> <p>Raises:</p> <ul> <li> <code>TypeError</code>           \u2013          <p>If the output of <code>serializer</code> is not bytes.</p> </li> </ul> Source code in <code>proxystore/store/base.py</code> <pre><code>def put_batch(\n    self,\n    objs: Sequence[Any],\n    *,\n    lifetime: Lifetime | None = None,\n    serializer: SerializerT | None = None,\n    **kwargs: Any,\n) -&gt; list[ConnectorKeyT]:\n    \"\"\"Put multiple objects in the store.\n\n    Args:\n        objs: Sequence of objects to put in the store.\n        serializer: Optionally override the default serializer for the\n            store instance.\n        lifetime: Attach the keys to this lifetime. The objects associated\n            with each key will be evicted when the lifetime ends.\n        kwargs: Additional keyword arguments to pass to\n            [`Connector.put_batch()`][proxystore.connectors.protocols.Connector.put_batch].\n\n    Returns:\n        A list of keys which can be used to retrieve the objects.\n\n    Raises:\n        TypeError: If the output of `serializer` is not bytes.\n    \"\"\"\n    timer = Timer()\n    timer.start()\n\n    def _serialize(obj: Any) -&gt; bytes:\n        if serializer is not None:\n            obj = serializer(obj)\n        else:\n            obj = self.serializer(obj)\n\n        if not isinstance(obj, bytes):\n            raise TypeError('Serializer must produce bytes.')\n\n        return obj\n\n    with Timer() as serialize_timer:\n        _objs = list(map(_serialize, objs))\n\n    with Timer() as connector_timer:\n        keys = self.connector.put_batch(_objs, **kwargs)\n\n    if lifetime is not None:\n        lifetime.add_key(*keys, store=self)\n\n    timer.stop()\n    if self.metrics is not None:\n        ctime = connector_timer.elapsed_ms\n        stime = serialize_timer.elapsed_ms\n        sizes = sum(len(obj) for obj in _objs)\n        self.metrics.add_attribute(\n            'store.put_batch.object_sizes',\n            keys,\n            sizes,\n        )\n        self.metrics.add_time('store.put_batch.serialize', keys, stime)\n        self.metrics.add_time('store.put_batch.connector', keys, ctime)\n        self.metrics.add_time('store.put_batch', keys, timer.elapsed_ms)\n\n    logger.debug(\n        f'Store(name=\"{self.name}\"): PUT_BATCH ({len(keys)} items) in '\n        f'{timer.elapsed_ms:.3f} ms',\n    )\n    return keys\n</code></pre>"},{"location":"api/store/#proxystore.store.StoreConfig","title":"StoreConfig","text":"<p>             Bases: <code>BaseModel</code></p> <p>Store configuration.</p> Tip <p>See the <code>Store</code> parameters for more information about each configuration option.</p> <p>Attributes:</p> <ul> <li> <code>name</code>             (<code>str</code>)         \u2013          <p>Store name.</p> </li> <li> <code>connector</code>             (<code>ConnectorConfig</code>)         \u2013          <p>Connector configuration.</p> </li> <li> <code>serializer</code>             (<code>Optional[SerializerT]</code>)         \u2013          <p>Optional serializer.</p> </li> <li> <code>deserializer</code>             (<code>Optional[DeserializerT]</code>)         \u2013          <p>Optional deserializer.</p> </li> <li> <code>cache_size</code>             (<code>int</code>)         \u2013          <p>Cache size.</p> </li> <li> <code>metrics</code>             (<code>bool</code>)         \u2013          <p>Enable recording operation metrics.</p> </li> <li> <code>populate_target</code>             (<code>bool</code>)         \u2013          <p>Set the default value for the <code>populate_target</code> parameter of proxy methods.</p> </li> <li> <code>auto_register</code>             (<code>bool</code>)         \u2013          <p>Auto-register the store.</p> </li> </ul>"},{"location":"api/store/#proxystore.store.StoreConfig.from_toml","title":"from_toml()  <code>classmethod</code>","text":"<pre><code>from_toml(filepath: str | Path) -&gt; Self\n</code></pre> <p>Create a configuration file from a TOML file.</p> Example <p>See <code>write_toml()</code>.</p> <p>Parameters:</p> <ul> <li> <code>filepath</code>             (<code>str | Path</code>)         \u2013          <p>Path to TOML file to load.</p> </li> </ul> Source code in <code>proxystore/store/config.py</code> <pre><code>@classmethod\ndef from_toml(cls, filepath: str | pathlib.Path) -&gt; Self:\n    \"\"\"Create a configuration file from a TOML file.\n\n    Example:\n        See\n        [`write_toml()`][proxystore.store.config.StoreConfig.write_toml].\n\n    Args:\n        filepath: Path to TOML file to load.\n    \"\"\"\n    with open(filepath, 'rb') as f:\n        return load(cls, f)\n</code></pre>"},{"location":"api/store/#proxystore.store.StoreConfig.write_toml","title":"write_toml()","text":"<pre><code>write_toml(filepath: str | Path) -&gt; None\n</code></pre> <p>Write a configuration to a TOML file.</p> Example <p><pre><code>from proxystore.store.config import ConnectorConfig\nfrom proxystore.store.config import StoreConfig\n\nconfig = StoreConfig(\n    name='example',\n    connector=ConnectorConfig(\n        kind='file',\n        options={'store_dir': '/tmp/proxystore-cache'},\n    ),\n)\n\nconfig.write_toml('config.toml')\n</code></pre> The resulting TOML file contains the full configuration, including default options, and can be loaded again using <code>StoreConfig.from_toml('config.toml')</code>. config.toml<pre><code>name = \"example\"\ncache_size = 16\nmetrics = false\npopulate_target = true\nauto_register = false\n\n[connector]\nkind = \"file\"\n\n[connector.options]\nstore_dir = \"/tmp/proxystore-cache\"\n</code></pre></p> <p>Parameters:</p> <ul> <li> <code>filepath</code>             (<code>str | Path</code>)         \u2013          <p>Path to TOML file to write.</p> </li> </ul> Source code in <code>proxystore/store/config.py</code> <pre><code>def write_toml(self, filepath: str | pathlib.Path) -&gt; None:\n    \"\"\"Write a configuration to a TOML file.\n\n    Example:\n        ```python\n        from proxystore.store.config import ConnectorConfig\n        from proxystore.store.config import StoreConfig\n\n        config = StoreConfig(\n            name='example',\n            connector=ConnectorConfig(\n                kind='file',\n                options={'store_dir': '/tmp/proxystore-cache'},\n            ),\n        )\n\n        config.write_toml('config.toml')\n        ```\n        The resulting TOML file contains the full configuration,\n        including default options, and can be loaded again\n        using `#!python StoreConfig.from_toml('config.toml')`.\n        ```toml title=\"config.toml\"\n        name = \"example\"\n        cache_size = 16\n        metrics = false\n        populate_target = true\n        auto_register = false\n\n        [connector]\n        kind = \"file\"\n\n        [connector.options]\n        store_dir = \"/tmp/proxystore-cache\"\n        ```\n\n    Args:\n        filepath: Path to TOML file to write.\n    \"\"\"\n    filepath = pathlib.Path(filepath)\n    filepath.parent.mkdir(parents=True, exist_ok=True)\n    with open(filepath, 'wb') as f:\n        dump(self, f)\n</code></pre>"},{"location":"api/store/#proxystore.store.StoreFactory","title":"StoreFactory","text":"<pre><code>StoreFactory(\n    key: ConnectorKeyT,\n    store_config: StoreConfig,\n    *,\n    evict: bool = False,\n    deserializer: DeserializerT | None = None\n)\n</code></pre> <p>             Bases: <code>Generic[ConnectorT, T]</code></p> <p>Factory that resolves an object from a store.</p> <p>Adds support for asynchronously retrieving objects from a <code>Store</code> instance.</p> <p>The factory takes the <code>store_config</code> parameter that is used to reinitialize the store if the factory is sent to a remote process where the store has not already been initialized.</p> <p>Parameters:</p> <ul> <li> <code>key</code>             (<code>ConnectorKeyT</code>)         \u2013          <p>Key corresponding to object in store.</p> </li> <li> <code>store_config</code>             (<code>StoreConfig</code>)         \u2013          <p>Store configuration used to reinitialize the store if needed.</p> </li> <li> <code>evict</code>             (<code>bool</code>, default:                 <code>False</code> )         \u2013          <p>If True, evict the object from the store once <code>resolve()</code> is called.</p> </li> <li> <code>deserializer</code>             (<code>DeserializerT | None</code>, default:                 <code>None</code> )         \u2013          <p>Optional callable used to deserialize the byte string. If <code>None</code>, the default deserializer (<code>deserialize()</code>) will be used.</p> </li> </ul> Source code in <code>proxystore/store/factory.py</code> <pre><code>def __init__(\n    self,\n    key: ConnectorKeyT,\n    store_config: StoreConfig,\n    *,\n    evict: bool = False,\n    deserializer: DeserializerT | None = None,\n) -&gt; None:\n    self.key = key\n    self.store_config = store_config\n    self.evict = evict\n    self.deserializer = deserializer\n\n    # The following are not included when a factory is serialized\n    # because they are specific to that instance of the factory\n    self._obj_future: Future[T] | None = None\n</code></pre>"},{"location":"api/store/#proxystore.store.StoreFactory.get_store","title":"get_store()","text":"<pre><code>get_store() -&gt; Store[ConnectorT]\n</code></pre> <p>Get store and reinitialize if necessary.</p> Source code in <code>proxystore/store/factory.py</code> <pre><code>def get_store(self) -&gt; Store[ConnectorT]:\n    \"\"\"Get store and reinitialize if necessary.\"\"\"\n    return proxystore.store.get_or_create_store(\n        self.store_config,\n        register=True,\n    )\n</code></pre>"},{"location":"api/store/#proxystore.store.StoreFactory.resolve","title":"resolve()","text":"<pre><code>resolve() -&gt; T\n</code></pre> <p>Get object associated with key from store.</p> <p>Raises:</p> <ul> <li> <code>ProxyResolveMissingKeyError</code>           \u2013          <p>If the key associated with this factory does not exist in the store.</p> </li> </ul> Source code in <code>proxystore/store/factory.py</code> <pre><code>def resolve(self) -&gt; T:\n    \"\"\"Get object associated with key from store.\n\n    Raises:\n        ProxyResolveMissingKeyError: If the key associated with this\n            factory does not exist in the store.\n    \"\"\"\n    with Timer() as timer:\n        store = self.get_store()\n        obj = store.get(\n            self.key,\n            deserializer=self.deserializer,\n            default=_MISSING_OBJECT,\n        )\n\n        if obj is _MISSING_OBJECT:\n            raise ProxyResolveMissingKeyError(\n                self.key,\n                type(store),\n                store.name,\n            )\n\n        if self.evict:\n            store.evict(self.key)\n\n    if store.metrics is not None:\n        total_time = timer.elapsed_ns\n        store.metrics.add_time('factory.resolve', self.key, total_time)\n\n    return cast(T, obj)\n</code></pre>"},{"location":"api/store/#proxystore.store.StoreFactory.resolve_async","title":"resolve_async()","text":"<pre><code>resolve_async() -&gt; None\n</code></pre> <p>Asynchronously get object associated with key from store.</p> Source code in <code>proxystore/store/factory.py</code> <pre><code>def resolve_async(self) -&gt; None:\n    \"\"\"Asynchronously get object associated with key from store.\"\"\"\n    logger.debug(f'Starting asynchronous resolve of {self.key}')\n    self._obj_future = _default_pool.submit(self.resolve)\n</code></pre>"},{"location":"api/store/#proxystore.store.get_store","title":"get_store()","text":"<pre><code>get_store(val: str | Proxy[T]) -&gt; Store[Any] | None\n</code></pre> <p>Get a registered store by name.</p> <p>Parameters:</p> <ul> <li> <code>val</code>             (<code>str | Proxy[T]</code>)         \u2013          <p>name of the store to get or a <code>Proxy</code> instance.</p> </li> </ul> <p>Returns:</p> <ul> <li> <code>Store[Any] | None</code>         \u2013          <p><code>Store</code> if a store matching the         name or belonging to the proxy exists. If the store does not exist,         returns <code>None</code>.</p> </li> </ul> <p>Raises:</p> <ul> <li> <code>ProxyStoreFactoryError</code>           \u2013          <p>If the value is a proxy but does not contain a factory of type <code>StoreFactory</code>.</p> </li> </ul> Source code in <code>proxystore/store/__init__.py</code> <pre><code>def get_store(val: str | Proxy[T]) -&gt; Store[Any] | None:\n    \"\"\"Get a registered store by name.\n\n    Args:\n        val: name of the store to get or a [`Proxy`][proxystore.proxy.Proxy]\n            instance.\n\n    Returns:\n        [`Store`][proxystore.store.base.Store] if a store matching the \\\n        name or belonging to the proxy exists. If the store does not exist, \\\n        returns `None`.\n\n    Raises:\n        ProxyStoreFactoryError: If the value is a proxy but does not contain a\n            factory of type\n            [`StoreFactory`][proxystore.store.base.StoreFactory].\n    \"\"\"\n    if isinstance(val, Proxy):\n        # If the object is a proxy, get the factory that will access the store\n        factory = get_factory(val)\n        if isinstance(factory, StoreFactory):\n            return factory.get_store()\n        else:\n            raise ProxyStoreFactoryError(\n                'The proxy must contain a factory with type '\n                f'{StoreFactory.__name__}. {type(factory).__name__} '\n                'is not supported.',\n            )\n    else:\n        name = val\n\n    with _stores_lock:\n        if name in _stores:\n            return _stores[name]\n        return None\n</code></pre>"},{"location":"api/store/#proxystore.store.register_store","title":"register_store()","text":"<pre><code>register_store(\n    store: Store[Any], exist_ok: bool = False\n) -&gt; None\n</code></pre> <p>Register the store instance to the global registry.</p> Note <p>Global means globally accessible within the Python process.</p> Tip <p>Use the <code>store_registration</code> context manager to automatically register and unregister as store.</p> <p>Parameters:</p> <ul> <li> <code>store</code>             (<code>Store[Any]</code>)         \u2013          <p>Store instance to register.</p> </li> <li> <code>exist_ok</code>             (<code>bool</code>, default:                 <code>False</code> )         \u2013          <p>If a store with the same name exists, overwrite it.</p> </li> </ul> <p>Raises:</p> <ul> <li> <code>StoreExistsError</code>           \u2013          <p>If a store with the same name is already registered and <code>exist_ok</code> is false.</p> </li> </ul> Source code in <code>proxystore/store/__init__.py</code> <pre><code>def register_store(store: Store[Any], exist_ok: bool = False) -&gt; None:\n    \"\"\"Register the store instance to the global registry.\n\n    Note:\n        Global means globally accessible within the Python process.\n\n    Tip:\n        Use the [`store_registration`][proxystore.store.store_registration]\n        context manager to automatically register and unregister as store.\n\n    Args:\n        store: Store instance to register.\n        exist_ok: If a store with the same name exists, overwrite it.\n\n    Raises:\n        StoreExistsError: If a store with the same name is already registered\n            and `exist_ok` is false.\n    \"\"\"\n    with _stores_lock:\n        if store.name in _stores and not exist_ok:\n            raise StoreExistsError(\n                f'A store named \"{store.name}\" already exists.',\n            )\n\n        _stores[store.name] = store\n        logger.info(f'Registered a store named \"{store.name}\"')\n</code></pre>"},{"location":"api/store/#proxystore.store.store_registration","title":"store_registration()","text":"<pre><code>store_registration(\n    *stores: Store[Any], exist_ok: bool = False\n) -&gt; Generator[None, None, None]\n</code></pre> <p>Context manager that registers and unregisters a set of stores.</p> Example <pre><code>from proxystore.connectors.local import LocalConnector\nfrom proxystore.store import Store\nfrom proxystore.store import store_registration\n\nwith Store('store', LocalConnector()) as store:\n    with store_registration(store):\n        ...\n\nstores = [\n    Store('store1', LocalConnector()),\n    Store('store2', LocalConnector()),\n]\nwith store_registration(*stores):\n    ...\n</code></pre> <p>Parameters:</p> <ul> <li> <code>stores</code>             (<code>Store[Any]</code>, default:                 <code>()</code> )         \u2013          <p>Set of <code>Store</code> instances to register then unregister when the context manager is exited.</p> </li> <li> <code>exist_ok</code>             (<code>bool</code>, default:                 <code>False</code> )         \u2013          <p>If a store with the same name exists, overwrite it.</p> </li> </ul> <p>Raises:</p> <ul> <li> <code>StoreExistsError</code>           \u2013          <p>If a store with the same name is already registered and <code>exist_ok</code> is false.</p> </li> </ul> Source code in <code>proxystore/store/__init__.py</code> <pre><code>@contextlib.contextmanager\ndef store_registration(\n    *stores: Store[Any],\n    exist_ok: bool = False,\n) -&gt; Generator[None, None, None]:\n    \"\"\"Context manager that registers and unregisters a set of stores.\n\n    Example:\n        ```python\n        from proxystore.connectors.local import LocalConnector\n        from proxystore.store import Store\n        from proxystore.store import store_registration\n\n        with Store('store', LocalConnector()) as store:\n            with store_registration(store):\n                ...\n\n        stores = [\n            Store('store1', LocalConnector()),\n            Store('store2', LocalConnector()),\n        ]\n        with store_registration(*stores):\n            ...\n        ```\n\n    Args:\n        stores: Set of [`Store`][proxystore.store.base.Store] instances to\n            register then unregister when the context manager is exited.\n        exist_ok: If a store with the same name exists, overwrite it.\n\n    Raises:\n        StoreExistsError: If a store with the same name is already registered\n            and `exist_ok` is false.\n    \"\"\"\n    for store in stores:\n        register_store(store, exist_ok=exist_ok)\n\n    yield\n\n    for store in stores:\n        unregister_store(store)\n</code></pre>"},{"location":"api/store/#proxystore.store.unregister_store","title":"unregister_store()","text":"<pre><code>unregister_store(name_or_store: str | Store[Any]) -&gt; None\n</code></pre> <p>Unregisters the store instance from the global registry.</p> Note <p>This function is a no-op if no store matching the name exists (i.e., no exception will be raised).</p> <p>Parameters:</p> <ul> <li> <code>name_or_store</code>             (<code>str | Store[Any]</code>)         \u2013          <p>Name of the store to unregister or a store itself.</p> </li> </ul> Source code in <code>proxystore/store/__init__.py</code> <pre><code>def unregister_store(name_or_store: str | Store[Any]) -&gt; None:\n    \"\"\"Unregisters the store instance from the global registry.\n\n    Note:\n        This function is a no-op if no store matching the name\n        exists (i.e., no exception will be raised).\n\n    Args:\n        name_or_store: Name of the store to unregister or a store itself.\n    \"\"\"\n    name = (\n        name_or_store if isinstance(name_or_store, str) else name_or_store.name\n    )\n    with _stores_lock:\n        if name in _stores:\n            del _stores[name]\n            logger.info(f'Unregistered a store named {name}')\n</code></pre>"},{"location":"api/store/base/","title":"proxystore.store.base","text":"<code>proxystore/store/base.py</code> <p>Store implementation.</p>"},{"location":"api/store/base/#proxystore.store.base.Store","title":"Store","text":"<pre><code>Store(\n    name: str,\n    connector: ConnectorT,\n    *,\n    serializer: SerializerT | None = None,\n    deserializer: DeserializerT | None = None,\n    cache_size: int = 16,\n    metrics: bool = False,\n    populate_target: bool = True,\n    register: bool = False\n)\n</code></pre> <p>             Bases: <code>Generic[ConnectorT]</code></p> <p>Key-value store interface for proxies.</p> Tip <p>A <code>Store</code> instance can be used as a context manager which will automatically call <code>close()</code> on exit.</p> <pre><code>with Store('my-store', connector=...) as store:\n    key = store.put('value')\n    store.get(key)\n</code></pre> Warning <p>The default value of <code>populate_target=True</code> can cause unexpected behavior when providing custom serializer/deserializers because neither the serializer nor deserializer will be applied to the target object being cached in the resulting <code>Proxy</code>.</p> <pre><code>import pickle\nfrom proxystore.store import Store\nfrom proxystore.connectors.local import LocalConnector\n\nwith Store('example', LocalConnector(), register=True) as store:\n    data = [1, 2, 3]\n    data_bytes = pickle.dumps(data)\n\n    data_proxy = store.proxy(\n        data_bytes,\n        serializer=lambda s: s,\n        deserializer=pickle.loads,\n        populate_target=True,\n    )\n\n    print(data_proxy)\n    # b'\\x80\\x04\\x95\\x0b\\x00\\x00\\x00\\x00\\x00\\x00\\x00]\\x94(K\\x01K\\x02K\\x03e.'\n</code></pre> <p>In this example, the serialized <code>data_bytes</code> was populated as the target object in the resulting proxy so the proxy looks like a proxy of bytes rather than the intended list of integers. To fix this, set <code>populate_target=False</code> so the custom deserializer is correctly applied to <code>data_bytes</code> when the proxy is resolved.</p> <p>Parameters:</p> <ul> <li> <code>name</code>             (<code>str</code>)         \u2013          <p>Name of the store instance.</p> </li> <li> <code>connector</code>             (<code>ConnectorT</code>)         \u2013          <p>Connector instance to use for object storage.</p> </li> <li> <code>serializer</code>             (<code>SerializerT | None</code>, default:                 <code>None</code> )         \u2013          <p>Optional callable which serializes the object. If <code>None</code>, the default serializer (<code>serialize()</code>) will be used.</p> </li> <li> <code>deserializer</code>             (<code>DeserializerT | None</code>, default:                 <code>None</code> )         \u2013          <p>Optional callable used by the factory to deserialize the byte string. If <code>None</code>, the default deserializer (<code>deserialize()</code>) will be used.</p> </li> <li> <code>cache_size</code>             (<code>int</code>, default:                 <code>16</code> )         \u2013          <p>Size of LRU cache (in # of objects). If 0, the cache is disabled. The cache is local to the Python process.</p> </li> <li> <code>metrics</code>             (<code>bool</code>, default:                 <code>False</code> )         \u2013          <p>Enable recording operation metrics.</p> </li> <li> <code>populate_target</code>             (<code>bool</code>, default:                 <code>True</code> )         \u2013          <p>Set the default value of <code>populate_target</code> for proxy methods of the store.</p> </li> <li> <code>register</code>             (<code>bool</code>, default:                 <code>False</code> )         \u2013          <p>Register the store instance after initialization.</p> </li> </ul> <p>Raises:</p> <ul> <li> <code>ValueError</code>           \u2013          <p>If <code>cache_size</code> is less than zero.</p> </li> <li> <code>StoreExistsError</code>           \u2013          <p>If <code>register=True</code> and a store with <code>name</code> already exists.</p> </li> </ul> Source code in <code>proxystore/store/base.py</code> <pre><code>def __init__(\n    self,\n    name: str,\n    connector: ConnectorT,\n    *,\n    serializer: SerializerT | None = None,\n    deserializer: DeserializerT | None = None,\n    cache_size: int = 16,\n    metrics: bool = False,\n    populate_target: bool = True,\n    register: bool = False,\n) -&gt; None:\n    if cache_size &lt; 0:\n        raise ValueError(\n            f'Cache size cannot be negative. Got {cache_size}.',\n        )\n\n    self.connector = connector\n    self.cache: LRUCache[ConnectorKeyT, Any] = LRUCache(cache_size)\n    self._name = name\n    self._metrics = StoreMetrics() if metrics else None\n    self._cache_size = cache_size\n    self._serializer = serializer\n    self._deserializer = deserializer\n    self._populate_target = populate_target\n    self._register = register\n\n    if self._register:\n        try:\n            proxystore.store.register_store(self)\n        except StoreExistsError as e:\n            if sys.version_info &gt;= (3, 11):  # pragma: &gt;=3.11 cover\n                e.add_note(\n                    'Consider using get_store(name) rather than '\n                    'initializing a new instance with register=True.',\n                )\n            else:  # pragma: &lt;3.11 cover\n                pass\n            raise\n\n    logger.info(f'Initialized {self}')\n</code></pre>"},{"location":"api/store/base/#proxystore.store.base.Store.name","title":"name  <code>property</code>","text":"<pre><code>name: str\n</code></pre> <p>Name of this <code>Store</code> instance.</p>"},{"location":"api/store/base/#proxystore.store.base.Store.metrics","title":"metrics  <code>property</code>","text":"<pre><code>metrics: StoreMetrics | None\n</code></pre> <p>Optional metrics for this instance.</p>"},{"location":"api/store/base/#proxystore.store.base.Store.serializer","title":"serializer  <code>property</code>","text":"<pre><code>serializer: SerializerT\n</code></pre> <p>Serializer for this instance.</p>"},{"location":"api/store/base/#proxystore.store.base.Store.deserializer","title":"deserializer  <code>property</code>","text":"<pre><code>deserializer: DeserializerT\n</code></pre> <p>Deserializer for this instance.</p>"},{"location":"api/store/base/#proxystore.store.base.Store.close","title":"close()","text":"<pre><code>close(*args: Any, **kwargs: Any) -&gt; None\n</code></pre> <p>Close the connector associated with the store.</p> <p>This will (1) close the connector and (2) unregister the store if <code>register=True</code> was set during initialization.</p> Warning <p>This method should only be called at the end of the program when the store will no longer be used, for example once all proxies have been resolved.</p> <p>Parameters:</p> <ul> <li> <code>args</code>             (<code>Any</code>, default:                 <code>()</code> )         \u2013          <p>Positional arguments to pass to <code>Connector.close()</code>.</p> </li> <li> <code>kwargs</code>             (<code>Any</code>, default:                 <code>{}</code> )         \u2013          <p>Keyword arguments to pass to <code>Connector.close()</code>.</p> </li> </ul> Source code in <code>proxystore/store/base.py</code> <pre><code>def close(self, *args: Any, **kwargs: Any) -&gt; None:\n    \"\"\"Close the connector associated with the store.\n\n    This will (1) close the connector and (2) unregister the store if\n    `register=True` was set during initialization.\n\n    Warning:\n        This method should only be called at the end of the program\n        when the store will no longer be used, for example once all\n        proxies have been resolved.\n\n    Args:\n        args: Positional arguments to pass to\n            [`Connector.close()`][proxystore.connectors.protocols.Connector.close].\n        kwargs: Keyword arguments to pass to\n            [`Connector.close()`][proxystore.connectors.protocols.Connector.close].\n    \"\"\"\n    if self._register:\n        proxystore.store.unregister_store(self.name)\n    self.connector.close(*args, **kwargs)\n</code></pre>"},{"location":"api/store/base/#proxystore.store.base.Store.config","title":"config()","text":"<pre><code>config() -&gt; StoreConfig\n</code></pre> <p>Get the store configuration.</p> Example <pre><code>&gt;&gt;&gt; store = Store(...)\n&gt;&gt;&gt; config = store.config()\n&gt;&gt;&gt; store = Store.from_config(config)\n</code></pre> <p>Returns:</p> <ul> <li> <code>StoreConfig</code>         \u2013          <p>Store configuration.</p> </li> </ul> Source code in <code>proxystore/store/base.py</code> <pre><code>def config(self) -&gt; StoreConfig:\n    \"\"\"Get the store configuration.\n\n    Example:\n        ```python\n        &gt;&gt;&gt; store = Store(...)\n        &gt;&gt;&gt; config = store.config()\n        &gt;&gt;&gt; store = Store.from_config(config)\n        ```\n\n    Returns:\n        Store configuration.\n    \"\"\"\n    return StoreConfig(\n        name=self.name,\n        connector=ConnectorConfig(\n            kind=get_object_path(type(self.connector)),\n            options=self.connector.config(),\n        ),\n        serializer=self._serializer,\n        deserializer=self._deserializer,\n        cache_size=self._cache_size,\n        metrics=self.metrics is not None,\n        populate_target=self._populate_target,\n        auto_register=self._register,\n    )\n</code></pre>"},{"location":"api/store/base/#proxystore.store.base.Store.from_config","title":"from_config()  <code>classmethod</code>","text":"<pre><code>from_config(config: StoreConfig) -&gt; Store[Any]\n</code></pre> <p>Create a new store instance from a configuration.</p> <p>Parameters:</p> <ul> <li> <code>config</code>             (<code>StoreConfig</code>)         \u2013          <p>Configuration returned by <code>.config()</code>.</p> </li> </ul> <p>Returns:</p> <ul> <li> <code>Store[Any]</code>         \u2013          <p>Store instance.</p> </li> </ul> Source code in <code>proxystore/store/base.py</code> <pre><code>@classmethod\ndef from_config(cls, config: StoreConfig) -&gt; Store[Any]:\n    \"\"\"Create a new store instance from a configuration.\n\n    Args:\n        config: Configuration returned by `#!python .config()`.\n\n    Returns:\n        Store instance.\n    \"\"\"\n    connector = cast(ConnectorT, config.connector.get_connector())\n    return cls(\n        name=config.name,\n        connector=connector,\n        serializer=config.serializer,\n        deserializer=config.deserializer,\n        cache_size=config.cache_size,\n        metrics=config.metrics,\n        populate_target=config.populate_target,\n        register=config.auto_register,\n    )\n</code></pre>"},{"location":"api/store/base/#proxystore.store.base.Store.future","title":"future()","text":"<pre><code>future(\n    *,\n    evict: bool = False,\n    serializer: SerializerT | None = None,\n    deserializer: DeserializerT | None = None,\n    polling_interval: float = 1,\n    polling_backoff_factor: float = 1,\n    polling_interval_limit: float | None = None,\n    polling_timeout: float | None = None\n) -&gt; Future[T]\n</code></pre> <p>Create a future to an object.</p> Example <pre><code>from proxystore.connectors.file import FileConnector\nfrom proxystore.store import Store\nfrom proxystore.store.future import Future\n\ndef remote_foo(future: Future) -&gt; None:\n    # Computation that generates a result value needed by\n    # the remote_bar function.\n    future.set_result(...)\n\ndef remote_bar(data: Any) -&gt; None:\n    # Function uses data, which is a proxy, as normal, blocking\n    # until the remote_foo function has called set_result.\n    ...\n\nwith Store('future-example', FileConnector(...)) as store:\n    future = store.future()\n\n    # The invoke_remove function invokes a provided function\n    # on a remote process. For example, this could be a serverless\n    # function execution.\n    foo_result_future = invoke_remote(remote_foo, future)\n    bar_result_future = invoke_remote(remote_bar, future.proxy())\n\n    foo_result_future.result()\n    bar_result_future.result()\n</code></pre> Warning <p>This method only works if the <code>connector</code> is of type <code>DeferrableConnector</code>.</p> Warning <p>This method and the <code>Future.proxy()</code> are experimental features and may change in future releases.</p> <p>Parameters:</p> <ul> <li> <code>evict</code>             (<code>bool</code>, default:                 <code>False</code> )         \u2013          <p>If a proxy returned by <code>Future.proxy()</code> should evict the object once resolved.</p> </li> <li> <code>serializer</code>             (<code>SerializerT | None</code>, default:                 <code>None</code> )         \u2013          <p>Optionally override the default serializer for the store instance.</p> </li> <li> <code>deserializer</code>             (<code>DeserializerT | None</code>, default:                 <code>None</code> )         \u2013          <p>Optionally override the default deserializer for the store instance.</p> </li> <li> <code>polling_interval</code>             (<code>float</code>, default:                 <code>1</code> )         \u2013          <p>Initial seconds to sleep between polling the store for the object.</p> </li> <li> <code>polling_backoff_factor</code>             (<code>float</code>, default:                 <code>1</code> )         \u2013          <p>Multiplicative factor applied to the polling_interval applied after each unsuccessful poll.</p> </li> <li> <code>polling_interval_limit</code>             (<code>float | None</code>, default:                 <code>None</code> )         \u2013          <p>Maximum polling interval allowed. Prevents the backoff factor from increasing the current polling interval to unreasonable values.</p> </li> <li> <code>polling_timeout</code>             (<code>float | None</code>, default:                 <code>None</code> )         \u2013          <p>Optional maximum number of seconds to poll for. If the timeout is reached an error is raised.</p> </li> </ul> <p>Returns:</p> <ul> <li> <code>Future[T]</code>         \u2013          <p>Future which can be used to get the result object at a later time             or create a proxy which will resolve to the result of the future.</p> </li> </ul> <p>Raises:</p> <ul> <li> <code>NotImplementedError</code>           \u2013          <p>If the <code>connector</code> is not of type <code>DeferrableConnector</code>.</p> </li> </ul> Source code in <code>proxystore/store/base.py</code> <pre><code>def future(\n    self,\n    *,\n    evict: bool = False,\n    serializer: SerializerT | None = None,\n    deserializer: DeserializerT | None = None,\n    polling_interval: float = 1,\n    polling_backoff_factor: float = 1,\n    polling_interval_limit: float | None = None,\n    polling_timeout: float | None = None,\n) -&gt; Future[T]:\n    \"\"\"Create a future to an object.\n\n    Example:\n        ```python\n        from proxystore.connectors.file import FileConnector\n        from proxystore.store import Store\n        from proxystore.store.future import Future\n\n        def remote_foo(future: Future) -&gt; None:\n            # Computation that generates a result value needed by\n            # the remote_bar function.\n            future.set_result(...)\n\n        def remote_bar(data: Any) -&gt; None:\n            # Function uses data, which is a proxy, as normal, blocking\n            # until the remote_foo function has called set_result.\n            ...\n\n        with Store('future-example', FileConnector(...)) as store:\n            future = store.future()\n\n            # The invoke_remove function invokes a provided function\n            # on a remote process. For example, this could be a serverless\n            # function execution.\n            foo_result_future = invoke_remote(remote_foo, future)\n            bar_result_future = invoke_remote(remote_bar, future.proxy())\n\n            foo_result_future.result()\n            bar_result_future.result()\n        ```\n\n    Warning:\n        This method only works if the `connector` is of type\n        [`DeferrableConnector`][proxystore.connectors.protocols.DeferrableConnector].\n\n    Warning:\n        This method and the\n        [`Future.proxy()`][proxystore.store.future.Future.proxy]\n        are experimental features and may change in future releases.\n\n    Args:\n        evict: If a proxy returned by\n            [`Future.proxy()`][proxystore.store.future.Future.proxy]\n            should evict the object once resolved.\n        serializer: Optionally override the default serializer for the\n            store instance.\n        deserializer: Optionally override the default deserializer for the\n            store instance.\n        polling_interval: Initial seconds to sleep between polling the\n            store for the object.\n        polling_backoff_factor: Multiplicative factor applied to the\n            polling_interval applied after each unsuccessful poll.\n        polling_interval_limit: Maximum polling interval allowed. Prevents\n            the backoff factor from increasing the current polling interval\n            to unreasonable values.\n        polling_timeout: Optional maximum number of seconds to poll for. If\n            the timeout is reached an error is raised.\n\n    Returns:\n        Future which can be used to get the result object at a later time \\\n        or create a proxy which will resolve to the result of the future.\n\n    Raises:\n        NotImplementedError: If the `connector` is not of type\n            [`DeferrableConnector`][proxystore.connectors.protocols.DeferrableConnector].\n    \"\"\"\n    timer = Timer()\n    timer.start()\n\n    if not isinstance(self.connector, DeferrableConnector):\n        raise NotImplementedError(\n            'The provided connector is type '\n            f'{type(self.connector).__name__} which does not implement '\n            f'the {DeferrableConnector.__name__} necessary to use the '\n            f'{Future.__name__} interface.',\n        )\n\n    with Timer() as connector_timer:\n        key = self.connector.new_key()\n\n    if self.metrics is not None:\n        ctime = connector_timer.elapsed_ms\n        self.metrics.add_time('store.future.connector', key, ctime)\n\n    factory: PollingStoreFactory[ConnectorT, T] = PollingStoreFactory(\n        key,\n        store_config=self.config(),\n        deserializer=deserializer,\n        evict=evict,\n        polling_interval=polling_interval,\n        polling_backoff_factor=polling_backoff_factor,\n        polling_interval_limit=polling_interval_limit,\n        polling_timeout=polling_timeout,\n    )\n    future = Future(factory, serializer=serializer)\n\n    timer.stop()\n    if self.metrics is not None:\n        self.metrics.add_time('store.future', key, timer.elapsed_ms)\n\n    logger.debug(\n        f'Store(name=\"{self.name}\"): FUTURE {key} in '\n        f'{timer.elapsed_ms:.3f} ms',\n    )\n    return future\n</code></pre>"},{"location":"api/store/base/#proxystore.store.base.Store.evict","title":"evict()","text":"<pre><code>evict(key: ConnectorKeyT) -&gt; None\n</code></pre> <p>Evict the object associated with the key.</p> <p>Parameters:</p> <ul> <li> <code>key</code>             (<code>ConnectorKeyT</code>)         \u2013          <p>Key associated with object to evict.</p> </li> </ul> Source code in <code>proxystore/store/base.py</code> <pre><code>def evict(self, key: ConnectorKeyT) -&gt; None:\n    \"\"\"Evict the object associated with the key.\n\n    Args:\n        key: Key associated with object to evict.\n    \"\"\"\n    with Timer() as timer:\n        with Timer() as connector_timer:\n            self.connector.evict(key)\n\n        if self.metrics is not None:\n            ctime = connector_timer.elapsed_ms\n            self.metrics.add_time('store.evict.connector', key, ctime)\n\n        self.cache.evict(key)\n\n    if self.metrics is not None:\n        self.metrics.add_time('store.evict', key, timer.elapsed_ms)\n\n    logger.debug(\n        f'Store(name=\"{self.name}\"): EVICT {key} in '\n        f'{timer.elapsed_ms:.3f} ms',\n    )\n</code></pre>"},{"location":"api/store/base/#proxystore.store.base.Store.exists","title":"exists()","text":"<pre><code>exists(key: ConnectorKeyT) -&gt; bool\n</code></pre> <p>Check if an object associated with the key exists.</p> <p>Parameters:</p> <ul> <li> <code>key</code>             (<code>ConnectorKeyT</code>)         \u2013          <p>Key potentially associated with stored object.</p> </li> </ul> <p>Returns:</p> <ul> <li> <code>bool</code>         \u2013          <p>If an object associated with the key exists.</p> </li> </ul> Source code in <code>proxystore/store/base.py</code> <pre><code>def exists(self, key: ConnectorKeyT) -&gt; bool:\n    \"\"\"Check if an object associated with the key exists.\n\n    Args:\n        key: Key potentially associated with stored object.\n\n    Returns:\n        If an object associated with the key exists.\n    \"\"\"\n    with Timer() as timer:\n        res = self.cache.exists(key)\n        if not res:\n            with Timer() as connector_timer:\n                res = self.connector.exists(key)\n\n            if self.metrics is not None:\n                ctime = connector_timer.elapsed_ms\n                self.metrics.add_time('store.exists.connector', key, ctime)\n\n    if self.metrics is not None:\n        self.metrics.add_time('store.exists', key, timer.elapsed_ms)\n\n    logger.debug(\n        f'Store(name=\"{self.name}\"): EXISTS {key} in '\n        f'{timer.elapsed_ms:.3f} ms',\n    )\n    return res\n</code></pre>"},{"location":"api/store/base/#proxystore.store.base.Store.get","title":"get()","text":"<pre><code>get(\n    key: ConnectorKeyT,\n    *,\n    deserializer: DeserializerT | None = None,\n    default: object | None = None\n) -&gt; Any | None\n</code></pre> <p>Get the object associated with the key.</p> <p>Parameters:</p> <ul> <li> <code>key</code>             (<code>ConnectorKeyT</code>)         \u2013          <p>Key associated with the object to retrieve.</p> </li> <li> <code>deserializer</code>             (<code>DeserializerT | None</code>, default:                 <code>None</code> )         \u2013          <p>Optionally override the default deserializer for the store instance.</p> </li> <li> <code>default</code>             (<code>object | None</code>, default:                 <code>None</code> )         \u2013          <p>An optional value to be returned if an object associated with the key does not exist.</p> </li> </ul> <p>Returns:</p> <ul> <li> <code>Any | None</code>         \u2013          <p>Object or <code>None</code> if the object does not exist.</p> </li> </ul> <p>Raises:</p> <ul> <li> <code>SerializationError</code>           \u2013          <p>If an exception is caught when deserializing the object associated with the key.</p> </li> </ul> Source code in <code>proxystore/store/base.py</code> <pre><code>def get(\n    self,\n    key: ConnectorKeyT,\n    *,\n    deserializer: DeserializerT | None = None,\n    default: object | None = None,\n) -&gt; Any | None:\n    \"\"\"Get the object associated with the key.\n\n    Args:\n        key: Key associated with the object to retrieve.\n        deserializer: Optionally override the default deserializer for the\n            store instance.\n        default: An optional value to be returned if an object\n            associated with the key does not exist.\n\n    Returns:\n        Object or `None` if the object does not exist.\n\n    Raises:\n        SerializationError: If an exception is caught when deserializing\n            the object associated with the key.\n    \"\"\"\n    timer = Timer()\n    timer.start()\n\n    if self.is_cached(key):\n        value = self.cache.get(key)\n\n        timer.stop()\n        if self.metrics is not None:\n            self.metrics.add_counter('store.get.cache_hits', key, 1)\n            self.metrics.add_time('store.get', key, timer.elapsed_ms)\n\n        logger.debug(\n            f'Store(name=\"{self.name}\"): GET {key} in '\n            f'{timer.elapsed_ms:.3f} ms (cached=True)',\n        )\n        return value\n\n    with Timer() as connector_timer:\n        value = self.connector.get(key)\n\n    if self.metrics is not None:\n        ctime = connector_timer.elapsed_ms\n        self.metrics.add_counter('store.get.cache_misses', key, 1)\n        self.metrics.add_time('store.get.connector', key, ctime)\n\n    if value is not None:\n        with Timer() as deserializer_timer:\n            deserializer = (\n                deserializer\n                if deserializer is not None\n                else self.deserializer\n            )\n            try:\n                result = deserializer(value)\n            except Exception as e:\n                name = get_object_path(deserializer)\n                raise SerializationError(\n                    'Failed to deserialize object '\n                    f'(deserializer={name}, key={key}).',\n                ) from e\n\n        if self.metrics is not None:\n            dtime = deserializer_timer.elapsed_ms\n            obj_size = len(value)\n            self.metrics.add_time('store.get.deserialize', key, dtime)\n            self.metrics.add_attribute(\n                'store.get.object_size',\n                key,\n                obj_size,\n            )\n\n        self.cache.set(key, result)\n    else:\n        result = default\n\n    timer.stop()\n    if self.metrics is not None:\n        self.metrics.add_time('store.get', key, timer.elapsed_ms)\n\n    logger.debug(\n        f'Store(name=\"{self.name}\"): GET {key} in '\n        f'{timer.elapsed_ms:.3f} ms (cached=False)',\n    )\n    return result\n</code></pre>"},{"location":"api/store/base/#proxystore.store.base.Store.is_cached","title":"is_cached()","text":"<pre><code>is_cached(key: ConnectorKeyT) -&gt; bool\n</code></pre> <p>Check if an object associated with the key is cached locally.</p> <p>Parameters:</p> <ul> <li> <code>key</code>             (<code>ConnectorKeyT</code>)         \u2013          <p>Key potentially associated with stored object.</p> </li> </ul> <p>Returns:</p> <ul> <li> <code>bool</code>         \u2013          <p>If the object is cached.</p> </li> </ul> Source code in <code>proxystore/store/base.py</code> <pre><code>def is_cached(self, key: ConnectorKeyT) -&gt; bool:\n    \"\"\"Check if an object associated with the key is cached locally.\n\n    Args:\n        key: Key potentially associated with stored object.\n\n    Returns:\n        If the object is cached.\n    \"\"\"\n    return self.cache.exists(key)\n</code></pre>"},{"location":"api/store/base/#proxystore.store.base.Store.proxy","title":"proxy()","text":"<pre><code>proxy(\n    obj: T | NonProxiableT,\n    *,\n    evict: bool = False,\n    lifetime: Lifetime | None = None,\n    serializer: SerializerT | None = None,\n    deserializer: DeserializerT | None = None,\n    populate_target: bool | None = None,\n    skip_nonproxiable: bool = False,\n    **kwargs: Any\n) -&gt; Proxy[T] | NonProxiableT\n</code></pre> <p>Create a proxy that will resolve to an object in the store.</p> <p>Parameters:</p> <ul> <li> <code>obj</code>             (<code>T | NonProxiableT</code>)         \u2013          <p>The object to place in store and return a proxy for.</p> </li> <li> <code>evict</code>             (<code>bool</code>, default:                 <code>False</code> )         \u2013          <p>If the proxy should evict the object once resolved. Mutually exclusive with the <code>lifetime</code> parameter.</p> </li> <li> <code>lifetime</code>             (<code>Lifetime | None</code>, default:                 <code>None</code> )         \u2013          <p>Attach the proxy to this lifetime. The object associated with the proxy will be evicted when the lifetime ends. Mutually exclusive with the <code>evict</code> parameter.</p> </li> <li> <code>serializer</code>             (<code>SerializerT | None</code>, default:                 <code>None</code> )         \u2013          <p>Optionally override the default serializer for the store instance.</p> </li> <li> <code>deserializer</code>             (<code>DeserializerT | None</code>, default:                 <code>None</code> )         \u2013          <p>Optionally override the default deserializer for the store instance.</p> </li> <li> <code>populate_target</code>             (<code>bool | None</code>, default:                 <code>None</code> )         \u2013          <p>Pass <code>cache_defaults=True</code> and <code>target=obj</code> to the <code>Proxy</code> constructor. I.e., return a proxy that (1) is already resolved, (2) can be used in <code>isinstance</code> checks without resolving, and (3) is hashable without resolving if <code>obj</code> is a hashable type. This is <code>False</code> by default because the returned proxy will hold a reference to <code>obj</code> which will prevent garbage collecting <code>obj</code>. If <code>None</code>, defaults to the store-wide setting.</p> </li> <li> <code>skip_nonproxiable</code>             (<code>bool</code>, default:                 <code>False</code> )         \u2013          <p>Return non-proxiable types (e.g., built-in constants like <code>bool</code> or <code>None</code>) rather than raising a <code>NonProxiableTypeError</code>.</p> </li> <li> <code>kwargs</code>             (<code>Any</code>, default:                 <code>{}</code> )         \u2013          <p>Additional keyword arguments to pass to <code>Connector.put()</code>.</p> </li> </ul> <p>Returns:</p> <ul> <li> <code>Proxy[T] | NonProxiableT</code>         \u2013          <p>A proxy of the object unless <code>obj</code> is a non-proxiable type             <code>skip_nonproxiable is True</code> in which case <code>obj</code> is             returned directly.</p> </li> </ul> <p>Raises:</p> <ul> <li> <code>NonProxiableTypeError</code>           \u2013          <p>If <code>obj</code> is a non-proxiable type. This behavior can be overridden by setting <code>skip_nonproxiable=True</code>.</p> </li> <li> <code>ValueError</code>           \u2013          <p>If <code>evict</code> is <code>True</code> and <code>lifetime</code> is not <code>None</code> because these parameters are mutually exclusive.</p> </li> </ul> Source code in <code>proxystore/store/base.py</code> <pre><code>def proxy(\n    self,\n    obj: T | NonProxiableT,\n    *,\n    evict: bool = False,\n    lifetime: Lifetime | None = None,\n    serializer: SerializerT | None = None,\n    deserializer: DeserializerT | None = None,\n    populate_target: bool | None = None,\n    skip_nonproxiable: bool = False,\n    **kwargs: Any,\n) -&gt; Proxy[T] | NonProxiableT:\n    \"\"\"Create a proxy that will resolve to an object in the store.\n\n    Args:\n        obj: The object to place in store and return a proxy for.\n        evict: If the proxy should evict the object once resolved.\n            Mutually exclusive with the `lifetime` parameter.\n        lifetime: Attach the proxy to this lifetime. The object associated\n            with the proxy will be evicted when the lifetime ends.\n            Mutually exclusive with the `evict` parameter.\n        serializer: Optionally override the default serializer for the\n            store instance.\n        deserializer: Optionally override the default deserializer for the\n            store instance.\n        populate_target: Pass `cache_defaults=True` and `target=obj` to\n            the [`Proxy`][proxystore.proxy.Proxy] constructor. I.e.,\n            return a proxy that (1) is already resolved, (2) can be used\n            in [`isinstance`][isinstance] checks without resolving, and (3)\n            is hashable without resolving if `obj` is a hashable type.\n            This is `False` by default because the returned proxy will\n            hold a reference to `obj` which will prevent garbage\n            collecting `obj`. If `None`, defaults to the store-wide\n            setting.\n        skip_nonproxiable: Return non-proxiable types (e.g., built-in\n            constants like `bool` or `None`) rather than raising a\n            [`NonProxiableTypeError`][proxystore.store.exceptions.NonProxiableTypeError].\n        kwargs: Additional keyword arguments to pass to\n            [`Connector.put()`][proxystore.connectors.protocols.Connector.put].\n\n    Returns:\n        A proxy of the object unless `obj` is a non-proxiable type \\\n        `#!python skip_nonproxiable is True` in which case `obj` is \\\n        returned directly.\n\n    Raises:\n        NonProxiableTypeError: If `obj` is a non-proxiable type. This\n            behavior can be overridden by setting\n            `#!python skip_nonproxiable=True`.\n        ValueError: If `evict` is `True` and `lifetime` is not `None`\n            because these parameters are mutually exclusive.\n    \"\"\"\n    if evict and lifetime is not None:\n        raise ValueError(\n            'The evict and lifetime parameters are mutually exclusive. '\n            'Only set one of evict or lifetime.',\n        )\n\n    if isinstance(obj, _NON_PROXIABLE_TYPES):\n        if skip_nonproxiable:\n            # MyPy raises the following error which is not correct:\n            #     Incompatible return value type (got \"Optional[bool]\",\n            #     expected \"Optional[Proxy[T]]\")  [return-value]\n            return obj  # type: ignore[return-value]\n        else:\n            raise NonProxiableTypeError(\n                f'Object of {type(obj)} is not proxiable.',\n            )\n\n    with Timer() as timer:\n        key = self.put(obj, serializer=serializer, **kwargs)\n        factory: StoreFactory[ConnectorT, T] = StoreFactory(\n            key,\n            store_config=self.config(),\n            deserializer=deserializer,\n            evict=evict,\n        )\n        populate_target = (\n            self._populate_target\n            if populate_target is None\n            else populate_target\n        )\n        if populate_target:\n            # If obj were None, we would have escaped early when\n            # checking _NON_PROXIABLE_TYPES.\n            assert obj is not None\n            proxy = Proxy(factory, cache_defaults=True, target=obj)\n        else:\n            proxy = Proxy(factory)\n\n        if lifetime is not None:\n            lifetime.add_proxy(proxy)\n\n    if self.metrics is not None:\n        self.metrics.add_time('store.proxy', key, timer.elapsed_ms)\n\n    logger.debug(\n        f'Store(name=\"{self.name}\"): PROXY {key} in '\n        f'{timer.elapsed_ms:.3f} ms',\n    )\n    return proxy\n</code></pre>"},{"location":"api/store/base/#proxystore.store.base.Store.proxy_batch","title":"proxy_batch()","text":"<pre><code>proxy_batch(\n    objs: Sequence[T | NonProxiableT],\n    *,\n    evict: bool = False,\n    lifetime: Lifetime | None = None,\n    serializer: SerializerT | None = None,\n    deserializer: DeserializerT | None = None,\n    populate_target: bool | None = None,\n    skip_nonproxiable: bool = False,\n    **kwargs: Any\n) -&gt; list[Proxy[T] | NonProxiableT]\n</code></pre> <p>Create proxies that will resolve to an object in the store.</p> <p>Parameters:</p> <ul> <li> <code>objs</code>             (<code>Sequence[T | NonProxiableT]</code>)         \u2013          <p>The objects to place in store and return a proxies for.</p> </li> <li> <code>evict</code>             (<code>bool</code>, default:                 <code>False</code> )         \u2013          <p>If a proxy should evict its object once resolved. Mutually exclusive with the <code>lifetime</code> parameter.</p> </li> <li> <code>lifetime</code>             (<code>Lifetime | None</code>, default:                 <code>None</code> )         \u2013          <p>Attach the proxies to this lifetime. The objects associated with each proxy will be evicted when the lifetime ends. Mutually exclusive with the <code>evict</code> parameter.</p> </li> <li> <code>serializer</code>             (<code>SerializerT | None</code>, default:                 <code>None</code> )         \u2013          <p>Optionally override the default serializer for the store instance.</p> </li> <li> <code>deserializer</code>             (<code>DeserializerT | None</code>, default:                 <code>None</code> )         \u2013          <p>Optionally override the default deserializer for the store instance.</p> </li> <li> <code>populate_target</code>             (<code>bool | None</code>, default:                 <code>None</code> )         \u2013          <p>Pass <code>cache_defaults=True</code> and <code>target=obj</code> to the <code>Proxy</code> constructor. I.e., return a proxy that (1) is already resolved, (2) can be used in <code>isinstance</code> checks without resolving, and (3) is hashable without resolving if <code>obj</code> is a hashable type. If <code>None</code>, defaults to the store-wide setting.</p> </li> <li> <code>skip_nonproxiable</code>             (<code>bool</code>, default:                 <code>False</code> )         \u2013          <p>Return non-proxiable types (e.g., built-in constants like <code>bool</code> or <code>None</code>) rather than raising a <code>NonProxiableTypeError</code>.</p> </li> <li> <code>kwargs</code>             (<code>Any</code>, default:                 <code>{}</code> )         \u2013          <p>Additional keyword arguments to pass to <code>Connector.put_batch()</code>.</p> </li> </ul> <p>Returns:</p> <ul> <li> <code>list[Proxy[T] | NonProxiableT]</code>         \u2013          <p>A list of proxies of each object or the object itself if said             object is not proxiable and <code>skip_nonproxiable is True</code>.</p> </li> </ul> <p>Raises:</p> <ul> <li> <code>NonProxiableTypeError</code>           \u2013          <p>If <code>obj</code> is a non-proxiable type. This behavior can be overridden by setting <code>skip_nonproxiable=True</code>.</p> </li> <li> <code>ValueError</code>           \u2013          <p>If <code>evict</code> is <code>True</code> and <code>lifetime</code> is not <code>None</code> because these parameters are mutually exclusive.</p> </li> </ul> Source code in <code>proxystore/store/base.py</code> <pre><code>def proxy_batch(  # type: ignore[misc]\n    self,\n    objs: Sequence[T | NonProxiableT],\n    *,\n    evict: bool = False,\n    lifetime: Lifetime | None = None,\n    serializer: SerializerT | None = None,\n    deserializer: DeserializerT | None = None,\n    populate_target: bool | None = None,\n    skip_nonproxiable: bool = False,\n    **kwargs: Any,\n) -&gt; list[Proxy[T] | NonProxiableT]:\n    \"\"\"Create proxies that will resolve to an object in the store.\n\n    Args:\n        objs: The objects to place in store and return a proxies for.\n        evict: If a proxy should evict its object once resolved.\n            Mutually exclusive with the `lifetime` parameter.\n        lifetime: Attach the proxies to this lifetime. The objects\n            associated with each proxy will be evicted when the lifetime\n            ends. Mutually exclusive with the `evict` parameter.\n        serializer: Optionally override the default serializer for the\n            store instance.\n        deserializer: Optionally override the default deserializer for the\n            store instance.\n        populate_target: Pass `cache_defaults=True` and `target=obj` to\n            the [`Proxy`][proxystore.proxy.Proxy] constructor. I.e.,\n            return a proxy that (1) is already resolved, (2) can be used\n            in [`isinstance`][isinstance] checks without resolving, and (3)\n            is hashable without resolving if `obj` is a hashable type.\n            If `None`, defaults to the store-wide setting.\n        skip_nonproxiable: Return non-proxiable types (e.g., built-in\n            constants like `bool` or `None`) rather than raising a\n            [`NonProxiableTypeError`][proxystore.store.exceptions.NonProxiableTypeError].\n        kwargs: Additional keyword arguments to pass to\n            [`Connector.put_batch()`][proxystore.connectors.protocols.Connector.put_batch].\n\n    Returns:\n        A list of proxies of each object or the object itself if said \\\n        object is not proxiable and `#!python skip_nonproxiable is True`.\n\n    Raises:\n        NonProxiableTypeError: If `obj` is a non-proxiable type. This\n            behavior can be overridden by setting\n            `#!python skip_nonproxiable=True`.\n        ValueError: If `evict` is `True` and `lifetime` is not `None`\n            because these parameters are mutually exclusive.\n    \"\"\"\n    if evict and lifetime is not None:\n        raise ValueError(\n            'The evict and lifetime parameters are mutually exclusive. '\n            'Only set one of evict or lifetime.',\n        )\n\n    with Timer() as timer:\n        # Find if there are non-proxiable types and if that's okay\n        non_proxiable: list[tuple[int, Any]] = []\n        for i, obj in enumerate(objs):\n            if isinstance(obj, _NON_PROXIABLE_TYPES):\n                non_proxiable.append((i, obj))\n\n        if len(non_proxiable) &gt; 0 and not skip_nonproxiable:\n            raise NonProxiableTypeError(\n                f'Input sequence contains {len(non_proxiable)} '\n                'objects that are not proxiable.',\n            )\n\n        # Pop non-proxiable types so we can batch proxy the proxiable ones\n        non_proxiable_indicies = [i for i, _ in non_proxiable]\n        proxiable_objs = [\n            obj\n            for i, obj in enumerate(objs)\n            if i not in non_proxiable_indicies\n        ]\n\n        keys = self.put_batch(\n            proxiable_objs,\n            serializer=serializer,\n            **kwargs,\n        )\n        factories: list[StoreFactory[ConnectorT, T]] = [\n            StoreFactory(\n                key,\n                store_config=self.config(),\n                evict=evict,\n                deserializer=deserializer,\n            )\n            for key in keys\n        ]\n\n        populate_target = (\n            self._populate_target\n            if populate_target is None\n            else populate_target\n        )\n\n        proxies: list[Proxy[T]] = []\n        for factory, obj in zip(factories, proxiable_objs):\n            if populate_target:\n                proxy = Proxy(factory, cache_defaults=True, target=obj)\n            else:\n                proxy = Proxy(factory)\n            proxies.append(proxy)\n\n        if lifetime is not None:\n            lifetime.add_proxy(*proxies)\n\n        # Put non-proxiable objects back in their original positions.\n        # The indices of non_proxiable must still be sorted\n        for original_index, original_object in non_proxiable:\n            proxies.insert(original_index, original_object)\n\n    if self.metrics is not None:\n        self.metrics.add_time('store.proxy_batch', keys, timer.elapsed_ms)\n\n    logger.debug(\n        f'Store(name=\"{self.name}\"): PROXY_BATCH ({len(proxies)} items) '\n        f'in {timer.elapsed_ms:.3f} ms',\n    )\n    return cast(List[Union[Proxy[T], NonProxiableT]], proxies)\n</code></pre>"},{"location":"api/store/base/#proxystore.store.base.Store.proxy_from_key","title":"proxy_from_key()","text":"<pre><code>proxy_from_key(\n    key: ConnectorKeyT,\n    *,\n    evict: bool = False,\n    lifetime: Lifetime | None = None,\n    deserializer: DeserializerT | None = None\n) -&gt; Proxy[T]\n</code></pre> <p>Create a proxy that will resolve to an object already in the store.</p> <p>Parameters:</p> <ul> <li> <code>key</code>             (<code>ConnectorKeyT</code>)         \u2013          <p>The key associated with an object already in the store.</p> </li> <li> <code>evict</code>             (<code>bool</code>, default:                 <code>False</code> )         \u2013          <p>If the proxy should evict the object once resolved. Mutually exclusive with the <code>lifetime</code> parameter.</p> </li> <li> <code>lifetime</code>             (<code>Lifetime | None</code>, default:                 <code>None</code> )         \u2013          <p>Attach the proxy to this lifetime. The object associated with the proxy will be evicted when the lifetime ends. Mutually exclusive with the <code>evict</code> parameter.</p> </li> <li> <code>deserializer</code>             (<code>DeserializerT | None</code>, default:                 <code>None</code> )         \u2013          <p>Optionally override the default deserializer for the store instance.</p> </li> </ul> <p>Returns:</p> <ul> <li> <code>Proxy[T]</code>         \u2013          <p>A proxy of the object.</p> </li> </ul> <p>Raises:</p> <ul> <li> <code>ValueError</code>           \u2013          <p>If <code>evict</code> is <code>True</code> and <code>lifetime</code> is not <code>None</code> because these parameters are mutually exclusive.</p> </li> </ul> Source code in <code>proxystore/store/base.py</code> <pre><code>def proxy_from_key(\n    self,\n    key: ConnectorKeyT,\n    *,\n    evict: bool = False,\n    lifetime: Lifetime | None = None,\n    deserializer: DeserializerT | None = None,\n) -&gt; Proxy[T]:\n    \"\"\"Create a proxy that will resolve to an object already in the store.\n\n    Args:\n        key: The key associated with an object already in the store.\n        evict: If the proxy should evict the object once resolved.\n            Mutually exclusive with the `lifetime` parameter.\n        lifetime: Attach the proxy to this lifetime. The object associated\n            with the proxy will be evicted when the lifetime ends.\n            Mutually exclusive with the `evict` parameter.\n        deserializer: Optionally override the default deserializer for the\n            store instance.\n\n    Returns:\n        A proxy of the object.\n\n    Raises:\n        ValueError: If `evict` is `True` and `lifetime` is not `None`\n            because these parameters are mutually exclusive.\n    \"\"\"\n    if evict and lifetime is not None:\n        raise ValueError(\n            'The evict and lifetime parameters are mutually exclusive. '\n            'Only set one of evict or lifetime.',\n        )\n\n    factory: StoreFactory[ConnectorT, T] = StoreFactory(\n        key,\n        store_config=self.config(),\n        deserializer=deserializer,\n        evict=evict,\n    )\n    proxy = Proxy(factory)\n\n    logger.debug(f'Store(name=\"{self.name}\"): PROXY_FROM_KEY {key}')\n\n    if lifetime is not None:\n        lifetime.add_proxy(proxy)\n\n    return proxy\n</code></pre>"},{"location":"api/store/base/#proxystore.store.base.Store.locked_proxy","title":"locked_proxy()","text":"<pre><code>locked_proxy(\n    obj: T | NonProxiableT,\n    *,\n    evict: bool = False,\n    lifetime: Lifetime | None = None,\n    serializer: SerializerT | None = None,\n    deserializer: DeserializerT | None = None,\n    populate_target: bool | None = None,\n    skip_nonproxiable: bool = True,\n    **kwargs: Any\n) -&gt; ProxyLocker[T] | NonProxiableT\n</code></pre> <p>Proxy an object and return <code>ProxyLocker</code>.</p> <p>Parameters:</p> <ul> <li> <code>obj</code>             (<code>T | NonProxiableT</code>)         \u2013          <p>The object to place in store and return a proxy for.</p> </li> <li> <code>evict</code>             (<code>bool</code>, default:                 <code>False</code> )         \u2013          <p>If the proxy should evict the object once resolved. Mutually exclusive with the <code>lifetime</code> parameter.</p> </li> <li> <code>lifetime</code>             (<code>Lifetime | None</code>, default:                 <code>None</code> )         \u2013          <p>Attach the proxy to this lifetime. The object associated with the proxy will be evicted when the lifetime ends. Mutually exclusive with the <code>evict</code> parameter.</p> </li> <li> <code>serializer</code>             (<code>SerializerT | None</code>, default:                 <code>None</code> )         \u2013          <p>Optionally override the default serializer for the store instance.</p> </li> <li> <code>deserializer</code>             (<code>DeserializerT | None</code>, default:                 <code>None</code> )         \u2013          <p>Optionally override the default deserializer for the store instance.</p> </li> <li> <code>populate_target</code>             (<code>bool | None</code>, default:                 <code>None</code> )         \u2013          <p>Pass <code>cache_defaults=True</code> and <code>target=obj</code> to the <code>Proxy</code> constructor. I.e., return a proxy that (1) is already resolved, (2) can be used in <code>isinstance</code> checks without resolving, and (3) is hashable without resolving if <code>obj</code> is a hashable type. If <code>None</code>, defaults to the store-wide setting.</p> </li> <li> <code>skip_nonproxiable</code>             (<code>bool</code>, default:                 <code>True</code> )         \u2013          <p>Return non-proxiable types (e.g., built-in constants like <code>bool</code> or <code>None</code>) rather than raising a <code>NonProxiableTypeError</code>.</p> </li> <li> <code>kwargs</code>             (<code>Any</code>, default:                 <code>{}</code> )         \u2013          <p>Additional keyword arguments to pass to <code>Connector.put()</code>.</p> </li> </ul> <p>Returns:</p> <ul> <li> <code>ProxyLocker[T] | NonProxiableT</code>         \u2013          <p>A proxy wrapped in a             <code>ProxyLocker</code> unless <code>obj</code> is a             non-proxiable type <code>skip_nonproxiable is True</code> in which             case <code>obj</code> is returned directly.</p> </li> </ul> <p>Raises:</p> <ul> <li> <code>NonProxiableTypeError</code>           \u2013          <p>If <code>obj</code> is a non-proxiable type. This behavior can be overridden by setting <code>skip_nonproxiable=True</code>.</p> </li> <li> <code>ValueError</code>           \u2013          <p>If <code>evict</code> is <code>True</code> and <code>lifetime</code> is not <code>None</code> because these parameters are mutually exclusive.</p> </li> </ul> Source code in <code>proxystore/store/base.py</code> <pre><code>def locked_proxy(\n    self,\n    obj: T | NonProxiableT,\n    *,\n    evict: bool = False,\n    lifetime: Lifetime | None = None,\n    serializer: SerializerT | None = None,\n    deserializer: DeserializerT | None = None,\n    populate_target: bool | None = None,\n    skip_nonproxiable: bool = True,\n    **kwargs: Any,\n) -&gt; ProxyLocker[T] | NonProxiableT:\n    \"\"\"Proxy an object and return [`ProxyLocker`][proxystore.proxy.ProxyLocker].\n\n    Args:\n        obj: The object to place in store and return a proxy for.\n        evict: If the proxy should evict the object once resolved.\n            Mutually exclusive with the `lifetime` parameter.\n        lifetime: Attach the proxy to this lifetime. The object associated\n            with the proxy will be evicted when the lifetime ends.\n            Mutually exclusive with the `evict` parameter.\n        serializer: Optionally override the default serializer for the\n            store instance.\n        deserializer: Optionally override the default deserializer for the\n            store instance.\n        populate_target: Pass `cache_defaults=True` and `target=obj` to\n            the [`Proxy`][proxystore.proxy.Proxy] constructor. I.e.,\n            return a proxy that (1) is already resolved, (2) can be used\n            in [`isinstance`][isinstance] checks without resolving, and (3)\n            is hashable without resolving if `obj` is a hashable type.\n            If `None`, defaults to the store-wide setting.\n        skip_nonproxiable: Return non-proxiable types (e.g., built-in\n            constants like `bool` or `None`) rather than raising a\n            [`NonProxiableTypeError`][proxystore.store.exceptions.NonProxiableTypeError].\n        kwargs: Additional keyword arguments to pass to\n            [`Connector.put()`][proxystore.connectors.protocols.Connector.put].\n\n    Returns:\n        A proxy wrapped in a \\\n        [`ProxyLocker`][proxystore.proxy.ProxyLocker] unless `obj` is a \\\n        non-proxiable type `#!python skip_nonproxiable is True` in which \\\n        case `obj` is returned directly.\n\n    Raises:\n        NonProxiableTypeError: If `obj` is a non-proxiable type. This\n            behavior can be overridden by setting\n            `#!python skip_nonproxiable=True`.\n        ValueError: If `evict` is `True` and `lifetime` is not `None`\n            because these parameters are mutually exclusive.\n    \"\"\"  # noqa: E501\n    possible_proxy = self.proxy(\n        obj,\n        evict=evict,\n        lifetime=lifetime,\n        serializer=serializer,\n        deserializer=deserializer,\n        populate_target=populate_target,\n        skip_nonproxiable=skip_nonproxiable,\n        **kwargs,\n    )\n\n    if isinstance(possible_proxy, Proxy):\n        return ProxyLocker(possible_proxy)\n    return possible_proxy\n</code></pre>"},{"location":"api/store/base/#proxystore.store.base.Store.owned_proxy","title":"owned_proxy()","text":"<pre><code>owned_proxy(\n    obj: T | NonProxiableT,\n    *,\n    serializer: SerializerT | None = None,\n    deserializer: DeserializerT | None = None,\n    populate_target: bool | None = None,\n    skip_nonproxiable: bool = True,\n    **kwargs: Any\n) -&gt; OwnedProxy[T] | NonProxiableT\n</code></pre> <p>Create a proxy that will enforce ownership rules over the object.</p> <p>An <code>OwnedProxy</code> will auto-evict the object once it goes out of scope. This proxy type can also be borrowed.</p> <p>Parameters:</p> <ul> <li> <code>obj</code>             (<code>T | NonProxiableT</code>)         \u2013          <p>The object to place in store and return a proxy for.</p> </li> <li> <code>serializer</code>             (<code>SerializerT | None</code>, default:                 <code>None</code> )         \u2013          <p>Optionally override the default serializer for the store instance.</p> </li> <li> <code>deserializer</code>             (<code>DeserializerT | None</code>, default:                 <code>None</code> )         \u2013          <p>Optionally override the default deserializer for the store instance.</p> </li> <li> <code>populate_target</code>             (<code>bool | None</code>, default:                 <code>None</code> )         \u2013          <p>Pass <code>cache_defaults=True</code> and <code>target=obj</code> to the <code>Proxy</code> constructor. I.e., return a proxy that (1) is already resolved, (2) can be used in <code>isinstance</code> checks without resolving, and (3) is hashable without resolving if <code>obj</code> is a hashable type. If <code>None</code>, defaults to the store-wide setting.</p> </li> <li> <code>skip_nonproxiable</code>             (<code>bool</code>, default:                 <code>True</code> )         \u2013          <p>Return non-proxiable types (e.g., built-in constants like <code>bool</code> or <code>None</code>) rather than raising a <code>NonProxiableTypeError</code>.</p> </li> <li> <code>kwargs</code>             (<code>Any</code>, default:                 <code>{}</code> )         \u2013          <p>Additional keyword arguments to pass to <code>Connector.put()</code>.</p> </li> </ul> <p>Returns:</p> <ul> <li> <code>OwnedProxy[T] | NonProxiableT</code>         \u2013          <p>A proxy of the object unless <code>obj</code> is a non-proxiable type             <code>skip_nonproxiable is True</code> in which case <code>obj</code> is             returned directly.</p> </li> </ul> <p>Raises:</p> <ul> <li> <code>NonProxiableTypeError</code>           \u2013          <p>If <code>obj</code> is a non-proxiable type. This behavior can be overridden by setting <code>skip_nonproxiable=True</code>.</p> </li> </ul> Source code in <code>proxystore/store/base.py</code> <pre><code>def owned_proxy(\n    self,\n    obj: T | NonProxiableT,\n    *,\n    serializer: SerializerT | None = None,\n    deserializer: DeserializerT | None = None,\n    populate_target: bool | None = None,\n    skip_nonproxiable: bool = True,\n    **kwargs: Any,\n) -&gt; OwnedProxy[T] | NonProxiableT:\n    \"\"\"Create a proxy that will enforce ownership rules over the object.\n\n    An [`OwnedProxy`][proxystore.store.ref.OwnedProxy] will auto-evict\n    the object once it goes out of scope. This proxy type can also\n    be borrowed.\n\n    Args:\n        obj: The object to place in store and return a proxy for.\n        serializer: Optionally override the default serializer for the\n            store instance.\n        deserializer: Optionally override the default deserializer for the\n            store instance.\n        populate_target: Pass `cache_defaults=True` and `target=obj` to\n            the [`Proxy`][proxystore.proxy.Proxy] constructor. I.e.,\n            return a proxy that (1) is already resolved, (2) can be used\n            in [`isinstance`][isinstance] checks without resolving, and (3)\n            is hashable without resolving if `obj` is a hashable type.\n            If `None`, defaults to the store-wide setting.\n        skip_nonproxiable: Return non-proxiable types (e.g., built-in\n            constants like `bool` or `None`) rather than raising a\n            [`NonProxiableTypeError`][proxystore.store.exceptions.NonProxiableTypeError].\n        kwargs: Additional keyword arguments to pass to\n            [`Connector.put()`][proxystore.connectors.protocols.Connector.put].\n\n    Returns:\n        A proxy of the object unless `obj` is a non-proxiable type \\\n        `#!python skip_nonproxiable is True` in which case `obj` is \\\n        returned directly.\n\n    Raises:\n        NonProxiableTypeError: If `obj` is a non-proxiable type. This\n            behavior can be overridden by setting\n            `#!python skip_nonproxiable=True`.\n    \"\"\"\n    possible_proxy = self.proxy(\n        obj,\n        evict=False,\n        serializer=serializer,\n        deserializer=deserializer,\n        populate_target=populate_target,\n        skip_nonproxiable=skip_nonproxiable,\n        **kwargs,\n    )\n\n    if isinstance(possible_proxy, Proxy):\n        populate_target = (\n            self._populate_target\n            if populate_target is None\n            else populate_target\n        )\n        return into_owned(possible_proxy, populate_target=populate_target)\n    return possible_proxy\n</code></pre>"},{"location":"api/store/base/#proxystore.store.base.Store.put","title":"put()","text":"<pre><code>put(\n    obj: Any,\n    *,\n    lifetime: Lifetime | None = None,\n    serializer: SerializerT | None = None,\n    **kwargs: Any\n) -&gt; ConnectorKeyT\n</code></pre> <p>Put an object in the store.</p> <p>Parameters:</p> <ul> <li> <code>obj</code>             (<code>Any</code>)         \u2013          <p>Object to put in the store.</p> </li> <li> <code>serializer</code>             (<code>SerializerT | None</code>, default:                 <code>None</code> )         \u2013          <p>Optionally override the default serializer for the store instance.</p> </li> <li> <code>lifetime</code>             (<code>Lifetime | None</code>, default:                 <code>None</code> )         \u2013          <p>Attach the key to this lifetime. The object associated with the key will be evicted when the lifetime ends.</p> </li> <li> <code>kwargs</code>             (<code>Any</code>, default:                 <code>{}</code> )         \u2013          <p>Additional keyword arguments to pass to <code>Connector.put()</code>.</p> </li> </ul> <p>Returns:</p> <ul> <li> <code>ConnectorKeyT</code>         \u2013          <p>A key which can be used to retrieve the object.</p> </li> </ul> <p>Raises:</p> <ul> <li> <code>TypeError</code>           \u2013          <p>If the output of <code>serializer</code> is not bytes.</p> </li> </ul> Source code in <code>proxystore/store/base.py</code> <pre><code>def put(\n    self,\n    obj: Any,\n    *,\n    lifetime: Lifetime | None = None,\n    serializer: SerializerT | None = None,\n    **kwargs: Any,\n) -&gt; ConnectorKeyT:\n    \"\"\"Put an object in the store.\n\n    Args:\n        obj: Object to put in the store.\n        serializer: Optionally override the default serializer for the\n            store instance.\n        lifetime: Attach the key to this lifetime. The object associated\n            with the key will be evicted when the lifetime ends.\n        kwargs: Additional keyword arguments to pass to\n            [`Connector.put()`][proxystore.connectors.protocols.Connector.put].\n\n    Returns:\n        A key which can be used to retrieve the object.\n\n    Raises:\n        TypeError: If the output of `serializer` is not bytes.\n    \"\"\"\n    timer = Timer()\n    timer.start()\n\n    with Timer() as serialize_timer:\n        if serializer is not None:\n            obj = serializer(obj)\n        else:\n            obj = self.serializer(obj)\n\n    if not isinstance(obj, bytes):\n        raise TypeError('Serializer must produce bytes.')\n\n    with Timer() as connector_timer:\n        key = self.connector.put(obj, **kwargs)\n\n    if lifetime is not None:\n        lifetime.add_key(key, store=self)\n\n    timer.stop()\n    if self.metrics is not None:\n        ctime = connector_timer.elapsed_ms\n        stime = serialize_timer.elapsed_ms\n        self.metrics.add_attribute('store.put.object_size', key, len(obj))\n        self.metrics.add_time('store.put.serialize', key, stime)\n        self.metrics.add_time('store.put.connector', key, ctime)\n        self.metrics.add_time('store.put', key, timer.elapsed_ms)\n\n    logger.debug(\n        f'Store(name=\"{self.name}\"): PUT {key} in '\n        f'{timer.elapsed_ms:.3f} ms',\n    )\n    return key\n</code></pre>"},{"location":"api/store/base/#proxystore.store.base.Store.put_batch","title":"put_batch()","text":"<pre><code>put_batch(\n    objs: Sequence[Any],\n    *,\n    lifetime: Lifetime | None = None,\n    serializer: SerializerT | None = None,\n    **kwargs: Any\n) -&gt; list[ConnectorKeyT]\n</code></pre> <p>Put multiple objects in the store.</p> <p>Parameters:</p> <ul> <li> <code>objs</code>             (<code>Sequence[Any]</code>)         \u2013          <p>Sequence of objects to put in the store.</p> </li> <li> <code>serializer</code>             (<code>SerializerT | None</code>, default:                 <code>None</code> )         \u2013          <p>Optionally override the default serializer for the store instance.</p> </li> <li> <code>lifetime</code>             (<code>Lifetime | None</code>, default:                 <code>None</code> )         \u2013          <p>Attach the keys to this lifetime. The objects associated with each key will be evicted when the lifetime ends.</p> </li> <li> <code>kwargs</code>             (<code>Any</code>, default:                 <code>{}</code> )         \u2013          <p>Additional keyword arguments to pass to <code>Connector.put_batch()</code>.</p> </li> </ul> <p>Returns:</p> <ul> <li> <code>list[ConnectorKeyT]</code>         \u2013          <p>A list of keys which can be used to retrieve the objects.</p> </li> </ul> <p>Raises:</p> <ul> <li> <code>TypeError</code>           \u2013          <p>If the output of <code>serializer</code> is not bytes.</p> </li> </ul> Source code in <code>proxystore/store/base.py</code> <pre><code>def put_batch(\n    self,\n    objs: Sequence[Any],\n    *,\n    lifetime: Lifetime | None = None,\n    serializer: SerializerT | None = None,\n    **kwargs: Any,\n) -&gt; list[ConnectorKeyT]:\n    \"\"\"Put multiple objects in the store.\n\n    Args:\n        objs: Sequence of objects to put in the store.\n        serializer: Optionally override the default serializer for the\n            store instance.\n        lifetime: Attach the keys to this lifetime. The objects associated\n            with each key will be evicted when the lifetime ends.\n        kwargs: Additional keyword arguments to pass to\n            [`Connector.put_batch()`][proxystore.connectors.protocols.Connector.put_batch].\n\n    Returns:\n        A list of keys which can be used to retrieve the objects.\n\n    Raises:\n        TypeError: If the output of `serializer` is not bytes.\n    \"\"\"\n    timer = Timer()\n    timer.start()\n\n    def _serialize(obj: Any) -&gt; bytes:\n        if serializer is not None:\n            obj = serializer(obj)\n        else:\n            obj = self.serializer(obj)\n\n        if not isinstance(obj, bytes):\n            raise TypeError('Serializer must produce bytes.')\n\n        return obj\n\n    with Timer() as serialize_timer:\n        _objs = list(map(_serialize, objs))\n\n    with Timer() as connector_timer:\n        keys = self.connector.put_batch(_objs, **kwargs)\n\n    if lifetime is not None:\n        lifetime.add_key(*keys, store=self)\n\n    timer.stop()\n    if self.metrics is not None:\n        ctime = connector_timer.elapsed_ms\n        stime = serialize_timer.elapsed_ms\n        sizes = sum(len(obj) for obj in _objs)\n        self.metrics.add_attribute(\n            'store.put_batch.object_sizes',\n            keys,\n            sizes,\n        )\n        self.metrics.add_time('store.put_batch.serialize', keys, stime)\n        self.metrics.add_time('store.put_batch.connector', keys, ctime)\n        self.metrics.add_time('store.put_batch', keys, timer.elapsed_ms)\n\n    logger.debug(\n        f'Store(name=\"{self.name}\"): PUT_BATCH ({len(keys)} items) in '\n        f'{timer.elapsed_ms:.3f} ms',\n    )\n    return keys\n</code></pre>"},{"location":"api/store/cache/","title":"proxystore.store.cache","text":"<code>proxystore/store/cache.py</code> <p>Simple Cache Implementation.</p>"},{"location":"api/store/cache/#proxystore.store.cache.LRUCache","title":"LRUCache","text":"<pre><code>LRUCache(maxsize: int = 16)\n</code></pre> <p>             Bases: <code>Generic[KeyT, ValueT]</code></p> <p>Simple LRU Cache.</p> <p>Parameters:</p> <ul> <li> <code>maxsize</code>             (<code>int</code>, default:                 <code>16</code> )         \u2013          <p>Maximum number of value to cache.</p> </li> </ul> <p>Raises:</p> <ul> <li> <code>ValueError</code>           \u2013          <p>If <code>maxsize &lt;= 0</code>.</p> </li> </ul> Source code in <code>proxystore/store/cache.py</code> <pre><code>def __init__(self, maxsize: int = 16) -&gt; None:\n    if maxsize &lt; 0:\n        raise ValueError('Cache size must by &gt;= 0')\n    self.maxsize = maxsize\n    self.data: dict[KeyT, ValueT] = {}\n    self.lru: list[KeyT] = []\n\n    # Count hits/misses\n    self.hits = 0\n    self.misses = 0\n</code></pre>"},{"location":"api/store/cache/#proxystore.store.cache.LRUCache.evict","title":"evict()","text":"<pre><code>evict(key: KeyT) -&gt; None\n</code></pre> <p>Evict key from cache.</p> Source code in <code>proxystore/store/cache.py</code> <pre><code>def evict(self, key: KeyT) -&gt; None:\n    \"\"\"Evict key from cache.\"\"\"\n    if key in self.data:\n        del self.data[key]\n        self.lru.remove(key)\n</code></pre>"},{"location":"api/store/cache/#proxystore.store.cache.LRUCache.exists","title":"exists()","text":"<pre><code>exists(key: KeyT) -&gt; bool\n</code></pre> <p>Check if key is in cache.</p> Source code in <code>proxystore/store/cache.py</code> <pre><code>def exists(self, key: KeyT) -&gt; bool:\n    \"\"\"Check if key is in cache.\"\"\"\n    return key in self.data\n</code></pre>"},{"location":"api/store/cache/#proxystore.store.cache.LRUCache.get","title":"get()","text":"<pre><code>get(\n    key: KeyT, default: ValueT | None = None\n) -&gt; ValueT | None\n</code></pre> <p>Get value for key if it exists else returns default.</p> Source code in <code>proxystore/store/cache.py</code> <pre><code>def get(self, key: KeyT, default: ValueT | None = None) -&gt; ValueT | None:\n    \"\"\"Get value for key if it exists else returns default.\"\"\"\n    if self.exists(key):\n        # Move to front b/c most recently used\n        self.hits += 1\n        self.lru.remove(key)\n        self.lru.insert(0, key)\n        return self.data[key]\n    else:\n        self.misses += 1\n        return default\n</code></pre>"},{"location":"api/store/cache/#proxystore.store.cache.LRUCache.set","title":"set()","text":"<pre><code>set(key: KeyT, value: ValueT) -&gt; None\n</code></pre> <p>Set key to value.</p> Source code in <code>proxystore/store/cache.py</code> <pre><code>def set(self, key: KeyT, value: ValueT) -&gt; None:\n    \"\"\"Set key to value.\"\"\"\n    if self.maxsize == 0:\n        return\n    if len(self.data) &gt;= self.maxsize:\n        lru_key = self.lru.pop()\n        del self.data[lru_key]\n    self.lru.insert(0, key)\n    self.data[key] = value\n</code></pre>"},{"location":"api/store/config/","title":"proxystore.store.config","text":"<code>proxystore/store/config.py</code> <p>Store configuration model.</p>"},{"location":"api/store/config/#proxystore.store.config.ConnectorConfig","title":"ConnectorConfig","text":"<p>             Bases: <code>BaseModel</code></p> <p>Connector configuration.</p> Example <pre><code>from proxystore.connectors.redis import RedisConnector\nfrom proxystore.store.config import ConnectorConfig\n\nconfig = ConnectorConfig(\n    kind='redis',\n    options={'hostname': 'localhost', 'port': 1234},\n)\n\nconnector = config.get_connector()\nassert isinstance(connector, RedisConnector)\n</code></pre> <p>Attributes:</p> <ul> <li> <code>kind</code>             (<code>str</code>)         \u2013          <p>Fully-qualified path used to import a <code>Connector</code> type or a shortened name for a builtin <code>Connector</code> type. E.g., <code>'file'</code> or <code>'FileConnector'</code> are valid shortcuts for <code>'proxystore.connectors.file.FileConnector'</code>.</p> </li> <li> <code>options</code>             (<code>Dict[str, Any]</code>)         \u2013          <p>Dictionary of keyword arguments to pass to the <code>Connector</code> constructor.</p> </li> </ul>"},{"location":"api/store/config/#proxystore.store.config.ConnectorConfig.get_connector_type","title":"get_connector_type()","text":"<pre><code>get_connector_type() -&gt; type[Connector[Any]]\n</code></pre> <p>Resolve the class type for the specified connector.</p> <p>This method works by first attempting to import the class by treating <code>kind</code> as a fully-qualified path. For example, if <code>kind='proxystore.connectors.local.LocalConnector'</code>, the <code>LocalConnector</code> is imported from <code>proxystore.connectors.local</code>.</p> <p>If the import fails, <code>kind</code> will be checked against a list of known (i.e., builtin) <code>Connector</code> types. <code>kind</code> will be psuedo-fuzzy matched against the class names of the known <code>Connector</code> types. For example, <code>kind='local'</code> and <code>kind='LocalConnector'</code> will both match to <code>'proxystore.connectors.local.LocalConnector'</code>.</p> <p>Returns:</p> <ul> <li> <code>type[Connector[Any]]</code>         \u2013          <p><code>Connector</code> type.</p> </li> </ul> <p>Raises:</p> <ul> <li> <code>ValueError</code>           \u2013          <p>If a <code>Connector</code> named <code>kind</code> failed to import or if <code>kind</code> does not match a builtin connector.</p> </li> </ul> Source code in <code>proxystore/store/config.py</code> <pre><code>def get_connector_type(self) -&gt; type[Connector[Any]]:\n    \"\"\"Resolve the class type for the specified connector.\n\n    This method works by first attempting to import the class\n    by treating `kind` as a fully-qualified path. For example,\n    if `kind='proxystore.connectors.local.LocalConnector'`, the\n    [`LocalConnector`][proxystore.connectors.local.LocalConnector] is\n    imported from\n    [`proxystore.connectors.local`][proxystore.connectors.local].\n\n    If the import fails, `kind` will be checked against a list of known\n    (i.e., builtin)\n    [`Connector`][proxystore.connectors.protocols.Connector] types.\n    `kind` will be psuedo-fuzzy matched against the class names of the\n    known [`Connector`][proxystore.connectors.protocols.Connector] types.\n    For example, `kind='local'` and `kind='LocalConnector'` will both\n    match to `'proxystore.connectors.local.LocalConnector'`.\n\n    Returns:\n        [`Connector`][proxystore.connectors.protocols.Connector] type.\n\n    Raises:\n        ValueError: If a\n            [`Connector`][proxystore.connectors.protocols.Connector]\n            named `kind` failed to import or if `kind` does not match\n            a builtin connector.\n    \"\"\"\n    try:\n        return import_from_path(self.kind)\n    except ImportError as e:\n        for path in _KNOWN_CONNECTORS:\n            _, name = path.rsplit('.', 1)\n            name = name.lower()\n            choices = [name, name.replace('connector', '')]\n            if self.kind.lower() in choices:\n                return import_from_path(path)\n        raise ValueError(f'Unknown connector type \"{self.kind}\".') from e\n</code></pre>"},{"location":"api/store/config/#proxystore.store.config.ConnectorConfig.get_connector","title":"get_connector()","text":"<pre><code>get_connector() -&gt; Connector[Any]\n</code></pre> <p>Get the connector specified by the configuration.</p> <p>Returns:</p> <ul> <li> <code>Connector[Any]</code>         \u2013          <p>A <code>Connector</code>             instance.</p> </li> </ul> Source code in <code>proxystore/store/config.py</code> <pre><code>def get_connector(self) -&gt; Connector[Any]:\n    \"\"\"Get the connector specified by the configuration.\n\n    Returns:\n        A [`Connector`][proxystore.connectors.protocols.Connector] \\\n        instance.\n    \"\"\"\n    connector_type = self.get_connector_type()\n    return connector_type(**self.options)\n</code></pre>"},{"location":"api/store/config/#proxystore.store.config.StoreConfig","title":"StoreConfig","text":"<p>             Bases: <code>BaseModel</code></p> <p>Store configuration.</p> Tip <p>See the <code>Store</code> parameters for more information about each configuration option.</p> <p>Attributes:</p> <ul> <li> <code>name</code>             (<code>str</code>)         \u2013          <p>Store name.</p> </li> <li> <code>connector</code>             (<code>ConnectorConfig</code>)         \u2013          <p>Connector configuration.</p> </li> <li> <code>serializer</code>             (<code>Optional[SerializerT]</code>)         \u2013          <p>Optional serializer.</p> </li> <li> <code>deserializer</code>             (<code>Optional[DeserializerT]</code>)         \u2013          <p>Optional deserializer.</p> </li> <li> <code>cache_size</code>             (<code>int</code>)         \u2013          <p>Cache size.</p> </li> <li> <code>metrics</code>             (<code>bool</code>)         \u2013          <p>Enable recording operation metrics.</p> </li> <li> <code>populate_target</code>             (<code>bool</code>)         \u2013          <p>Set the default value for the <code>populate_target</code> parameter of proxy methods.</p> </li> <li> <code>auto_register</code>             (<code>bool</code>)         \u2013          <p>Auto-register the store.</p> </li> </ul>"},{"location":"api/store/config/#proxystore.store.config.StoreConfig.from_toml","title":"from_toml()  <code>classmethod</code>","text":"<pre><code>from_toml(filepath: str | Path) -&gt; Self\n</code></pre> <p>Create a configuration file from a TOML file.</p> Example <p>See <code>write_toml()</code>.</p> <p>Parameters:</p> <ul> <li> <code>filepath</code>             (<code>str | Path</code>)         \u2013          <p>Path to TOML file to load.</p> </li> </ul> Source code in <code>proxystore/store/config.py</code> <pre><code>@classmethod\ndef from_toml(cls, filepath: str | pathlib.Path) -&gt; Self:\n    \"\"\"Create a configuration file from a TOML file.\n\n    Example:\n        See\n        [`write_toml()`][proxystore.store.config.StoreConfig.write_toml].\n\n    Args:\n        filepath: Path to TOML file to load.\n    \"\"\"\n    with open(filepath, 'rb') as f:\n        return load(cls, f)\n</code></pre>"},{"location":"api/store/config/#proxystore.store.config.StoreConfig.write_toml","title":"write_toml()","text":"<pre><code>write_toml(filepath: str | Path) -&gt; None\n</code></pre> <p>Write a configuration to a TOML file.</p> Example <p><pre><code>from proxystore.store.config import ConnectorConfig\nfrom proxystore.store.config import StoreConfig\n\nconfig = StoreConfig(\n    name='example',\n    connector=ConnectorConfig(\n        kind='file',\n        options={'store_dir': '/tmp/proxystore-cache'},\n    ),\n)\n\nconfig.write_toml('config.toml')\n</code></pre> The resulting TOML file contains the full configuration, including default options, and can be loaded again using <code>StoreConfig.from_toml('config.toml')</code>. config.toml<pre><code>name = \"example\"\ncache_size = 16\nmetrics = false\npopulate_target = true\nauto_register = false\n\n[connector]\nkind = \"file\"\n\n[connector.options]\nstore_dir = \"/tmp/proxystore-cache\"\n</code></pre></p> <p>Parameters:</p> <ul> <li> <code>filepath</code>             (<code>str | Path</code>)         \u2013          <p>Path to TOML file to write.</p> </li> </ul> Source code in <code>proxystore/store/config.py</code> <pre><code>def write_toml(self, filepath: str | pathlib.Path) -&gt; None:\n    \"\"\"Write a configuration to a TOML file.\n\n    Example:\n        ```python\n        from proxystore.store.config import ConnectorConfig\n        from proxystore.store.config import StoreConfig\n\n        config = StoreConfig(\n            name='example',\n            connector=ConnectorConfig(\n                kind='file',\n                options={'store_dir': '/tmp/proxystore-cache'},\n            ),\n        )\n\n        config.write_toml('config.toml')\n        ```\n        The resulting TOML file contains the full configuration,\n        including default options, and can be loaded again\n        using `#!python StoreConfig.from_toml('config.toml')`.\n        ```toml title=\"config.toml\"\n        name = \"example\"\n        cache_size = 16\n        metrics = false\n        populate_target = true\n        auto_register = false\n\n        [connector]\n        kind = \"file\"\n\n        [connector.options]\n        store_dir = \"/tmp/proxystore-cache\"\n        ```\n\n    Args:\n        filepath: Path to TOML file to write.\n    \"\"\"\n    filepath = pathlib.Path(filepath)\n    filepath.parent.mkdir(parents=True, exist_ok=True)\n    with open(filepath, 'wb') as f:\n        dump(self, f)\n</code></pre>"},{"location":"api/store/exceptions/","title":"proxystore.store.exceptions","text":"<code>proxystore/store/exceptions.py</code> <p>Exceptions for Stores.</p>"},{"location":"api/store/exceptions/#proxystore.store.exceptions.StoreError","title":"StoreError","text":"<p>             Bases: <code>Exception</code></p> <p>Base exception class for store errors.</p>"},{"location":"api/store/exceptions/#proxystore.store.exceptions.StoreExistsError","title":"StoreExistsError","text":"<p>             Bases: <code>StoreError</code></p> <p>Exception raised when a store with the same name already exists.</p>"},{"location":"api/store/exceptions/#proxystore.store.exceptions.ProxyStoreFactoryError","title":"ProxyStoreFactoryError","text":"<p>             Bases: <code>StoreError</code></p> <p>Exception raised when a proxy was not created by a Store.</p>"},{"location":"api/store/exceptions/#proxystore.store.exceptions.ProxyResolveMissingKeyError","title":"ProxyResolveMissingKeyError","text":"<pre><code>ProxyResolveMissingKeyError(\n    key: ConnectorKeyT,\n    store_type: type[Store[Any]],\n    store_name: str,\n)\n</code></pre> <p>             Bases: <code>Exception</code></p> <p>Exception raised when the key associated with a proxy is missing.</p> <p>Init ProxyResolveMissingKeyError.</p> <p>Parameters:</p> <ul> <li> <code>key</code>             (<code>ConnectorKeyT</code>)         \u2013          <p>Key associated with target object that could not be found in the store.</p> </li> <li> <code>store_type</code>             (<code>type[Store[Any]]</code>)         \u2013          <p>Type of store that the key could not be found in.</p> </li> <li> <code>store_name</code>             (<code>str</code>)         \u2013          <p>Name of store that the key could not be found in.</p> </li> </ul> Source code in <code>proxystore/store/exceptions.py</code> <pre><code>def __init__(\n    self,\n    key: base.ConnectorKeyT,\n    store_type: type[base.Store[Any]],\n    store_name: str,\n) -&gt; None:\n    \"\"\"Init ProxyResolveMissingKeyError.\n\n    Args:\n        key: Key associated with target object that could not be found in\n            the store.\n        store_type: Type of store that the key could not be found in.\n        store_name: Name of store that the key could not be found in.\n    \"\"\"\n    self.key = key\n    self.store_type = store_type\n    self.store_name = store_name\n    super().__init__(\n        f\"Proxy cannot resolve target object with key='{self.key}' \"\n        f\"from {self.store_type.__name__}(name='{self.store_name}'): \"\n        'store returned NoneType with key.',\n    )\n</code></pre>"},{"location":"api/store/exceptions/#proxystore.store.exceptions.NonProxiableTypeError","title":"NonProxiableTypeError","text":"<p>             Bases: <code>Exception</code></p> <p>Exception raised when proxying an unproxiable type.</p>"},{"location":"api/store/executor/","title":"proxystore.store.executor","text":"<code>proxystore/store/executor.py</code> <p>Executor wrapper that automatically proxies input and output objects.</p> <p>The following example wraps a <code>ProcessPoolExecutor</code> to automatically proxy certain input and output values. Here, we create a <code>Store</code> using a <code>FileConnector</code>. <code>StoreExecutor</code> takes a <code>should_proxy</code> argument which is a callable used to determine which inputs and output values should be proxied. In this example, we use <code>ProxyType(str)</code> which cause only instances of <code>str</code> to be proxied. All other input or output types will be ignored.</p> <pre><code>from concurrent.futures import ProcessPoolExecutor\n\nfrom proxystore.connectors.file import FileConnector\nfrom proxystore.proxy import Proxy\nfrom proxystore.store import Store\nfrom proxystore.store.executor import StoreExecutor, ProxyType\n\nbase_executor = ProcessPoolExecutor()\nstore = Store('executor-example', FileConnector('./object-cache'))\n\ndef concat(base: str, *, num: int) -&gt; str:\n    return f'{base}-{num}'\n\nwith StoreExecutor(\n    base_executor,\n    store=store,\n    should_proxy=ProxyType(str),\n) as executor:\n    future = executor.submit(concat, 'foobar', num=42)\n    result = future.result()\n\n    assert isinstance(result, Proxy)\n    assert result == 'foobar-42'\n</code></pre> <p>The execution of <code>concat</code>, above, uses a <code>str</code> and <code>int</code> inputs and produces a <code>str</code> output. Because we configured the <code>StoreExecutor</code> to proxy only <code>str</code> instances, only the str input and output were proxied. The <code>int</code> input was not proxied.</p> <p>The <code>should_proxy</code> callable passed to <code>StoreExecutor</code> can be as complicated as you want. For example, you could write one which checks if an array is larger than some threshold.</p>"},{"location":"api/store/executor/#proxystore.store.executor.ProxyAlways","title":"ProxyAlways","text":"<p>Should-proxy callable which always returns <code>True</code>.</p>"},{"location":"api/store/executor/#proxystore.store.executor.ProxyNever","title":"ProxyNever","text":"<p>Should-proxy callable which always returns <code>False</code>.</p>"},{"location":"api/store/executor/#proxystore.store.executor.ProxyType","title":"ProxyType","text":"<pre><code>ProxyType(*types: type)\n</code></pre> <p>Proxy objects with matching types.</p> Example <pre><code>from proxystore.store.executor import ProxyType\n\nshould_proxy = ProxyType(float, str)\nassert not should_proxy([1, 2, 3])\nassert should_proxy(3.14)\nassert should_proxy('Hello, World!')\n</code></pre> <p>Parameters:</p> <ul> <li> <code>types</code>             (<code>type</code>, default:                 <code>()</code> )         \u2013          <p>Variable number of object types for which objects of that type should be proxied.</p> </li> </ul> Source code in <code>proxystore/store/executor.py</code> <pre><code>def __init__(self, *types: type) -&gt; None:\n    self.types = types\n</code></pre>"},{"location":"api/store/executor/#proxystore.store.executor.StoreExecutor","title":"StoreExecutor","text":"<pre><code>StoreExecutor(\n    executor: Executor,\n    store: Store[Any],\n    should_proxy: Callable[[Any], bool] | None = None,\n    *,\n    ownership: bool = True,\n    close_store: bool = True\n)\n</code></pre> <p>             Bases: <code>Executor</code></p> <p>Executor wrapper that automatically proxies arguments and results.</p> <p>By default, the <code>StoreExecutor</code> will automatically manage the memory of proxied objects by evicting proxied inputs after execution has completed (via callbacks on the futures) and using Ownership for result values.</p> <p>Parameters:</p> <ul> <li> <code>executor</code>             (<code>Executor</code>)         \u2013          <p>Executor to use for scheduling callables. This class takes ownership of <code>executor</code>, meaning that, when closed, it will also close <code>executor</code>.</p> </li> <li> <code>store</code>             (<code>Store[Any]</code>)         \u2013          <p>Store to use for proxying arguments and results. This class takes ownership of <code>store</code>, meaning that, when closed, it will also close <code>store</code>.</p> </li> <li> <code>should_proxy</code>             (<code>Callable[[Any], bool] | None</code>, default:                 <code>None</code> )         \u2013          <p>Callable used to determine which arguments and results should be proxied. This is only applied to positional arguments, keyword arguments, and return values. Container types will not be recursively checked. The callable must be serializable. <code>None</code> defaults to <code>ProxyNever</code>.</p> </li> <li> <code>ownership</code>             (<code>bool</code>, default:                 <code>True</code> )         \u2013          <p>Use <code>OwnedProxy</code> for result values rather than <code>Proxy</code> types. <code>OwnedProxy</code> types will evict the proxied data from the store when they get garbage collected. If <code>False</code> and default proxies are used, it is the responsibility of the caller to clean up data associated with any result proxies.</p> </li> <li> <code>close_store</code>             (<code>bool</code>, default:                 <code>True</code> )         \u2013          <p>Close <code>store</code> when this executor is closed.</p> </li> </ul> Source code in <code>proxystore/store/executor.py</code> <pre><code>def __init__(\n    self,\n    executor: Executor,\n    store: Store[Any],\n    should_proxy: Callable[[Any], bool] | None = None,\n    *,\n    ownership: bool = True,\n    close_store: bool = True,\n) -&gt; None:\n    if should_proxy is None:\n        should_proxy = ProxyNever()\n\n    self.executor = executor\n    self.store = store\n    self.should_proxy: Callable[[Any], bool] = should_proxy\n    self.ownership = ownership\n    self.close_store = close_store\n\n    self._registered: dict[\n        Callable[..., Any],\n        _FunctionWrapper[Any, Any],\n    ] = {}\n</code></pre>"},{"location":"api/store/executor/#proxystore.store.executor.StoreExecutor.submit","title":"submit()","text":"<pre><code>submit(\n    function: Callable[P, R],\n    /,\n    *args: args,\n    **kwargs: kwargs,\n) -&gt; Future[R | Proxy[R]]\n</code></pre> <p>Schedule the callable to be executed.</p> <p>Parameters:</p> <ul> <li> <code>function</code>             (<code>Callable[P, R]</code>)         \u2013          <p>Callable to execute.</p> </li> <li> <code>args</code>             (<code>args</code>, default:                 <code>()</code> )         \u2013          <p>Positional arguments.</p> </li> <li> <code>kwargs</code>             (<code>kwargs</code>, default:                 <code>{}</code> )         \u2013          <p>Keyword arguments.</p> </li> </ul> <p>Returns:</p> <ul> <li> <code>Future[R | Proxy[R]]</code>         \u2013          <p><code>Future</code> representing             the result of the execution of the callable.</p> </li> </ul> Source code in <code>proxystore/store/executor.py</code> <pre><code>def submit(\n    self,\n    function: Callable[P, R],\n    /,\n    *args: P.args,\n    **kwargs: P.kwargs,\n) -&gt; Future[R | Proxy[R]]:\n    \"\"\"Schedule the callable to be executed.\n\n    Args:\n        function: Callable to execute.\n        args: Positional arguments.\n        kwargs: Keyword arguments.\n\n    Returns:\n        [`Future`][concurrent.futures.Future] representing \\\n        the result of the execution of the callable.\n    \"\"\"\n    # We cast the transformed args and kwargs back to P.args and P.kwargs,\n    # but note that those types aren't exactly correct. Some items\n    # may be Proxy[T] rather than T, but this is not practicle to type.\n    pargs, keys1 = _proxy_iterable(args, self.store, self.should_proxy)\n    pargs = cast(P.args, pargs)\n\n    pkwargs, keys2 = _proxy_mapping(kwargs, self.store, self.should_proxy)\n    pkwargs = cast(P.kwargs, pkwargs)\n\n    wrapped = self._wrapped(function)\n    future = self.executor.submit(wrapped, *pargs, **pkwargs)\n\n    future.add_done_callback(_evict_callback(self.store, keys1 + keys2))\n    return future\n</code></pre>"},{"location":"api/store/executor/#proxystore.store.executor.StoreExecutor.map","title":"map()","text":"<pre><code>map(\n    function: Callable[P, R],\n    *iterables: Iterable[args],\n    timeout: float | None = None,\n    chunksize: int = 1\n) -&gt; Iterator[R | Proxy[R]]\n</code></pre> <p>Map a function onto iterables of arguments.</p> <p>Parameters:</p> <ul> <li> <code>function</code>             (<code>Callable[P, R]</code>)         \u2013          <p>A callable that will take as many arguments as there are passed iterables.</p> </li> <li> <code>iterables</code>             (<code>Iterable[args]</code>, default:                 <code>()</code> )         \u2013          <p>Variable number of iterables.</p> </li> <li> <code>timeout</code>             (<code>float | None</code>, default:                 <code>None</code> )         \u2013          <p>The maximum number of seconds to wait. If None, then there is no limit on the wait time.</p> </li> <li> <code>chunksize</code>             (<code>int</code>, default:                 <code>1</code> )         \u2013          <p>Sets the Dask batch size.</p> </li> </ul> <p>Returns:</p> <ul> <li> <code>Iterator[R | Proxy[R]]</code>         \u2013          <p>An iterator equivalent to: <code>map(func, *iterables)</code> but the calls             may be evaluated out-of-order.</p> </li> </ul> Source code in <code>proxystore/store/executor.py</code> <pre><code>def map(\n    self,\n    function: Callable[P, R],\n    *iterables: Iterable[P.args],\n    timeout: float | None = None,\n    chunksize: int = 1,\n) -&gt; Iterator[R | Proxy[R]]:\n    \"\"\"Map a function onto iterables of arguments.\n\n    Args:\n        function: A callable that will take as many arguments as there are\n            passed iterables.\n        iterables: Variable number of iterables.\n        timeout: The maximum number of seconds to wait. If None, then there\n            is no limit on the wait time.\n        chunksize: Sets the Dask batch size.\n\n    Returns:\n        An iterator equivalent to: `map(func, *iterables)` but the calls \\\n        may be evaluated out-of-order.\n    \"\"\"\n    iterables, keys = _proxy_iterable(\n        iterables,\n        self.store,\n        self.should_proxy,\n    )\n\n    wrapped = self._wrapped(function)\n    results = self.executor.map(\n        wrapped,\n        *iterables,\n        timeout=timeout,\n        chunksize=chunksize,\n    )\n\n    def _result_iterator() -&gt; Generator[R, None, None]:\n        yield from results\n\n        # Wait to evict input proxies until all results have been received.\n        # Waiting is needed because there is no guarantee what order tasks\n        # complete in.\n        for key in keys:\n            self.store.evict(key)\n\n    return _result_iterator()\n</code></pre>"},{"location":"api/store/executor/#proxystore.store.executor.StoreExecutor.shutdown","title":"shutdown()","text":"<pre><code>shutdown(\n    wait: bool = True, *, cancel_futures: bool = False\n) -&gt; None\n</code></pre> <p>Shutdown the executor and close the store.</p> Warning <p>This will close the <code>Store</code> passed to this <code>StoreExecutor</code> instance if <code>close_store=True</code>, but it is possible the store is reinitialized again if <code>ownership=True</code> was configured and <code>register=True</code> was passed to the store. Any <code>OwnedProxy</code> instances returned by functions invoked through this executor that are still alive will evict themselves once they are garbage collected. Eviction requires a store instance so the garbage collection processes can inadvertently reinitialize and register a store that was previously closed.</p> <p>Parameters:</p> <ul> <li> <code>wait</code>             (<code>bool</code>, default:                 <code>True</code> )         \u2013          <p>Wait on all pending futures to complete.</p> </li> <li> <code>cancel_futures</code>             (<code>bool</code>, default:                 <code>False</code> )         \u2013          <p>Cancel all pending futures that the executor has not started running. Only used in Python 3.9 and later.</p> </li> </ul> Source code in <code>proxystore/store/executor.py</code> <pre><code>def shutdown(\n    self,\n    wait: bool = True,\n    *,\n    cancel_futures: bool = False,\n) -&gt; None:\n    \"\"\"Shutdown the executor and close the store.\n\n    Warning:\n        This will close the [`Store`][proxystore.store.base.Store] passed\n        to this [`StoreExecutor`][proxystore.store.executor.StoreExecutor]\n        instance if `close_store=True`, but it is possible the store is\n        reinitialized again if `ownership=True` was configured and\n        `register=True` was passed to the store. Any\n        [`OwnedProxy`][proxystore.store.ref.OwnedProxy]\n        instances returned by functions invoked through this executor that\n        are still alive will evict themselves once they are garbage\n        collected. Eviction requires a store instance so the garbage\n        collection processes can inadvertently reinitialize and register\n        a store that was previously closed.\n\n    Args:\n        wait: Wait on all pending futures to complete.\n        cancel_futures: Cancel all pending futures that the executor\n            has not started running. Only used in Python 3.9 and later.\n    \"\"\"\n    if sys.version_info &gt;= (3, 9):  # pragma: &gt;=3.9 cover\n        self.executor.shutdown(wait=wait, cancel_futures=cancel_futures)\n    else:  # pragma: &lt;3.9 cover\n        self.executor.shutdown(wait=wait)\n\n    if self.close_store:\n        self.store.close()\n</code></pre>"},{"location":"api/store/factory/","title":"proxystore.store.factory","text":"<code>proxystore/store/factory.py</code> <p>Factory implementations.</p>"},{"location":"api/store/factory/#proxystore.store.factory.StoreFactory","title":"StoreFactory","text":"<pre><code>StoreFactory(\n    key: ConnectorKeyT,\n    store_config: StoreConfig,\n    *,\n    evict: bool = False,\n    deserializer: DeserializerT | None = None\n)\n</code></pre> <p>             Bases: <code>Generic[ConnectorT, T]</code></p> <p>Factory that resolves an object from a store.</p> <p>Adds support for asynchronously retrieving objects from a <code>Store</code> instance.</p> <p>The factory takes the <code>store_config</code> parameter that is used to reinitialize the store if the factory is sent to a remote process where the store has not already been initialized.</p> <p>Parameters:</p> <ul> <li> <code>key</code>             (<code>ConnectorKeyT</code>)         \u2013          <p>Key corresponding to object in store.</p> </li> <li> <code>store_config</code>             (<code>StoreConfig</code>)         \u2013          <p>Store configuration used to reinitialize the store if needed.</p> </li> <li> <code>evict</code>             (<code>bool</code>, default:                 <code>False</code> )         \u2013          <p>If True, evict the object from the store once <code>resolve()</code> is called.</p> </li> <li> <code>deserializer</code>             (<code>DeserializerT | None</code>, default:                 <code>None</code> )         \u2013          <p>Optional callable used to deserialize the byte string. If <code>None</code>, the default deserializer (<code>deserialize()</code>) will be used.</p> </li> </ul> Source code in <code>proxystore/store/factory.py</code> <pre><code>def __init__(\n    self,\n    key: ConnectorKeyT,\n    store_config: StoreConfig,\n    *,\n    evict: bool = False,\n    deserializer: DeserializerT | None = None,\n) -&gt; None:\n    self.key = key\n    self.store_config = store_config\n    self.evict = evict\n    self.deserializer = deserializer\n\n    # The following are not included when a factory is serialized\n    # because they are specific to that instance of the factory\n    self._obj_future: Future[T] | None = None\n</code></pre>"},{"location":"api/store/factory/#proxystore.store.factory.StoreFactory.get_store","title":"get_store()","text":"<pre><code>get_store() -&gt; Store[ConnectorT]\n</code></pre> <p>Get store and reinitialize if necessary.</p> Source code in <code>proxystore/store/factory.py</code> <pre><code>def get_store(self) -&gt; Store[ConnectorT]:\n    \"\"\"Get store and reinitialize if necessary.\"\"\"\n    return proxystore.store.get_or_create_store(\n        self.store_config,\n        register=True,\n    )\n</code></pre>"},{"location":"api/store/factory/#proxystore.store.factory.StoreFactory.resolve","title":"resolve()","text":"<pre><code>resolve() -&gt; T\n</code></pre> <p>Get object associated with key from store.</p> <p>Raises:</p> <ul> <li> <code>ProxyResolveMissingKeyError</code>           \u2013          <p>If the key associated with this factory does not exist in the store.</p> </li> </ul> Source code in <code>proxystore/store/factory.py</code> <pre><code>def resolve(self) -&gt; T:\n    \"\"\"Get object associated with key from store.\n\n    Raises:\n        ProxyResolveMissingKeyError: If the key associated with this\n            factory does not exist in the store.\n    \"\"\"\n    with Timer() as timer:\n        store = self.get_store()\n        obj = store.get(\n            self.key,\n            deserializer=self.deserializer,\n            default=_MISSING_OBJECT,\n        )\n\n        if obj is _MISSING_OBJECT:\n            raise ProxyResolveMissingKeyError(\n                self.key,\n                type(store),\n                store.name,\n            )\n\n        if self.evict:\n            store.evict(self.key)\n\n    if store.metrics is not None:\n        total_time = timer.elapsed_ns\n        store.metrics.add_time('factory.resolve', self.key, total_time)\n\n    return cast(T, obj)\n</code></pre>"},{"location":"api/store/factory/#proxystore.store.factory.StoreFactory.resolve_async","title":"resolve_async()","text":"<pre><code>resolve_async() -&gt; None\n</code></pre> <p>Asynchronously get object associated with key from store.</p> Source code in <code>proxystore/store/factory.py</code> <pre><code>def resolve_async(self) -&gt; None:\n    \"\"\"Asynchronously get object associated with key from store.\"\"\"\n    logger.debug(f'Starting asynchronous resolve of {self.key}')\n    self._obj_future = _default_pool.submit(self.resolve)\n</code></pre>"},{"location":"api/store/factory/#proxystore.store.factory.PollingStoreFactory","title":"PollingStoreFactory","text":"<pre><code>PollingStoreFactory(\n    key: ConnectorKeyT,\n    store_config: StoreConfig,\n    *,\n    deserializer: DeserializerT | None = None,\n    evict: bool = False,\n    polling_interval: float = 1,\n    polling_backoff_factor: float = 1,\n    polling_interval_limit: float | None = None,\n    polling_timeout: float | None = None\n)\n</code></pre> <p>             Bases: <code>StoreFactory[ConnectorT, T]</code></p> <p>Factory that polls a store until and object can be resolved.</p> <p>This is an extension of the <code>StoreFactory</code> with the <code>resolve()</code> method overridden to poll the store until the target object is available.</p> <p>Parameters:</p> <ul> <li> <code>key</code>             (<code>ConnectorKeyT</code>)         \u2013          <p>Key corresponding to object in store.</p> </li> <li> <code>store_config</code>             (<code>StoreConfig</code>)         \u2013          <p>Store configuration used to reinitialize the store if needed.</p> </li> <li> <code>deserializer</code>             (<code>DeserializerT | None</code>, default:                 <code>None</code> )         \u2013          <p>Optional callable used to deserialize the byte string. If <code>None</code>, the default deserializer (<code>deserialize()</code>) will be used.</p> </li> <li> <code>evict</code>             (<code>bool</code>, default:                 <code>False</code> )         \u2013          <p>If True, evict the object from the store once <code>resolve()</code> is called.</p> </li> <li> <code>polling_interval</code>             (<code>float</code>, default:                 <code>1</code> )         \u2013          <p>Initial seconds to sleep between polling the store for the object.</p> </li> <li> <code>polling_backoff_factor</code>             (<code>float</code>, default:                 <code>1</code> )         \u2013          <p>Multiplicative factor applied to the polling_interval applied after each unsuccessful poll.</p> </li> <li> <code>polling_interval_limit</code>             (<code>float | None</code>, default:                 <code>None</code> )         \u2013          <p>Maximum polling interval allowed. Prevents the backoff factor from increasing the current polling interval to unreasonable values.</p> </li> <li> <code>polling_timeout</code>             (<code>float | None</code>, default:                 <code>None</code> )         \u2013          <p>Optional maximum number of seconds to poll for. If the timeout is reached an error is raised.</p> </li> </ul> Source code in <code>proxystore/store/factory.py</code> <pre><code>def __init__(\n    self,\n    key: ConnectorKeyT,\n    store_config: StoreConfig,\n    *,\n    deserializer: DeserializerT | None = None,\n    evict: bool = False,\n    polling_interval: float = 1,\n    polling_backoff_factor: float = 1,\n    polling_interval_limit: float | None = None,\n    polling_timeout: float | None = None,\n) -&gt; None:\n    super().__init__(\n        key,\n        store_config,\n        evict=evict,\n        deserializer=deserializer,\n    )\n    self._polling_interval = polling_interval\n    self._polling_backoff_factor = polling_backoff_factor\n    self._polling_interval_limit = polling_interval_limit\n    self._polling_timeout = polling_timeout\n</code></pre>"},{"location":"api/store/factory/#proxystore.store.factory.PollingStoreFactory.get_store","title":"get_store()","text":"<pre><code>get_store() -&gt; Store[ConnectorT]\n</code></pre> <p>Get store and reinitialize if necessary.</p> Source code in <code>proxystore/store/factory.py</code> <pre><code>def get_store(self) -&gt; Store[ConnectorT]:\n    \"\"\"Get store and reinitialize if necessary.\"\"\"\n    return proxystore.store.get_or_create_store(\n        self.store_config,\n        register=True,\n    )\n</code></pre>"},{"location":"api/store/factory/#proxystore.store.factory.PollingStoreFactory.resolve_async","title":"resolve_async()","text":"<pre><code>resolve_async() -&gt; None\n</code></pre> <p>Asynchronously get object associated with key from store.</p> Source code in <code>proxystore/store/factory.py</code> <pre><code>def resolve_async(self) -&gt; None:\n    \"\"\"Asynchronously get object associated with key from store.\"\"\"\n    logger.debug(f'Starting asynchronous resolve of {self.key}')\n    self._obj_future = _default_pool.submit(self.resolve)\n</code></pre>"},{"location":"api/store/factory/#proxystore.store.factory.PollingStoreFactory.resolve","title":"resolve()","text":"<pre><code>resolve() -&gt; T\n</code></pre> <p>Get object associated with key from store.</p> <p>Raises:</p> <ul> <li> <code>ProxyResolveMissingKeyError</code>           \u2013          <p>If the object associated with the key is not available after <code>polling_timeout</code> seconds.</p> </li> </ul> Source code in <code>proxystore/store/factory.py</code> <pre><code>def resolve(self) -&gt; T:\n    \"\"\"Get object associated with key from store.\n\n    Raises:\n        ProxyResolveMissingKeyError: If the object associated with the\n            key is not available after `polling_timeout` seconds.\n    \"\"\"\n    with Timer() as timer:\n        store = self.get_store()\n        sleep_interval = self._polling_interval\n        time_waited = 0.0\n\n        while True:\n            obj = store.get(\n                self.key,\n                deserializer=self.deserializer,\n                default=_MISSING_OBJECT,\n            )\n\n            # Break because we found the object or we hit the timeout\n            if obj is not _MISSING_OBJECT or (\n                self._polling_timeout is not None\n                and time_waited &gt;= self._polling_timeout\n            ):\n                break\n\n            time.sleep(sleep_interval)\n            time_waited += sleep_interval\n            new_interval = sleep_interval * self._polling_backoff_factor\n            sleep_interval = (\n                new_interval\n                if self._polling_interval_limit is None\n                else min(new_interval, self._polling_interval_limit)\n            )\n\n        if obj is _MISSING_OBJECT:\n            raise ProxyResolveMissingKeyError(\n                self.key,\n                type(store),\n                store.name,\n            )\n        elif self.evict:\n            store.evict(self.key)\n\n    if store.metrics is not None:\n        total_time = timer.elapsed_ns\n        store.metrics.add_time(\n            'factory.polling_resolve',\n            self.key,\n            total_time,\n        )\n\n    return cast(T, obj)\n</code></pre>"},{"location":"api/store/future/","title":"proxystore.store.future","text":"<code>proxystore/store/future.py</code> <p>Proxy-future interface implementation.</p>"},{"location":"api/store/future/#proxystore.store.future.Future","title":"Future","text":"<pre><code>Future(\n    factory: PollingStoreFactory[ConnectorT, T],\n    *,\n    serializer: SerializerT | None = None\n)\n</code></pre> <p>             Bases: <code>Generic[T]</code></p> <p>Future interface to a <code>Store</code>.</p> <p>Parameters:</p> <ul> <li> <code>factory</code>             (<code>PollingStoreFactory[ConnectorT, T]</code>)         \u2013          <p>Factory that can resolve the object once it is resolved. This factory should block when resolving until the object is available.</p> </li> <li> <code>serializer</code>             (<code>SerializerT | None</code>, default:                 <code>None</code> )         \u2013          <p>Use a custom serializer when setting the result object of this future.</p> </li> </ul> Source code in <code>proxystore/store/future.py</code> <pre><code>def __init__(\n    self,\n    factory: PollingStoreFactory[ConnectorT, T],\n    *,\n    serializer: SerializerT | None = None,\n) -&gt; None:\n    self._factory = factory\n    self._serializer = serializer\n</code></pre>"},{"location":"api/store/future/#proxystore.store.future.Future.done","title":"done()","text":"<pre><code>done() -&gt; bool\n</code></pre> <p>Check if the result has been set yet.</p> Source code in <code>proxystore/store/future.py</code> <pre><code>def done(self) -&gt; bool:\n    \"\"\"Check if the result has been set yet.\"\"\"\n    return self._factory.get_store().exists(self._factory.key)\n</code></pre>"},{"location":"api/store/future/#proxystore.store.future.Future.proxy","title":"proxy()","text":"<pre><code>proxy() -&gt; Proxy[T]\n</code></pre> <p>Create a proxy which will resolve to the result of this future.</p> Source code in <code>proxystore/store/future.py</code> <pre><code>def proxy(self) -&gt; Proxy[T]:\n    \"\"\"Create a proxy which will resolve to the result of this future.\"\"\"\n    return Proxy(self._factory)\n</code></pre>"},{"location":"api/store/future/#proxystore.store.future.Future.result","title":"result()","text":"<pre><code>result() -&gt; T\n</code></pre> <p>Get the result object of this future.</p> Source code in <code>proxystore/store/future.py</code> <pre><code>def result(self) -&gt; T:\n    \"\"\"Get the result object of this future.\"\"\"\n    return self._factory.resolve()\n</code></pre>"},{"location":"api/store/future/#proxystore.store.future.Future.set_result","title":"set_result()","text":"<pre><code>set_result(obj: T) -&gt; None\n</code></pre> <p>Set the result object of this future.</p> <p>Parameters:</p> <ul> <li> <code>obj</code>             (<code>T</code>)         \u2013          <p>Result object.</p> </li> </ul> Source code in <code>proxystore/store/future.py</code> <pre><code>def set_result(self, obj: T) -&gt; None:\n    \"\"\"Set the result object of this future.\n\n    Args:\n        obj: Result object.\n    \"\"\"\n    self._factory.get_store()._set(\n        self._factory.key,\n        obj,\n        serializer=self._serializer,\n    )\n</code></pre>"},{"location":"api/store/lifetimes/","title":"proxystore.store.lifetimes","text":"<code>proxystore/store/lifetimes.py</code> <p>Lifetime managers for objects in shared stores.</p> <p>Learn more about managing object lifetimes in the Object Lifetimes guide.</p>"},{"location":"api/store/lifetimes/#proxystore.store.lifetimes.Lifetime","title":"Lifetime","text":"<p>             Bases: <code>Protocol</code></p> <p>Lifetime protocol.</p>"},{"location":"api/store/lifetimes/#proxystore.store.lifetimes.Lifetime.add_key","title":"add_key()","text":"<pre><code>add_key(\n    *keys: ConnectorKeyT, store: Store[Any] | None = None\n) -&gt; None\n</code></pre> <p>Associate a new object with the lifetime.</p> Warning <p>All keys should have been created by the same <code>Store</code> that this lifetime was initialized with.</p> <p>Parameters:</p> <ul> <li> <code>keys</code>             (<code>ConnectorKeyT</code>, default:                 <code>()</code> )         \u2013          <p>One or more keys of objects to associate with this lifetime.</p> </li> <li> <code>store</code>             (<code>Store[Any] | None</code>, default:                 <code>None</code> )         \u2013          <p>Optional <code>Store</code> that <code>keys</code> belongs to.</p> </li> </ul> Source code in <code>proxystore/store/lifetimes.py</code> <pre><code>def add_key(\n    self,\n    *keys: ConnectorKeyT,\n    store: Store[Any] | None = None,\n) -&gt; None:\n    \"\"\"Associate a new object with the lifetime.\n\n    Warning:\n        All keys should have been created by the same\n        [`Store`][proxystore.store.base.Store] that this lifetime was\n        initialized with.\n\n    Args:\n        keys: One or more keys of objects to associate with this lifetime.\n        store: Optional [`Store`][proxystore.store.base.Store] that `keys`\n            belongs to.\n    \"\"\"\n    ...\n</code></pre>"},{"location":"api/store/lifetimes/#proxystore.store.lifetimes.Lifetime.add_proxy","title":"add_proxy()","text":"<pre><code>add_proxy(*proxies: Proxy[Any]) -&gt; None\n</code></pre> <p>Associate a new object with the lifetime.</p> Warning <p>All proxies should have been created by the same <code>Store</code> that this lifetime was initialized with.</p> <p>Parameters:</p> <ul> <li> <code>proxies</code>             (<code>Proxy[Any]</code>, default:                 <code>()</code> )         \u2013          <p>One or more proxies of objects to associate with this lifetime.</p> </li> </ul> <p>Raises:</p> <ul> <li> <code>ProxyStoreFactoryError</code>           \u2013          <p>If the proxy's factory is not an instance of <code>StoreFactory</code>.</p> </li> </ul> Source code in <code>proxystore/store/lifetimes.py</code> <pre><code>def add_proxy(self, *proxies: Proxy[Any]) -&gt; None:\n    \"\"\"Associate a new object with the lifetime.\n\n    Warning:\n        All proxies should have been created by the same\n        [`Store`][proxystore.store.base.Store] that this lifetime was\n        initialized with.\n\n    Args:\n        proxies: One or more proxies of objects to associate with this\n            lifetime.\n\n    Raises:\n        ProxyStoreFactoryError: If the proxy's factory is not an instance\n            of [`StoreFactory`][proxystore.store.base.StoreFactory].\n    \"\"\"\n    ...\n</code></pre>"},{"location":"api/store/lifetimes/#proxystore.store.lifetimes.Lifetime.close","title":"close()","text":"<pre><code>close(*, close_stores: bool = False) -&gt; None\n</code></pre> <p>End the lifetime and evict all associated objects.</p> <p>Parameters:</p> <ul> <li> <code>close_stores</code>             (<code>bool</code>, default:                 <code>False</code> )         \u2013          <p>Close any <code>Store</code> store instances associated with the lifetime.</p> </li> </ul> Source code in <code>proxystore/store/lifetimes.py</code> <pre><code>def close(self, *, close_stores: bool = False) -&gt; None:\n    \"\"\"End the lifetime and evict all associated objects.\n\n    Args:\n        close_stores: Close any [`Store`][proxystore.store.base.Store]\n            store instances associated with the lifetime.\n    \"\"\"\n    ...\n</code></pre>"},{"location":"api/store/lifetimes/#proxystore.store.lifetimes.Lifetime.done","title":"done()","text":"<pre><code>done() -&gt; bool\n</code></pre> <p>Check if lifetime has ended.</p> Source code in <code>proxystore/store/lifetimes.py</code> <pre><code>def done(self) -&gt; bool:\n    \"\"\"Check if lifetime has ended.\"\"\"\n    ...\n</code></pre>"},{"location":"api/store/lifetimes/#proxystore.store.lifetimes.ContextLifetime","title":"ContextLifetime","text":"<pre><code>ContextLifetime(\n    store: Store[Any], *, name: str | None = None\n)\n</code></pre> <p>Basic lifetime manager.</p> <p>Object lifetime manager with context manager support.</p> Example <pre><code>from proxystore.store.base import Store\nfrom proxystore.store.lifetimes import ContextLifetime\n\nstore = Store(...)\n\nwith ContextLifetime(store) as lifetime:\n    # Objects in the store can be associated with this lifetime.\n    key = store.put('value', lifetime=lifetime)\n    proxy = store.proxy('value', lifetime=lifetime)\n\n# Objects associated with the lifetime are evicted once the\n# lifetime ends.\nassert not store.exists(key)\n\nstore.close()\n</code></pre> <p>Parameters:</p> <ul> <li> <code>store</code>             (<code>Store[Any]</code>)         \u2013          <p><code>Store</code> instance use to create the objects associated with this lifetime and that will be used to evict them when the lifetime has ended.</p> </li> <li> <code>name</code>             (<code>str | None</code>, default:                 <code>None</code> )         \u2013          <p>Specify a name for this lifetime used in logging. Otherwise, a unique ID will be generated.</p> </li> </ul> Source code in <code>proxystore/store/lifetimes.py</code> <pre><code>def __init__(\n    self,\n    store: Store[Any],\n    *,\n    name: str | None = None,\n) -&gt; None:\n    self.store = store\n    self.name = name if name is not None else str(uuid.uuid4())\n    self._done = False\n    self._keys: set[ConnectorKeyT] = set()\n\n    logger.info(f'Initialized lifetime manager (name={self.name})')\n</code></pre>"},{"location":"api/store/lifetimes/#proxystore.store.lifetimes.ContextLifetime.add_key","title":"add_key()","text":"<pre><code>add_key(\n    *keys: ConnectorKeyT, store: Store[Any] | None = None\n) -&gt; None\n</code></pre> <p>Associate a new object with the lifetime.</p> Warning <p>All keys should have been created by the same <code>Store</code> that this lifetime was initialized with.</p> <p>Parameters:</p> <ul> <li> <code>keys</code>             (<code>ConnectorKeyT</code>, default:                 <code>()</code> )         \u2013          <p>One or more keys of objects to associate with this lifetime.</p> </li> <li> <code>store</code>             (<code>Store[Any] | None</code>, default:                 <code>None</code> )         \u2013          <p>Optional <code>Store</code> that <code>keys</code> belongs to. Ignored by this implementation.</p> </li> </ul> <p>Raises:</p> <ul> <li> <code>RuntimeError</code>           \u2013          <p>If this lifetime has ended.</p> </li> </ul> Source code in <code>proxystore/store/lifetimes.py</code> <pre><code>@_error_if_done\ndef add_key(\n    self,\n    *keys: ConnectorKeyT,\n    store: Store[Any] | None = None,\n) -&gt; None:\n    \"\"\"Associate a new object with the lifetime.\n\n    Warning:\n        All keys should have been created by the same\n        [`Store`][proxystore.store.base.Store] that this lifetime was\n        initialized with.\n\n    Args:\n        keys: One or more keys of objects to associate with this lifetime.\n        store: Optional [`Store`][proxystore.store.base.Store] that `keys`\n            belongs to. Ignored by this implementation.\n\n    Raises:\n        RuntimeError: If this lifetime has ended.\n    \"\"\"\n    self._keys.update(keys)\n    logger.debug(\n        f'Added keys to lifetime manager (name={self.name}): '\n        f'{\", \".join(repr(key) for key in keys)}',\n    )\n</code></pre>"},{"location":"api/store/lifetimes/#proxystore.store.lifetimes.ContextLifetime.add_proxy","title":"add_proxy()","text":"<pre><code>add_proxy(*proxies: Proxy[Any]) -&gt; None\n</code></pre> <p>Associate a new object with the lifetime.</p> Warning <p>All proxies should have been created by the same <code>Store</code> that this lifetime was initialized with.</p> <p>Parameters:</p> <ul> <li> <code>proxies</code>             (<code>Proxy[Any]</code>, default:                 <code>()</code> )         \u2013          <p>One or more proxies of objects to associate with this lifetime.</p> </li> </ul> <p>Raises:</p> <ul> <li> <code>ProxyStoreFactoryError</code>           \u2013          <p>If the proxy's factory is not an instance of <code>StoreFactory</code>.</p> </li> <li> <code>RuntimeError</code>           \u2013          <p>If this lifetime has ended.</p> </li> </ul> Source code in <code>proxystore/store/lifetimes.py</code> <pre><code>@_error_if_done\ndef add_proxy(self, *proxies: Proxy[Any]) -&gt; None:\n    \"\"\"Associate a new object with the lifetime.\n\n    Warning:\n        All proxies should have been created by the same\n        [`Store`][proxystore.store.base.Store] that this lifetime was\n        initialized with.\n\n    Args:\n        proxies: One or more proxies of objects to associate with this\n            lifetime.\n\n    Raises:\n        ProxyStoreFactoryError: If the proxy's factory is not an instance\n            of [`StoreFactory`][proxystore.store.base.StoreFactory].\n        RuntimeError: If this lifetime has ended.\n    \"\"\"\n    keys: list[ConnectorKeyT] = []\n    for proxy in proxies:\n        factory = get_factory(proxy)\n        if isinstance(factory, StoreFactory):\n            keys.append(factory.key)\n        else:\n            raise ProxyStoreFactoryError(\n                'The proxy must contain a factory with type '\n                f'{StoreFactory.__name__}. {type(factory).__name__} '\n                'is not supported.',\n            )\n    self.add_key(*keys)\n</code></pre>"},{"location":"api/store/lifetimes/#proxystore.store.lifetimes.ContextLifetime.close","title":"close()","text":"<pre><code>close(*, close_stores: bool = False) -&gt; None\n</code></pre> <p>End the lifetime and evict all associated objects.</p> <p>Parameters:</p> <ul> <li> <code>close_stores</code>             (<code>bool</code>, default:                 <code>False</code> )         \u2013          <p>Close any <code>Store</code> store instances associated with the lifetime.</p> </li> </ul> Source code in <code>proxystore/store/lifetimes.py</code> <pre><code>def close(self, *, close_stores: bool = False) -&gt; None:\n    \"\"\"End the lifetime and evict all associated objects.\n\n    Args:\n        close_stores: Close any [`Store`][proxystore.store.base.Store]\n            store instances associated with the lifetime.\n    \"\"\"\n    if self.done():\n        return\n\n    for key in self._keys:\n        self.store.evict(key)\n    self._done = True\n    logger.info(\n        f'Closed lifetime manager and evicted {len(self._keys)} '\n        f'associated objects (name={self.name})',\n    )\n    self._keys.clear()\n\n    if close_stores:\n        self.store.close()\n</code></pre>"},{"location":"api/store/lifetimes/#proxystore.store.lifetimes.ContextLifetime.done","title":"done()","text":"<pre><code>done() -&gt; bool\n</code></pre> <p>Check if lifetime has ended.</p> Source code in <code>proxystore/store/lifetimes.py</code> <pre><code>def done(self) -&gt; bool:\n    \"\"\"Check if lifetime has ended.\"\"\"\n    return self._done\n</code></pre>"},{"location":"api/store/lifetimes/#proxystore.store.lifetimes.LeaseLifetime","title":"LeaseLifetime","text":"<pre><code>LeaseLifetime(\n    store: Store[Any],\n    expiry: datetime | timedelta | float,\n    *,\n    name: str | None = None\n)\n</code></pre> <p>             Bases: <code>ContextLifetime</code></p> <p>Time-based lease lifetime manager.</p> Example <pre><code>from proxystore.store.base import Store\nfrom proxystore.store.lifetimes import LeaseLifetime\n\nwith Store(...) as store:\n    # Create a new lifetime with a current lease of ten seconds.\n    lifetime = LeaseLifetime(store, expiry=10)\n\n    # Objects in the store can be associated with this lifetime.\n    key = store.put('value', lifetime=lifetime)\n    proxy = store.proxy('value', lifetime=lifetime)\n\n    # Extend the lease by another five seconds.\n    lifetime.extend(5)\n\n    time.sleep(15)\n\n    # Lease has expired so the lifetime has ended.\n    assert lifetime.done()\n    assert not store.exists(key)\n</code></pre> <p>Parameters:</p> <ul> <li> <code>store</code>             (<code>Store[Any]</code>)         \u2013          <p><code>Store</code> instance use to create the objects associated with this lifetime and that will be used to evict them when the lifetime has ended.</p> </li> <li> <code>expiry</code>             (<code>datetime | timedelta | float</code>)         \u2013          <p>Initial expiry time of the lease. Can either be a <code>datetime</code>, <code>timedelta</code>, or float value specifying the number of seconds before expiring.</p> </li> <li> <code>name</code>             (<code>str | None</code>, default:                 <code>None</code> )         \u2013          <p>Specify a name for this lifetime used in logging. Otherwise, a unique ID will be generated.</p> </li> </ul> Source code in <code>proxystore/store/lifetimes.py</code> <pre><code>def __init__(\n    self,\n    store: Store[Any],\n    expiry: datetime | timedelta | float,\n    *,\n    name: str | None = None,\n) -&gt; None:\n    if isinstance(expiry, datetime):\n        self._expiry = expiry.timestamp()\n    elif isinstance(expiry, timedelta):\n        self._expiry = time.time() + expiry.total_seconds()\n    elif isinstance(expiry, (int, float)):\n        self._expiry = time.time() + expiry\n    else:\n        raise AssertionError('Unreachable.')\n\n    super().__init__(store, name=name)\n\n    self._timer: threading.Timer | None = None\n    self._start_timer()\n</code></pre>"},{"location":"api/store/lifetimes/#proxystore.store.lifetimes.LeaseLifetime.add_key","title":"add_key()","text":"<pre><code>add_key(\n    *keys: ConnectorKeyT, store: Store[Any] | None = None\n) -&gt; None\n</code></pre> <p>Associate a new object with the lifetime.</p> Warning <p>All keys should have been created by the same <code>Store</code> that this lifetime was initialized with.</p> <p>Parameters:</p> <ul> <li> <code>keys</code>             (<code>ConnectorKeyT</code>, default:                 <code>()</code> )         \u2013          <p>One or more keys of objects to associate with this lifetime.</p> </li> <li> <code>store</code>             (<code>Store[Any] | None</code>, default:                 <code>None</code> )         \u2013          <p>Optional <code>Store</code> that <code>keys</code> belongs to. Ignored by this implementation.</p> </li> </ul> <p>Raises:</p> <ul> <li> <code>RuntimeError</code>           \u2013          <p>If this lifetime has ended.</p> </li> </ul> Source code in <code>proxystore/store/lifetimes.py</code> <pre><code>@_error_if_done\ndef add_key(\n    self,\n    *keys: ConnectorKeyT,\n    store: Store[Any] | None = None,\n) -&gt; None:\n    \"\"\"Associate a new object with the lifetime.\n\n    Warning:\n        All keys should have been created by the same\n        [`Store`][proxystore.store.base.Store] that this lifetime was\n        initialized with.\n\n    Args:\n        keys: One or more keys of objects to associate with this lifetime.\n        store: Optional [`Store`][proxystore.store.base.Store] that `keys`\n            belongs to. Ignored by this implementation.\n\n    Raises:\n        RuntimeError: If this lifetime has ended.\n    \"\"\"\n    self._keys.update(keys)\n    logger.debug(\n        f'Added keys to lifetime manager (name={self.name}): '\n        f'{\", \".join(repr(key) for key in keys)}',\n    )\n</code></pre>"},{"location":"api/store/lifetimes/#proxystore.store.lifetimes.LeaseLifetime.add_proxy","title":"add_proxy()","text":"<pre><code>add_proxy(*proxies: Proxy[Any]) -&gt; None\n</code></pre> <p>Associate a new object with the lifetime.</p> Warning <p>All proxies should have been created by the same <code>Store</code> that this lifetime was initialized with.</p> <p>Parameters:</p> <ul> <li> <code>proxies</code>             (<code>Proxy[Any]</code>, default:                 <code>()</code> )         \u2013          <p>One or more proxies of objects to associate with this lifetime.</p> </li> </ul> <p>Raises:</p> <ul> <li> <code>ProxyStoreFactoryError</code>           \u2013          <p>If the proxy's factory is not an instance of <code>StoreFactory</code>.</p> </li> <li> <code>RuntimeError</code>           \u2013          <p>If this lifetime has ended.</p> </li> </ul> Source code in <code>proxystore/store/lifetimes.py</code> <pre><code>@_error_if_done\ndef add_proxy(self, *proxies: Proxy[Any]) -&gt; None:\n    \"\"\"Associate a new object with the lifetime.\n\n    Warning:\n        All proxies should have been created by the same\n        [`Store`][proxystore.store.base.Store] that this lifetime was\n        initialized with.\n\n    Args:\n        proxies: One or more proxies of objects to associate with this\n            lifetime.\n\n    Raises:\n        ProxyStoreFactoryError: If the proxy's factory is not an instance\n            of [`StoreFactory`][proxystore.store.base.StoreFactory].\n        RuntimeError: If this lifetime has ended.\n    \"\"\"\n    keys: list[ConnectorKeyT] = []\n    for proxy in proxies:\n        factory = get_factory(proxy)\n        if isinstance(factory, StoreFactory):\n            keys.append(factory.key)\n        else:\n            raise ProxyStoreFactoryError(\n                'The proxy must contain a factory with type '\n                f'{StoreFactory.__name__}. {type(factory).__name__} '\n                'is not supported.',\n            )\n    self.add_key(*keys)\n</code></pre>"},{"location":"api/store/lifetimes/#proxystore.store.lifetimes.LeaseLifetime.done","title":"done()","text":"<pre><code>done() -&gt; bool\n</code></pre> <p>Check if lifetime has ended.</p> Source code in <code>proxystore/store/lifetimes.py</code> <pre><code>def done(self) -&gt; bool:\n    \"\"\"Check if lifetime has ended.\"\"\"\n    return self._done\n</code></pre>"},{"location":"api/store/lifetimes/#proxystore.store.lifetimes.LeaseLifetime.close","title":"close()","text":"<pre><code>close(*, close_stores: bool = False) -&gt; None\n</code></pre> <p>End the lifetime and evict all associated objects.</p> <p>This can be called before the specified expiry time to end the lifetime early.</p> <p>Parameters:</p> <ul> <li> <code>close_stores</code>             (<code>bool</code>, default:                 <code>False</code> )         \u2013          <p>Close any <code>Store</code> store instances associated with the lifetime.</p> </li> </ul> Source code in <code>proxystore/store/lifetimes.py</code> <pre><code>def close(self, *, close_stores: bool = False) -&gt; None:\n    \"\"\"End the lifetime and evict all associated objects.\n\n    This can be called before the specified expiry time to end the\n    lifetime early.\n\n    Args:\n        close_stores: Close any [`Store`][proxystore.store.base.Store]\n            store instances associated with the lifetime.\n    \"\"\"\n    if self._timer is not None:\n        self._timer.cancel()\n        self._timer = None\n\n    super().close(close_stores=close_stores)\n</code></pre>"},{"location":"api/store/lifetimes/#proxystore.store.lifetimes.LeaseLifetime.extend","title":"extend()","text":"<pre><code>extend(expiry: datetime | timedelta | float) -&gt; None\n</code></pre> <p>Extend the expiry of the lifetime lease.</p> <p>Parameters:</p> <ul> <li> <code>expiry</code>             (<code>datetime | timedelta | float</code>)         \u2013          <p>Extends the current expiry if the value is <code>timedelta</code> or float value specifying seconds. If a <code>datetime</code>, updates the expiry to the specified timestamp even if the new time is less than the current expiry.</p> </li> </ul> Source code in <code>proxystore/store/lifetimes.py</code> <pre><code>@_error_if_done\ndef extend(self, expiry: datetime | timedelta | float) -&gt; None:\n    \"\"\"Extend the expiry of the lifetime lease.\n\n    Args:\n        expiry: Extends the current expiry if the value is\n            [`timedelta`][datetime.timedelta] or float value specifying\n            seconds. If a [`datetime`][datetime.datetime], updates the\n            expiry to the specified timestamp even if the new time\n            is less than the current expiry.\n    \"\"\"\n    if isinstance(expiry, datetime):\n        self._expiry = expiry.timestamp()\n    elif isinstance(expiry, timedelta):\n        self._expiry += expiry.total_seconds()\n    elif isinstance(expiry, (int, float)):\n        self._expiry += expiry\n    else:\n        raise AssertionError('Unreachable.')\n</code></pre>"},{"location":"api/store/lifetimes/#proxystore.store.lifetimes.StaticLifetime","title":"StaticLifetime","text":"<pre><code>StaticLifetime()\n</code></pre> <p>Static lifetime manager.</p> <p>Keeps associated objects alive for the remainder of the program.</p> Note <p>This is a singleton class.</p> Warning <p>This class registers an atexit handler which will close the lifetime at the end of the program, evicting all objects associated with the lifetime. Therefore, <code>Store</code> instances used to created objects associated with the static lifetime should not be closed prior to program exit. The handler will close all of these stores. It is possible to call <code>StaticLifetime().close()</code> manually, after which it is safe to also close the stores.</p> Example Static Lifetime<pre><code>from proxystore.connectors.local import LocalConnector\nfrom proxystore.store import Store\nfrom proxystore.store.lifetimes import StaticLifetime\n\nstore = Store('default', LocalConnector(), register=True)  # (1)!\n\nkey = store.put('value', lifetime=StaticLifetime())  # (2)!\nproxy = store.proxy('value', lifetime=StaticLifetime())  # (3)!\n</code></pre> <ol> <li>The atexit handler will call <code>store.close()</code> at the end of the    program. Setting <code>register=True</code> is recommended to prevent another    instance being created internally when a proxy is resolved.</li> <li>The object associated with <code>key</code> will be evicted at the end of    the program.</li> <li>The object associated with <code>proxy</code> will be evicted at the end of    the program.</li> </ol> Source code in <code>proxystore/store/lifetimes.py</code> <pre><code>def __init__(self) -&gt; None:\n    if not self._initialized:\n        self._done = False\n        self._keys: dict[Store[Any], set[ConnectorKeyT]] = defaultdict(set)\n        self._callback = register_lifetime_atexit(self, close_stores=True)\n        self._initialized = True\n</code></pre>"},{"location":"api/store/lifetimes/#proxystore.store.lifetimes.StaticLifetime.add_key","title":"add_key()","text":"<pre><code>add_key(\n    *keys: ConnectorKeyT, store: Store[Any] | None = None\n) -&gt; None\n</code></pre> <p>Associate a new object with the lifetime.</p> <p>Parameters:</p> <ul> <li> <code>keys</code>             (<code>ConnectorKeyT</code>, default:                 <code>()</code> )         \u2013          <p>One or more keys of objects to associate with this lifetime.</p> </li> <li> <code>store</code>             (<code>Store[Any] | None</code>, default:                 <code>None</code> )         \u2013          <p><code>Store</code> that <code>keys</code> belongs to. Required by this implementation.</p> </li> </ul> <p>Raises:</p> <ul> <li> <code>RuntimeError</code>           \u2013          <p>If this lifetime has ended.</p> </li> <li> <code>ValueError</code>           \u2013          <p>If <code>store</code> is <code>None</code>.</p> </li> </ul> Source code in <code>proxystore/store/lifetimes.py</code> <pre><code>@_error_if_done\ndef add_key(\n    self,\n    *keys: ConnectorKeyT,\n    store: Store[Any] | None = None,\n) -&gt; None:\n    \"\"\"Associate a new object with the lifetime.\n\n    Args:\n        keys: One or more keys of objects to associate with this lifetime.\n        store: [`Store`][proxystore.store.base.Store] that `keys`\n            belongs to. Required by this implementation.\n\n    Raises:\n        RuntimeError: If this lifetime has ended.\n        ValueError: If `store` is `None`.\n    \"\"\"\n    if store is None:\n        raise ValueError(\n            f'The {self.__class__.__name__} requires the store parameter.',\n        )\n    self._keys[store].update(keys)\n    logger.debug(\n        f'Added keys to lifetime manager (name={self.name}): '\n        f'{\", \".join(repr(key) for key in keys)}',\n    )\n</code></pre>"},{"location":"api/store/lifetimes/#proxystore.store.lifetimes.StaticLifetime.add_proxy","title":"add_proxy()","text":"<pre><code>add_proxy(*proxies: Proxy[Any]) -&gt; None\n</code></pre> <p>Associate a new object with the lifetime.</p> Warning <p>This method will initialized new <code>Store</code> instances if the stores which were used to create the input proxies have not been registered by setting the <code>register</code> flag or by calling <code>register_store()</code>.</p> <p>Parameters:</p> <ul> <li> <code>proxies</code>             (<code>Proxy[Any]</code>, default:                 <code>()</code> )         \u2013          <p>One or more proxies of objects to associate with this lifetime.</p> </li> </ul> <p>Raises:</p> <ul> <li> <code>ProxyStoreFactoryError</code>           \u2013          <p>If the proxy's factory is not an instance of <code>StoreFactory</code>.</p> </li> <li> <code>RuntimeError</code>           \u2013          <p>If this lifetime has ended.</p> </li> </ul> Source code in <code>proxystore/store/lifetimes.py</code> <pre><code>@_error_if_done\ndef add_proxy(self, *proxies: Proxy[Any]) -&gt; None:\n    \"\"\"Associate a new object with the lifetime.\n\n    Warning:\n        This method will initialized new\n        [`Store`][proxystore.store.base.Store] instances if the stores\n        which were used to create the input proxies have not been\n        registered by setting the `register` flag or by calling\n        [`register_store()`][proxystore.store.register_store].\n\n    Args:\n        proxies: One or more proxies of objects to associate with this\n            lifetime.\n\n    Raises:\n        ProxyStoreFactoryError: If the proxy's factory is not an instance\n            of [`StoreFactory`][proxystore.store.base.StoreFactory].\n        RuntimeError: If this lifetime has ended.\n    \"\"\"\n    for proxy in proxies:\n        factory = get_factory(proxy)\n        if isinstance(factory, StoreFactory):\n            self.add_key(factory.key, store=factory.get_store())\n        else:\n            raise ProxyStoreFactoryError(\n                'The proxy must contain a factory with type '\n                f'{StoreFactory.__name__}. {type(factory).__name__} '\n                'is not supported.',\n            )\n</code></pre>"},{"location":"api/store/lifetimes/#proxystore.store.lifetimes.StaticLifetime.close","title":"close()","text":"<pre><code>close(*, close_stores: bool = False) -&gt; None\n</code></pre> <p>End the lifetime and evict all associated objects.</p> Warning <p>Because this class is a singleton this operation can only be performed once.</p> <p>Parameters:</p> <ul> <li> <code>close_stores</code>             (<code>bool</code>, default:                 <code>False</code> )         \u2013          <p>Close any <code>Store</code> store instances associated with the lifetime.</p> </li> </ul> Source code in <code>proxystore/store/lifetimes.py</code> <pre><code>def close(self, *, close_stores: bool = False) -&gt; None:\n    \"\"\"End the lifetime and evict all associated objects.\n\n    Warning:\n        Because this class is a singleton this operation can only\n        be performed once.\n\n    Args:\n        close_stores: Close any [`Store`][proxystore.store.base.Store]\n            store instances associated with the lifetime.\n    \"\"\"\n    if self.done():\n        return\n\n    count = 0\n    for store, keys in self._keys.items():\n        for key in keys:\n            store.evict(key)\n            count += 1\n\n        if close_stores:\n            store.close()\n\n    atexit.unregister(self._callback)\n\n    self._done = True\n    logger.info(\n        f'Closed lifetime manager and evicted {count} '\n        f'associated objects (name={self.name})',\n    )\n    self._keys.clear()\n</code></pre>"},{"location":"api/store/lifetimes/#proxystore.store.lifetimes.StaticLifetime.done","title":"done()","text":"<pre><code>done() -&gt; bool\n</code></pre> <p>Check if lifetime has ended.</p> Source code in <code>proxystore/store/lifetimes.py</code> <pre><code>def done(self) -&gt; bool:\n    \"\"\"Check if lifetime has ended.\"\"\"\n    return self._done\n</code></pre>"},{"location":"api/store/lifetimes/#proxystore.store.lifetimes.register_lifetime_atexit","title":"register_lifetime_atexit()","text":"<pre><code>register_lifetime_atexit(\n    lifetime: Lifetime, close_stores: bool = True\n) -&gt; Callable[[], None]\n</code></pre> <p>Register atexit callback to cleanup the lifetime.</p> <p>Registers an atexit callback which will close the lifetime on normal program exit and optionally close the associated store as well.</p> Tip <p>Do not close the <code>Store</code> associated with the lifetime when registering an atexit callback. Using a <code>Store</code> after closing it is undefined behaviour. Rather, let the callback handle closing after it is safe to do so.</p> Warning <p>Callbacks are not guaranteed to be called in all cases. See the <code>atexit</code> docs for more details.</p> <p>Parameters:</p> <ul> <li> <code>lifetime</code>             (<code>Lifetime</code>)         \u2013          <p>Lifetime to be closed at exit.</p> </li> <li> <code>close_stores</code>             (<code>bool</code>, default:                 <code>True</code> )         \u2013          <p>Close any <code>Store</code> instances associated with the lifetime.</p> </li> </ul> <p>Returns:</p> <ul> <li> <code>Callable[[], None]</code>         \u2013          <p>The registered callback function which can be used with         <code>atexit.unregister()</code> if needed.</p> </li> </ul> Source code in <code>proxystore/store/lifetimes.py</code> <pre><code>def register_lifetime_atexit(\n    lifetime: Lifetime,\n    close_stores: bool = True,\n) -&gt; Callable[[], None]:\n    \"\"\"Register atexit callback to cleanup the lifetime.\n\n    Registers an atexit callback which will close the lifetime on normal\n    program exit and optionally close the associated store as well.\n\n    Tip:\n        Do not close the [`Store`][proxystore.store.base.Store] associated\n        with the lifetime when registering an atexit callback. Using a\n        [`Store`][proxystore.store.base.Store] after closing it is undefined\n        behaviour. Rather, let the callback handle closing after it is\n        safe to do so.\n\n    Warning:\n        Callbacks are not guaranteed to be called in all cases. See the\n        [`atexit`][atexit] docs for more details.\n\n    Args:\n        lifetime: Lifetime to be closed at exit.\n        close_stores: Close any [`Store`][proxystore.store.base.Store]\n            instances associated with the lifetime.\n\n    Returns:\n        The registered callback function which can be used with \\\n        [`atexit.unregister()`][atexit.unregister] if needed.\n    \"\"\"\n\n    def _lifetime_atexit_callback() -&gt; None:\n        lifetime.close(close_stores=close_stores)\n\n    atexit.register(_lifetime_atexit_callback)\n    logger.debug(\n        f'Registered atexit callback for {lifetime!r}',\n    )\n    return _lifetime_atexit_callback\n</code></pre>"},{"location":"api/store/metrics/","title":"proxystore.store.metrics","text":"<code>proxystore/store/metrics.py</code> <p>Utilities for recording Store operation metrics.</p> <p>See the Performance Guide to learn more about interacting with metrics recorded for <code>Store</code> operations.</p>"},{"location":"api/store/metrics/#proxystore.store.metrics.KeyT","title":"KeyT  <code>module-attribute</code>","text":"<pre><code>KeyT = Union[ConnectorKeyT, Sequence[ConnectorKeyT]]\n</code></pre> <p>Key types supported by <code>StoreMetrics</code>.</p>"},{"location":"api/store/metrics/#proxystore.store.metrics.ProxyT","title":"ProxyT  <code>module-attribute</code>","text":"<pre><code>ProxyT = Union[Proxy[Any], Sequence[Proxy[Any]]]\n</code></pre> <p>Proxy types supported by <code>StoreMetrics</code>.</p> <p>When a <code>ProxyT</code> is passed, the keys are extracted from the proxies.</p>"},{"location":"api/store/metrics/#proxystore.store.metrics.TimeStats","title":"TimeStats  <code>dataclass</code>","text":"<pre><code>TimeStats(\n    count: int = 0,\n    avg_time_ms: float = 0,\n    min_time_ms: float = math.inf,\n    max_time_ms: float = 0,\n    last_time_ms: float = 0,\n    last_timestamp: float = 0,\n)\n</code></pre> <p>Tracks time statistics of a reoccuring event.</p> <p>Attributes:</p> <ul> <li> <code>count</code>             (<code>int</code>)         \u2013          <p>Number of times this event as occurred.</p> </li> <li> <code>avg_time_ms</code>             (<code>float</code>)         \u2013          <p>Average time in milliseconds of the event.</p> </li> <li> <code>min_time_ms</code>             (<code>float</code>)         \u2013          <p>Minimum time in milliseconds of all event occurrences.</p> </li> <li> <code>max_time_ms</code>             (<code>float</code>)         \u2013          <p>Maximum time in milliseconds of all event occurrences.</p> </li> <li> <code>last_time_ms</code>             (<code>float</code>)         \u2013          <p>Time in milliseconds of the most recent event occurrence.</p> </li> <li> <code>last_timestamp</code>             (<code>float</code>)         \u2013          <p>The UNIX timestamp (seconds) of when the last event time was recorded.</p> </li> </ul>"},{"location":"api/store/metrics/#proxystore.store.metrics.TimeStats.as_dict","title":"as_dict()","text":"<pre><code>as_dict() -&gt; dict[str, Any]\n</code></pre> <p>Convert the dataclass to a <code>dict</code>.</p> Source code in <code>proxystore/store/metrics.py</code> <pre><code>def as_dict(self) -&gt; dict[str, Any]:\n    \"\"\"Convert the dataclass to a [`dict`][dict].\"\"\"\n    return dataclasses.asdict(self)\n</code></pre>"},{"location":"api/store/metrics/#proxystore.store.metrics.Metrics","title":"Metrics  <code>dataclass</code>","text":"<pre><code>Metrics(\n    attributes: dict[str, Any] = dict(),\n    counters: dict[str, int] = dict(),\n    times: dict[str, TimeStats] = dict(),\n)\n</code></pre> <p>Records metrics and attributes for events.</p> <p>Attributes:</p> <ul> <li> <code>attributes</code>             (<code>dict[str, Any]</code>)         \u2013          <p>A mapping of attributes to their values.</p> </li> <li> <code>counters</code>             (<code>dict[str, int]</code>)         \u2013          <p>A mapping of counter names to the integer value of the counter.</p> </li> <li> <code>times</code>             (<code>dict[str, TimeStats]</code>)         \u2013          <p>A mapping of events to a summary of the statistics recorded over occurrences of that event.</p> </li> </ul>"},{"location":"api/store/metrics/#proxystore.store.metrics.Metrics.as_dict","title":"as_dict()","text":"<pre><code>as_dict() -&gt; dict[str, Any]\n</code></pre> <p>Convert the dataclass to a <code>dict</code>.</p> Source code in <code>proxystore/store/metrics.py</code> <pre><code>def as_dict(self) -&gt; dict[str, Any]:\n    \"\"\"Convert the dataclass to a [`dict`][dict].\"\"\"\n    return dataclasses.asdict(self)\n</code></pre>"},{"location":"api/store/metrics/#proxystore.store.metrics.StoreMetrics","title":"StoreMetrics","text":"<pre><code>StoreMetrics()\n</code></pre> <p>Record and query metrics on <code>Store</code> operations.</p> Source code in <code>proxystore/store/metrics.py</code> <pre><code>def __init__(self) -&gt; None:\n    self._metrics: dict[int, Metrics] = defaultdict(Metrics)\n</code></pre>"},{"location":"api/store/metrics/#proxystore.store.metrics.StoreMetrics.add_attribute","title":"add_attribute()","text":"<pre><code>add_attribute(name: str, key: KeyT, value: Any) -&gt; None\n</code></pre> <p>Add an attribute associated with the key.</p> <p>Parameters:</p> <ul> <li> <code>name</code>             (<code>str</code>)         \u2013          <p>Name of attribute.</p> </li> <li> <code>key</code>             (<code>KeyT</code>)         \u2013          <p>Key to add attribute to.</p> </li> <li> <code>value</code>             (<code>Any</code>)         \u2013          <p>Attribute value.</p> </li> </ul> Source code in <code>proxystore/store/metrics.py</code> <pre><code>def add_attribute(self, name: str, key: KeyT, value: Any) -&gt; None:\n    \"\"\"Add an attribute associated with the key.\n\n    Args:\n        name: Name of attribute.\n        key: Key to add attribute to.\n        value: Attribute value.\n    \"\"\"\n    self._metrics[_hash_key(key)].attributes[name] = value\n</code></pre>"},{"location":"api/store/metrics/#proxystore.store.metrics.StoreMetrics.add_counter","title":"add_counter()","text":"<pre><code>add_counter(name: str, key: KeyT, value: int) -&gt; None\n</code></pre> <p>Add to a counter.</p> <p>Parameters:</p> <ul> <li> <code>name</code>             (<code>str</code>)         \u2013          <p>Name of counter.</p> </li> <li> <code>key</code>             (<code>KeyT</code>)         \u2013          <p>Key associated with the counter.</p> </li> <li> <code>value</code>             (<code>int</code>)         \u2013          <p>Amount to increment counter by.</p> </li> </ul> Source code in <code>proxystore/store/metrics.py</code> <pre><code>def add_counter(self, name: str, key: KeyT, value: int) -&gt; None:\n    \"\"\"Add to a counter.\n\n    Args:\n        name: Name of counter.\n        key: Key associated with the counter.\n        value: Amount to increment counter by.\n    \"\"\"\n    counters = self._metrics[_hash_key(key)].counters\n    if name in counters:\n        counters[name] += value\n    else:\n        counters[name] = value\n</code></pre>"},{"location":"api/store/metrics/#proxystore.store.metrics.StoreMetrics.add_time","title":"add_time()","text":"<pre><code>add_time(name: str, key: KeyT, time_ms: float) -&gt; None\n</code></pre> <p>Record a new time for an event.</p> <p>Parameters:</p> <ul> <li> <code>name</code>             (<code>str</code>)         \u2013          <p>Event or operation the time is for.</p> </li> <li> <code>key</code>             (<code>KeyT</code>)         \u2013          <p>Key associated with the event.</p> </li> <li> <code>time_ms</code>             (<code>float</code>)         \u2013          <p>The time in milliseconds of the event.</p> </li> </ul> Source code in <code>proxystore/store/metrics.py</code> <pre><code>def add_time(self, name: str, key: KeyT, time_ms: float) -&gt; None:\n    \"\"\"Record a new time for an event.\n\n    Args:\n        name: Event or operation the time is for.\n        key: Key associated with the event.\n        time_ms: The time in milliseconds of the event.\n    \"\"\"\n    times = self._metrics[_hash_key(key)].times\n    if name not in times:\n        times[name] = TimeStats()\n    times[name].add_time(time_ms)\n</code></pre>"},{"location":"api/store/metrics/#proxystore.store.metrics.StoreMetrics.aggregate_times","title":"aggregate_times()","text":"<pre><code>aggregate_times() -&gt; dict[str, TimeStats]\n</code></pre> <p>Aggregate time statistics over all keys.</p> <p>Returns:</p> <ul> <li> <code>dict[str, TimeStats]</code>         \u2013          <p>Dictionary mapping event names to the time statistics aggregated             for that event.</p> </li> </ul> Source code in <code>proxystore/store/metrics.py</code> <pre><code>def aggregate_times(self) -&gt; dict[str, TimeStats]:\n    \"\"\"Aggregate time statistics over all keys.\n\n    Returns:\n        Dictionary mapping event names to the time statistics aggregated \\\n        for that event.\n    \"\"\"\n    times: dict[str, TimeStats] = defaultdict(TimeStats)\n    for metrics in self._metrics.values():\n        for key, value in metrics.times.items():\n            times[key] += value\n    return times\n</code></pre>"},{"location":"api/store/metrics/#proxystore.store.metrics.StoreMetrics.get_metrics","title":"get_metrics()","text":"<pre><code>get_metrics(key_or_proxy: KeyT | ProxyT) -&gt; Metrics | None\n</code></pre> <p>Get the metrics associated with a key.</p> <p>Parameters:</p> <ul> <li> <code>key_or_proxy</code>             (<code>KeyT | ProxyT</code>)         \u2013          <p>Key to get associated metrics. If a proxy or sequence of proxies, the key(s) will be extracted.</p> </li> </ul> <p>Returns:</p> <ul> <li> <code>Metrics | None</code>         \u2013          <p>Metrics associated with the key or <code>None</code> if the key does not             exist.</p> </li> </ul> Source code in <code>proxystore/store/metrics.py</code> <pre><code>def get_metrics(self, key_or_proxy: KeyT | ProxyT) -&gt; Metrics | None:\n    \"\"\"Get the metrics associated with a key.\n\n    Args:\n        key_or_proxy: Key to get associated metrics. If a proxy or\n            sequence of proxies, the key(s) will be extracted.\n\n    Returns:\n        Metrics associated with the key or `None` if the key does not \\\n        exist.\n    \"\"\"\n    key_hash = _hash_key(key_or_proxy)\n    if key_hash in self._metrics:\n        return copy.deepcopy(self._metrics[key_hash])\n    return None\n</code></pre>"},{"location":"api/store/ref/","title":"proxystore.store.ref","text":"<code>proxystore/store/ref.py</code> <p>Object ownership and borrowing with proxies.</p> Warning <p>These features are experimental and may change in future releases.</p> <p>This module implements Rust-like ownership and borrowing rules for Python objects in shared memory using transparent object proxies. Thus, these proxy reference types are similar to the type returned by <code>Store.proxy()</code>---they will resolve to an object in the global store. However, these proxy references enforce additional rules.</p> <ol> <li>Each target object of type <code>T</code> in the global store has an associated    <code>OwnedProxy[T]</code>.</li> <li>There can only be one <code>OwnedProxy[T]</code>    for any target in the global store.</li> <li>When an <code>OwnedProxy[T]</code> goes out of    scope (e.g., gets garbage collected), the associated target is removed    from the global store.</li> </ol> Tip <p>The docstrings often use <code>T</code> to refer to both the target object in the global store and the type of the target object.</p> <p>An <code>OwnedProxy[T]</code> can be borrowed without relinquishing ownership. This requires two additional rules.</p> <ol> <li>At any given time, you can have either one mutable reference to the    target, a <code>RefMutProxy[T]</code>, or    any number of immutable references, a    <code>RefProxy[T]</code>.</li> <li>References must always be valid. I.e., you cannot delete an    <code>OwnedProxy[T]</code> while it has been    borrowed via a <code>RefProxy[T]</code> or    <code>RefMutProxy[T]</code>.</li> </ol> <p>All three reference types (<code>OwnedProxy[T]</code>, <code>RefProxy[T]</code>, and <code>RefMutProxy[T]</code>) behave like an instance of <code>T</code>, forwarding operations on themselves to a locally cached instance of <code>T</code>.</p>"},{"location":"api/store/ref/#proxystore.store.ref.BaseRefProxyError","title":"BaseRefProxyError","text":"<p>             Bases: <code>Exception</code></p> <p>Base exception type for proxy references.</p>"},{"location":"api/store/ref/#proxystore.store.ref.MutableBorrowError","title":"MutableBorrowError","text":"<p>             Bases: <code>BaseRefProxyError</code></p> <p>Exception raised when violating borrowing rules.</p>"},{"location":"api/store/ref/#proxystore.store.ref.ReferenceNotOwnedError","title":"ReferenceNotOwnedError","text":"<p>             Bases: <code>BaseRefProxyError</code></p> <p>Exception raised when invoking an operation on a non-owned reference.</p>"},{"location":"api/store/ref/#proxystore.store.ref.ReferenceInvalidError","title":"ReferenceInvalidError","text":"<p>             Bases: <code>BaseRefProxyError</code></p> <p>Exception raised when a reference instance has been invalidated.</p>"},{"location":"api/store/ref/#proxystore.store.ref.BaseRefProxy","title":"BaseRefProxy","text":"<pre><code>BaseRefProxy(\n    factory: FactoryType[T],\n    *,\n    cache_defaults: bool = False,\n    target: T | None = None\n)\n</code></pre> <p>             Bases: <code>Proxy[T]</code></p> <p>Base reference proxy type.</p> <p>This base type adds some features to <code>Proxy</code> that are shared by all the reference types:</p> <ol> <li>Valid flag. When invalidated, the proxy will raise a    <code>ReferenceInvalidError</code>    when accessing the wrapped target object.</li> <li>Disable <code>copy()</code> and <code>deepcopy()</code>    support to prevent misuse of the API. Generally,    <code>borrow()</code> or    <code>clone()</code> should be used instead.</li> </ol> Source code in <code>proxystore/store/ref.py</code> <pre><code>def __init__(\n    self,\n    factory: FactoryType[T],\n    *,\n    cache_defaults: bool = False,\n    target: T | None = None,\n) -&gt; None:\n    object.__setattr__(self, '__proxy_valid__', True)\n    super().__init__(factory, cache_defaults=cache_defaults, target=target)\n</code></pre>"},{"location":"api/store/ref/#proxystore.store.ref.OwnedProxy","title":"OwnedProxy","text":"<pre><code>OwnedProxy(\n    factory: FactoryType[T],\n    *,\n    cache_defaults: bool = False,\n    target: T | None = None\n)\n</code></pre> <p>             Bases: <code>BaseRefProxy[T]</code></p> <p>Represents ownership over an object in a global store.</p> <p>This class maintains reference counts of the number of immutable and mutable borrows of this proxy. The target object will be evicted from the store once this proxy goes out of scope (this is handled via <code>__del__</code> and an atexit handler).</p> <p>Parameters:</p> <ul> <li> <code>factory</code>             (<code>FactoryType[T]</code>)         \u2013          <p><code>StoreFactory</code> used to resolve the target object from the store.</p> </li> <li> <code>cache_defaults</code>             (<code>bool</code>, default:                 <code>False</code> )         \u2013          <p>Precompute and cache the <code>__proxy_default_class__</code> and <code>__proxy_default_hash__</code> attributes of the proxy instance from <code>target</code>. Ignored if <code>target</code> is not provided.</p> </li> <li> <code>target</code>             (<code>T | None</code>, default:                 <code>None</code> )         \u2013          <p>Optionally preset the target object.</p> </li> </ul> Source code in <code>proxystore/store/ref.py</code> <pre><code>def __init__(\n    self,\n    factory: FactoryType[T],\n    *,\n    cache_defaults: bool = False,\n    target: T | None = None,\n) -&gt; None:\n    object.__setattr__(self, '__proxy_ref_count__', 0)\n    object.__setattr__(self, '__proxy_ref_mut_count__', 0)\n    object.__setattr__(\n        self,\n        '__proxy_finalizer__',\n        atexit.register(_WeakRefFinalizer(self, '__del__')),\n    )\n    super().__init__(factory, cache_defaults=cache_defaults, target=target)\n</code></pre>"},{"location":"api/store/ref/#proxystore.store.ref.RefProxy","title":"RefProxy","text":"<pre><code>RefProxy(\n    factory: FactoryType[T],\n    *,\n    cache_defaults: bool = False,\n    owner: OwnedProxy[T] | None = None,\n    target: T | None = None\n)\n</code></pre> <p>             Bases: <code>BaseRefProxy[T]</code></p> <p>Represents a borrowed reference to an object in the global store.</p> <p>Parameters:</p> <ul> <li> <code>factory</code>             (<code>FactoryType[T]</code>)         \u2013          <p><code>StoreFactory</code> used to resolve the target object from the store.</p> </li> <li> <code>cache_defaults</code>             (<code>bool</code>, default:                 <code>False</code> )         \u2013          <p>Precompute and cache the <code>__proxy_default_class__</code> and <code>__proxy_default_hash__</code> attributes of the proxy instance from <code>target</code>. Ignored if <code>target</code> is not provided.</p> </li> <li> <code>owner</code>             (<code>OwnedProxy[T] | None</code>, default:                 <code>None</code> )         \u2013          <p>Proxy which has ownership over the target object. This reference will keep the owner alive while this borrowed reference is alive. In the event this borrowed reference was initialized in a different address space from the proxy with ownership, then <code>owner</code> will be <code>None</code>.</p> </li> <li> <code>target</code>             (<code>T | None</code>, default:                 <code>None</code> )         \u2013          <p>Optionally preset the target object.</p> </li> </ul> Source code in <code>proxystore/store/ref.py</code> <pre><code>def __init__(\n    self,\n    factory: FactoryType[T],\n    *,\n    cache_defaults: bool = False,\n    owner: OwnedProxy[T] | None = None,\n    target: T | None = None,\n) -&gt; None:\n    object.__setattr__(self, '__proxy_owner__', owner)\n    object.__setattr__(\n        self,\n        '__proxy_finalizer__',\n        atexit.register(_WeakRefFinalizer(self, '__del__')),\n    )\n    super().__init__(factory, cache_defaults=cache_defaults, target=target)\n</code></pre>"},{"location":"api/store/ref/#proxystore.store.ref.RefMutProxy","title":"RefMutProxy","text":"<pre><code>RefMutProxy(\n    factory: FactoryType[T],\n    *,\n    cache_defaults: bool = False,\n    owner: OwnedProxy[T] | None = None,\n    target: T | None = None\n)\n</code></pre> <p>             Bases: <code>BaseRefProxy[T]</code></p> <p>Represents a borrowed mutable reference to an object in the global store.</p> <p>Parameters:</p> <ul> <li> <code>factory</code>             (<code>FactoryType[T]</code>)         \u2013          <p><code>StoreFactory</code> used to resolve the target object from the store.</p> </li> <li> <code>cache_defaults</code>             (<code>bool</code>, default:                 <code>False</code> )         \u2013          <p>Precompute and cache the <code>__proxy_default_class__</code> and <code>__proxy_default_hash__</code> attributes of the proxy instance from <code>target</code>. Ignored if <code>target</code> is not provided.</p> </li> <li> <code>owner</code>             (<code>OwnedProxy[T] | None</code>, default:                 <code>None</code> )         \u2013          <p>Proxy which has ownership over the target object. This reference will keep the owner alive while this borrowed reference is alive. In the event this borrowed reference was initialized in a different address space from the proxy with ownership, then <code>owner</code> will be <code>None</code>.</p> </li> <li> <code>target</code>             (<code>T | None</code>, default:                 <code>None</code> )         \u2013          <p>Optionally preset the target object.</p> </li> </ul> Source code in <code>proxystore/store/ref.py</code> <pre><code>def __init__(\n    self,\n    factory: FactoryType[T],\n    *,\n    cache_defaults: bool = False,\n    owner: OwnedProxy[T] | None = None,\n    target: T | None = None,\n) -&gt; None:\n    object.__setattr__(self, '__proxy_owner__', owner)\n    object.__setattr__(\n        self,\n        '__proxy_finalizer__',\n        atexit.register(_WeakRefFinalizer(self, '__del__')),\n    )\n    super().__init__(factory, cache_defaults=cache_defaults, target=target)\n</code></pre>"},{"location":"api/store/ref/#proxystore.store.ref.borrow","title":"borrow()","text":"<pre><code>borrow(\n    proxy: OwnedProxy[T], *, populate_target: bool = True\n) -&gt; RefProxy[T]\n</code></pre> <p>Borrow <code>T</code> by creating an immutable reference of <code>T</code>.</p> Note <p>This mutates <code>proxy</code>.</p> <p>Parameters:</p> <ul> <li> <code>proxy</code>             (<code>OwnedProxy[T]</code>)         \u2013          <p>Proxy reference to borrow.</p> </li> <li> <code>populate_target</code>             (<code>bool</code>, default:                 <code>True</code> )         \u2013          <p>If the target of <code>proxy</code> has already been resolved, copy the reference to the target into the returned proxy such that the returned proxy is already resolved.</p> </li> </ul> <p>Raises:</p> <ul> <li> <code>ReferenceNotOwnedError</code>           \u2013          <p>if <code>proxy</code> is not an <code>OwnedProxy</code> instance.</p> </li> <li> <code>MutableBorrowError</code>           \u2013          <p>if <code>proxy</code> has already been mutably borrowed.</p> </li> </ul> Source code in <code>proxystore/store/ref.py</code> <pre><code>def borrow(\n    proxy: OwnedProxy[T],\n    *,\n    populate_target: bool = True,\n) -&gt; RefProxy[T]:\n    \"\"\"Borrow `T` by creating an immutable reference of `T`.\n\n    Note:\n        This mutates `proxy`.\n\n    Args:\n        proxy: Proxy reference to borrow.\n        populate_target: If the target of `proxy` has already been resolved,\n            copy the reference to the target into the returned proxy such that\n            the returned proxy is already resolved.\n\n    Raises:\n        ReferenceNotOwnedError: if `proxy` is not an\n            [`OwnedProxy`][proxystore.store.ref.OwnedProxy] instance.\n        MutableBorrowError: if `proxy` has already been mutably borrowed.\n    \"\"\"\n    if not isinstance(proxy, OwnedProxy):\n        raise ReferenceNotOwnedError('Only owned references can be borrowed.')\n    if object.__getattribute__(proxy, '__proxy_ref_mut_count__') &gt; 0:\n        raise MutableBorrowError('Proxy was already borrowed as mutable.')\n    object.__setattr__(\n        proxy,\n        '__proxy_ref_count__',\n        object.__getattribute__(proxy, '__proxy_ref_count__') + 1,\n    )\n    ref_proxy = RefProxy(proxy.__proxy_factory__, owner=proxy)\n    if populate_target:\n        _copy_attributes(proxy, ref_proxy)\n    return ref_proxy\n</code></pre>"},{"location":"api/store/ref/#proxystore.store.ref.mut_borrow","title":"mut_borrow()","text":"<pre><code>mut_borrow(\n    proxy: OwnedProxy[T], *, populate_target: bool = True\n) -&gt; RefMutProxy[T]\n</code></pre> <p>Mutably borrow <code>T</code> by creating an mutable reference of <code>T</code>.</p> Note <p>This mutates <code>proxy</code>.</p> <p>Parameters:</p> <ul> <li> <code>proxy</code>             (<code>OwnedProxy[T]</code>)         \u2013          <p>Proxy reference to borrow.</p> </li> <li> <code>populate_target</code>             (<code>bool</code>, default:                 <code>True</code> )         \u2013          <p>If the target of <code>proxy</code> has already been resolved, copy the reference to the target into the returned proxy such that the returned proxy is already resolved.</p> </li> </ul> <p>Raises:</p> <ul> <li> <code>ReferenceNotOwnedError</code>           \u2013          <p>if <code>proxy</code> is not an <code>OwnedProxy</code> instance.</p> </li> <li> <code>MutableBorrowError</code>           \u2013          <p>if <code>proxy</code> has already been borrowed (mutable/immutable).</p> </li> </ul> Source code in <code>proxystore/store/ref.py</code> <pre><code>def mut_borrow(\n    proxy: OwnedProxy[T],\n    *,\n    populate_target: bool = True,\n) -&gt; RefMutProxy[T]:\n    \"\"\"Mutably borrow `T` by creating an mutable reference of `T`.\n\n    Note:\n        This mutates `proxy`.\n\n    Args:\n        proxy: Proxy reference to borrow.\n        populate_target: If the target of `proxy` has already been resolved,\n            copy the reference to the target into the returned proxy such that\n            the returned proxy is already resolved.\n\n    Raises:\n        ReferenceNotOwnedError: if `proxy` is not an\n            [`OwnedProxy`][proxystore.store.ref.OwnedProxy] instance.\n        MutableBorrowError: if `proxy` has already been borrowed\n            (mutable/immutable).\n    \"\"\"\n    if not isinstance(proxy, OwnedProxy):\n        raise ReferenceNotOwnedError('Only owned references can be borrowed.')\n    if object.__getattribute__(proxy, '__proxy_ref_mut_count__') &gt; 0:\n        raise MutableBorrowError('Proxy was already borrowed as mutable.')\n    if object.__getattribute__(proxy, '__proxy_ref_count__') &gt; 0:\n        raise MutableBorrowError('Proxy was already borrowed as immutable.')\n    object.__setattr__(\n        proxy,\n        '__proxy_ref_mut_count__',\n        object.__getattribute__(proxy, '__proxy_ref_mut_count__') + 1,\n    )\n    ref_proxy = RefMutProxy(proxy.__proxy_factory__, owner=proxy)\n    if populate_target:\n        _copy_attributes(proxy, ref_proxy)\n    return ref_proxy\n</code></pre>"},{"location":"api/store/ref/#proxystore.store.ref.clone","title":"clone()","text":"<pre><code>clone(proxy: OwnedProxy[T]) -&gt; OwnedProxy[T]\n</code></pre> <p>Clone the target object.</p> <p>Creates a new copy of <code>T</code> in the global store. If <code>proxy</code> is in the resolved state, the local version of <code>T</code> belonging to <code>proxy</code> will be deepcopied into the cloned proxy.</p> <p>Raises:</p> <ul> <li> <code>ReferenceNotOwnedError</code>           \u2013          <p>if <code>proxy</code> is not an <code>OwnedProxy</code> instance.</p> </li> </ul> Source code in <code>proxystore/store/ref.py</code> <pre><code>def clone(proxy: OwnedProxy[T]) -&gt; OwnedProxy[T]:\n    \"\"\"Clone the target object.\n\n    Creates a new copy of `T` in the global store. If `proxy` is in\n    the resolved state, the local version of `T` belonging to `proxy` will\n    be deepcopied into the cloned proxy.\n\n    Raises:\n        ReferenceNotOwnedError: if `proxy` is not an\n            [`OwnedProxy`][proxystore.store.ref.OwnedProxy] instance.\n    \"\"\"\n    if not isinstance(proxy, OwnedProxy):\n        raise ReferenceNotOwnedError('Only owned references can be cloned.')\n    factory = proxy.__proxy_factory__\n    store = factory.get_store()\n    data = store.connector.get(factory.key)\n    new_key = store.connector.put(data)\n    new_factory: StoreFactory[Any, T] = StoreFactory(\n        new_key,\n        store_config=store.config(),\n        evict=factory.evict,\n        deserializer=factory.deserializer,\n    )\n    owned = OwnedProxy(new_factory)\n    _copy_attributes(proxy, owned, deepcopy=True)\n    return owned\n</code></pre>"},{"location":"api/store/ref/#proxystore.store.ref.into_owned","title":"into_owned()","text":"<pre><code>into_owned(\n    proxy: Proxy[T], *, populate_target: bool = True\n) -&gt; OwnedProxy[T]\n</code></pre> <p>Convert a basic proxy into an owned proxy.</p> Warning <p>It is the caller's responsibility to ensure that <code>proxy</code> has not been copied already.</p> Note <p>This will unset the <code>evict</code> flag on the proxy.</p> <p>Parameters:</p> <ul> <li> <code>proxy</code>             (<code>Proxy[T]</code>)         \u2013          <p>Proxy reference to borrow.</p> </li> <li> <code>populate_target</code>             (<code>bool</code>, default:                 <code>True</code> )         \u2013          <p>If the target of <code>proxy</code> has already been resolved, copy the reference to the target into the returned proxy such that the returned proxy is already resolved.</p> </li> </ul> <p>Raises:</p> <ul> <li> <code>ValueError</code>           \u2013          <p>if <code>proxy</code> is already a <code>BaseRefProxy</code> instance.</p> </li> <li> <code>ProxyStoreFactoryError</code>           \u2013          <p>If the proxy's factory is not an instance of <code>StoreFactory</code>.</p> </li> </ul> Source code in <code>proxystore/store/ref.py</code> <pre><code>def into_owned(\n    proxy: Proxy[T],\n    *,\n    populate_target: bool = True,\n) -&gt; OwnedProxy[T]:\n    \"\"\"Convert a basic proxy into an owned proxy.\n\n    Warning:\n        It is the caller's responsibility to ensure that `proxy` has not been\n        copied already.\n\n    Note:\n        This will unset the `evict` flag on the proxy.\n\n    Args:\n        proxy: Proxy reference to borrow.\n        populate_target: If the target of `proxy` has already been resolved,\n            copy the reference to the target into the returned proxy such that\n            the returned proxy is already resolved.\n\n    Raises:\n        ValueError: if `proxy` is already a\n            [`BaseRefProxy`][proxystore.store.ref.BaseRefProxy] instance.\n        ProxyStoreFactoryError: If the proxy's factory is not an instance of\n            [`StoreFactory`][proxystore.store.base.StoreFactory].\n    \"\"\"\n    if type(proxy) in (OwnedProxy, RefProxy, RefMutProxy):\n        # We don't use isinstance to prevent resolving the proxy.\n        raise ValueError(\n            'Only a base proxy can be converted into an owned proxy.',\n        )\n    factory = proxy.__proxy_factory__\n    if not isinstance(factory, StoreFactory):\n        raise ProxyStoreFactoryError(\n            'The proxy must contain a factory with type '\n            f'{StoreFactory.__name__}. {type(factory).__name__} '\n            'is not supported.',\n        )\n    factory.evict = False\n    owned_proxy = OwnedProxy(factory)\n    if populate_target:\n        _copy_attributes(proxy, owned_proxy)\n    return owned_proxy\n</code></pre>"},{"location":"api/store/ref/#proxystore.store.ref.update","title":"update()","text":"<pre><code>update(\n    proxy: OwnedProxy[T] | RefMutProxy[T],\n    *,\n    serializer: SerializerT | None = None\n) -&gt; None\n</code></pre> <p>Update the global copy of the target.</p> Note <p>If the proxy has not been resolved, there is nothing to update and this function is a no-op.</p> Warning <p>This will not invalidate already cached copies of the global target.</p> <p>Parameters:</p> <ul> <li> <code>proxy</code>             (<code>OwnedProxy[T] | RefMutProxy[T]</code>)         \u2013          <p>Proxy containing a modified local copy of the target to use as the new global value.</p> </li> <li> <code>serializer</code>             (<code>SerializerT | None</code>, default:                 <code>None</code> )         \u2013          <p>Optionally override the default serializer for the     store instance when pushing the local copy to the store.</p> </li> </ul> <p>Raises:</p> <ul> <li> <code>MutableBorrowError</code>           \u2013          <p>if <code>proxy</code> has been mutably borrowed.</p> </li> <li> <code>NotImplementedError</code>           \u2013          <p>if the <code>connector</code> of the <code>store</code> used to create the proxy does not implement the <code>DeferrableConnector</code> protocol.</p> </li> <li> <code>ReferenceNotOwnedError</code>           \u2013          <p>if <code>proxy</code> is not an <code>OwnedProxy</code> or <code>RefMutProxy</code> instance.</p> </li> </ul> Source code in <code>proxystore/store/ref.py</code> <pre><code>def update(\n    proxy: OwnedProxy[T] | RefMutProxy[T],\n    *,\n    serializer: SerializerT | None = None,\n) -&gt; None:\n    \"\"\"Update the global copy of the target.\n\n    Note:\n        If the proxy has not been resolved, there is nothing to update and\n        this function is a no-op.\n\n    Warning:\n        This will not invalidate already cached copies of the global target.\n\n    Args:\n        proxy: Proxy containing a modified local copy of the target to use\n            as the new global value.\n        serializer: Optionally override the default serializer for the\n                store instance when pushing the local copy to the store.\n\n    Raises:\n        MutableBorrowError: if `proxy` has been mutably borrowed.\n        NotImplementedError: if the `connector` of the `store` used to create\n            the proxy does not implement the\n            [`DeferrableConnector`][proxystore.connectors.protocols.DeferrableConnector]\n            protocol.\n        ReferenceNotOwnedError: if `proxy` is not an\n            [`OwnedProxy`][proxystore.store.ref.OwnedProxy] or\n            [`RefMutProxy`][proxystore.store.ref.RefMutProxy] instance.\n    \"\"\"\n    if not isinstance(proxy, (OwnedProxy, RefMutProxy)):\n        raise ReferenceNotOwnedError('Reference is an immutable borrow.')\n    if isinstance(proxy, OwnedProxy) and (\n        object.__getattribute__(proxy, '__proxy_ref_mut_count__') &gt; 0\n        or object.__getattribute__(proxy, '__proxy_ref_count__') &gt; 0\n    ):\n        raise MutableBorrowError(\n            'OwnedProxy has been borrowed. Cannot mutate.',\n        )\n    if not is_resolved(proxy):\n        return\n\n    store = proxy.__proxy_factory__.get_store()\n    try:\n        store._set(\n            proxy.__proxy_factory__.key,\n            proxy.__proxy_wrapped__,\n            serializer=serializer,\n        )\n    except NotImplementedError as e:  # pragma: no cover\n        raise NotImplementedError(\n            'Mutating the global copy of the value requires a connector '\n            'type that supports set().',\n        ) from e\n</code></pre>"},{"location":"api/store/scopes/","title":"proxystore.store.scopes","text":"<code>proxystore/store/scopes.py</code> <p>Utilities for managing reference proxy scopes and lifetimes.</p>"},{"location":"api/store/scopes/#proxystore.store.scopes.FutureWithCallback","title":"FutureWithCallback","text":"<p>             Bases: <code>Protocol</code></p> <p>Protocol for Future objects that support callbacks.</p>"},{"location":"api/store/scopes/#proxystore.store.scopes.mark_refs_out_of_scope","title":"mark_refs_out_of_scope()","text":"<pre><code>mark_refs_out_of_scope(\n    *refs: RefProxy[Any] | RefMutProxy[Any],\n) -&gt; None\n</code></pre> <p>Mark proxy references as out of scope.</p> <p>This (1) decrements the reference count in the owner proxy, (2) marks the reference proxy invalid, and (3) removes the reference to the owner from the reference proxy so the reference proxy will not prevent the owned proxy from being garbage collected.</p> <p>Parameters:</p> <ul> <li> <code>refs</code>             (<code>RefProxy[Any] | RefMutProxy[Any]</code>, default:                 <code>()</code> )         \u2013          <p>Reference proxies to mark out of scope.</p> </li> </ul> <p>Raises:</p> <ul> <li> <code>RuntimeError</code>           \u2013          <p>if a reference proxy does not have a reference to its owner.</p> </li> </ul> Source code in <code>proxystore/store/scopes.py</code> <pre><code>def mark_refs_out_of_scope(\n    *refs: RefProxy[Any] | RefMutProxy[Any],\n) -&gt; None:\n    \"\"\"Mark proxy references as out of scope.\n\n    This (1) decrements the reference count in the owner proxy, (2)\n    marks the reference proxy invalid, and (3) removes the reference to the\n    owner from the reference proxy so the reference proxy will not prevent\n    the owned proxy from being garbage collected.\n\n    Args:\n        refs: Reference proxies to mark out of scope.\n\n    Raises:\n        RuntimeError: if a reference proxy does not have a reference to its\n            owner.\n    \"\"\"\n    for ref in refs:\n        if not object.__getattribute__(ref, '__proxy_valid__'):\n            # We've already encountered and handled this reference\n            continue\n        owner = object.__getattribute__(ref, '__proxy_owner__')\n        if owner is None:\n            raise RuntimeError(\n                f'Cannot mark {owner!r} as out of scope because it has '\n                'no reference to its owner.',\n            )\n\n        if isinstance(ref, RefProxy):\n            ref_count = object.__getattribute__(owner, '__proxy_ref_count__')\n            object.__setattr__(owner, '__proxy_ref_count__', ref_count - 1)\n        elif isinstance(ref, RefMutProxy):\n            ref_count = object.__getattribute__(\n                owner,\n                '__proxy_ref_mut_count__',\n            )\n            object.__setattr__(owner, '__proxy_ref_mut_count__', ref_count - 1)\n        else:\n            raise AssertionError('Unreachable.')\n\n        # Remove ref's reference to owner so it no longer keeps owner alive\n        object.__setattr__(ref, '__proxy_owner__', None)\n        # Mark ref as invalid in case the user tries to use it after it\n        # has already \"gone out of scope.\"\n        object.__setattr__(ref, '__proxy_valid__', False)\n</code></pre>"},{"location":"api/store/scopes/#proxystore.store.scopes.submit","title":"submit()","text":"<pre><code>submit(\n    submit_func: Callable[P, FutureT],\n    *,\n    args: args = (),\n    kwargs: kwargs | None = None,\n    register_custom_refs: Iterable[Any] = ()\n) -&gt; FutureT\n</code></pre> <p>Shim around function executor for managing reference proxy scopes.</p> <p>When invoking a remote function, such as via a <code>ProcessPoolExecutor</code> or a FaaS system, on a proxy reference, the owner proxy will not know when the proxy references go out of scope on the remote process. This function will register a callback to the future returned by the function invocation method (<code>submit_func</code>) that will mark all proxy references in <code>args</code> and <code>kwargs</code> as out of scope once the future completes.</p> Example <pre><code>from concurrent.futures import Future\nfrom concurrent.futures import ProcessPoolExecutor\nfrom proxystore.store.base import Store\nfrom proxystore.store.ref import borrow\n\nstore = Store('example', ...)\nproxy = store.owned_proxy([1, 2, 3])\nborrowed = borrow(proxy)\n\nwith ProcessPoolExecutor() as pool:\n    future: Future[int] = submit(pool.submit, args=(sum, borrowed))\n    assert future.result() == 6\n\nstore.close()\n</code></pre> Tip <p>To return a proxy from the invoked function, return a normal <code>Proxy</code> and then call <code>into_owned()</code> on the received result. Returning an <code>OwnedProxy</code> directly will often not work because the owned proxy will go out of scope when the function returns and the proxy is serialized causing the destructor of the owned proxy to evict the associated data.</p> <p>Parameters:</p> <ul> <li> <code>submit_func</code>             (<code>Callable[P, FutureT]</code>)         \u2013          <p>Function with submits a function with args and kwargs to be executed (e.g., <code>Executor.submit()</code>).</p> </li> <li> <code>args</code>             (<code>args</code>, default:                 <code>()</code> )         \u2013          <p>Positional arguments to pass to <code>submit_func</code>. Any proxy references in <code>args</code> will be registered to the scope cleanup callback.</p> </li> <li> <code>kwargs</code>             (<code>kwargs | None</code>, default:                 <code>None</code> )         \u2013          <p>Keyword arguments to pass to <code>submit_func</code>. Any proxy references in the values of <code>kwargs</code> will be registered to the scope cleanup callback.</p> </li> <li> <code>register_custom_refs</code>             (<code>Iterable[Any]</code>, default:                 <code>()</code> )         \u2013          <p>Iterable of additional proxy references to register to the scope cleanup callback. This is helpful if <code>args</code> or <code>kwargs</code> contain complex data structures containing more proxy references.</p> </li> </ul> Source code in <code>proxystore/store/scopes.py</code> <pre><code>def submit(\n    submit_func: Callable[P, FutureT],\n    *,\n    args: P.args = (),\n    kwargs: P.kwargs | None = None,\n    register_custom_refs: Iterable[Any] = (),\n) -&gt; FutureT:\n    \"\"\"Shim around function executor for managing reference proxy scopes.\n\n    When invoking a remote function, such as via a\n    [`ProcessPoolExecutor`][concurrent.futures.ProcessPoolExecutor]{target=_blank}\n    or a FaaS system, on a proxy reference, the owner proxy will not know when\n    the proxy references go out of scope on the remote process. This function\n    will register a callback to the future returned by the function\n    invocation method (`submit_func`) that will mark all proxy references in\n    `args` and `kwargs` as out of scope once the future completes.\n\n    Example:\n        ```python\n        from concurrent.futures import Future\n        from concurrent.futures import ProcessPoolExecutor\n        from proxystore.store.base import Store\n        from proxystore.store.ref import borrow\n\n        store = Store('example', ...)\n        proxy = store.owned_proxy([1, 2, 3])\n        borrowed = borrow(proxy)\n\n        with ProcessPoolExecutor() as pool:\n            future: Future[int] = submit(pool.submit, args=(sum, borrowed))\n            assert future.result() == 6\n\n        store.close()\n        ```\n\n    Tip:\n        To return a proxy from the invoked function, return a normal\n        [`Proxy`][proxystore.proxy.Proxy] and then call\n        [`into_owned()`][proxystore.store.ref.into_owned] on the received\n        result. Returning an [`OwnedProxy`][proxystore.store.ref.OwnedProxy]\n        directly will often not work because the owned proxy will go out of\n        scope when the function returns and the proxy is serialized causing\n        the destructor of the owned proxy to evict the associated data.\n\n    Args:\n        submit_func: Function with submits a function with args and kwargs to\n            be executed (e.g.,\n            [`Executor.submit()`][concurrent.futures.Executor.submit]{target=_blank}).\n        args: Positional arguments to pass to `submit_func`. Any proxy\n            references in `args` will be registered to the scope cleanup\n            callback.\n        kwargs: Keyword arguments to pass to `submit_func`. Any proxy\n            references in the values of `kwargs` will be registered to the\n            scope cleanup callback.\n        register_custom_refs: Iterable of additional proxy references to\n            register to the scope cleanup callback. This is helpful if `args`\n            or `kwargs` contain complex data structures containing more proxy\n            references.\n    \"\"\"\n    kwargs = {} if kwargs is None else kwargs\n\n    refs: list[RefProxy[Any] | RefMutProxy[Any]] = [\n        ref\n        for ref in register_custom_refs\n        if type(ref) in (RefProxy, RefMutProxy)\n    ]\n    refs.extend(arg for arg in args if type(arg) in (RefProxy, RefMutProxy))\n    refs.extend(\n        kwarg\n        for kwarg in kwargs.values()\n        if type(kwarg) in (RefProxy, RefMutProxy)\n    )\n\n    fut = submit_func(*args, **kwargs)\n\n    fut.add_done_callback(_make_out_of_scope_callback(refs))\n\n    return fut\n</code></pre>"},{"location":"api/store/types/","title":"proxystore.store.types","text":"<code>proxystore/store/types.py</code> <p>Common type definitions.</p>"},{"location":"api/store/types/#proxystore.store.types.ConnectorT","title":"ConnectorT  <code>module-attribute</code>","text":"<pre><code>ConnectorT = TypeVar('ConnectorT', bound=Connector[Any])\n</code></pre> <p>Connector type variable.</p>"},{"location":"api/store/types/#proxystore.store.types.ConnectorKeyT","title":"ConnectorKeyT  <code>module-attribute</code>","text":"<pre><code>ConnectorKeyT = Tuple[Any, ...]\n</code></pre> <p>Connector key type alias.</p>"},{"location":"api/store/types/#proxystore.store.types.SerializerT","title":"SerializerT  <code>module-attribute</code>","text":"<pre><code>SerializerT = Callable[[Any], bytes]\n</code></pre> <p>Serializer type alias.</p>"},{"location":"api/store/types/#proxystore.store.types.DeserializerT","title":"DeserializerT  <code>module-attribute</code>","text":"<pre><code>DeserializerT = Callable[[bytes], Any]\n</code></pre> <p>Deserializer type alias.</p>"},{"location":"api/store/utils/","title":"proxystore.store.utils","text":"<code>proxystore/store/utils.py</code> <p>Store utilities.</p>"},{"location":"api/store/utils/#proxystore.store.utils.ConnectorKeyT","title":"ConnectorKeyT  <code>module-attribute</code>","text":"<pre><code>ConnectorKeyT = Tuple[Any, ...]\n</code></pre> <p>Connector key type alias.</p>"},{"location":"api/store/utils/#proxystore.store.utils.get_key","title":"get_key()","text":"<pre><code>get_key(proxy: Proxy[T]) -&gt; ConnectorKeyT\n</code></pre> <p>Extract the key from the proxy's factory.</p> <p>Parameters:</p> <ul> <li> <code>proxy</code>             (<code>Proxy[T]</code>)         \u2013          <p>Proxy instance to get key from.</p> </li> </ul> <p>Returns:</p> <ul> <li> <code>ConnectorKeyT</code>         \u2013          <p>The key, a NamedTuple unique to the         <code>Store</code> that created the proxy..</p> </li> </ul> <p>Raises:</p> <ul> <li> <code>ProxyStoreFactoryError</code>           \u2013          <p>If the proxy's factory is not an instance of <code>StoreFactory</code>.</p> </li> </ul> Source code in <code>proxystore/store/utils.py</code> <pre><code>def get_key(proxy: Proxy[T]) -&gt; ConnectorKeyT:\n    \"\"\"Extract the key from the proxy's factory.\n\n    Args:\n        proxy: Proxy instance to get key from.\n\n    Returns:\n        The key, a NamedTuple unique to the \\\n        [`Store`][proxystore.store.base.Store] that created the proxy..\n\n    Raises:\n        ProxyStoreFactoryError: If the proxy's factory is not an instance of\n            [`StoreFactory`][proxystore.store.base.StoreFactory].\n    \"\"\"\n    factory = get_factory(proxy)\n    if isinstance(factory, base.StoreFactory):\n        return factory.key\n    else:\n        raise ProxyStoreFactoryError(\n            'The proxy must contain a factory with type '\n            f'{base.StoreFactory.__name__}. {type(factory).__name__} '\n            'is not supported.',\n        )\n</code></pre>"},{"location":"api/store/utils/#proxystore.store.utils.resolve_async","title":"resolve_async()","text":"<pre><code>resolve_async(proxy: Proxy[T]) -&gt; None\n</code></pre> <p>Begin resolving proxy asynchronously.</p> <p>Useful if the user knows a proxy will be needed soon and wants to resolve the proxy concurrently with other computation.</p> <pre><code>from proxystore.store.utils import resolve_async\n\nresolve_async(my_proxy)\ncomputation_without_proxy(...)\n# p is hopefully resolved\ncomputation_with_proxy(my_proxy, ...)\n</code></pre> Note <p>The asynchronous resolving functionality is implemented by <code>StoreFactory</code>. Factories that are not of this type will error when used with this function.</p> <p>Parameters:</p> <ul> <li> <code>proxy</code>             (<code>Proxy[T]</code>)         \u2013          <p>Proxy instance to begin asynchronously resolving.</p> </li> </ul> <p>Raises:</p> <ul> <li> <code>ProxyStoreFactoryError</code>           \u2013          <p>If the proxy's factory is not an instance of <code>StoreFactory</code>.</p> </li> </ul> Source code in <code>proxystore/store/utils.py</code> <pre><code>def resolve_async(proxy: Proxy[T]) -&gt; None:\n    \"\"\"Begin resolving proxy asynchronously.\n\n    Useful if the user knows a proxy will be needed soon and wants to\n    resolve the proxy concurrently with other computation.\n\n    ```python\n    from proxystore.store.utils import resolve_async\n\n    resolve_async(my_proxy)\n    computation_without_proxy(...)\n    # p is hopefully resolved\n    computation_with_proxy(my_proxy, ...)\n    ```\n\n    Note:\n        The asynchronous resolving functionality is implemented\n        by [`StoreFactory`][proxystore.store.base.StoreFactory]. Factories that\n        are not of this type will error when used with this function.\n\n    Args:\n        proxy: Proxy instance to begin asynchronously resolving.\n\n    Raises:\n        ProxyStoreFactoryError: If the proxy's factory is not an instance of\n            [`StoreFactory`][proxystore.store.base.StoreFactory].\n    \"\"\"\n    factory = get_factory(proxy)\n    if isinstance(factory, base.StoreFactory):\n        if not is_resolved(proxy):\n            factory.resolve_async()\n    else:\n        raise ProxyStoreFactoryError(\n            'The proxy must contain a factory with type '\n            f'{base.StoreFactory.__name__}. {type(factory).__name__} '\n            'is not supported.',\n        )\n</code></pre>"},{"location":"api/stream/","title":"proxystore.stream","text":"<code>proxystore/stream/__init__.py</code> <p>Proxy streaming interface.</p> Warning <p>The streaming interfaces are experimental and may change in future releases.</p> Tip <p>Checkout the Streaming Guide to learn more!</p> Note <p>The StreamProducer and StreamConsumer are defined in <code>proxystore.stream.interface</code> are re-exported here for convenience.</p>"},{"location":"api/stream/events/","title":"proxystore.stream.events","text":"<code>proxystore/stream/events.py</code> <p>Event metadata type.</p> Warning <p>Event types are not considered as part of the public API and may change at any time without warning. <code>Events</code> are created and consumed internally by the StreamProducer and StreamConsumer and never exposed to client code.</p>"},{"location":"api/stream/events/#proxystore.stream.events.Event","title":"Event  <code>module-attribute</code>","text":"<pre><code>Event = Union[EndOfStreamEvent, NewObjectEvent]\n</code></pre> <p>Event union type.</p>"},{"location":"api/stream/events/#proxystore.stream.events.EndOfStreamEvent","title":"EndOfStreamEvent  <code>dataclass</code>","text":"<pre><code>EndOfStreamEvent()\n</code></pre> <p>End of stream event.</p>"},{"location":"api/stream/events/#proxystore.stream.events.EndOfStreamEvent.from_dict","title":"from_dict()  <code>classmethod</code>","text":"<pre><code>from_dict(data: dict[str, Any]) -&gt; EndOfStreamEvent\n</code></pre> <p>Create a new event instance from its dictionary representation.</p> Source code in <code>proxystore/stream/events.py</code> <pre><code>@classmethod\ndef from_dict(cls, data: dict[str, Any]) -&gt; EndOfStreamEvent:\n    \"\"\"Create a new event instance from its dictionary representation.\"\"\"\n    return cls()\n</code></pre>"},{"location":"api/stream/events/#proxystore.stream.events.NewObjectEvent","title":"NewObjectEvent  <code>dataclass</code>","text":"<pre><code>NewObjectEvent(\n    key_type: str,\n    raw_key: list[Any],\n    evict: bool,\n    metadata: dict[str, Any],\n)\n</code></pre> <p>New object in stream event metadata.</p>"},{"location":"api/stream/events/#proxystore.stream.events.NewObjectEvent.from_dict","title":"from_dict()  <code>classmethod</code>","text":"<pre><code>from_dict(data: dict[str, Any]) -&gt; NewObjectEvent\n</code></pre> <p>Create a new event instance from its dictionary representation.</p> Source code in <code>proxystore/stream/events.py</code> <pre><code>@classmethod\ndef from_dict(cls, data: dict[str, Any]) -&gt; NewObjectEvent:\n    \"\"\"Create a new event instance from its dictionary representation.\"\"\"\n    return NewObjectEvent(**data)\n</code></pre>"},{"location":"api/stream/events/#proxystore.stream.events.NewObjectEvent.from_key","title":"from_key()  <code>classmethod</code>","text":"<pre><code>from_key(\n    key: tuple[Any, ...],\n    evict: bool,\n    metadata: dict[str, Any],\n) -&gt; NewObjectEvent\n</code></pre> <p>Create a new event from a key and metadata.</p> Source code in <code>proxystore/stream/events.py</code> <pre><code>@classmethod\ndef from_key(\n    cls,\n    key: tuple[Any, ...],\n    evict: bool,\n    metadata: dict[str, Any],\n) -&gt; NewObjectEvent:\n    \"\"\"Create a new event from a key and metadata.\"\"\"\n    return cls(\n        key_type=get_object_path(type(key)),\n        raw_key=list(key),\n        evict=evict,\n        metadata=metadata,\n    )\n</code></pre>"},{"location":"api/stream/events/#proxystore.stream.events.NewObjectEvent.get_key","title":"get_key()","text":"<pre><code>get_key() -&gt; Any\n</code></pre> <p>Get the object key associated with the event.</p> Source code in <code>proxystore/stream/events.py</code> <pre><code>def get_key(self) -&gt; Any:\n    \"\"\"Get the object key associated with the event.\"\"\"\n    key_type = import_from_path(self.key_type)\n    return key_type(*self.raw_key)\n</code></pre>"},{"location":"api/stream/events/#proxystore.stream.events.EventBatch","title":"EventBatch  <code>dataclass</code>","text":"<pre><code>EventBatch(\n    events: list[Event],\n    topic: str,\n    store_config: StoreConfig,\n)\n</code></pre> <p>Batch of stream events.</p>"},{"location":"api/stream/events/#proxystore.stream.events.EventBatch.from_dict","title":"from_dict()  <code>classmethod</code>","text":"<pre><code>from_dict(data: dict[str, Any]) -&gt; EventBatch\n</code></pre> <p>Create a new event instance from its dictionary representation.</p> Source code in <code>proxystore/stream/events.py</code> <pre><code>@classmethod\ndef from_dict(cls, data: dict[str, Any]) -&gt; EventBatch:\n    \"\"\"Create a new event instance from its dictionary representation.\"\"\"\n    events = [dict_to_event(d) for d in data['events']]\n    return cls(\n        events=events,  # type: ignore[arg-type]\n        topic=data['topic'],\n        store_config=StoreConfig(**data['store_config']),\n    )\n</code></pre>"},{"location":"api/stream/events/#proxystore.stream.events.event_to_dict","title":"event_to_dict()","text":"<pre><code>event_to_dict(event: Event | EventBatch) -&gt; dict[str, Any]\n</code></pre> <p>Convert event to dict.</p> Source code in <code>proxystore/stream/events.py</code> <pre><code>def event_to_dict(event: Event | EventBatch) -&gt; dict[str, Any]:\n    \"\"\"Convert event to dict.\"\"\"\n    if isinstance(event, EventBatch):\n        data = {\n            'events': [event_to_dict(e) for e in event.events],\n            'topic': event.topic,\n            'store_config': event.store_config.model_dump(),\n        }\n    else:\n        data = dataclasses.asdict(event)\n    data['event_type'] = _EventMapping(type(event)).name\n    return data\n</code></pre>"},{"location":"api/stream/events/#proxystore.stream.events.dict_to_event","title":"dict_to_event()","text":"<pre><code>dict_to_event(data: dict[str, Any]) -&gt; Event | EventBatch\n</code></pre> <p>Convert dict to event.</p> Source code in <code>proxystore/stream/events.py</code> <pre><code>def dict_to_event(data: dict[str, Any]) -&gt; Event | EventBatch:\n    \"\"\"Convert dict to event.\"\"\"\n    event_type = data.pop('event_type')\n    event = _EventMapping[event_type].value.from_dict(data)\n    return event\n</code></pre>"},{"location":"api/stream/events/#proxystore.stream.events.event_to_bytes","title":"event_to_bytes()","text":"<pre><code>event_to_bytes(event: Event | EventBatch) -&gt; bytes\n</code></pre> <p>Convert event to byte-string.</p> Source code in <code>proxystore/stream/events.py</code> <pre><code>def event_to_bytes(event: Event | EventBatch) -&gt; bytes:\n    \"\"\"Convert event to byte-string.\"\"\"\n    data = event_to_dict(event)\n    return json.dumps(data).encode()\n</code></pre>"},{"location":"api/stream/events/#proxystore.stream.events.bytes_to_event","title":"bytes_to_event()","text":"<pre><code>bytes_to_event(s: bytes) -&gt; Event | EventBatch\n</code></pre> <p>Convert byte-string to event.</p> Source code in <code>proxystore/stream/events.py</code> <pre><code>def bytes_to_event(s: bytes) -&gt; Event | EventBatch:\n    \"\"\"Convert byte-string to event.\"\"\"\n    data = json.loads(s.decode())\n    return dict_to_event(data)\n</code></pre>"},{"location":"api/stream/exceptions/","title":"proxystore.stream.exceptions","text":"<code>proxystore/stream/exceptions.py</code> <p>Streaming exception types.</p>"},{"location":"api/stream/exceptions/#proxystore.stream.exceptions.TopicClosedError","title":"TopicClosedError","text":"<p>             Bases: <code>Exception</code></p> <p>Object sent to topic that has already been closed.</p>"},{"location":"api/stream/filters/","title":"proxystore.stream.filters","text":"<code>proxystore/stream/filters.py</code> <p>Set of common stream filters.</p>"},{"location":"api/stream/filters/#proxystore.stream.filters.NullFilter","title":"NullFilter","text":"<p>Filter which never filters out objects.</p>"},{"location":"api/stream/filters/#proxystore.stream.filters.NullFilter.__call__","title":"__call__()","text":"<pre><code>__call__(metadata: dict[str, Any]) -&gt; bool\n</code></pre> <p>Apply the filter to event metadata.</p> Source code in <code>proxystore/stream/filters.py</code> <pre><code>def __call__(self, metadata: dict[str, Any]) -&gt; bool:\n    \"\"\"Apply the filter to event metadata.\"\"\"\n    return False\n</code></pre>"},{"location":"api/stream/filters/#proxystore.stream.filters.SamplingFilter","title":"SamplingFilter","text":"<pre><code>SamplingFilter(p: float)\n</code></pre> <p>Filter that randomly filters out objects.</p> <p>Parameters:</p> <ul> <li> <code>p</code>             (<code>float</code>)         \u2013          <p>Probability of the filter return <code>True</code>. I.e., the object gets filtered out.</p> </li> </ul> <p>Raises:</p> <ul> <li> <code>ValueError</code>           \u2013          <p>if <code>p</code> is not in the range <code>[0, 1]</code>.</p> </li> </ul> Source code in <code>proxystore/stream/filters.py</code> <pre><code>def __init__(self, p: float) -&gt; None:\n    if p &lt; 0 or p &gt; 1:\n        raise ValueError(\n            f'Filter probability p must be in [0, 1]. Got p={p}.',\n        )\n    self._p = p\n</code></pre>"},{"location":"api/stream/filters/#proxystore.stream.filters.SamplingFilter.__call__","title":"__call__()","text":"<pre><code>__call__(metadata: dict[str, Any]) -&gt; bool\n</code></pre> <p>Apply the filter to event metadata.</p> Source code in <code>proxystore/stream/filters.py</code> <pre><code>def __call__(self, metadata: dict[str, Any]) -&gt; bool:\n    \"\"\"Apply the filter to event metadata.\"\"\"\n    return random.random() &lt;= self._p\n</code></pre>"},{"location":"api/stream/interface/","title":"proxystore.stream.interface","text":"<code>proxystore/stream/interface.py</code> <p>Stream producer and consumer interfaces.</p> Note <p>The StreamProducer and StreamConsumer are re-exported in <code>proxystore.stream</code> for convenience.</p>"},{"location":"api/stream/interface/#proxystore.stream.interface.StreamProducer","title":"StreamProducer","text":"<pre><code>StreamProducer(\n    publisher: Publisher,\n    stores: Mapping[str | None, Store[Any]],\n    *,\n    aggregator: Callable[[list[T]], T] | None = None,\n    batch_size: int = 1,\n    filter_: Filter | None = None\n)\n</code></pre> <p>             Bases: <code>Generic[T]</code></p> <p>Proxy stream producer interface.</p> Note <p>The <code>StreamProducer</code> can be used as a context manager.</p> <pre><code>with StreamProducer(...) as stream:\n    for item in ...:\n        stream.send(item)\n</code></pre> Warning <p>The producer is not thread-safe.</p> Tip <p>This class is generic, so it is recommended that the type of objects in the stream be annotated appropriately. This is useful for enabling a static type checker to validate that the correct object types are published to the stream. <pre><code>producer = StreamProducer[str](...)\n# mypy will raise an error that StreamProducer.send() expects a str\n# but got a list[int].\nproducer.send('default', [1, 2, 3])\n</code></pre></p> <p>Attributes:</p> <ul> <li> <code>publisher</code>         \u2013          <p>Publisher interface.</p> </li> </ul> <p>Parameters:</p> <ul> <li> <code>publisher</code>             (<code>Publisher</code>)         \u2013          <p>Object which implements the <code>Publisher</code> protocol. Used to publish event messages when new objects are added to the stream.</p> </li> <li> <code>stores</code>             (<code>Mapping[str | None, Store[Any]]</code>)         \u2013          <p>Mapping from topic names to the <code>Store</code> instance used to store and communicate serialized objects streamed to that topic. The <code>None</code> topic can be used to specify a default <code>Store</code> used for topics not present in this mapping.</p> </li> <li> <code>aggregator</code>             (<code>Callable[[list[T]], T] | None</code>, default:                 <code>None</code> )         \u2013          <p>Optional aggregator which takes as input the batch of objects and returns a single object of the same type when invoked. The size of the batch passed to the aggregator is controlled by the <code>batch_size</code> parameter. When aggregation is used, the metadata associated with the aggregated object will be the union of each metadata dict from each object in the batch.</p> </li> <li> <code>batch_size</code>             (<code>int</code>, default:                 <code>1</code> )         \u2013          <p>Batch size used for batching and aggregation.</p> </li> <li> <code>filter_</code>             (<code>Filter | None</code>, default:                 <code>None</code> )         \u2013          <p>Optional filter to apply prior to sending objects to the stream. If the filter returns <code>True</code> for a given object's metadata, the object will not be sent to the stream. The filter is applied before aggregation or batching.</p> </li> </ul> Source code in <code>proxystore/stream/interface.py</code> <pre><code>def __init__(\n    self,\n    publisher: Publisher,\n    stores: Mapping[str | None, Store[Any]],\n    *,\n    aggregator: Callable[[list[T]], T] | None = None,\n    batch_size: int = 1,\n    filter_: Filter | None = None,\n) -&gt; None:\n    self.publisher = publisher\n    self._stores = stores\n    self._aggregator = aggregator\n    self._batch_size = batch_size\n    self._filter: Filter = filter_ if filter_ is not None else NullFilter()\n\n    # Mapping between topic and buffers\n    self._buffer: dict[str, _TopicBuffer[T]] = defaultdict(\n        lambda: _TopicBuffer([], False),\n    )\n</code></pre>"},{"location":"api/stream/interface/#proxystore.stream.interface.StreamProducer.close","title":"close()","text":"<pre><code>close(\n    *,\n    topics: Iterable[str] = (),\n    publisher: bool = True,\n    stores: bool = False\n) -&gt; None\n</code></pre> <p>Close the producer.</p> Warning <p>Objects buffered in an incomplete batch will be lost. Call <code>flush()</code> to ensure that all objects are sent before closing.</p> Warning <p>By default, this will close the <code>Publisher</code> interface, but will not close the <code>Store</code> interfaces.</p> <p>Parameters:</p> <ul> <li> <code>topics</code>             (<code>Iterable[str]</code>, default:                 <code>()</code> )         \u2013          <p>Topics to send end of stream events to. Equivalent to calling <code>close_topics()</code> first.</p> </li> <li> <code>publisher</code>             (<code>bool</code>, default:                 <code>True</code> )         \u2013          <p>Close the <code>Publisher</code> interface.</p> </li> <li> <code>stores</code>             (<code>bool</code>, default:                 <code>False</code> )         \u2013          <p>Close and unregister the <code>Store</code> instances.</p> </li> </ul> Source code in <code>proxystore/stream/interface.py</code> <pre><code>def close(\n    self,\n    *,\n    topics: Iterable[str] = (),\n    publisher: bool = True,\n    stores: bool = False,\n) -&gt; None:\n    \"\"\"Close the producer.\n\n    Warning:\n        Objects buffered in an incomplete batch will be lost. Call\n        [`flush()`][proxystore.stream.interface.StreamProducer] to ensure\n        that all objects are sent before closing.\n\n    Warning:\n        By default, this will close the\n        [`Publisher`][proxystore.stream.protocols.Publisher] interface,\n        but will **not** close the [`Store`][proxystore.store.base.Store]\n        interfaces.\n\n    Args:\n        topics: Topics to send end of stream events to. Equivalent to\n            calling [`close_topics()`][proxystore.stream.interface.StreamProducer.close_topics]\n            first.\n        publisher: Close the\n            [`Publisher`][proxystore.stream.protocols.Publisher] interface.\n        stores: Close and [unregister][proxystore.store.unregister_store]\n            the [`Store`][proxystore.store.base.Store] instances.\n    \"\"\"  # noqa: E501\n    self.close_topics(*topics)\n    if stores:\n        for store in self._stores.values():\n            store.close()\n            unregister_store(store)\n    if publisher:\n        self.publisher.close()\n</code></pre>"},{"location":"api/stream/interface/#proxystore.stream.interface.StreamProducer.close_topics","title":"close_topics()","text":"<pre><code>close_topics(*topics: str) -&gt; None\n</code></pre> <p>Send publish an end of stream event to each topic.</p> <p>A <code>StreamConsumer</code> will raise a <code>StopIteration</code> exception when an end of stream event is received. The end of stream event is still ordered, however, so all prior sent events will be consumed first before the end of stream event is propagated.</p> Note <p>This will flush the topic buffer.</p> <p>Parameters:</p> <ul> <li> <code>topics</code>             (<code>str</code>, default:                 <code>()</code> )         \u2013          <p>Topics to send end of stream events to.</p> </li> </ul> Source code in <code>proxystore/stream/interface.py</code> <pre><code>def close_topics(self, *topics: str) -&gt; None:\n    \"\"\"Send publish an end of stream event to each topic.\n\n    A [`StreamConsumer`][proxystore.stream.interface.StreamConsumer]\n    will raise a [`StopIteration`][StopIteration] exception when an\n    end of stream event is received. The end of stream event is still\n    ordered, however, so all prior sent events will be consumed first\n    before the end of stream event is propagated.\n\n    Note:\n        This will flush the topic buffer.\n\n    Args:\n        topics: Topics to send end of stream events to.\n    \"\"\"\n    for topic in topics:\n        self._buffer[topic].closed = True\n        self.flush_topic(topic)\n</code></pre>"},{"location":"api/stream/interface/#proxystore.stream.interface.StreamProducer.flush","title":"flush()","text":"<pre><code>flush() -&gt; None\n</code></pre> <p>Flush batch buffers for all topics.</p> Source code in <code>proxystore/stream/interface.py</code> <pre><code>def flush(self) -&gt; None:\n    \"\"\"Flush batch buffers for all topics.\"\"\"\n    for topic in self._buffer:\n        self.flush_topic(topic)\n</code></pre>"},{"location":"api/stream/interface/#proxystore.stream.interface.StreamProducer.flush_topic","title":"flush_topic()","text":"<pre><code>flush_topic(topic: str) -&gt; None\n</code></pre> <p>Flush the batch buffer for a topic.</p> <p>This method:</p> <ol> <li>Pops the current batch of objects off the topic buffer.</li> <li>Applies the aggregator to the batch if one was provided.</li> <li>Puts the batch of objects in the    <code>Store</code>.</li> <li>Creates a new batch event using the keys returned by the store and    additional metadata.</li> <li>Publishes the event to the stream via the    <code>Publisher</code>.</li> </ol> <p>Parameters:</p> <ul> <li> <code>topic</code>             (<code>str</code>)         \u2013          <p>Topic to flush.</p> </li> </ul> if a store associated with <code>topic</code> is not found <p>in the mapping of topics to stores nor a default store is provided.</p> Source code in <code>proxystore/stream/interface.py</code> <pre><code>def flush_topic(self, topic: str) -&gt; None:\n    \"\"\"Flush the batch buffer for a topic.\n\n    This method:\n\n    1. Pops the current batch of objects off the topic buffer.\n    2. Applies the aggregator to the batch if one was provided.\n    3. Puts the batch of objects in the\n       [`Store`][proxystore.store.base.Store].\n    4. Creates a new batch event using the keys returned by the store and\n       additional metadata.\n    5. Publishes the event to the stream via the\n       [`Publisher`][proxystore.stream.protocols.Publisher].\n\n    Args:\n        topic: Topic to flush.\n\n    ValueError: if a store associated with `topic` is not found\n        in the mapping of topics to stores nor a default store is\n        provided.\n    \"\"\"\n    objects = self._buffer[topic].objects\n    closed = self._buffer[topic].closed\n\n    if len(objects) == 0 and not closed:\n        # No events to send so quick return\n        return\n\n    # Reset buffer\n    self._buffer[topic].objects = []\n\n    if self._aggregator is not None and len(objects) &gt; 0:\n        obj = self._aggregator([item.obj for item in objects])\n        evict = any([item.evict for item in objects])\n        metadata: dict[str, Any] = {}\n        for item in objects:\n            metadata.update(item.metadata)\n        objects = [_BufferedObject(obj, evict, metadata)]\n\n    if topic in self._stores:\n        store = self._stores[topic]\n    elif None in self._stores:\n        store = self._stores[None]\n    else:\n        raise ValueError(\n            f'No store associated with topic \"{topic}\" found or '\n            'default store.',\n        )\n\n    events: list[Event] = []\n\n    if len(objects) &gt; 0:\n        keys = store.put_batch([item.obj for item in objects])\n\n        for key, item in zip(keys, objects):\n            event = NewObjectEvent.from_key(\n                key,\n                evict=item.evict,\n                metadata=item.metadata,\n            )\n            events.append(event)\n\n    if closed:\n        events.append(EndOfStreamEvent())\n\n    # If there are no new events and the stream wasn't closed we should\n    # have early exited\n    assert len(events) &gt; 0\n\n    batch_event = EventBatch(events, topic, store.config())\n    message = event_to_bytes(batch_event)\n    self.publisher.send(topic, message)\n</code></pre>"},{"location":"api/stream/interface/#proxystore.stream.interface.StreamProducer.send","title":"send()","text":"<pre><code>send(\n    topic: str,\n    obj: T,\n    *,\n    evict: bool = True,\n    metadata: dict[str, Any] | None = None\n) -&gt; None\n</code></pre> <p>Send an item to the stream.</p> <p>This method:</p> <ol> <li>Applies the filter to the metadata associated with this event,    skipping streaming this object if the filter returns <code>True</code>.</li> <li>Adds the object to the internal event buffer for this topic.</li> <li>Flushes the event buffer once the batch size is reached.</li> </ol> Warning <p>Careful consideration should be given to the setting of the <code>evict</code> flag. When set to <code>True</code>, the corresponding proxy yielded by the consumer of the stream will only be resolvable once. If you encounter unexpected <code>ProxyResolveMissingKeyError</code> errors, it may be due to proxies from the stream being resolved multiple times but the first resolve triggered an eviction of the underlying data.</p> <p>Parameters:</p> <ul> <li> <code>topic</code>             (<code>str</code>)         \u2013          <p>Stream topic to send the object to.</p> </li> <li> <code>obj</code>             (<code>T</code>)         \u2013          <p>Object to send via the stream.</p> </li> <li> <code>evict</code>             (<code>bool</code>, default:                 <code>True</code> )         \u2013          <p>Evict the object from the <code>Store</code> once the object is consumed by a <code>StreamConsumer</code>. Set to <code>False</code> if a single object in the stream will be consumed by multiple consumers. Note that when set to <code>False</code>, data eviction must be handled manually.</p> </li> <li> <code>metadata</code>             (<code>dict[str, Any] | None</code>, default:                 <code>None</code> )         \u2013          <p>Dictionary containing metadata about the object. This can be used by the producer or consumer to filter new object events. The default value <code>None</code> is replaced with an empty <code>dict</code>.</p> </li> </ul> <p>Raises:</p> <ul> <li> <code>TopicClosedError</code>           \u2013          <p>if the <code>topic</code> has already been closed via <code>close_topics()</code>.</p> </li> <li> <code>ValueError</code>           \u2013          <p>if a store associated with <code>topic</code> is not found in the mapping of topics to stores nor a default store is provided.</p> </li> </ul> Source code in <code>proxystore/stream/interface.py</code> <pre><code>def send(\n    self,\n    topic: str,\n    obj: T,\n    *,\n    evict: bool = True,\n    metadata: dict[str, Any] | None = None,\n) -&gt; None:\n    \"\"\"Send an item to the stream.\n\n    This method:\n\n    1. Applies the filter to the metadata associated with this event,\n       skipping streaming this object if the filter returns `True`.\n    2. Adds the object to the internal event buffer for this topic.\n    3. Flushes the event buffer once the batch size is reached.\n\n    Warning:\n        Careful consideration should be given to the setting of the\n        `evict` flag. When set to `True`, the corresponding proxy\n        yielded by the consumer of the stream will only be resolvable\n        once. If you encounter unexpected\n        [`ProxyResolveMissingKeyError`][proxystore.store.exceptions.ProxyResolveMissingKeyError]\n        errors, it may be due to proxies from the stream being resolved\n        multiple times but the first resolve triggered an eviction\n        of the underlying data.\n\n    Args:\n        topic: Stream topic to send the object to.\n        obj: Object to send via the stream.\n        evict: Evict the object from the\n            [`Store`][proxystore.store.base.Store] once the object is\n            consumed by a\n            [`StreamConsumer`][proxystore.stream.interface.StreamConsumer].\n            Set to `False` if a single object in the stream will be\n            consumed by multiple consumers. Note that when set to `False`,\n            data eviction must be handled manually.\n        metadata: Dictionary containing metadata about the object. This\n            can be used by the producer or consumer to filter new\n            object events. The default value `None` is replaced with an\n            empty [`dict`][dict].\n\n    Raises:\n        TopicClosedError: if the `topic` has already been closed via\n            [`close_topics()`][proxystore.stream.interface.StreamProducer.close_topics].\n        ValueError: if a store associated with `topic` is not found\n            in the mapping of topics to stores nor a default store is\n            provided.\n    \"\"\"\n    if self._buffer[topic].closed:\n        raise TopicClosedError(f'Topic \"{topic}\" has been closed.')\n\n    metadata = metadata if metadata is not None else {}\n    if self._filter(metadata):\n        return\n\n    item = _BufferedObject(obj, evict, metadata)\n    self._buffer[topic].objects.append(item)\n\n    if len(self._buffer[topic].objects) &gt;= self._batch_size:\n        self.flush_topic(topic)\n</code></pre>"},{"location":"api/stream/interface/#proxystore.stream.interface.StreamConsumer","title":"StreamConsumer","text":"<pre><code>StreamConsumer(\n    subscriber: Subscriber, *, filter_: Filter | None = None\n)\n</code></pre> <p>             Bases: <code>Generic[T]</code></p> <p>Proxy stream consumer interface.</p> <p>This interface acts as an iterator that will yield items from the stream until the stream is closed.</p> Note <p>The <code>StreamConsumer</code> can be used as a context manager.</p> <pre><code>with StreamConsumer(...) as stream:\n    for item in stream:\n        ...\n</code></pre> Tip <p>This class is generic, so it is recommended that the type of objects in the stream be annotated appropriately. <pre><code>consumer = StreamConsumer[str](...)\nreveal_type(consumer.next())\n# Proxy[str]\n</code></pre> If the stream is heterogeneous or objects types are not known ahead of time, it may be appropriate to annotate the stream with <code>Any</code>. <pre><code>consumer = StreamConsumer[Any](...)\nreveal_type(consumer.next())\n# Proxy[Any]\n</code></pre></p> Warning <p>If you encounter unexpected <code>ProxyResolveMissingKeyError</code> errors, it may be due to proxies from the stream being resolved multiple times but the first resolve triggered an eviction of the underlying data. If this is the case, confirm that the setting of the <code>evict</code> flag on <code>StreamProducer.send()</code> is set correctly and the there is not code incidentally resolving proxies before you expect.</p> Note <p>The consumer is not thread-safe.</p> <p>Attributes:</p> <ul> <li> <code>subscriber</code>         \u2013          <p>Subscriber interface.</p> </li> </ul> <p>Parameters:</p> <ul> <li> <code>subscriber</code>             (<code>Subscriber</code>)         \u2013          <p>Object which implements the <code>Subscriber</code> protocol. Used to listen for new event messages indicating new objects in the stream.</p> </li> <li> <code>filter_</code>             (<code>Filter | None</code>, default:                 <code>None</code> )         \u2013          <p>Optional filter to apply to event metadata received from the stream. If the filter returns <code>True</code>, the event will be dropped (i.e., not yielded back to the user), and the object associated with that event will be deleted if the <code>evict</code> flag was set on the producer side.</p> </li> </ul> Source code in <code>proxystore/stream/interface.py</code> <pre><code>def __init__(\n    self,\n    subscriber: Subscriber,\n    *,\n    filter_: Filter | None = None,\n) -&gt; None:\n    self.subscriber = subscriber\n    self._stores: dict[str, Store[Any]] = {}\n    self._filter: Filter = filter_ if filter_ is not None else NullFilter()\n\n    self._current_batch: EventBatch | None = None\n</code></pre>"},{"location":"api/stream/interface/#proxystore.stream.interface.StreamConsumer.__iter__","title":"__iter__()","text":"<pre><code>__iter__() -&gt; Self\n</code></pre> <p>Return an iterator that will yield proxies of stream objects.</p> Source code in <code>proxystore/stream/interface.py</code> <pre><code>def __iter__(self) -&gt; Self:\n    \"\"\"Return an iterator that will yield proxies of stream objects.\"\"\"\n    return self\n</code></pre>"},{"location":"api/stream/interface/#proxystore.stream.interface.StreamConsumer.__next__","title":"__next__()","text":"<pre><code>__next__() -&gt; Proxy[T]\n</code></pre> <p>Alias for <code>next()</code>.</p> Source code in <code>proxystore/stream/interface.py</code> <pre><code>def __next__(self) -&gt; Proxy[T]:\n    \"\"\"Alias for [`next()`][proxystore.stream.interface.StreamConsumer.next].\"\"\"  # noqa: E501\n    return self.next()\n</code></pre>"},{"location":"api/stream/interface/#proxystore.stream.interface.StreamConsumer.close","title":"close()","text":"<pre><code>close(\n    *, stores: bool = False, subscriber: bool = True\n) -&gt; None\n</code></pre> <p>Close the consumer.</p> Warning <p>By default, this will close the <code>Subscriber</code> interface, but will not close the <code>Store</code> interfaces.</p> <p>Parameters:</p> <ul> <li> <code>stores</code>             (<code>bool</code>, default:                 <code>False</code> )         \u2013          <p>Close and unregister the <code>Store</code> instances used to resolve objects consumed from the stream.</p> </li> <li> <code>subscriber</code>             (<code>bool</code>, default:                 <code>True</code> )         \u2013          <p>Close the <code>Subscriber</code> interface.</p> </li> </ul> Source code in <code>proxystore/stream/interface.py</code> <pre><code>def close(self, *, stores: bool = False, subscriber: bool = True) -&gt; None:\n    \"\"\"Close the consumer.\n\n    Warning:\n        By default, this will close the\n        [`Subscriber`][proxystore.stream.protocols.Subscriber] interface,\n        but will **not** close the [`Store`][proxystore.store.base.Store]\n        interfaces.\n\n    Args:\n        stores: Close and [unregister][proxystore.store.unregister_store]\n            the [`Store`][proxystore.store.base.Store] instances\n            used to resolve objects consumed from the stream.\n        subscriber: Close the\n            [`Subscriber`][proxystore.stream.protocols.Subscriber]\n            interface.\n    \"\"\"\n    if stores:\n        for store in self._stores.values():\n            store.close()\n            unregister_store(store)\n    if subscriber:\n        self.subscriber.close()\n</code></pre>"},{"location":"api/stream/interface/#proxystore.stream.interface.StreamConsumer.iter_with_metadata","title":"iter_with_metadata()","text":"<pre><code>iter_with_metadata() -&gt; (\n    Generator[tuple[dict[str, Any], Proxy[T]], None, None]\n)\n</code></pre> <p>Return an iterator that yields tuples of metadata and proxies.</p> Note <p>This is different from <code>iter(consumer)</code> which will yield only proxies of objects in the stream.</p> Source code in <code>proxystore/stream/interface.py</code> <pre><code>def iter_with_metadata(\n    self,\n) -&gt; Generator[tuple[dict[str, Any], Proxy[T]], None, None]:\n    \"\"\"Return an iterator that yields tuples of metadata and proxies.\n\n    Note:\n        This is different from `iter(consumer)` which will yield\n        *only* proxies of objects in the stream.\n    \"\"\"\n    while True:\n        try:\n            yield self.next_with_metadata()\n        except StopIteration:\n            return\n</code></pre>"},{"location":"api/stream/interface/#proxystore.stream.interface.StreamConsumer.iter_objects","title":"iter_objects()","text":"<pre><code>iter_objects() -&gt; Generator[T, None, None]\n</code></pre> <p>Return an iterator that yields objects from the stream.</p> Note <p>This is different from <code>iter(consumer)</code> which will yield proxies of objects in the stream.</p> Source code in <code>proxystore/stream/interface.py</code> <pre><code>def iter_objects(self) -&gt; Generator[T, None, None]:\n    \"\"\"Return an iterator that yields objects from the stream.\n\n    Note:\n        This is different from `iter(consumer)` which will yield\n        proxies of objects in the stream.\n    \"\"\"\n    while True:\n        try:\n            yield self.next_object()\n        except StopIteration:\n            return\n</code></pre>"},{"location":"api/stream/interface/#proxystore.stream.interface.StreamConsumer.iter_objects_with_metadata","title":"iter_objects_with_metadata()","text":"<pre><code>iter_objects_with_metadata() -&gt; (\n    Generator[tuple[dict[str, Any], T], None, None]\n)\n</code></pre> <p>Return an iterator that yields tuples of metadata and objects.</p> Note <p>This is different from <code>iter(consumer)</code> which will yield proxies of objects in the stream.</p> Source code in <code>proxystore/stream/interface.py</code> <pre><code>def iter_objects_with_metadata(\n    self,\n) -&gt; Generator[tuple[dict[str, Any], T], None, None]:\n    \"\"\"Return an iterator that yields tuples of metadata and objects.\n\n    Note:\n        This is different from `iter(consumer)` which will yield\n        proxies of objects in the stream.\n    \"\"\"\n    while True:\n        try:\n            yield self.next_object_with_metadata()\n        except StopIteration:\n            return\n</code></pre>"},{"location":"api/stream/interface/#proxystore.stream.interface.StreamConsumer.next","title":"next()","text":"<pre><code>next() -&gt; Proxy[T]\n</code></pre> <p>Return a proxy of the next object in the stream.</p> Note <p>This method has the potential side effect of initializing and globally registering a new <code>Store</code> instance. This will happen at most once per topic because the producer can map topic names to <code>Store</code> instances. This class will keep track of the <code>Store</code> instances used by the stream and will close and unregister them when this class is closed.</p> <p>Raises:</p> <ul> <li> <code>StopIteration</code>           \u2013          <p>when an end of stream event is received from a producer. Note that this does not call <code>close()</code>.</p> </li> </ul> Source code in <code>proxystore/stream/interface.py</code> <pre><code>def next(self) -&gt; Proxy[T]:\n    \"\"\"Return a proxy of the next object in the stream.\n\n    Note:\n        This method has the potential side effect of initializing and\n        globally registering a new [`Store`][proxystore.store.base.Store]\n        instance. This will happen at most once per topic because the\n        producer can map topic names to\n        [`Store`][proxystore.store.base.Store] instances. This class will\n        keep track of the [`Store`][proxystore.store.base.Store] instances\n        used by the stream and will close and unregister them when this\n        class is closed.\n\n    Raises:\n        StopIteration: when an end of stream event is received from a\n            producer. Note that this does not call\n            [`close()`][proxystore.stream.interface.StreamConsumer.close].\n    \"\"\"\n    _, proxy = self.next_with_metadata()\n    return proxy\n</code></pre>"},{"location":"api/stream/interface/#proxystore.stream.interface.StreamConsumer.next_with_metadata","title":"next_with_metadata()","text":"<pre><code>next_with_metadata() -&gt; tuple[dict[str, Any], Proxy[T]]\n</code></pre> <p>Return a tuple of metadata and proxy for the next object.</p> Note <p>This method has the same potential side effects as <code>next()</code>.</p> <p>Returns:</p> <ul> <li> <code>dict[str, Any]</code>         \u2013          <p>Dictionary of user-provided metadata associated with the object.</p> </li> <li> <code>Proxy[T]</code>         \u2013          <p>Proxy of the next object in the stream.</p> </li> </ul> <p>Raises:</p> <ul> <li> <code>StopIteration</code>           \u2013          <p>when an end of stream event is received from a producer. Note that this does not call <code>close()</code>.</p> </li> </ul> Source code in <code>proxystore/stream/interface.py</code> <pre><code>def next_with_metadata(self) -&gt; tuple[dict[str, Any], Proxy[T]]:\n    \"\"\"Return a tuple of metadata and proxy for the next object.\n\n    Note:\n        This method has the same potential side effects as\n        [`next()`][proxystore.stream.interface.StreamConsumer.next].\n\n    Returns:\n        Dictionary of user-provided metadata associated with the object.\n        Proxy of the next object in the stream.\n\n    Raises:\n        StopIteration: when an end of stream event is received from a\n            producer. Note that this does not call\n            [`close()`][proxystore.stream.interface.StreamConsumer.close].\n    \"\"\"\n    event_info = self._next_event_with_filter()\n    store = self._get_store(event_info)\n    event = event_info.event\n    key = event.get_key()\n\n    proxy: Proxy[T] = store.proxy_from_key(key, evict=event.evict)\n    return event.metadata, proxy\n</code></pre>"},{"location":"api/stream/interface/#proxystore.stream.interface.StreamConsumer.next_object","title":"next_object()","text":"<pre><code>next_object() -&gt; T\n</code></pre> <p>Return the next object in the stream.</p> Note <p>This method has the same potential side effects as <code>next()</code>.</p> <p>Raises:</p> <ul> <li> <code>StopIteration</code>           \u2013          <p>when an end of stream event is received from a producer. Note that this does not call <code>close()</code>.</p> </li> <li> <code>ValueError</code>           \u2013          <p>if the store does not return an object using the key included in the object's event metadata.</p> </li> </ul> Source code in <code>proxystore/stream/interface.py</code> <pre><code>def next_object(self) -&gt; T:\n    \"\"\"Return the next object in the stream.\n\n    Note:\n        This method has the same potential side effects as\n        [`next()`][proxystore.stream.interface.StreamConsumer.next].\n\n    Raises:\n        StopIteration: when an end of stream event is received from a\n            producer. Note that this does not call\n            [`close()`][proxystore.stream.interface.StreamConsumer.close].\n        ValueError: if the store does not return an object using the key\n            included in the object's event metadata.\n    \"\"\"\n    _, obj = self.next_object_with_metadata()\n    return obj\n</code></pre>"},{"location":"api/stream/interface/#proxystore.stream.interface.StreamConsumer.next_object_with_metadata","title":"next_object_with_metadata()","text":"<pre><code>next_object_with_metadata() -&gt; tuple[dict[str, Any], T]\n</code></pre> <p>Return a tuple of metadata and the next object in the stream.</p> Note <p>This method has the same potential side effects as <code>next()</code>.</p> <p>Returns:</p> <ul> <li> <code>dict[str, Any]</code>         \u2013          <p>Dictionary of user-provided metadata associated with the object.</p> </li> <li> <code>T</code>         \u2013          <p>Next object in the stream.</p> </li> </ul> <p>Raises:</p> <ul> <li> <code>StopIteration</code>           \u2013          <p>when an end of stream event is received from a producer. Note that this does not call <code>close()</code>.</p> </li> </ul> Source code in <code>proxystore/stream/interface.py</code> <pre><code>def next_object_with_metadata(self) -&gt; tuple[dict[str, Any], T]:\n    \"\"\"Return a tuple of metadata and the next object in the stream.\n\n    Note:\n        This method has the same potential side effects as\n        [`next()`][proxystore.stream.interface.StreamConsumer.next].\n\n    Returns:\n        Dictionary of user-provided metadata associated with the object.\n        Next object in the stream.\n\n    Raises:\n        StopIteration: when an end of stream event is received from a\n            producer. Note that this does not call\n            [`close()`][proxystore.stream.interface.StreamConsumer.close].\n    \"\"\"\n    event_info = self._next_event_with_filter()\n    store = self._get_store(event_info)\n    event = event_info.event\n    key = event.get_key()\n\n    obj = store.get(key)\n    if obj is None:\n        raise ValueError(\n            f'Store(name=\"{store.name}\") returned None for key={key}.',\n        )\n\n    if event.evict:\n        store.evict(key)\n\n    return event.metadata, cast(T, obj)\n</code></pre>"},{"location":"api/stream/protocols/","title":"proxystore.stream.protocols","text":"<code>proxystore/stream/protocols.py</code> <p>Protocols used by the stream interfaces.</p>"},{"location":"api/stream/protocols/#proxystore.stream.protocols--publishersubscriber","title":"Publisher/Subscriber","text":"<p>The <code>Publisher</code> and <code>Subscriber</code> are <code>Protocols</code> which define the publisher and subscriber interfaces to a pub/sub-like messaging system.</p> <p>In general, these protocols do not enforce any other implementation details besides the interface. For example, implementations could choose to support any producer-to-consumer configurations (e.g., 1:1, 1:N, N:N). A set of shims implementing these protocols for third-party message brokers are provided in <code>proxystore.stream.shims</code>.</p>"},{"location":"api/stream/protocols/#proxystore.stream.protocols--plugins","title":"Plugins","text":"<p>Additional protocols, such as the <code>Filter</code>, are plugins used by the <code>StreamProducer</code> and/or <code>StreamConsumer</code> that alter their behavior.</p>"},{"location":"api/stream/protocols/#proxystore.stream.protocols.Publisher","title":"Publisher","text":"<p>             Bases: <code>Protocol</code></p> <p>Publisher interface to message stream.</p>"},{"location":"api/stream/protocols/#proxystore.stream.protocols.Publisher.close","title":"close()","text":"<pre><code>close() -&gt; None\n</code></pre> <p>Close this publisher.</p> Source code in <code>proxystore/stream/protocols.py</code> <pre><code>def close(self) -&gt; None:\n    \"\"\"Close this publisher.\"\"\"\n    ...\n</code></pre>"},{"location":"api/stream/protocols/#proxystore.stream.protocols.Publisher.send","title":"send()","text":"<pre><code>send(topic: str, message: bytes) -&gt; None\n</code></pre> <p>Publish a message to the stream.</p> <p>Parameters:</p> <ul> <li> <code>topic</code>             (<code>str</code>)         \u2013          <p>Stream topic to publish message to.</p> </li> <li> <code>message</code>             (<code>bytes</code>)         \u2013          <p>Message as bytes to publish to the stream.</p> </li> </ul> Source code in <code>proxystore/stream/protocols.py</code> <pre><code>def send(self, topic: str, message: bytes) -&gt; None:\n    \"\"\"Publish a message to the stream.\n\n    Args:\n        topic: Stream topic to publish message to.\n        message: Message as bytes to publish to the stream.\n    \"\"\"\n    ...\n</code></pre>"},{"location":"api/stream/protocols/#proxystore.stream.protocols.Subscriber","title":"Subscriber","text":"<p>             Bases: <code>Protocol</code></p> <p>Subscriber interface to message stream.</p> <p>The subscriber protocol is an iterable object which yields objects from the stream until the stream is closed.</p>"},{"location":"api/stream/protocols/#proxystore.stream.protocols.Subscriber.close","title":"close()","text":"<pre><code>close() -&gt; None\n</code></pre> <p>Close this subscriber.</p> Source code in <code>proxystore/stream/protocols.py</code> <pre><code>def close(self) -&gt; None:\n    \"\"\"Close this subscriber.\"\"\"\n    ...\n</code></pre>"},{"location":"api/stream/protocols/#proxystore.stream.protocols.Filter","title":"Filter","text":"<p>             Bases: <code>Protocol</code></p> <p>Filter protocol.</p> <p>A filter takes as input the dictionary of metadata associated with a new object event and returns a boolean indicating if the event should be dropped. I.e., if the filter returns <code>True</code>, the event will be filtered out of the stream and lost.</p>"},{"location":"api/stream/protocols/#proxystore.stream.protocols.Filter.__call__","title":"__call__()","text":"<pre><code>__call__(metadata: dict[str, Any]) -&gt; bool\n</code></pre> <p>Apply the filter to event metadata.</p> Source code in <code>proxystore/stream/protocols.py</code> <pre><code>def __call__(self, metadata: dict[str, Any]) -&gt; bool:\n    \"\"\"Apply the filter to event metadata.\"\"\"\n    ...\n</code></pre>"},{"location":"api/stream/shims/","title":"proxystore.stream.shims","text":"<code>proxystore/stream/shims/__init__.py</code> <p>Shim interfaces to common message brokers.</p> <p>The <code>Publisher</code> and <code>Subscriber</code> are <code>Protocols</code> which define the publisher and subscriber interfaces to a pub/sub-like message broker.</p> <p>This sub-package provides a set of shim or adapter interfaces to common pub/sub systems like Kafka, Redis, and ZeroMQ. Generally, these shims are very lightweight and mostly serve to adapt the third-party interface to match the <code>Publisher</code> and <code>Subscriber</code> protocols expected by the StreamProducer and StreamConsumer.</p> Warning <p>Most of the provided shims have a external dependency that may not be installed by default with ProxyStore.</p>"},{"location":"api/stream/shims/kafka/","title":"proxystore.stream.shims.kafka","text":"<code>proxystore/stream/shims/kafka.py</code> <p>Kafka publisher and subscriber shims.</p> <p>Shims to the <code>confluent-kafka</code> package.</p>"},{"location":"api/stream/shims/kafka/#proxystore.stream.shims.kafka.KafkaPublisher","title":"KafkaPublisher","text":"<pre><code>KafkaPublisher(client: Producer)\n</code></pre> <p>Kafka publisher shim.</p> <p>Parameters:</p> <ul> <li> <code>client</code>             (<code>Producer</code>)         \u2013          <p>Kafka producer client.</p> </li> </ul> Source code in <code>proxystore/stream/shims/kafka.py</code> <pre><code>def __init__(self, client: confluent_kafka.Producer) -&gt; None:\n    self.client = client\n</code></pre>"},{"location":"api/stream/shims/kafka/#proxystore.stream.shims.kafka.KafkaPublisher.close","title":"close()","text":"<pre><code>close() -&gt; None\n</code></pre> <p>Close this publisher.</p> Source code in <code>proxystore/stream/shims/kafka.py</code> <pre><code>def close(self) -&gt; None:\n    \"\"\"Close this publisher.\"\"\"\n    self.client.flush()\n</code></pre>"},{"location":"api/stream/shims/kafka/#proxystore.stream.shims.kafka.KafkaPublisher.send","title":"send()","text":"<pre><code>send(topic: str, message: bytes) -&gt; None\n</code></pre> <p>Publish a message to the stream.</p> <p>Parameters:</p> <ul> <li> <code>topic</code>             (<code>str</code>)         \u2013          <p>Stream topic to publish message to.</p> </li> <li> <code>message</code>             (<code>bytes</code>)         \u2013          <p>Message as bytes to publish to the stream.</p> </li> </ul> Source code in <code>proxystore/stream/shims/kafka.py</code> <pre><code>def send(self, topic: str, message: bytes) -&gt; None:\n    \"\"\"Publish a message to the stream.\n\n    Args:\n        topic: Stream topic to publish message to.\n        message: Message as bytes to publish to the stream.\n    \"\"\"\n    self.client.produce(topic, message)\n    self.client.flush()\n</code></pre>"},{"location":"api/stream/shims/kafka/#proxystore.stream.shims.kafka.KafkaSubscriber","title":"KafkaSubscriber","text":"<pre><code>KafkaSubscriber(client: Consumer)\n</code></pre> <p>Kafka subscriber shim.</p> <p>This shim is an iterable object which will yield <code>bytes</code> messages from the stream, blocking on the next message, until the stream is closed.</p> <p>Parameters:</p> <ul> <li> <code>client</code>             (<code>Consumer</code>)         \u2013          <p>Kafka consumer client. The <code>client</code> must already be subscribed to the relevant topics.</p> </li> </ul> Source code in <code>proxystore/stream/shims/kafka.py</code> <pre><code>def __init__(self, client: confluent_kafka.Consumer) -&gt; None:\n    self.client = client\n</code></pre>"},{"location":"api/stream/shims/kafka/#proxystore.stream.shims.kafka.KafkaSubscriber.close","title":"close()","text":"<pre><code>close() -&gt; None\n</code></pre> <p>Close this subscriber.</p> Source code in <code>proxystore/stream/shims/kafka.py</code> <pre><code>def close(self) -&gt; None:\n    \"\"\"Close this subscriber.\"\"\"\n    self.client.close()\n</code></pre>"},{"location":"api/stream/shims/queue/","title":"proxystore.stream.shims.queue","text":"<code>proxystore/stream/shims/queue.py</code> <p>Python queue-based pub/sub implementation.</p> Warning <p>This implementation is meant for streaming between Python threads within the same process, or between Python processes on the same machine. Each queue topic may only have one subscriber.</p>"},{"location":"api/stream/shims/queue/#proxystore.stream.shims.queue.QueuePublisher","title":"QueuePublisher","text":"<pre><code>QueuePublisher(\n    queues: Mapping[str, Queue[bytes] | Queue[bytes]],\n    *,\n    block: bool = True,\n    timeout: float | None = None\n)\n</code></pre> <p>Publisher built on Python queues.</p> Warning <p>Each topic can only have one subscriber.</p> <p>Parameters:</p> <ul> <li> <code>queues</code>             (<code>Mapping[str, Queue[bytes] | Queue[bytes]]</code>)         \u2013          <p>Mapping of topic name to Python queue.</p> </li> <li> <code>block</code>             (<code>bool</code>, default:                 <code>True</code> )         \u2013          <p>Block until a free slot is available when sending a new message to the queue.</p> </li> <li> <code>timeout</code>             (<code>float | None</code>, default:                 <code>None</code> )         \u2013          <p>Block at most <code>timeout</code> seconds.</p> </li> </ul> Source code in <code>proxystore/stream/shims/queue.py</code> <pre><code>def __init__(\n    self,\n    queues: Mapping[\n        str,\n        multiprocessing.Queue[bytes] | queue.Queue[bytes],\n    ],\n    *,\n    block: bool = True,\n    timeout: float | None = None,\n) -&gt; None:\n    self._queues = queues\n    self._block = block\n    self._timeout = timeout\n</code></pre>"},{"location":"api/stream/shims/queue/#proxystore.stream.shims.queue.QueuePublisher.close","title":"close()","text":"<pre><code>close() -&gt; None\n</code></pre> <p>Close this publisher.</p> Source code in <code>proxystore/stream/shims/queue.py</code> <pre><code>def close(self) -&gt; None:\n    \"\"\"Close this publisher.\"\"\"\n    for q in self._queues.values():\n        if isinstance(q, multiprocessing.queues.Queue):\n            q.close()\n</code></pre>"},{"location":"api/stream/shims/queue/#proxystore.stream.shims.queue.QueuePublisher.send","title":"send()","text":"<pre><code>send(topic: str, message: bytes) -&gt; None\n</code></pre> <p>Publish a message to the stream.</p> <p>Parameters:</p> <ul> <li> <code>topic</code>             (<code>str</code>)         \u2013          <p>Stream topic to publish message to.</p> </li> <li> <code>message</code>             (<code>bytes</code>)         \u2013          <p>Message as bytes to publish to the stream.</p> </li> </ul> <p>Raises:</p> <ul> <li> <code>ValueError</code>           \u2013          <p>if a queue with the name <code>topic</code> does not exist.</p> </li> </ul> Source code in <code>proxystore/stream/shims/queue.py</code> <pre><code>def send(self, topic: str, message: bytes) -&gt; None:\n    \"\"\"Publish a message to the stream.\n\n    Args:\n        topic: Stream topic to publish message to.\n        message: Message as bytes to publish to the stream.\n\n    Raises:\n        ValueError: if a queue with the name `topic` does not exist.\n    \"\"\"\n    if topic not in self._queues:\n        raise ValueError(f'Unknown topic \"{topic}\".')\n    self._queues[topic].put(\n        message,\n        block=self._block,\n        timeout=self._timeout,\n    )\n</code></pre>"},{"location":"api/stream/shims/queue/#proxystore.stream.shims.queue.QueueSubscriber","title":"QueueSubscriber","text":"<pre><code>QueueSubscriber(\n    queue: Queue[bytes] | Queue[bytes],\n    *,\n    block: bool = True,\n    timeout: float | None = None\n)\n</code></pre> <p>Subscriber to a <code>QueuePublisher</code> topic.</p> Warning <p>Each topic can only have one subscriber.</p> <p>Parameters:</p> <ul> <li> <code>queue</code>             (<code>Queue[bytes] | Queue[bytes]</code>)         \u2013          <p>Queue shared with the <code>QueuePublisher</code> to pull messages from.</p> </li> <li> <code>block</code>             (<code>bool</code>, default:                 <code>True</code> )         \u2013          <p>Block until the next message is available in the queue.</p> </li> <li> <code>timeout</code>             (<code>float | None</code>, default:                 <code>None</code> )         \u2013          <p>Block at most <code>timeout</code> seconds.</p> </li> </ul> Source code in <code>proxystore/stream/shims/queue.py</code> <pre><code>def __init__(\n    self,\n    queue: multiprocessing.Queue[bytes] | queue.Queue[bytes],\n    *,\n    block: bool = True,\n    timeout: float | None = None,\n) -&gt; None:\n    self._queue = queue\n    self._block = block\n    self._timeout = timeout\n</code></pre>"},{"location":"api/stream/shims/queue/#proxystore.stream.shims.queue.QueueSubscriber.close","title":"close()","text":"<pre><code>close() -&gt; None\n</code></pre> <p>Close this subscriber.</p> Source code in <code>proxystore/stream/shims/queue.py</code> <pre><code>def close(self) -&gt; None:\n    \"\"\"Close this subscriber.\"\"\"\n    pass\n</code></pre>"},{"location":"api/stream/shims/redis/","title":"proxystore.stream.shims.redis","text":"<code>proxystore/stream/shims/redis.py</code> <p>Redis publisher and subscriber shims.</p> <p>Shims to the <code>redis-py</code> Publish / Subscribe interface.</p>"},{"location":"api/stream/shims/redis/#proxystore.stream.shims.redis.RedisPublisher","title":"RedisPublisher","text":"<pre><code>RedisPublisher(hostname: str, port: int, **kwargs: Any)\n</code></pre> <p>Redis pub/sub publisher shim.</p> Note <p>In Redis pub/sub, all subscribers will receive all messages, and messages will be dropped if no subscribers are present. The <code>RedisQueuePublisher</code> provides message persistence and single consumption messages.</p> <p>Parameters:</p> <ul> <li> <code>hostname</code>             (<code>str</code>)         \u2013          <p>Redis server hostname.</p> </li> <li> <code>port</code>             (<code>int</code>)         \u2013          <p>Redis server port.</p> </li> <li> <code>kwargs</code>             (<code>Any</code>, default:                 <code>{}</code> )         \u2013          <p>Extra keyword arguments to pass to <code>redis.Redis()</code>.</p> </li> </ul> Source code in <code>proxystore/stream/shims/redis.py</code> <pre><code>def __init__(\n    self,\n    hostname: str,\n    port: int,\n    **kwargs: Any,\n) -&gt; None:\n    self._redis_client = redis.StrictRedis(\n        host=hostname,\n        port=port,\n        **kwargs,\n    )\n</code></pre>"},{"location":"api/stream/shims/redis/#proxystore.stream.shims.redis.RedisPublisher.close","title":"close()","text":"<pre><code>close() -&gt; None\n</code></pre> <p>Close this publisher.</p> Source code in <code>proxystore/stream/shims/redis.py</code> <pre><code>def close(self) -&gt; None:\n    \"\"\"Close this publisher.\"\"\"\n    self._redis_client.close()\n</code></pre>"},{"location":"api/stream/shims/redis/#proxystore.stream.shims.redis.RedisPublisher.send","title":"send()","text":"<pre><code>send(topic: str, message: bytes) -&gt; None\n</code></pre> <p>Publish a message to the stream.</p> <p>Parameters:</p> <ul> <li> <code>topic</code>             (<code>str</code>)         \u2013          <p>Stream topic to publish message to.</p> </li> <li> <code>message</code>             (<code>bytes</code>)         \u2013          <p>Message as bytes to publish to the stream.</p> </li> </ul> Source code in <code>proxystore/stream/shims/redis.py</code> <pre><code>def send(self, topic: str, message: bytes) -&gt; None:\n    \"\"\"Publish a message to the stream.\n\n    Args:\n        topic: Stream topic to publish message to.\n        message: Message as bytes to publish to the stream.\n    \"\"\"\n    self._redis_client.publish(topic, message)\n</code></pre>"},{"location":"api/stream/shims/redis/#proxystore.stream.shims.redis.RedisSubscriber","title":"RedisSubscriber","text":"<pre><code>RedisSubscriber(\n    hostname: str,\n    port: int,\n    topic: str | Sequence[str],\n    **kwargs: Any\n)\n</code></pre> <p>Redis pub/sub subscriber shim.</p> <p>This shim is an iterable object which will yield <code>bytes</code> messages from the stream, blocking on the next message, until the stream is closed.</p> <p>Parameters:</p> <ul> <li> <code>hostname</code>             (<code>str</code>)         \u2013          <p>Redis server hostname.</p> </li> <li> <code>port</code>             (<code>int</code>)         \u2013          <p>Redis server port.</p> </li> <li> <code>topic</code>             (<code>str | Sequence[str]</code>)         \u2013          <p>Topic or sequence of topics to subscribe to.</p> </li> <li> <code>kwargs</code>             (<code>Any</code>, default:                 <code>{}</code> )         \u2013          <p>Extra keyword arguments to pass to <code>redis.Redis()</code>.</p> </li> </ul> Source code in <code>proxystore/stream/shims/redis.py</code> <pre><code>def __init__(\n    self,\n    hostname: str,\n    port: int,\n    topic: str | Sequence[str],\n    **kwargs: Any,\n) -&gt; None:\n    self._redis_client = redis.StrictRedis(\n        host=hostname,\n        port=port,\n        **kwargs,\n    )\n    self._topics = [topic] if isinstance(topic, str) else topic\n    self._pubsub_client = self._redis_client.pubsub()\n    self._pubsub_client.subscribe(*self._topics)\n</code></pre>"},{"location":"api/stream/shims/redis/#proxystore.stream.shims.redis.RedisSubscriber.close","title":"close()","text":"<pre><code>close() -&gt; None\n</code></pre> <p>Close this subscriber.</p> Source code in <code>proxystore/stream/shims/redis.py</code> <pre><code>def close(self) -&gt; None:\n    \"\"\"Close this subscriber.\"\"\"\n    self._pubsub_client.unsubscribe()\n    self._pubsub_client.close()\n    self._redis_client.close()\n</code></pre>"},{"location":"api/stream/shims/redis/#proxystore.stream.shims.redis.RedisQueuePublisher","title":"RedisQueuePublisher","text":"<pre><code>RedisQueuePublisher(\n    hostname: str, port: int, **kwargs: Any\n)\n</code></pre> <p>Redis queue publisher shim.</p> Note <p>Only a single subscriber will be able to read each message sent to the queue. The <code>RedisPublisher</code> uses pub/sub and supports broadcasting messages to all active subscribers.</p> <p>Parameters:</p> <ul> <li> <code>hostname</code>             (<code>str</code>)         \u2013          <p>Redis server hostname.</p> </li> <li> <code>port</code>             (<code>int</code>)         \u2013          <p>Redis server port.</p> </li> <li> <code>kwargs</code>             (<code>Any</code>, default:                 <code>{}</code> )         \u2013          <p>Extra keyword arguments to pass to <code>redis.Redis()</code>.</p> </li> </ul> Source code in <code>proxystore/stream/shims/redis.py</code> <pre><code>def __init__(\n    self,\n    hostname: str,\n    port: int,\n    **kwargs: Any,\n) -&gt; None:\n    self._redis_client = redis.StrictRedis(\n        host=hostname,\n        port=port,\n        **kwargs,\n    )\n</code></pre>"},{"location":"api/stream/shims/redis/#proxystore.stream.shims.redis.RedisQueuePublisher.close","title":"close()","text":"<pre><code>close() -&gt; None\n</code></pre> <p>Close this publisher.</p> Source code in <code>proxystore/stream/shims/redis.py</code> <pre><code>def close(self) -&gt; None:\n    \"\"\"Close this publisher.\"\"\"\n    self._redis_client.close()\n</code></pre>"},{"location":"api/stream/shims/redis/#proxystore.stream.shims.redis.RedisQueuePublisher.send","title":"send()","text":"<pre><code>send(topic: str, message: bytes) -&gt; None\n</code></pre> <p>Publish a message to the stream.</p> <p>Parameters:</p> <ul> <li> <code>topic</code>             (<code>str</code>)         \u2013          <p>Stream topic to publish message to.</p> </li> <li> <code>message</code>             (<code>bytes</code>)         \u2013          <p>Message as bytes to publish to the stream.</p> </li> </ul> Source code in <code>proxystore/stream/shims/redis.py</code> <pre><code>def send(self, topic: str, message: bytes) -&gt; None:\n    \"\"\"Publish a message to the stream.\n\n    Args:\n        topic: Stream topic to publish message to.\n        message: Message as bytes to publish to the stream.\n    \"\"\"\n    self._redis_client.rpush(topic, message)\n</code></pre>"},{"location":"api/stream/shims/redis/#proxystore.stream.shims.redis.RedisQueueSubscriber","title":"RedisQueueSubscriber","text":"<pre><code>RedisQueueSubscriber(\n    hostname: str,\n    port: int,\n    topic: str,\n    *,\n    timeout: int | None = None,\n    **kwargs: Any\n)\n</code></pre> <p>Redis queue subscriber shim.</p> <p>This shim is an iterable object which will yield <code>bytes</code> messages from the queue, blocking on the next message, forever.</p> <p>Parameters:</p> <ul> <li> <code>hostname</code>             (<code>str</code>)         \u2013          <p>Redis server hostname.</p> </li> <li> <code>port</code>             (<code>int</code>)         \u2013          <p>Redis server port.</p> </li> <li> <code>topic</code>             (<code>str</code>)         \u2013          <p>Topic to subscribe to (I.e., the name of the key corresponding to a Redis list).</p> </li> <li> <code>timeout</code>             (<code>int | None</code>, default:                 <code>None</code> )         \u2013          <p>Timeout for waiting on the next item. If <code>None</code>, the timeout will be set to one second but will loop indefinitely.</p> </li> <li> <code>kwargs</code>             (<code>Any</code>, default:                 <code>{}</code> )         \u2013          <p>Extra keyword arguments to pass to <code>redis.Redis()</code>.</p> </li> </ul> Source code in <code>proxystore/stream/shims/redis.py</code> <pre><code>def __init__(\n    self,\n    hostname: str,\n    port: int,\n    topic: str,\n    *,\n    timeout: int | None = None,\n    **kwargs: Any,\n) -&gt; None:\n    self._redis_client = redis.StrictRedis(\n        host=hostname,\n        port=port,\n        **kwargs,\n    )\n    self._topic = topic\n    self._timeout = timeout\n</code></pre>"},{"location":"api/stream/shims/redis/#proxystore.stream.shims.redis.RedisQueueSubscriber.close","title":"close()","text":"<pre><code>close() -&gt; None\n</code></pre> <p>Close this subscriber.</p> Source code in <code>proxystore/stream/shims/redis.py</code> <pre><code>def close(self) -&gt; None:\n    \"\"\"Close this subscriber.\"\"\"\n    self._redis_client.close()\n</code></pre>"},{"location":"api/stream/shims/zmq/","title":"proxystore.stream.shims.zmq","text":"<code>proxystore/stream/shims/zmq.py</code> <p>ZeroMQ pub/sub interface.</p> Note <p>Unlike some of the other shims that simply interface with a third-party message broker system, here the subscriber connects directly to the publisher. This means that if the publisher is not alive when creating the subscriber, the subscriber will fail.</p>"},{"location":"api/stream/shims/zmq/#proxystore.stream.shims.zmq.ZeroMQPublisher","title":"ZeroMQPublisher","text":"<pre><code>ZeroMQPublisher(address: str, port: int)\n</code></pre> <p>ZeroMQ publisher interface.</p> <p>Parameters:</p> <ul> <li> <code>address</code>             (<code>str</code>)         \u2013          <p>Address to bind to. The full address bound to will be <code>'tcp://{address}:{port}'</code>.</p> </li> <li> <code>port</code>             (<code>int</code>)         \u2013          <p>Port to bind to.</p> </li> </ul> Source code in <code>proxystore/stream/shims/zmq.py</code> <pre><code>def __init__(self, address: str, port: int) -&gt; None:\n    self._context = zmq.Context()\n    self._socket = self._context.socket(zmq.PUB)\n    self._socket.bind(f'tcp://{address}:{port}')\n</code></pre>"},{"location":"api/stream/shims/zmq/#proxystore.stream.shims.zmq.ZeroMQPublisher.close","title":"close()","text":"<pre><code>close() -&gt; None\n</code></pre> <p>Close this publisher.</p> Source code in <code>proxystore/stream/shims/zmq.py</code> <pre><code>def close(self) -&gt; None:\n    \"\"\"Close this publisher.\"\"\"\n    self._context.destroy()\n</code></pre>"},{"location":"api/stream/shims/zmq/#proxystore.stream.shims.zmq.ZeroMQPublisher.send","title":"send()","text":"<pre><code>send(topic: str, message: bytes) -&gt; None\n</code></pre> <p>Publish a message to the stream.</p> <p>Parameters:</p> <ul> <li> <code>topic</code>             (<code>str</code>)         \u2013          <p>Stream topic to publish message to.</p> </li> <li> <code>message</code>             (<code>bytes</code>)         \u2013          <p>Message as bytes to publish to the stream.</p> </li> </ul> Source code in <code>proxystore/stream/shims/zmq.py</code> <pre><code>def send(self, topic: str, message: bytes) -&gt; None:\n    \"\"\"Publish a message to the stream.\n\n    Args:\n        topic: Stream topic to publish message to.\n        message: Message as bytes to publish to the stream.\n    \"\"\"\n    self._socket.send_multipart((topic.encode(), message))\n</code></pre>"},{"location":"api/stream/shims/zmq/#proxystore.stream.shims.zmq.ZeroMQSubscriber","title":"ZeroMQSubscriber","text":"<pre><code>ZeroMQSubscriber(\n    address: str, port: int, *, topic: str = \"\"\n)\n</code></pre> <p>ZeroMQ subscriber interface.</p> <p>This subscriber is an iterable object which yields <code>bytes</code> messages indefinitely from the stream while connected to a publisher.</p> <p>Parameters:</p> <ul> <li> <code>address</code>             (<code>str</code>)         \u2013          <p>Publisher address to connect to. The full address will be constructed as <code>'tcp://{address}:{port}'</code>.</p> </li> <li> <code>port</code>             (<code>int</code>)         \u2013          <p>Publisher port to connect to.</p> </li> <li> <code>topic</code>             (<code>str</code>, default:                 <code>''</code> )         \u2013          <p>Topic to subscribe to. The default <code>''</code> subscribes to all topics.</p> </li> </ul> Source code in <code>proxystore/stream/shims/zmq.py</code> <pre><code>def __init__(self, address: str, port: int, *, topic: str = '') -&gt; None:\n    self._context = zmq.Context()\n    self._socket = self._context.socket(zmq.SUB)\n    self._socket.connect(f'tcp://{address}:{port}')\n    self._socket.setsockopt(zmq.SUBSCRIBE, topic.encode())\n</code></pre>"},{"location":"api/stream/shims/zmq/#proxystore.stream.shims.zmq.ZeroMQSubscriber.close","title":"close()","text":"<pre><code>close() -&gt; None\n</code></pre> <p>Close this subscriber.</p> Source code in <code>proxystore/stream/shims/zmq.py</code> <pre><code>def close(self) -&gt; None:\n    \"\"\"Close this subscriber.\"\"\"\n    self._context.destroy()\n</code></pre>"},{"location":"api/utils/","title":"proxystore.utils","text":"<code>proxystore/utils/__init__.py</code> <p>General purpose utility functions.</p>"},{"location":"api/utils/config/","title":"proxystore.utils.config","text":"<code>proxystore/utils/config.py</code> <p>Read and write TOML config files using Pydantic BaseClasses.</p>"},{"location":"api/utils/config/#proxystore.utils.config.dump","title":"dump()","text":"<pre><code>dump(\n    model: BaseModel,\n    fp: BinaryIO,\n    *,\n    exclude_none: bool = True\n) -&gt; None\n</code></pre> <p>Serialize data class as a TOML formatted stream to file-like object.</p> <p>Parameters:</p> <ul> <li> <code>model</code>             (<code>BaseModel</code>)         \u2013          <p>Config model instance to write.</p> </li> <li> <code>fp</code>             (<code>BinaryIO</code>)         \u2013          <p>File-like bytes stream to write to.</p> </li> <li> <code>exclude_none</code>             (<code>bool</code>, default:                 <code>True</code> )         \u2013          <p>Skip writing none attributes.</p> </li> </ul> Source code in <code>proxystore/utils/config.py</code> <pre><code>def dump(\n    model: BaseModel,\n    fp: BinaryIO,\n    *,\n    exclude_none: bool = True,\n) -&gt; None:\n    \"\"\"Serialize data class as a TOML formatted stream to file-like object.\n\n    Args:\n        model: Config model instance to write.\n        fp: File-like bytes stream to write to.\n        exclude_none: Skip writing none attributes.\n    \"\"\"\n    data_dict = model.model_dump(exclude_none=exclude_none)\n    tomli_w.dump(data_dict, fp)\n</code></pre>"},{"location":"api/utils/config/#proxystore.utils.config.dumps","title":"dumps()","text":"<pre><code>dumps(\n    model: BaseModel, *, exclude_none: bool = True\n) -&gt; str\n</code></pre> <p>Serialize data class to a TOML formatted string.</p> <p>Parameters:</p> <ul> <li> <code>model</code>             (<code>BaseModel</code>)         \u2013          <p>Config model instance to write.</p> </li> <li> <code>exclude_none</code>             (<code>bool</code>, default:                 <code>True</code> )         \u2013          <p>Skip writing none attributes.</p> </li> </ul> <p>Returns:</p> <ul> <li> <code>str</code>         \u2013          <p>TOML string of data class.</p> </li> </ul> Source code in <code>proxystore/utils/config.py</code> <pre><code>def dumps(model: BaseModel, *, exclude_none: bool = True) -&gt; str:\n    \"\"\"Serialize data class to a TOML formatted string.\n\n    Args:\n        model: Config model instance to write.\n        exclude_none: Skip writing none attributes.\n\n    Returns:\n        TOML string of data class.\n    \"\"\"\n    data_dict = model.model_dump(exclude_none=exclude_none)\n    return tomli_w.dumps(data_dict)\n</code></pre>"},{"location":"api/utils/config/#proxystore.utils.config.load","title":"load()","text":"<pre><code>load(model: type[BaseModelT], fp: BinaryIO) -&gt; BaseModelT\n</code></pre> <p>Parse TOML from a binary file to a data class.</p> <p>Parameters:</p> <ul> <li> <code>model</code>             (<code>type[BaseModelT]</code>)         \u2013          <p>Config model type to parse TOML using.</p> </li> <li> <code>fp</code>             (<code>BinaryIO</code>)         \u2013          <p>File-like bytes stream to read in.</p> </li> </ul> <p>Returns:</p> <ul> <li> <code>BaseModelT</code>         \u2013          <p>Model initialized from TOML file.</p> </li> </ul> Source code in <code>proxystore/utils/config.py</code> <pre><code>def load(model: type[BaseModelT], fp: BinaryIO) -&gt; BaseModelT:\n    \"\"\"Parse TOML from a binary file to a data class.\n\n    Args:\n        model: Config model type to parse TOML using.\n        fp: File-like bytes stream to read in.\n\n    Returns:\n        Model initialized from TOML file.\n    \"\"\"\n    return loads(model, fp.read().decode())\n</code></pre>"},{"location":"api/utils/config/#proxystore.utils.config.loads","title":"loads()","text":"<pre><code>loads(model: type[BaseModelT], data: str) -&gt; BaseModelT\n</code></pre> <p>Parse TOML string to data class.</p> <p>Parameters:</p> <ul> <li> <code>model</code>             (<code>type[BaseModelT]</code>)         \u2013          <p>Config model type to parse TOML using.</p> </li> <li> <code>data</code>             (<code>str</code>)         \u2013          <p>TOML string to parse.</p> </li> </ul> <p>Returns:</p> <ul> <li> <code>BaseModelT</code>         \u2013          <p>Model initialized from TOML file.</p> </li> </ul> Source code in <code>proxystore/utils/config.py</code> <pre><code>def loads(model: type[BaseModelT], data: str) -&gt; BaseModelT:\n    \"\"\"Parse TOML string to data class.\n\n    Args:\n        model: Config model type to parse TOML using.\n        data: TOML string to parse.\n\n    Returns:\n        Model initialized from TOML file.\n    \"\"\"\n    data_dict = tomllib.loads(data)\n    return model.model_validate(data_dict, strict=True)\n</code></pre>"},{"location":"api/utils/counter/","title":"proxystore.utils.counter","text":"<code>proxystore/utils/counter.py</code> <p>Atomic counting utilities.</p>"},{"location":"api/utils/counter/#proxystore.utils.counter.AtomicCounter","title":"AtomicCounter","text":"<pre><code>AtomicCounter(size: int | None = None)\n</code></pre> <p>Thread-safe counter.</p> <p>Parameters:</p> <ul> <li> <code>size</code>             (<code>int | None</code>, default:                 <code>None</code> )         \u2013          <p>Optional max count upon which an exception will be raised.</p> </li> </ul> Source code in <code>proxystore/utils/counter.py</code> <pre><code>def __init__(self, size: int | None = None) -&gt; None:\n    self._size = size\n    self._value = 0\n    self._lock = threading.Lock()\n</code></pre>"},{"location":"api/utils/counter/#proxystore.utils.counter.AtomicCounter.increment","title":"increment()","text":"<pre><code>increment() -&gt; int\n</code></pre> <p>Get current count and increment value.</p> <p>Returns:</p> <ul> <li> <code>int</code>         \u2013          <p>Current count.</p> </li> </ul> <p>Raises:</p> <ul> <li> <code>ValueError</code>           \u2013          <p>If current count is equal to or greater than size.</p> </li> </ul> Source code in <code>proxystore/utils/counter.py</code> <pre><code>def increment(self) -&gt; int:\n    \"\"\"Get current count and increment value.\n\n    Returns:\n        Current count.\n\n    Raises:\n        ValueError: If current count is equal to or greater than size.\n    \"\"\"\n    with self._lock:\n        value = self._value\n        if self._size is not None and value &gt;= self._size:\n            raise ValueError(f'Max counter size exceeded ({self._size}).')\n        self._value += 1\n        return value\n</code></pre>"},{"location":"api/utils/data/","title":"proxystore.utils.data","text":"<code>proxystore/utils/data.py</code> <p>Utilities for interacting with data.</p>"},{"location":"api/utils/data/#proxystore.utils.data.chunk_bytes","title":"chunk_bytes()","text":"<pre><code>chunk_bytes(\n    data: bytes, chunk_size: int\n) -&gt; Generator[bytes, None, None]\n</code></pre> <p>Yield chunks of binary data.</p> <p>Parameters:</p> <ul> <li> <code>data</code>             (<code>bytes</code>)         \u2013          <p>Data to be chunked.</p> </li> <li> <code>chunk_size</code>             (<code>int</code>)         \u2013          <p>Chunk size in bytes.</p> </li> </ul> <p>Returns:</p> <ul> <li> <code>Generator[bytes, None, None]</code>         \u2013          <p>Generator that yields chunks of bytes.</p> </li> </ul> Source code in <code>proxystore/utils/data.py</code> <pre><code>def chunk_bytes(\n    data: bytes,\n    chunk_size: int,\n) -&gt; Generator[bytes, None, None]:\n    \"\"\"Yield chunks of binary data.\n\n    Args:\n        data: Data to be chunked.\n        chunk_size: Chunk size in bytes.\n\n    Returns:\n        Generator that yields chunks of bytes.\n    \"\"\"\n    length = len(data)\n    for index in range(0, length, chunk_size):\n        yield data[index : min(index + chunk_size, length)]\n</code></pre>"},{"location":"api/utils/data/#proxystore.utils.data.bytes_to_readable","title":"bytes_to_readable()","text":"<pre><code>bytes_to_readable(size: int, precision: int = 3) -&gt; str\n</code></pre> <p>Convert bytes to human readable value.</p> Note <p>This method uses base-10 values for KB, MB, GB, etc. instead of base-2 values (i.e., KiB, MiB, GiB, etc.).</p> <p>Parameters:</p> <ul> <li> <code>size</code>             (<code>int</code>)         \u2013          <p>Byte value to make readable.</p> </li> <li> <code>precision</code>             (<code>int</code>, default:                 <code>3</code> )         \u2013          <p>Number of decimal places.</p> </li> </ul> <p>Returns:</p> <ul> <li> <code>str</code>         \u2013          <p>String with human readable number of bytes.</p> </li> </ul> <p>Raises:</p> <ul> <li> <code>ValueError</code>           \u2013          <p>If size is negative.</p> </li> </ul> Source code in <code>proxystore/utils/data.py</code> <pre><code>def bytes_to_readable(size: int, precision: int = 3) -&gt; str:\n    \"\"\"Convert bytes to human readable value.\n\n    Note:\n        This method uses base-10 values for KB, MB, GB, etc. instead of\n        base-2 values (i.e., KiB, MiB, GiB, etc.).\n\n    Args:\n        size: Byte value to make readable.\n        precision: Number of decimal places.\n\n    Returns:\n        String with human readable number of bytes.\n\n    Raises:\n        ValueError: If size is negative.\n    \"\"\"\n    kb = int(1e3)\n    mb = int(1e6)\n    gb = int(1e9)\n    tb = int(1e12)\n\n    size_ = float(size)\n    if 0 &lt;= size &lt; kb:\n        suffix = 'B'\n    elif kb &lt;= size &lt; mb:\n        suffix = 'KB'\n        size_ /= kb\n    elif mb &lt;= size &lt; gb:\n        suffix = 'MB'\n        size_ /= mb\n    elif gb &lt;= size &lt; tb:\n        suffix = 'GB'\n        size_ /= gb\n    elif tb &lt;= size:\n        suffix = 'TB'\n        size_ /= tb\n    else:\n        raise ValueError(f'Size ({size}) cannot be negative.')\n\n    value = str(round(size_, precision))\n    value = value.rstrip('0').rstrip('.')\n    return f'{value} {suffix}'\n</code></pre>"},{"location":"api/utils/data/#proxystore.utils.data.readable_to_bytes","title":"readable_to_bytes()","text":"<pre><code>readable_to_bytes(size: str) -&gt; int\n</code></pre> <p>Convert string with bytes units to the integer value of bytes.</p> Example <pre><code>&gt;&gt;&gt; readable_to_bytes('1.2 KB')\n1200\n&gt;&gt;&gt; readable_to_bytes('0.6 MiB')\n629146\n</code></pre> <p>Parameters:</p> <ul> <li> <code>size</code>             (<code>str</code>)         \u2013          <p>String to parse for bytes size.</p> </li> </ul> <p>Returns:</p> <ul> <li> <code>int</code>         \u2013          <p>Integer number of bytes parsed from the string.</p> </li> </ul> <p>Raises:</p> <ul> <li> <code>ValueError</code>           \u2013          <p>If the input string contains more than two parts (i.e., a value and a unit).</p> </li> <li> <code>ValueError</code>           \u2013          <p>If the unit is not one of KB, MB, GB, TB, KiB, MiB, GiB, or TiB.</p> </li> <li> <code>ValueError</code>           \u2013          <p>If the value cannot be cast to a float.</p> </li> </ul> Source code in <code>proxystore/utils/data.py</code> <pre><code>def readable_to_bytes(size: str) -&gt; int:\n    \"\"\"Convert string with bytes units to the integer value of bytes.\n\n    Example:\n        ```python\n        &gt;&gt;&gt; readable_to_bytes('1.2 KB')\n        1200\n        &gt;&gt;&gt; readable_to_bytes('0.6 MiB')\n        629146\n        ```\n\n    Args:\n        size: String to parse for bytes size.\n\n    Returns:\n        Integer number of bytes parsed from the string.\n\n    Raises:\n        ValueError: If the input string contains more than two parts (i.e., a\n            value and a unit).\n        ValueError: If the unit is not one of KB, MB, GB, TB, KiB, MiB, GiB,\n            or TiB.\n        ValueError: If the value cannot be cast to a float.\n    \"\"\"\n    units_to_bytes = {\n        'b': 1,\n        'kb': int(1e3),\n        'mb': int(1e6),\n        'gb': int(1e9),\n        'tb': int(1e12),\n        'kib': int(2**10),\n        'mib': int(2**20),\n        'gib': int(2**30),\n        'tib': int(2**40),\n    }\n\n    # Try casting size to value (will only work if no units)\n    try:\n        return int(float(size))\n    except ValueError:\n        pass\n\n    # Ensure space between value and unit\n    size = re.sub(r'([a-zA-Z]+)', r' \\1', size.strip())\n\n    parts = [s.strip() for s in size.split()]\n    if len(parts) != 2:\n        raise ValueError(\n            'Input string \"{size}\" must contain only a value and a unit.',\n        )\n\n    value, unit = parts\n\n    try:\n        value_size = decimal.Decimal(value)\n    except decimal.InvalidOperation as e:\n        raise ValueError(f'Unable to interpret \"{value}\" as a float.') from e\n    try:\n        unit_size = units_to_bytes[unit.lower()]\n    except KeyError as e:\n        raise ValueError(f'Unknown unit type {unit}.') from e\n\n    return int(value_size * unit_size)\n</code></pre>"},{"location":"api/utils/environment/","title":"proxystore.utils.environment","text":"<code>proxystore/utils/environment.py</code> <p>Utilities related to the current execution environment.</p>"},{"location":"api/utils/environment/#proxystore.utils.environment.home_dir","title":"home_dir()","text":"<pre><code>home_dir() -&gt; str\n</code></pre> <p>Return the absolute path to the proxystore home directory.</p> <p>If set, <code>$PROXYSTORE_HOME</code> is preferred. Otherwise, <code>$XDG_DATA_HOME/proxystore</code> is returned where <code>$XDG_DATA_HOME</code> defaults to <code>$HOME/.local/share</code> if unset.</p> Source code in <code>proxystore/utils/environment.py</code> <pre><code>def home_dir() -&gt; str:\n    \"\"\"Return the absolute path to the proxystore home directory.\n\n    If set, `$PROXYSTORE_HOME` is preferred. Otherwise,\n    `$XDG_DATA_HOME/proxystore` is returned where `$XDG_DATA_HOME` defaults\n    to `$HOME/.local/share` if unset.\n    \"\"\"\n    path = os.environ.get('PROXYSTORE_HOME')\n    if path is None:\n        prefix = os.environ.get('XDG_DATA_HOME') or os.path.expanduser(\n            '~/.local/share',\n        )\n        path = os.path.join(prefix, 'proxystore')\n    return os.path.abspath(path)\n</code></pre>"},{"location":"api/utils/environment/#proxystore.utils.environment.hostname","title":"hostname()","text":"<pre><code>hostname() -&gt; str\n</code></pre> <p>Return current hostname.</p> Source code in <code>proxystore/utils/environment.py</code> <pre><code>def hostname() -&gt; str:\n    \"\"\"Return current hostname.\"\"\"\n    return socket.gethostname()\n</code></pre>"},{"location":"api/utils/imports/","title":"proxystore.utils.imports","text":"<code>proxystore/utils/imports.py</code> <p>Resolve imports by string paths.</p>"},{"location":"api/utils/imports/#proxystore.utils.imports.get_object_path","title":"get_object_path()","text":"<pre><code>get_object_path(obj: Any) -&gt; str\n</code></pre> <p>Get the fully qualified path of an object.</p> Example <pre><code>&gt;&gt;&gt; from proxystore.connectors.protocols import Connector\n&gt;&gt;&gt; get_object_path(Connector)\n'proxystore.connectors.protocols.Connector'\n</code></pre> <p>Parameters:</p> <ul> <li> <code>obj</code>             (<code>Any</code>)         \u2013          <p>Object to get fully qualified path of.</p> </li> </ul> <p>Returns:</p> <ul> <li> <code>str</code>         \u2013          <p>Fully qualified path of <code>obj</code>.</p> </li> </ul> Source code in <code>proxystore/utils/imports.py</code> <pre><code>def get_object_path(obj: Any) -&gt; str:\n    \"\"\"Get the fully qualified path of an object.\n\n    Example:\n        ```python\n        &gt;&gt;&gt; from proxystore.connectors.protocols import Connector\n        &gt;&gt;&gt; get_object_path(Connector)\n        'proxystore.connectors.protocols.Connector'\n        ```\n\n    Args:\n        obj: Object to get fully qualified path of.\n\n    Returns:\n        Fully qualified path of `obj`.\n    \"\"\"\n    return f'{obj.__module__}.{obj.__qualname__}'\n</code></pre>"},{"location":"api/utils/imports/#proxystore.utils.imports.import_from_path","title":"import_from_path()","text":"<pre><code>import_from_path(path: str) -&gt; type[Any]\n</code></pre> <p>Import object via its fully qualified path.</p> Example <pre><code>&gt;&gt;&gt; import_from_path('proxystore.connectors.protocols.Connector')\n&lt;class 'proxystore.connectors.protocols.Connector'&gt;\n</code></pre> <p>Parameters:</p> <ul> <li> <code>path</code>             (<code>str</code>)         \u2013          <p>Fully qualified path of object to import.</p> </li> </ul> <p>Returns:</p> <ul> <li> <code>type[Any]</code>         \u2013          <p>Imported object.</p> </li> </ul> <p>Raises:</p> <ul> <li> <code>ImportError</code>           \u2013          <p>If an object at the <code>path</code> is not found.</p> </li> </ul> Source code in <code>proxystore/utils/imports.py</code> <pre><code>def import_from_path(path: str) -&gt; type[Any]:\n    \"\"\"Import object via its fully qualified path.\n\n    Example:\n        ```python\n        &gt;&gt;&gt; import_from_path('proxystore.connectors.protocols.Connector')\n        &lt;class 'proxystore.connectors.protocols.Connector'&gt;\n        ```\n\n    Args:\n        path: Fully qualified path of object to import.\n\n    Returns:\n        Imported object.\n\n    Raises:\n        ImportError: If an object at the `path` is not found.\n    \"\"\"\n    module_path, _, name = path.rpartition('.')\n    if len(module_path) == 0:\n        raise ImportError(\n            f'Object path must contain at least one module. Got {path}',\n        )\n    module = importlib.import_module(module_path)\n    return getattr(module, name)\n</code></pre>"},{"location":"api/utils/tasks/","title":"proxystore.utils.tasks","text":"<code>proxystore/utils/tasks.py</code> <p>Safely spawn asyncio background tasks with error handling.</p>"},{"location":"api/utils/tasks/#proxystore.utils.tasks.SafeTaskExitError","title":"SafeTaskExitError","text":"<p>             Bases: <code>Exception</code></p> <p>Exception that can be raised inside a task to safely exit it.</p>"},{"location":"api/utils/tasks/#proxystore.utils.tasks.exit_on_error","title":"exit_on_error()","text":"<pre><code>exit_on_error(task: Task[Any]) -&gt; None\n</code></pre> <p>Task callback that raises SystemExit on task exception.</p> Source code in <code>proxystore/utils/tasks.py</code> <pre><code>def exit_on_error(task: asyncio.Task[Any]) -&gt; None:\n    \"\"\"Task callback that raises SystemExit on task exception.\"\"\"\n    if (\n        not task.cancelled()\n        and task.exception() is not None\n        and not isinstance(task.exception(), SafeTaskExitError)\n    ):\n        logger.error(\n            f'Exception in background task (name=\"{task.get_name()}\"): '\n            f'{task.exception()!r}',\n        )\n        raise SystemExit(1)\n</code></pre>"},{"location":"api/utils/tasks/#proxystore.utils.tasks.spawn_guarded_background_task","title":"spawn_guarded_background_task()","text":"<pre><code>spawn_guarded_background_task(\n    coro: Callable[..., Coroutine[Any, Any, None]],\n    *args: Any,\n    **kwargs: Any\n) -&gt; Task[Any]\n</code></pre> <p>Run a coroutine safely in the background.</p> <p>Launches the coroutine as an asyncio task and sets the done callback to <code>exit_on_error()</code>. This is \"safe\" because it will ensure exceptions inside the task get logged and cause the program to exit. Otherwise, background tasks that are not awaited may not have their exceptions raised such that programs hang with no notice of the exception that caused the hang.</p> <p>Tasks can raise <code>SafeTaskExit</code> to signal the task is finished but should not cause a system exit.</p> <p>Source: https://stackoverflow.com/questions/62588076</p> <p>Parameters:</p> <ul> <li> <code>coro</code>             (<code>Callable[..., Coroutine[Any, Any, None]]</code>)         \u2013          <p>Coroutine to run as task.</p> </li> <li> <code>args</code>             (<code>Any</code>, default:                 <code>()</code> )         \u2013          <p>Positional arguments for the coroutine.</p> </li> <li> <code>kwargs</code>             (<code>Any</code>, default:                 <code>{}</code> )         \u2013          <p>Keyword arguments for the coroutine.</p> </li> </ul> <p>Returns:</p> <ul> <li> <code>Task[Any]</code>         \u2013          <p>Asyncio task handle.</p> </li> </ul> Source code in <code>proxystore/utils/tasks.py</code> <pre><code>def spawn_guarded_background_task(\n    coro: Callable[..., Coroutine[Any, Any, None]],\n    *args: Any,\n    **kwargs: Any,\n) -&gt; asyncio.Task[Any]:\n    \"\"\"Run a coroutine safely in the background.\n\n    Launches the coroutine as an asyncio task and sets the done\n    callback to [`exit_on_error()`][proxystore.utils.tasks.exit_on_error].\n    This is \"safe\" because it will ensure exceptions inside the task get logged\n    and cause the program to exit. Otherwise, background tasks that are not\n    awaited may not have their exceptions raised such that programs hang with\n    no notice of the exception that caused the hang.\n\n    Tasks can raise [`SafeTaskExit`][proxystore.utils.tasks.SafeTaskExitError]\n    to signal the task is finished but should not cause a system exit.\n\n    Source: https://stackoverflow.com/questions/62588076\n\n    Args:\n        coro: Coroutine to run as task.\n        args: Positional arguments for the coroutine.\n        kwargs: Keyword arguments for the coroutine.\n\n    Returns:\n        Asyncio task handle.\n    \"\"\"\n    task = asyncio.create_task(\n        _execute_and_log_traceback(coro, *args, **kwargs),\n    )\n    task.add_done_callback(exit_on_error)\n    return task\n</code></pre>"},{"location":"api/utils/timer/","title":"proxystore.utils.timer","text":"<code>proxystore/utils/timer.py</code> <p>Timing utilities.</p>"},{"location":"api/utils/timer/#proxystore.utils.timer.Timer","title":"Timer","text":"<pre><code>Timer()\n</code></pre> <p>Performance timer with nanosecond precision.</p> Example <pre><code>from proxystore.timer import Timer\n\nwith Timer() as timer:\n    ...\n\nprint(timer.elapsed_ms)\n</code></pre> Example <pre><code>from proxystore.timer import Timer\n\ntimer = Timer()\ntimer.start()\n...\ntimer.stop()\n\nprint(timer.elapsed_ms)\n</code></pre> <p>Raises:</p> <ul> <li> <code>RuntimeError</code>           \u2013          <p>If the elapsed time is accessed before the timer is stopped or the context block is exited.</p> </li> </ul> Source code in <code>proxystore/utils/timer.py</code> <pre><code>def __init__(self) -&gt; None:\n    self._start = 0\n    self._end = 0\n    self._running = False\n</code></pre>"},{"location":"api/utils/timer/#proxystore.utils.timer.Timer.elapsed_ns","title":"elapsed_ns  <code>property</code>","text":"<pre><code>elapsed_ns: int\n</code></pre> <p>Elapsed time in nanoseconds.</p>"},{"location":"api/utils/timer/#proxystore.utils.timer.Timer.elapsed_ms","title":"elapsed_ms  <code>property</code>","text":"<pre><code>elapsed_ms: float\n</code></pre> <p>Elapsed time in milliseconds.</p>"},{"location":"api/utils/timer/#proxystore.utils.timer.Timer.elapsed_s","title":"elapsed_s  <code>property</code>","text":"<pre><code>elapsed_s: float\n</code></pre> <p>Elapsed time in seconds.</p>"},{"location":"api/utils/timer/#proxystore.utils.timer.Timer.start","title":"start()","text":"<pre><code>start() -&gt; None\n</code></pre> <p>Start the timer.</p> Source code in <code>proxystore/utils/timer.py</code> <pre><code>def start(self) -&gt; None:\n    \"\"\"Start the timer.\"\"\"\n    self._running = True\n    self._start = time.perf_counter_ns()\n</code></pre>"},{"location":"api/utils/timer/#proxystore.utils.timer.Timer.stop","title":"stop()","text":"<pre><code>stop() -&gt; None\n</code></pre> <p>Stop the timer.</p> Source code in <code>proxystore/utils/timer.py</code> <pre><code>def stop(self) -&gt; None:\n    \"\"\"Stop the timer.\"\"\"\n    self._end = time.perf_counter_ns()\n    self._running = False\n</code></pre>"},{"location":"concepts/","title":"Concepts","text":"<p>Figure 1: High-level overview of how the ProxyStore components fit together.</p> <p>ProxyStore is composed of three main components: the <code>Proxy</code>, <code>Connector</code>, and <code>Store</code>.</p> <p>The <code>Proxy</code> model provides pass-by-reference semantics and just-in-time object resolution transparently to consumers.</p> <p>The <code>Connector</code> is a <code>Protocol</code> that defines the low-level interface to a mediated communication channel or object store. Many <code>Connector</code> implementations are provided in the <code>proxystore.connectors</code> module, and users can easily create their own.</p> <p>The <code>Store</code> is a high-level abstraction of an object store and the intended means by which an application uses ProxyStore. The <code>Store</code> is initialized with a <code>Connector</code> and provides extra functionality like caching and serialization. Most important is that the <code>.proxy()</code> method is provided which can produce a <code>Proxy</code> of an arbitrary object put in the store.</p> <p>Continue reading to learn more about these concepts.</p> <ul> <li>Proxy</li> <li>Connector</li> <li>Store</li> </ul>"},{"location":"concepts/connector/","title":"Connector","text":"<p>The <code>Connector</code> is a <code>Protocol</code> that defines the low-level interface to a mediated communication channel or object store. The <code>Connector</code> methods operate of <code>bytes</code> of data and keys which are tuples of metadata that can identify a unique object.</p> <p>The protocol is as follows: Connector Protocol<pre><code>KeyT = TypeVar('KeyT', bound=NamedTuple)\n\nclass Connector(Protocol[KeyT]):\n    def close(self) -&gt; None: ...\n    def config(self) -&gt; dict[str, Any]: ...\n    def from_config(self, config: dict[str, Any]) -&gt; Connector[KeyT]: ...\n    def evict(self, key: KeyT) -&gt; None: ...\n    def exists(self, key: KeyT) -&gt; bool: ...\n    def get(self, key: KeyT) -&gt; bytes | None: ...\n    def get_batch(self, Sequence[KeyT]) -&gt; list[bytes | None]: ...\n    def put(self, obj: bytes) -&gt; KeyT: ...\n    def put_batch(self, objs: Sequence[bytes]) -&gt; list[KeyT]: ...\n</code></pre></p>"},{"location":"concepts/connector/#implementations","title":"Implementations","text":"<p>Implementing a custom <code>Connector</code> requires creating a class which implements the above methods. Note that the custom class does not need to inherit from <code>Connector</code> because it is a <code>Protocol</code>.</p> <p>Many <code>Connector</code> implementations are provided in the <code>proxystore.connectors</code> module, and users can easily create their own. A <code>Connector</code> instance is used by the <code>Store</code> to interact with the store.</p>"},{"location":"concepts/connector/#extensions","title":"Extensions","text":"<p>A <code>Connector</code> implementation can be extended to implement the <code>DeferrableConnector</code> protocol. A <code>DeferrableConnector</code> provides methods for creating a key and then setting that key to an object at a later time. Not all of the provided <code>Connector</code> implementations implement the <code>DeferrableConnector</code> protocol because some transfer methods require the object before creating a key for that object.</p>"},{"location":"concepts/proxy/","title":"Proxy","text":"<p>Proxies are commonly used to add additional functionality to their target object or enforce assertions prior to forwarding operations to the target. For example, a proxy can wrap sensitive objects with access control or provide caching for expensive operations.</p> <p>Two valuable properties that a proxy can provide are transparency and lazy resolution. A transparent proxy behaves identically to its target object by forwarding all operations on itself to the target. For example, given a proxy <code>p</code> of an arbitrary object <code>v</code>, the types of <code>v</code> and <code>p</code> will be equivalent, i.e., <code>isinstance(p, type(v))</code> and any operation on <code>p</code> will invoke the corresponding operation on <code>v</code>.</p> <p>A lazy or virtual proxy provides just-in-time resolution of its target object. In this case, the proxy is initialized with a factory rather than the target object. A factory is any object that is callable like a function and returns the target object. The proxy is lazy in that it does not call the factory to retrieve the target until it is first accessed. This process is referred to as resolving the proxy. Functionally, proxies have both pass-by-reference and pass-by-value attributes. The eventual user of the proxied data gets a copy, but unnecessary copies are avoided when the proxy is passed between multiple functions.</p>"},{"location":"concepts/proxy/#creating-proxies","title":"Creating Proxies","text":"<pre><code>from proxystore.proxy import Proxy\n\ndef resolve_object(...):\n   # Function that produces the object of interest\n   return obj\n\np = Proxy(resolve_object)\n</code></pre> <p><code>resolve_object()</code> will be called when the proxy <code>p</code> does its just-in-time resolution, and then <code>p</code> will behave exactly like <code>obj</code>. A factory for a <code>Proxy</code> can be any callable object (i.e., object which implements <code>__call__</code>).</p> <p>Proxies are powerful because they can intercept and redefine functionality of an object while emulating the rest of the objects behavior.</p> <pre><code>import numpy as np\nfrom proxystore.proxy import Proxy\n\nx = np.array([1, 2, 3])\n\nclass MyFactory():\n   def __init__(self, obj):\n       self.obj = obj\n\n   def __class__(self):\n       return self.obj\n\np = Proxy(MyFactory(x))\n\nassert isinstance(p, Proxy) # (1)!\nassert isinstance(p, np.ndarray)\n\nassert np.array_equal(p, [1, 2, 3]) # (2)!\nassert np.sum(p) == 6\ny = x + p\nassert np.array_equal(y, [2, 4, 6])\n</code></pre> <ol> <li>A proxy is an instance of its wrapped object.</li> <li>The proxy can do everything the numpy array can.</li> </ol> <p>The ProxyStore <code>Proxy</code> is built on the proxy from <code>lazy-object-proxy</code> which intercepts all calls to the object's magic functions (<code>__func_name__()</code> functions) and forwards the calls to the factory that was passed to the proxy constructor to retrieve the object that should be wrapped.</p> <p>Generally, a proxy is only ever resolved once. However, when a proxy is serialized, only the factory is serialized, and when the proxy is deserialized again and used, the factory will be called again to resolve the object.</p>"},{"location":"concepts/proxy/#interacting-with-proxies","title":"Interacting with Proxies","text":"<p>While a proxy can be used just as one would normally use the proxy's target object, additional functions are provided for interacting with the proxy directly.</p> <pre><code>from proxystore.proxy import Proxy\nfrom proxystore.proxy import extract\nfrom proxystore.proxy import is_resolved\nfrom proxystore.proxy import resolve\n\np = Proxy(...)\n\n# Check if a proxy has been resolved yet\nis_resolved(p)\n\n# Force a proxy to resolve itself\nresolve(p)\n\n# Extract the wrapped object from the proxy\nx = extract(p)\nassert not isinstance(x, Proxy)\n</code></pre>"},{"location":"concepts/store/","title":"Store","text":"<p>A <code>Store</code> is initialized with a <code>Connector</code> instance and provides extra functionality. Similar to the <code>Connector</code>, the <code>Store</code> exposes <code>evict</code>, <code>exist</code>, <code>get</code>, and <code>put</code> operations; however, these operations act on Python objects rather than <code>bytes</code>. The <code>Store</code> will (de)serialize objects accordingly before invoking the corresponding operation on the <code>Connector</code>. The <code>Store</code> also provides caching of operations to reduce communication costs, and objects are cached after deserialization to avoid duplicate deserialization.</p> <p>However, instead of the application directly invoking these aforementioned operations, the proxy method, also provided by the <code>Store</code>, is used. Calling <code>Store.proxy()</code> puts an object in the mediated channel and returns a proxy (see example below). The object is serialized before being put in the mediated channel, a factory with the key returned by the <code>Connector</code> and other information necessary to retrieve the object from the mediated channel is generated, and then a new proxy, internalized with the factory, is returned.</p> Base Store Usage<pre><code>from proxystore.connectors.redis import RedisConnector\nfrom proxystore.proxy import Proxy\nfrom proxystore.store import Store\n\ndef my_function(x: MyDataType) -&gt; ...:\n    assert isinstance(x, MyDataType)  # (1)!\n    # More computation...\n\nconnector = RedisConnector()  # (2)!\nstore = Store('my-store', connector, register=True)  # (3)!\n\nmy_object = MyDataType(...) # (4)!\np = store.proxy(my_object)\nisinstance(p, Proxy)\n\nmy_function(p) # (5)!\n</code></pre> <ol> <li><code>x</code> is resolved from \"my-store\" on the first use of <code>x</code>.</li> <li>The <code>Connector</code> defines the low-level communication method used by the <code>Store</code>.</li> <li>Passing the <code>register=True</code> will call <code>register_store()</code> automatically to register the instance globally by name.    This enables proxies to reuse the same store instance to improve performance.</li> <li>Store the object and get a proxy.</li> <li>Always succeeds regardless of if <code>p</code> is the true object or a proxy.</li> </ol>"},{"location":"concepts/store/#asynchronous-resolving","title":"Asynchronous Resolving","text":"<p>It is common in distributed computation for inputs to functions executed remotely to not be needed immediately upon execution. Proxies created by a <code>Store</code> support asynchronous resolution to overlap communication and computation.</p> <pre><code>from proxystore.store.utils import resolve_async\n\ndef complex_function(large_proxied_input):\n   resolve_async(large_proxied_input)\n\n   # More computation...\n\n   # First access to the proxy will not be as expensive because\n   # of the asynchronous resolution\n   compute_input(large_proxied_input)\n</code></pre>"},{"location":"concepts/store/#caching","title":"Caching","text":"<p>The <code>Store</code> provides built in caching functionality. Caches are local to the Python process but will speed up the resolution when multiple proxies refer to the same object.</p> <pre><code>from proxystore.store import Store\n\n# Cache size of 16 is the default\nStore('mystore', connector=..., cache_size=16)\n</code></pre>"},{"location":"concepts/store/#transactional-guarantees","title":"Transactional Guarantees","text":"<p>ProxyStore is designed around optimizing the communication of ephemeral data (e.g., inputs and outputs of functions) which is typically write-once, read-many. Thus, ProxyStore does not provide <code>update</code> semantics on keys.</p>"},{"location":"concepts/store/#serialization","title":"Serialization","text":"<p>All <code>Store</code> operations use ProxyStore's provided serialization utilities (<code>proxystore.serialize</code>) by default. However, the <code>Store</code> can be initialized with custom default serializers or deserializers of the form:</p> <p><pre><code>serializer = Callable[[Any], bytes]\ndeserializer = Callable[[bytes], Any]\n</code></pre> Most methods also support specifying an alternative serializer or deserializer to the default. Implementing a custom serializer may be beneficial for complex structures where pickle/cloudpickle (the default serializers used by ProxyStore) are innefficient. E.g.,</p> <pre><code>import torch\nimport io\n\nfrom proxystore.serialize import serialize\nfrom proxystore.store import Store\n\ndef serialize_torch_model(obj: Any) -&gt; bytes:\n   if isinstance(obj, torch.nn.Module):\n       buffer = io.BytesIO()\n       torch.save(model, buffer)\n       return buffer.read()\n   else:\n       # Fallback for unsupported types\n       return serialize(obj)\n\nmymodel = torch.nn.Module()\n\nstore = Store(...)\nkey = store.put(mymodel, serializer=serialize_torch_model)\n</code></pre> <p>Tip</p> <p>In some cases, data may already be serialized in which case an identity function can be passed as the serializer (e.g., <code>lambda x: x</code>). However, <code>populate_target=False</code> should also be set in this case to avoid prepopulating the proxy with the serialized target object. See the <code>Store</code> docstring for more information.</p> <p>Rather than providing a custom serializer or deserializer to each method invocation, a default serializer and deserializer can be provided when initializing a new <code>Store</code>. See Issue #146 for further discussion on where custom serializers can be helpful.</p>"},{"location":"contributing/","title":"Contributing","text":""},{"location":"contributing/#getting-started-for-local-development","title":"Getting Started for Local Development","text":"<p>We recommend using Tox to setup the development environment. This will create a new virtual environment with all of the required packages installed and ProxyStore installed in editable mode with the necessary extras options.</p> <pre><code>$ git clone https://github.com/proxystore/proxystore\n$ cd proxystore\n$ tox --devenv venv -e py311\n$ . venv/bin/activate\n</code></pre> <p>Warning</p> <p>Running Tox in a Conda environment is possible but it may conflict with Tox's ability to find the correct Python versions. E.g., if your Conda environment is Python 3.12, running <code>$ tox -e p311</code> may still use Python 3.12.</p> <p>To install manually: <pre><code>$ git clone https://github.com/proxystore/proxystore\n$ cd proxystore\n$ python -m venv venv\n$ . venv/bin/activate\n$ pip install -e .[dev,docs,endpoints,...]\n</code></pre></p>"},{"location":"contributing/#continuous-integration","title":"Continuous Integration","text":"<p>ProxyStore uses pre-commit and Tox for continuous integration (test, linting, etc.).</p>"},{"location":"contributing/#linting-and-type-checking-pre-commit","title":"Linting and Type Checking (pre-commit)","text":"<p>To use pre-commit, install the hook and then run against files.</p> <pre><code>$ pre-commit install\n$ pre-commit run --all-files\n</code></pre>"},{"location":"contributing/#tests-tox","title":"Tests (tox)","text":"<p>The entire CI workflow can be run with <code>$ tox</code>. This will test against multiple versions of Python and can be slow.</p> <p>Module-level unit-test are located in the <code>tests/</code> directory and its structure is intended to match that of <code>proxystore/</code>. E.g. the tests for <code>proxystore/store/cache.py</code> are located in <code>tests/store/cache_test.py</code>; however, additional test files can be added as needed. Tests should be narrowly focused and target a single aspect of the code's functionality, tests should not test internal implementation details of the code, and tests should not be dependent on the order in which they are run.</p> <p>Code that is useful for building tests but is not a test itself belongs in the <code>testing/</code> directory.</p> <pre><code># Run all tests in tests/\n$ tox -e py311\n# Run a specific test\n$ tox -e py311 -- tests/factory_test.py::test_lambda_factory\n</code></pre> <p>Many of the tests are asyncio tests. The asyncio default event loop is used by default, but uvloop can be used instead by passing <code>--use-uvloop</code> to pytest.</p>"},{"location":"contributing/#docs","title":"Docs","text":"<p>If code changes require an update to the documentation (e.g., for function signature changes, new modules, etc.), the documentation can be built using MKDocs.</p> <pre><code># Manually\n$ pip install -e .[docs]\n$ mkdocs build --strict  # Build only to site/index.html\n$ mkdocs serve           # Serve locally\n\n# With tox (will only build, does not serve)\n$ tox -e docs\n</code></pre> <p>Docstrings are automatically generated, but it is recommended to check the generated docstrings to make sure details/links/etc. are correct.</p>"},{"location":"contributing/issues-pull-requests/","title":"Issues and Pull Requests","text":""},{"location":"contributing/issues-pull-requests/#issues","title":"Issues","text":"<p>Issue Tracker</p> <p>We use GitHub issues to report problems, request and track changes, and discuss future ideas. If you open an issue for a specific problem, please follow the template guides.</p>"},{"location":"contributing/issues-pull-requests/#pull-requests","title":"Pull Requests","text":"<p>We use the standard GitHub contribution cycle where all contributions are made via pull requests (including code owners!).</p> <ol> <li>Fork the repository and clone to your local machine.</li> <li> <p>Create local changes.</p> <ul> <li>Changes should conform to the style and testing guidelines, referenced   above.</li> <li>Preferred commit message format (source):<ul> <li>separate subject from body with a blank line,</li> <li>limit subject line to 50 characters,</li> <li>capitalize first word of subject line,</li> <li>do not end the subject line with a period,</li> <li>use the imperative mood for subject lines,</li> <li>include related issue numbers at end of subject line,</li> <li>wrap body at 72 characters, and</li> <li>use the body to explain what/why rather than how.</li> <li>Example: <code>Fix concurrency bug in Store (#42)</code></li> </ul> </li> </ul> </li> <li> <p>Push commits to your fork.</p> <ul> <li>Please squash commits fixing mistakes to keep the git history clean.   For example, if commit \"b\" follows commit \"a\" and only fixes a small typo   from \"a\", please squash \"a\" and \"b\" into a single, correct commit.   This keeps the commit history readable and easier to search through when   debugging (e.g., git blame/bisect).</li> </ul> </li> <li>Open a pull request in this repository.<ul> <li>The pull request should include a description of the motivation for the   PR and included changes. A PR template is provided to guide this process.</li> </ul> </li> </ol>"},{"location":"contributing/releases/","title":"Releases","text":""},{"location":"contributing/releases/#release-timeline","title":"Release Timeline","text":"<p>Releases are created on an as-needed basis. Milestones are the Issue Tracker are used to track features to be included in upcoming releases.</p>"},{"location":"contributing/releases/#creating-releases","title":"Creating Releases","text":"<ol> <li>Choose the next version number, referred to as <code>{VERSION}</code> for the    rest of the instructions. ProxyStore versioning follows semver    (<code>major.minor.patch</code>) with optional PEP-440    pre-release/post-release/dev-release segments. Major/minor/patch numbers    start at 0 and pre-release/post-release/dev-release segments start at 1.</li> <li>Update the version in <code>pyproject.toml</code> to <code>{VERSION}</code>.</li> <li>Commit and merge the version updates/changelogs into main.</li> <li>Tag the release commit and push (typically this is the commit updating the    version numbers).    <pre><code>$ git tag -s v{VERSION} -m \"ProxyStore v{VERSION}\"\n$ git push origin v{VERSION}\n</code></pre>    Note the version number is prepended by \"v\" for the tags so we can    distinguish release tags from non-release tags.</li> <li>Create a new release on GitHub using the tag. The title should be    <code>ProxyStore v{VERSION}</code>.</li> <li>Official release:<ol> <li>Use the \"Generate release notes\" option and set the previous tag as the previous official release tag. E.g., for <code>v0.4.1</code>, the previous release tag should be <code>v0.4.0</code> and NOT <code>v0.4.1a1</code>.</li> <li>Add an \"Upgrade Steps\" section at the top (see previous releases for examples).</li> <li>Review the generated notes and edit as needed. PRs are organized by tag, but some PRs will be missing tags and need to be moved from the \"Other Changes\" section to the correct section.</li> <li>Select \"Set as the latest release.\"</li> </ol> </li> <li>Unofficial release: (alpha/dev builds)<ol> <li>Do NOT generate release notes. The body can be along the lines of \"Development pre-prelease for <code>V{VERSION}</code>.\"</li> <li>Leave the previous tag as \"auto.\"</li> <li>Select \"Set as a pre-release.\"</li> </ol> </li> </ol>"},{"location":"contributing/style-guide/","title":"Style Guide","text":"<p>The Python code and docstring format mostly follows Google's Python Style Guide, but the pre-commit config is the authoritative source for code format compliance.</p> <p>Nits:</p> <ul> <li>Avoid imports in <code>__init__.py</code> (reduces the likelihood of circular imports).</li> <li>Prefer pure functions where possible.</li> <li>Define all class attributes inside <code>__init__</code> so all attributes are visible   in one place. Attributes that are defined later can be set as <code>None</code>   as a placeholder.</li> <li>Prefer f-strings (<code>f'name: {name}</code>) over string format   (<code>'name: {}'.format(name)</code>). Never use the <code>%</code> operator.</li> <li>Prefer typing.NamedTuple over collections.namedtuple.</li> <li>Exception messages should read as complete sentences with punctuation.   Logging messages can forgo trailing punctuation.   <pre><code>raise ValueError('Name must contain alphanumeric characters only.')\nlogger.info(f'New connection opened to {address}')\n</code></pre></li> <li>Document all exceptions that may be raised by a function in the docstring.</li> </ul>"},{"location":"guides/","title":"Guides","text":"<p>Tip</p> <p>More guides are available on the ProxyStore Extensions page.</p> <ul> <li>Dask Distributed</li> <li>Globus Compute</li> <li>Endpoints Overview</li> <li>Endpoints Debugging</li> <li>Object Lifetimes</li> <li>Performance Tracking</li> <li>Proxy Futures</li> <li>Relay Serving</li> <li>Streaming</li> </ul>"},{"location":"guides/dask-distributed/","title":"Dask Distributed with ProxyStore","text":"<p>Last updated 24 April 2024</p> <p>This guide walks through using ProxyStore in Dask Distributed. ProxyStore can be used to efficiently pass large intermediate values between function invocations.</p> <p>Note</p> <p>Some familiarity with using Dask Distributed and ProxyStore is assumed. Check out the Dask Distributed Quickstart and ProxyStore Get Started to learn more.</p>"},{"location":"guides/dask-distributed/#installation","title":"Installation","text":"<p>Create a new virtual environment of your choosing and install Dask Distributed and ProxyStore.</p> <p>Note</p> <p>The below versions represent the latest versions of these packages available when this guide was written. These instructions should generally work with newer versions as well.</p> <pre><code>$ python -m venv venv\n$ . venv/bin/activate\n$ pip install dask[distributed]==2024.4.2 proxystore==0.6.5\n</code></pre>"},{"location":"guides/dask-distributed/#using-dask-distributed","title":"Using Dask Distributed","text":"<p>Dask Distributed is a library for futures-based distributed computing. The <code>Client.submit()</code> and <code>Client.map()</code> methods behave similarly to those of <code>concurrent.futures.Executor</code>. Consider this trivial example where we submit <code>sum()</code> on a list of numbers.</p> example.py<pre><code>from dask.distributed import Client\n\ndef main() -&gt; None:\n    client = Client(processes=True)\n\n    x = list(range(100))\n    y = client.submit(sum, x)\n    print(f'Result: {y.result()}')\n\n    client.close()\n\nif __name__ == '__main__':\n    main()\n</code></pre> <pre><code>$ python example.py\nResult: 4950\n</code></pre>"},{"location":"guides/dask-distributed/#using-proxystore","title":"Using ProxyStore","text":"<p>Dask Distributed has many builtin optimizations for data management when working with array-like data (e.g., NumPy arrays for Pandas dataframes). However, other large objects can cause performance degradation when serialized along with the task graph. ProxyStore provides a seamless alternative for passing objects to and from task invocations.</p> <p>Here, we will modify the above example to use ProxyStore's <code>FileConnector</code> to communicate intermediate data. This example will work the same for any <code>Connector</code> implementations, but different implementations can yield different performance benefits depending on the data or Dask Distributed deployment characteristics.</p> example.py<pre><code>from dask.distributed import Client\nfrom proxystore.connectors.file import FileConnector\nfrom proxystore.store import Store\n\ndef main() -&gt; None:\n    client = Client(processes=True)\n\n    with Store(\n        name='dask',\n        connector=FileConnector('/tmp/proxystore-cache'),\n        populate_target=True,  # (1)!\n        register=True,  # (2)!\n    ) as store:\n        x = list(range(100))\n        proxy = store.proxy(x)\n        y = client.submit(sum, proxy)\n\n        print(f'Result: {y.result()}')\n\n    client.close()\n\nif __name__ == '__main__':\n    main()\n</code></pre> <ol> <li>Setting <code>populate_target=True</code> is always recommended with Dask Distributed.</li> <li>Setting <code>register=True</code> is always recommended with Dask Distributed.</li> </ol> <p>As expected, the result is the same.</p> <pre><code>$ python example.py\nResult: 4950\n</code></pre> <p>Under the hood, ProxyStore is serializing <code>x</code> and putting the value in the connector. The resulting <code>proxy</code> acts like a reference to the <code>x</code> that is now stored in a shared location. The reference-like nature of <code>proxy</code> means that Dask does not end up serializing or transferring <code>x</code> itself; rather, Dask serializes the lightweight <code>proxy</code>. The transparent nature of <code>proxy</code> means that when used by the task, <code>proxy</code> will resolve to and act like <code>x</code> ensuring that the functionality of the program is the exact same.</p>"},{"location":"guides/dask-distributed/#performance-tips","title":"Performance Tips","text":"<p>In the above example, we set two flags (<code>register</code> and <code>populate_target</code>) which will improve performance with ProxyStore in Dask Distributed applications. Passing <code>register=True</code> will call <code>register_store()</code> automatically to register the <code>Store</code> instance globally by name. This enables proxies to reuse the same store instance, improving performance by sharing the same cache and stateful connections.</p> <p>Most important for ProxyStore performance in Dask Distributed is <code>populate_target=True</code>. When <code>True</code>, created proxies will be \"pre-resolved\" and have their <code>__class__</code> and <code>__hash__</code> attributes cached inside the proxy. This allows Dask to call <code>hash()</code> and <code>isinstance()</code> on a proxy without needing to resolve the proxy. If <code>populate_target=False</code> and we run the example with <code>DEBUG</code> level logging enabled, we will see that the target object of the proxy is retrieved three times. <pre><code>import logging\nlogging.basicConfig(level=logging.DEBUG)\n</code></pre></p> <pre><code>$ python\nINFO:proxystore.store:Registered a store named \"dask\"\nINFO:proxystore.store.base:Initialized Store(\"dask\", connector=FileConnector(directory=/tmp/proxystore-cache), serializer=default, deserializer=default, cache_size=16, metrics=False)\nDEBUG:proxystore.store.base:Store(name=\"dask\"): PUT FileKey(filename='3682883f-40bd-4990-bec0-73242f56067a') in 0.058 ms\nDEBUG:proxystore.store.base:Store(name=\"dask\"): PROXY FileKey(filename='3682883f-40bd-4990-bec0-73242f56067a') in 0.108 ms\nDEBUG:proxystore.store.base:Store(name=\"dask\"): GET FileKey(filename='3682883f-40bd-4990-bec0-73242f56067a') in 0.026 ms (cached=False)\nDEBUG:proxystore.store.base:Store(name=\"dask\"): GET FileKey(filename='3682883f-40bd-4990-bec0-73242f56067a') in 0.002 ms (cached=True)\nINFO:proxystore.store:Registered a store named \"dask\"\nINFO:proxystore.store.base:Initialized Store(\"dask\", connector=FileConnector(directory=/tmp/proxystore-cache), serializer=default, deserializer=default, cache_size=16, metrics=False)\nINFO:proxystore.store:Registered a store named \"dask\"\nDEBUG:proxystore.store.base:Store(name=\"dask\"): GET FileKey(filename='3682883f-40bd-4990-bec0-73242f56067a') in 0.034 ms (cached=False)\nResult: 4950\nINFO:proxystore.store:Unregistered a store named dask\n</code></pre> <p>Each <code>GET</code> message corresponds to an instance of <code>proxy</code> being resolved. In this example, this happens (1) when the Dask client serializes <code>proxy</code>, (2) on the Dask scheduler when the task request message is processed, and (3) on the Dask worker when <code>proxy</code> is actually used in the computation. If <code>x</code> was very large or costly to retrieve, this could significantly increase the application's memory usage or harmfully reduce task dispatch latency. Running the example again with logging enabled but <code>populate_target=True</code> will produce a single <code>GET</code> message corresponding to the Dask worker resolving <code>proxy</code> when the sum is computed which is optimal for performance.</p>"},{"location":"guides/dask-distributed/#memory-management","title":"Memory Management","text":"<p>The <code>Store</code>, by default, will not delete stored objects once they are no longer needed. In the above example, this means that <code>x</code> will be stored in the <code>FileConnector</code> until <code>Store.close()</code> is called and the directory <code>/tmp/proxystore-cache</code> is deleted. (Here, <code>Store.close()</code> is called when exiting the <code>with</code> context block.) However, it is not a requirement that <code>Connector</code> implementations clear stored objects when closed. In this case, the shared object <code>x</code> would be \"leaked\" because it was never deleted when no longer needed by the application.</p> <p>ProxyStore provides many opt-in mechanisms for automated management of shared objects. For single-use proxies, passing <code>evict=True</code> to <code>Store.proxy()</code> will automatically delete the object from the store once the proxy is resolved. In more complex scenarios where a proxy may be used by many processes, Lifetimes or Ownership can be used. Check out the Object Lifetimes guide to learn more.</p>"},{"location":"guides/endpoints-debugging/","title":"Endpoints Debugging","text":"<p>Last updated 2 May 2023</p> <p>This guide outlines some common trouble-shooting steps to take if you are encountering issues using ProxyStore Endpoints.</p>"},{"location":"guides/endpoints-debugging/#test-a-local-endpoint","title":"Test a Local Endpoint","text":"<p>Consider you configured and started an endpoint as follows: <pre><code>$ proxystore-endpoint configure myendpoint\nINFO: Configured endpoint myendpoint &lt;f4dc841d-377e-4785-8d66-8eade34f63cd&gt;. Start with:\nINFO:   $ proxystore-endpoint start myendpoint\n$ proxystore-endpoint start myendpoint\nINFO: Starting endpoint process as daemon.\nINFO: Logs will be written to ~/.local/share/proxystore/myendpoint/log.txt\n</code></pre></p>"},{"location":"guides/endpoints-debugging/#check-endpoint-logs","title":"Check Endpoint Logs","text":"<p>Endpoint logs are written to a directory in <code>$XDG_DATA_HOME/proxystore</code> which in this case is <code>~/.local/share/proxystore/myendpoint</code> (see <code>home_dir()</code> for the full specification). <pre><code>$ tail -n 1 ~/.local/share/proxystore/myendpoint/log.txt\nINFO  (uvicorn.error) :: Uvicorn running on http://127.0.1.1:8766 (Press CTRL+C to quit)\n</code></pre> The logs are the first place to check for any potential issues.</p>"},{"location":"guides/endpoints-debugging/#monitor-the-endpoint","title":"Monitor the Endpoint","text":"<p>Debug level logging can be enabled when starting the endpoint, and the endpoint can be run directly in the terminal instead of as a daemon process via the <code>--no-detach</code> flag. These two options are helpful for live monitoring the endpoint. <pre><code>$ proxystore-endpoint --log-level DEBUG start myendpoint --no-detach\n</code></pre></p>"},{"location":"guides/endpoints-debugging/#use-the-test-cli","title":"Use the Test CLI","text":"<p>The <code>proxystore-endpoint</code> CLI provides a <code>test</code> subcommand for testing endpoint commands. See the CLI Reference. <pre><code>$ proxystore-endpoint test myendpoint exists abcdef\nINFO: Object exists: False\n</code></pre> As expected, an object with key <code>abcdef</code> does not exist in the store, but we got a valid response so we know the endpoint is running correctly. You can also validate that this request was logged by the endpoint.</p>"},{"location":"guides/endpoints-debugging/#invoke-a-rest-request","title":"Invoke a REST Request","text":"<p>Endpoints serve a REST API so <code>curl</code> can be used to check if an endpoint is accessible. Note the <code>proxystore-endpoint test</code> CLI is preferred for debugging. The correct address the endpoint is listening on can be found in the logs. <pre><code>$ curl http://127.0.0.1:8765/exists?key=abcdef\n{\"exists\": false}\n</code></pre></p>"},{"location":"guides/endpoints-debugging/#test-a-remote-endpoint","title":"Test a Remote Endpoint","text":"<p>Consider I have an endpoint running on system A with UUID <code>aaaa0259-5a8c-454b-b17d-61f010d874d4</code> and another on System B with UUID <code>bbbbab4d-c73a-44ee-a316-58ec8857e83a</code>.</p>"},{"location":"guides/endpoints-debugging/#check-relay-server-connections","title":"Check Relay Server Connections","text":"<p>Both endpoints must be connected to the same relay server to form a peer connection. First, check the <code>address</code> value in the <code>[relay]</code> section is present and set to the correct URI string. The endpoint config is found in the <code>config.toml</code> file in the endpoint directory (e.g., <code>~/.local/share/proxystore/myendpoint/config.toml</code>). Restart your endpoints if you had to change the configuration.</p> <p>Second, confirm the endpoint connects to the relay server when started by checking the endpoint logs for a line like this. <pre><code>INFO  (proxystore.p2p.relay_client) :: Established client connection to relay server at ws://localhost:8765 with client uuid=aaaa0259-5a8c-454b-b17d-61f010d874d4 and name=myendpoint\n</code></pre></p>"},{"location":"guides/endpoints-debugging/#use-the-test-cli_1","title":"Use the Test CLI","text":"<p>The <code>proxystore-endpoint test</code> CLI can be used to establish a peer connection between two endpoints and invoke remote operations. Here, we will request the endpoint on system A (named \"myendpoint\") to invoke an <code>exists</code> operation on the endpoint on system B. <pre><code>$ proxystore-endpoint test --remote bbbbab4d-c73a-44ee-a316-58ec8857e83a myendpoint exists abcdef\nINFO: Object exists: False\n</code></pre></p> <p>You will get an error if the peer connection fails. For example: <pre><code>ERROR: Endpoint returned HTTP error code 500. Request to peer bbbbab4d-c73a-44ee-a316-58ec8857e83a failed: ...\n</code></pre> If this happens, check the logs for both endpoints for further error messages. Peer requests typically fail for two reasons:</p> <ol> <li>One of the endpoints is not running (e.g., an endpoint crashed) or is not    connected to the relay server.</li> <li>One of the endpoints is behind a symmetric NAT. The NAT traversal    techniques used to establish peer-to-peer connections between endpoints    are not reliable across symmetric NATs or poorly behaved legacy NATs.</li> </ol>"},{"location":"guides/endpoints-debugging/#check-peer-to-peer-compatibility","title":"Check Peer-to-Peer Compatibility","text":"<p>After ensuring both endpoints are running and connected to the relay server, you can check the NAT compatibility in two ways.</p> <ol> <li>Endpoints will attempt to discover and log the NAT type on startup, so check    the logs to see if this could be the reason.    <pre><code>INFO  (proxystore.p2p.nat) :: Checking NAT type. This may take a moment...\nINFO  (proxystore.p2p.nat) :: NAT Type:       Full-cone NAT\nINFO  (proxystore.p2p.nat) :: External IP:    &lt;IP ADDRESS&gt;\nINFO  (proxystore.p2p.nat) :: External Port:  &lt;PORT&gt;\nINFO  (proxystore.p2p.nat) :: NAT traversal for peer-to-peer methods (e.g., hole-punching) is likely to work. (NAT traversal does not work reliably across symmetric NATs or poorly behaved legacy NATs.)\n</code></pre></li> <li>Use the    <code>proxystore-endpoint check-nat</code>    command to discover your NAT type.    <pre><code>$ proxystore-endpoint check-nat\nINFO: Checking NAT type. This may take a moment...\nINFO: NAT Type:       Full-cone NAT\nINFO: External IP:    &lt;IP ADDRESS&gt;\nINFO: External Port:  &lt;PORT&gt;\nINFO: NAT traversal for peer-to-peer methods (e.g., hole-punching) is likely to work. (NAT traversal does not work reliably across symmetric NATs or poorly behaved legacy NATs.)\n</code></pre></li> </ol>"},{"location":"guides/endpoints/","title":"Peer-to-Peer Endpoints","text":"<p>Last updated 26 September 2023</p> <p>ProxyStore Endpoints are in-memory object stores with peering capabilities. Endpoints enable data transfer with proxies between multiple sites using NAT traversal.</p> <p>Warning</p> <p>Endpoints are experimental and the interfaces and underlying implementations may change. Refer to the API docs for the most up-to-date information.</p>"},{"location":"guides/endpoints/#overview","title":"Overview","text":"<p>At its core, the <code>Endpoint</code> is an in-memory data store built on asyncio. Endpoints provide a REST API, served using Quart, and ProxyStore provides the <code>EndpointConnector</code> as the primary interface for clients to interact with endpoints.</p> <p></p> <p>Figure 1: ProxyStore Endpoints overview. Clients can make requests to any endpoint and those request will be forwarded to the correct endpoint. Endpoints establish peer-to-peer connections using UDP hole-punching and a publicly accessible relay server.</p> <p>Unlike popular in-memory data stores (Redis, Memcached, etc.), ProxyStore endpoints can operate as peers even from behind different NATs without the need to open ports or SSH tunnels. To achieve direct data transfer between peers, endpoints use the WebRTC standard to determine how the peers can connect.</p> <p>As shown in Fig. 1, endpoints use a commonly accessible relay server to facilitate peer connections. When an endpoint is started, the Endpoint registers with the relay server. Then, when an endpoint needs to make a request from a peer, (1) the endpoint creates an offer and asks the relay server to forward the offer to the peer endpoint. The relay server forwards the offer (2) and the peer endpoint creates an answer to the received offer. The peer endpoint returns the answer to the original endpoint via the relay server (3, 4).</p> <p>The offer and answer contain information about the local and remote sessions of the endpoints which can be used to complete the peer-to-peer connection (5). (Note: this is a great simplification and more details can be found at https://webrtc.org/getting-started/peer-connections.) The peers will then keep a data channel open between themselves for the remainder of their lifetime.</p> <p>Clients interacting with an endpoint via the REST API and typical object store operations (get, set, etc.) specify a key and an endpoint UUID. Endpoints that receive a request with a different endpoint UUID will attempt a peer connection to the endpoint if one does not exist already and forward the request along and facilitate returning the response back to the client.</p>"},{"location":"guides/endpoints/#endpoint-cli","title":"Endpoint CLI","text":"<p>Warning</p> <p>Peer-to-peer connections between two Endpoints are not supported on all network types. The NAT traversal techniques used to establish peer-to-peer connections are unreliable across symmetric NATs or poorly behaved legacy NATs. To check the compatibility of your network, use the <code>proxystore-endpoint check-nat</code> CLI tool.</p> <p>Endpoints can be configure and started with the <code>proxystore-endpoint</code> command. By default, an Endpoint is configured to connect to ProxyStore's cloud-hosted relay server. This relay server uses Globus Auth for identity and access management. To use the provided relay server, authenticate using the <code>proxystore-globus-auth login</code> CLI. Authentication only needs to be performed once per system.</p> <p>Tip</p> <p>Endpoints can be started using a client identity, rather than as a user, by exporting the <code>PROXYSTORE_GLOBUS_CLIENT_ID</code> and <code>PROXYSTORE_GLOBUS_CLIENT_SECRET</code> environment variables. This is similar to how Globus Compute supports client login.</p> <pre><code>$ proxystore-globus-auth login\n$ proxystore-endpoint configure my-endpoint\nINFO: Configured endpoint: my-endpoint &lt;a6c7f036-3e29-4a7a-bf90-5a5f21056e39&gt;\nINFO: Config and log file directory: ~/.local/share/proxystore/my-endpoint\nINFO: Start the endpoint with:\nINFO:   $ proxystore-endpoint start my-endpoint\n</code></pre> <p>Endpoint configurations are stored in <code>$PROXYSTORE_HOME/{endpoint-name}</code> or <code>$XDG_DATA_HOME/proxystore/{endpoint-name}</code> (see <code>home_dir()</code>) and contain the name, UUID, host address, port, relay server address, and more.</p> <p>Tip</p> <p>By default, <code>$XDG_DATA_HOME/proxystore</code> will usually resolve to <code>~/.local/share/proxystore</code>. You can change this behavior by setting <code>$PROXYSTORE_HOME</code> in your <code>~/.bashrc</code> or similar configuration file. <pre><code>export PROXYSTORE_HOME=\"$HOME/.proxystore\"\n</code></pre></p> <p>A typical configuration looks like the following.</p> config.toml<pre><code>name = \"my-endpoint\"  # (1)!\nuuid = \"d27cf8cb-45fa-46b0-b907-27c830da62e3\"  # (2)!\nport = 8765  # (3)!\n\n[relay]\naddress = \"wss://relay.proxystore.dev\"  # (4)!\npeer_channels = 1  # (5)!\nverify_certificate = true  # (6)!\n\n[relay.auth]\nmethod = \"globus\"  # (7)!\n\n[relay.auth.kwargs]  # (8)!\n\n[storage]\ndatabase_path = \"~/.local/share/proxystore/my-endpoint/blobs.db\"  # (9)!\nmax_object_size = 10000000  # (10)!\n</code></pre> <ol> <li>Human-readable name of this endpoint. Only used for logging and CLI    operations.</li> <li>Unique identifier of this endpoint.</li> <li>Change the default port if running multiple endpoints on the same system.</li> <li>Comment out the relay address if you want to start the endpoint in SOLO    mode. Peering will not be available, but all other functionality will    remain.</li> <li>Number of channels to multiplex peer communications over. Increasing this    to two or four may improve performance on certain networks.</li> <li>Only disable this when connecting to a local relay server using self-signed    certificates for testing and development purposes.</li> <li>Authentication method to use with the relay server. Comment this out when    using a local relay server without authentication.</li> <li>Optional keyword arguments to use when creating the authorization headers.    Typically only used for testing and development purposes.</li> <li>Optional path to a SQLite database for persisting endpoint objects. See    the tip below for more details.</li> <li>Maximum object size. Comment out to disable object size limits.</li> </ol> <p>Tip</p> <p>Endpoints provide no data persistence by default, but this can be enabled by passing the <code>--persist</code> flag when configuring the endpoint or by setting <code>\"database_path\"</code> in the <code>[storage]</code> section of the config. When set, blobs stored by the endpoint will be written to a SQLite database file. Note this will result in slower performance.</p> <p>An up-to-date configuration description can found in the <code>EndpointConfig</code> docstring.</p> <p>Starting the endpoint will load the configuration from the ProxyStore home directory, initialize the endpoint, and start a Quart app using the host and port.</p> <pre><code>$ proxystore-endpoint start my-endpoint\n</code></pre>"},{"location":"guides/endpoints/#endpointconnector","title":"EndpointConnector","text":"<p>The primary interface to endpoints is the <code>EndpointConnector</code>.</p> <p>Note</p> <p>This section assumes familiarity with proxies and the <code>Store</code> interface. See the Get Started guide before getting started with endpoints.</p> Endpoint Client Example<pre><code>from proxystore.connectors.endpoint import EndpointConnector\nfrom proxystore.store import Store\n\nconnector = EndpointConnector(\n   endpoints=[\n       '5349ffce-edeb-4a8b-94a6-ab16ade1c1a1',\n       'd62910f6-0d29-452e-80b7-e0cd601949db',\n       ...\n   ],\n)\nstore = Store(name='default', connector=connector)\n\np = store.proxy(my_object)\n</code></pre> <p>The <code>EndpointConnector</code> takes a list of endpoint UUIDs. This list represents any endpoint that proxies created by this store may interact with to resolve themselves. The <code>EndpointConnector</code> will use this list to find its home endpoint, the endpoint that will be used to issue operations to. To find the home endpoint, the ProxyStore home directory will be scanned for any endpoint configurations matching the one of the UUIDs. If a match is found, the <code>EndpointConnector</code> will attempt to connect to the endpoint using the host and port in the configuration. This process is repeated until a reachable endpoint is found. While the user could specify the home endpoint directly, the home endpoint may change when a proxy travels to a different machine.</p>"},{"location":"guides/endpoints/#proxy-lifecycle","title":"Proxy Lifecycle","text":"<p>Figure 2: Flow of data when transferring objects via proxies and endpoints.</p> <p>In distributed systems, proxies created from an <code>EndpointConnector</code> can be used to facilitate simple and fast data communication. The flow of data and their associated proxies are shown in Fig. 2.</p> <ol> <li>Host A creates a proxy of the target object. The serialized target    is placed in Host A's home/local endpoint (Endpoint 1).    The proxy contains the key referencing the target, the endpoint UUID with    the target data (Endpoint 1's UUID), and the list of    all endpoint UUIDs configured with the    <code>EndpointConnector</code>    (the UUIDs of Endpoints 1 and 2).</li> <li>Host A communicates the proxy object to Host B. This communication is    cheap because the proxy is just a thin reference to the object.</li> <li>Host B receives the proxy and attempts to use the proxy initiating the    proxy resolve process. The proxy requests the data from Host B's    home endpoint (Endpoint 2).</li> <li>Endpoint 2 sees that the proxy is requesting data from a different endpoint    (Endpoint 1) so Endpoint 2 initiates a peer connection to Endpoint 1 and    requests the data.</li> <li>Endpoint 1 sends the data to Endpoint 2.</li> <li>Endpoint 2 replies to Host B's request for the data with the data received    from Endpoint 2. Host B deserializes the target object and the proxy    is resolved.</li> </ol>"},{"location":"guides/endpoints/#hosting-a-relay-server","title":"Hosting a Relay Server","text":"<p>The <code>proxystore-endpoint configure</code> CLI will configure endpoints to use a relay server hosted by the ProxyStore team.  If this is not suitable (or the ProxyStore relay is unavailable) we provide all of the tools to host your own relay server. See the Relay Serving Guide to learn more.</p>"},{"location":"guides/globus-compute/","title":"Globus Compute with ProxyStore","text":"<p>Last updated 20 April 2024</p> <p>This guide walks through integrating ProxyStore into a Globus Compute application. A more complete example of using ProxyStore with Globus Compute can be found in the <code>examples/</code>.</p> <p>Note</p> <p>Some familiarity with using Globus Compute and ProxyStore is assumed. Check out the Globus Compute Quickstart and ProxyStore Get Started to learn more.</p>"},{"location":"guides/globus-compute/#installation","title":"Installation","text":"<p>Create a new virtual environment of your choosing and install Globus Compute and ProxyStore.</p> <p>Note</p> <p>The below versions represent the latest versions of these packages available when this guide was written. These instructions should generally work with newer versions as well.</p> <pre><code>$ python -m venv venv\n$ . venv/bin/activate\n$ pip install globus-compute-sdk==2.18.1 globus-compute-endpoint==2.18.1 proxystore==0.6.5\n</code></pre>"},{"location":"guides/globus-compute/#using-globus-compute","title":"Using Globus Compute","text":"<p>We will first configure and start a Globus Compute endpoint.</p> <pre><code>$ globus-compute-endpoint configure proxystore-example\n$ globus-compute-endpoint start proxystore-example\n</code></pre> <p>After configuring the endpoint, you will get back an endpoint UUID which we will need in the next step.</p> <p>Below is a modified example based on the example Globus Compute app from the Quickstart guide. example.py<pre><code>from globus_compute_sdk import Executor\n\nENDPOINT_UUID = '5b994a7d-8d7c-48d1-baa1-0fda09ea1687' # (1)!\n\ndef average(x: list[float]) -&gt; float:  # (2)!\n    return sum(x) / len(x)\n\nwith Executor(endpoint_id=ENDPOINT_UUID) as gce:  # (3)!\n    x = list(range(1, 100000))\n    future = gce.submit(average, x)  # (4)!\n\n    print(future.result())  # (5)!\n</code></pre></p> <ol> <li>Your endpoint's UUID.</li> <li>Define the function that will be executed remotely.</li> <li>Create the Globus Compute executor.</li> <li>Submit the function for execution.</li> <li>Wait on the result future.</li> </ol> <p>Running this script will return <code>50000</code>. <pre><code>$ python example.py\n50000.0\n</code></pre></p>"},{"location":"guides/globus-compute/#using-proxystore","title":"Using ProxyStore","text":"<p>Now we will update our script to use ProxyStore. This takes three steps:</p> <ol> <li>Initialize a <code>Connector</code> and    <code>Store</code>. The <code>Connector</code> is the interface    to the byte-level communication channel that will be used, and the <code>Store</code>    is the high-level interface provided by ProxyStore.</li> <li>Register the <code>Store</code> instance globally. This is not strictly necessary, but    is an optimization which enables proxies to share the same original <code>Store</code>    instance, because the <code>Store</code> and <code>Connector</code> can have state (e.g., caches,    open connections, etc.).</li> <li>Proxy the function inputs.</li> </ol> example.py<pre><code>from globus_compute_sdk import Executor\nfrom proxystore.connectors.file import FileConnector\nfrom proxystore.store import Store\n\nENDPOINT_UUID = '5b994a7d-8d7c-48d1-baa1-0fda09ea1687'\n\ndef average(x: list[float]) -&gt; float:\n    return sum(x) / len(x)\n\nstore = Store('my-store', FileConnector('./proxystore-cache'), register=True)  # (1)!\n\nwith Executor(endpoint_id=ENDPOINT_UUID) as gce:\n    x = list(range(1, 100000))\n    p = store.proxy(x) # (2)!\n    future = gce.submit(average, p)\n\n    print(future.result())\n\nstore.close() # (3)!\n</code></pre> <ol> <li>Create a new store using the file system for mediated communication.    Register the store instance so states (e.g., caches, etc.) can be shared.</li> <li>Proxy the input data.</li> <li>Close the <code>Store</code> to cleanup any resources.</li> </ol> <p>Tip</p> <p>The <code>Store</code> can also be used as a context manager that will automatically clean up resources.</p> <pre><code>with Store('my-store', FileConnector('./proxystore-cache')) as store:\n    x = list(range(1, 100000))\n    p = store.proxy(x)\n    future = gce.submit(average, p)\n\n    print(future.result())\n</code></pre> <p>We can also use ProxyStore to return data via the same communication method.</p> example.py<pre><code>def average(x: list[float]) -&gt; float:\n    from proxystore.proxy import Proxy # (1)!\n    from proxystore.store import get_store\n\n    avg = sum(x) / len(x)\n\n    if isinstance(x, Proxy): # (2)!\n        store = get_store(x)\n        avg = store.proxy(avg)\n\n    return avg\n</code></pre> <ol> <li>Globus Compute functions will be executed in a different process so we must    import inside the function.</li> <li>If our input data was communicated via a proxy, we get the same <code>Store</code> that    create our input proxy which we then use to proxy the output.</li> </ol>"},{"location":"guides/globus-compute/#closing-thoughts","title":"Closing Thoughts","text":"<p>While this example is trivial, the target function is still executed on the local machine and the data sizes are small, the key takeaway is that the <code>Proxy</code> model simplifies the process of moving data via alternate means between the Globus Compute client and executors.</p> <p>More complex applications where the Globus Compute endpoints live elsewhere (e.g., on an HPC) cluster or that move larger data will benefit from the various <code>Connector</code> implementations provided.</p> <p>Checkout the other Guides to learn about more advanced ProxyStore features.</p>"},{"location":"guides/object-lifetimes/","title":"Object Lifetimes","text":"<p>Last updated 20 April 2024</p> <p>The <code>Store</code>, by default, leaves the responsibility of managing shared objects to the application. For example, a object put into a <code>Store</code> will persist there until the key is manually evicted. Some <code>Connectors</code>, and therefore <code>Stores</code>, delete all of their objects when closed but this is not a specified requirement of the protocol.</p> <p>ProxyStore, however, provides optional mechanisms for more automated management of shared objects.</p> Method Supports keys? Supports proxies? Ephemeral Proxies \u2717 \u2713 Lifetimes \u2713 \u2713 Ownership \u2717 \u2713 <p>Note: Currently, these methods are mutually exclusive with each other.</p>"},{"location":"guides/object-lifetimes/#ephemeral-proxies","title":"Ephemeral Proxies","text":"<p>Setting the <code>evict=True</code> flag when creating a proxy of an object with <code>Store.proxy()</code>, <code>Store.proxy_batch()</code>, <code>Store.proxy_from_key()</code>, or <code>Store.locked_proxy()</code> marks the proxy as ephemeral (one-time use). The factory will evict the object from the store when the proxy's factory is invoked for the first time to resolve the proxy. This is useful when the a proxy will be created once and consumed once by an application.</p> <p>A common side-effect of <code>evict=True</code> is obscure <code>ProxyResolveMissingKeyError</code> tracebacks. This commonly happens when a proxy is unintentionally resolved by another component of the program. For example, certain serializers may attempt to inspect the proxy to optimize serialization but resolve the proxy in the process, or datastructures like <code>set()</code> access the <code>__hash__</code> method of the proxy which will resolve the proxy. These accidental resolves will automatically evict the target object so later resolves of the proxy will fail.</p> <p>If you run into these errors, try:</p> <ul> <li>Enabling <code>DEBUG</code> level logging to determine where unintentional proxy resolution is occurring.   The <code>Store</code> will log every <code>GET</code> and <code>EVICT</code> operation on a key.</li> <li>Avoid use of datastructures or functions which unnecessarily resolve proxies.</li> <li>If avoiding use of the datastructures or functions causing the problem is not possible, consider using the <code>populate_target=True</code> flag when creating the proxy.   The <code>populate_target</code> flag will return a proxy that is already resolved so the factory, which would evict the target object, does not need to be called until the proxy is serialized and then deserialized and resolved on a different process.   The flag will also cache the class type and hash value of the target such that the proxy can be used in datastructures which rely on <code>hash()</code> or in <code>isinstance</code> checks without needing to resolve the proxy.</li> </ul>"},{"location":"guides/object-lifetimes/#lifetimes","title":"Lifetimes","text":"<p>Shared objects in a <code>Store</code> can be associated with a <code>Lifetime</code>. Lifetimes provide a management mechanism for keeping track of objects and cleaning them up when appropriate.</p>"},{"location":"guides/object-lifetimes/#contextual-lifetime","title":"Contextual Lifetime","text":"<p>The <code>ContextLifetime</code> provides a simple interface for managing shared objects. Objects added to a <code>Store</code> can be associated with the lifetime via the <code>lifetime</code> parameter supported by most <code>Store</code> methods. Objects associated with the lifetime are evicted when the lifetime is closed/ended.</p> Contextual Lifetime<pre><code>from proxystore.store.base import Store\nfrom proxystore.store.lifetimes import ContextLifetime\n\nstore = Store(...)\n\nlifetime = ContextLifetime(store)  # (1)!\n\nkey = store.put('value', lifetime=lifetime)  # (2)!\nproxy = store.proxy('value', lifetime=lifetime)  # (3)!\n\nlifetime.close()  # (4)!\nassert not store.exists(key)\n\nstore.close()  # (5)!\n</code></pre> <ol> <li>The <code>ContextLifetime</code> and all its associated objects must be associated with the same <code>Store</code>.</li> <li>A new key can be automatically associated with a lifetime.</li> <li>The target object of a proxy can be automatically associated with a lifetime.</li> <li>Ending a lifetime will cause all of its associated objects to be evicted.</li> <li>The <code>Store</code> should be closed after any associated lifetimes because lifetimes use the <code>Store</code> for cleanup.</li> </ol> <p>The <code>ContextLifetime</code> can be used as a context manager.</p> Contextual Lifetime<pre><code>from proxystore.store.base import Store\nfrom proxystore.store.lifetimes import ContextLifetime\n\nstore = Store(...)\n\nwith ContextLifetime(store) as lifetime:\n    key = store.put('value', lifetime=lifetime)\n    proxy = store.proxy('value', lifetime=lifetime)\n\nassert not store.exists(key)\n\nstore.close()\n</code></pre>"},{"location":"guides/object-lifetimes/#leased-lifetime","title":"Leased Lifetime","text":"<p>The <code>LeaseLifetime</code> provides time-based object lifetimes. Each <code>LeaseLifetime</code> has an associated expiration time after which any associated objects will be evicted. The lease can be extended as needed with <code>extend()</code> or ended early <code>close()</code>.</p> Leased Lifetime<pre><code>from proxystore.store.base import Store\nfrom proxystore.store.lifetimes import LeaseLifetime\n\nwith Store(...) as store:\n    lifetime = LeaseLifetime(store, expiry=10)  # (1)!\n\n    key = store.put('value', lifetime=lifetime)\n    proxy = store.proxy('value', lifetime=lifetime)\n\n    lifetime.extend(5)  # (2)!\n\n    time.sleep(20)  #(3)!\n\n    assert lifetime.done()  #(4)!\n    assert not store.exists(key)\n</code></pre> <ol> <li>Create a new lifetime with a current lease of ten seconds.</li> <li>Extend the lease by another five seconds.</li> <li>Sleep for longer than our current lease.</li> <li>Lease has expired so the lifetime has ended and associated objects have been evicted.</li> </ol>"},{"location":"guides/object-lifetimes/#static-lifetime","title":"Static Lifetime","text":"<p>A static lifetime indicates that the associated objects should live for the remainder of the lifetime of the running process which created the object. The <code>StaticLifetime</code>, a singleton class, will evict all associated objects at the end of the program via an atexit handler.</p> Static Lifetime<pre><code>from proxystore.connectors.local import LocalConnector\nfrom proxystore.store import Store\nfrom proxystore.store.lifetimes import StaticLifetime\n\nstore = Store('default', LocalConnector(), register=True)  # (1)!\n\nkey = store.put('value', lifetime=StaticLifetime())  # (2)!\nproxy = store.proxy('value', lifetime=StaticLifetime())  # (3)!\n</code></pre> <ol> <li>The atexit handler will call <code>store.close()</code> at the end of the program.    Setting <code>register=True</code> is recommended to prevent another instance being created internally when a proxy is resolved.</li> <li>The object associated with <code>key</code> will be evicted at the end of    the program.</li> <li>The object associated with <code>proxy</code> will be evicted at the end of    the program.</li> </ol> <p>Additional tips:</p> <ol> <li>Closing the <code>Store</code> at the end of the program but before the atexit handler has executed can cause undefined behaviour.    Let the handler perform all cleanup.</li> <li>The <code>StaticLifetime</code> can be closed manually, but only once.    This may be useful if the the associated stores need to be closed manually or outside of the atexit handler.    (Close the lifetime before the stores.)</li> <li>atexit does not guarantee that the handler will be called in some unexpected process shutdown cases.    This can lead to a memory leak in the connector(s).</li> </ol>"},{"location":"guides/object-lifetimes/#ownership","title":"Ownership","text":"<p>An <code>OwnedProxy</code>, created by <code>Store.owned_proxy()</code>, provides an alternative to the default <code>Proxy</code> which enforces Rust-like ownership and borrowing rules for objects in a <code>Store</code>.</p> <ol> <li>Each target object of type <code>T</code> in the global store has an associated <code>OwnedProxy[T]</code>.</li> <li>There can only be one <code>OwnedProxy[T]</code> for any target in the global store.</li> <li>When an <code>OwnedProxy[T]</code> goes out of scope (e.g., gets garbage collected), the associated target is removed from the global store.</li> </ol> <p>An <code>OwnedProxy[T]</code> can be borrowed without relinquishing ownership. This requires two additional rules.</p> <ol> <li>At any given time, you can have either one mutable reference to the target, a <code>RefMutProxy[T]</code>, or any number of immutable references, a <code>RefProxy[T]</code>.</li> <li>References must always be valid. I.e., you cannot delete an <code>OwnedProxy[T]</code> while it has been borrowed via a <code>RefProxy[T]</code> or <code>RefMutProxy[T]</code>.</li> </ol> <p>Reference proxy types can be created and used using: <code>borrow()</code>, <code>mut_borrow()</code>, <code>clone()</code>, <code>into_owned()</code>, and <code>update()</code>.</p> <p>The <code>submit()</code> associates proxy references with the scope of a function executed by a function executor, such as a <code>ProcessPoolExecutor</code> or FaaS system. This wrapper function ensures that immutable or mutable borrows of a value passed to a function are appropriately removed once the function completes.</p> Reference Lifetime Scopes<pre><code>from concurrent.futures import Future\nfrom concurrent.futures import ProcessPoolExecutor\nfrom proxystore.store.base import Store\nfrom proxystore.store.ref import borrow\n\nstore = Store(...)\nproxy = store.owned_proxy('value')\nborrowed = borrow(proxy)  # (1)!\n\nwith ProcessPoolExecutor() as pool:\n    future: Future[int] = submit(\n        pool.submit,  # (2)!\n        args=(sum, borrowed),  # (3)!\n    )\n    assert future.result() == 6  # (4)!\n\ndel proxy  # (5)!\n\nstore.close()\n</code></pre> <ol> <li>Borrow an <code>OwnedProxy</code> as a <code>RefProxy</code>.</li> <li><code>submit()</code> will call <code>pool.submit()</code> with the specified <code>args</code> and <code>kwargs</code>.    Here, <code>sum</code> will be the function invoked on a single argument <code>borrowed</code> which is a proxy of a list of integers.</li> <li>The <code>args</code> and <code>kwargs</code> will be scanned for any proxy reference types, and a callback will be added to the returned future that marks the input proxy references as out-of-scope once the future completes.</li> <li>Once the future is completed, the <code>borrowed</code> reference is marked out-of-scope and the reference count of borrows managed internally in <code>proxy</code> is decremented.</li> <li>The <code>OwnedProxy</code>, <code>proxy</code>, which owns the target value is safe to delete and get garbage collected because there are no remaining reference proxies which have borrowed the target value.</li> </ol>"},{"location":"guides/performance/","title":"Performance Tracking","text":"<p>Last updated 20 April 2024</p> <p>The <code>Store</code> can record metrics on executed operations (e.g., <code>get</code> and <code>put</code>). Metric collection is disabled by default and can be enabled by passing <code>metrics=True</code> to a <code>Store</code> constructor.</p>"},{"location":"guides/performance/#enabling-metrics","title":"Enabling Metrics","text":"<pre><code>import dataclasses\nfrom proxystore.connectors.file import FileConnector\nfrom proxystore.store.base import Store\n\nstore = Store(\n   name='example-store',\n   connector=FileConnector('/tmp/proxystore-dump'),\n   metrics=True,  # (1)!\n   register=True,\n)\nassert store.metrics is not None\n</code></pre> <ol> <li>Metric tracking is not enabled by default.</li> </ol> <p>Metrics are accessed via the <code>Store.metrics</code> property. This property will be <code>None</code> when metrics are disabled.</p> <p>Warning</p> <p>Metrics are local to each <code>Store</code> instance. In multi-process applications or applications that instantiate multiple <code>Store</code> instances, <code>Store.metrics</code> will only represent a partial view of the overall performance.</p> <p>Warning</p> <p>ProxyStore v0.6.4 and older have a bug that causes the conversion from nanoseconds to milliseconds in the <code>Metrics</code> class to be incorrect. This was fixed in v0.6.5 (see PR #538).</p> <p>Three types of metrics are collected.</p> <ul> <li>Attributes: arbitrary attributes associated with an operation.</li> <li>Counters: scalar counters that represent the number of times an event occurs.</li> <li>Times: durations of events.</li> </ul>"},{"location":"guides/performance/#a-simple-example","title":"A Simple Example","text":"<p>Consider executing a <code>get</code> and <code>put</code> operation on <code>store</code>. <pre><code>&gt;&gt;&gt; key = store.put([0, 1, 2, 3, 4, 5])\n&gt;&gt;&gt; store.get(key)\n</code></pre></p> <p>We can inspect the metrics recorded for operations on <code>key</code>. <pre><code>&gt;&gt;&gt; metrics = store.metrics.get_metrics(key)\n\n&gt;&gt;&gt; tuple(field.name for field in dataclasses.fields(metrics))\n('attributes', 'counters', 'times')\n</code></pre></p> <p><code>metrics</code> is an instance of <code>Metrics</code> which is a <code>dataclass</code> with three fields: <code>attributes</code>, <code>counters</code>, and <code>times</code>. We can further inspect these fields. <pre><code>&gt;&gt;&gt; metrics.attributes\n{'store.get.object_size': 219, 'store.put.object_size': 219}\n&gt;&gt;&gt; metrics.counters\n{'store.get.cache_misses': 1}\n&gt;&gt;&gt; metrics.times\n{\n    'store.put.serialize': TimeStats(\n        count=1, avg_time_ms=9.9, min_time_ms=9.9, max_time_ms=9.9\n    ),\n    'store.put.connector': TimeStats(\n       count=1, avg_time_ms=36.9, min_time_ms=36.9, max_time_ms=36.9\n    ),\n    'store.put': TimeStats(\n       count=1, avg_time_ms=53.4, min_time_ms=53.4, max_time_ms=53.4\n    ),\n    'store.get.connector': TimeStats(\n       count=1, avg_time_ms=16.1, min_time_ms=16.1, max_time_ms=16.1\n    ),\n    'store.get.deserialize': TimeStats(\n       count=1, avg_time_ms=7.6, min_time_ms=7.6, max_time_ms=7.6\n    ),\n   'store.get': TimeStats(\n       count=1, avg_time_ms=45.6, min_time_ms=45.6, max_time_ms=45.6\n   ),\n}\n</code></pre></p> <p>Operations or events are represented by a hierarchical namespace. E.g., <code>store.get.object_size</code> is the serialized object size from the call to <code>Store.get()</code>. In <code>metrics.attributes</code>, we see the serialized object was 219 bytes. In <code>metrics.counters</code>, we see we had one cache miss when getting the object. In <code>metrics.times</code>, we see statistics about the duration of each operation. For example, <code>store.get</code> is the overall time <code>Store.get()</code> took, <code>store.get.connector</code> is the time spent calling <code>Connector.get()</code>, and <code>store.get.deserialize</code> is the time spent deserializing the object returned by <code>Connector.get()</code>.</p> <p>If we get the object again, we'll see the metrics change. <pre><code>&gt;&gt;&gt; store.get(key)\n&gt;&gt;&gt; metrics = store.metrics.get_metrics(key)\n&gt;&gt;&gt; metrics.counters\n{'store.get.cache_hits': 1, 'store.get.cache_misses': 1}\n&gt;&gt;&gt; metrics.times['store.get']\nTimeStats(count=2, avg_time_ms=24.4, min_time_ms=3.2, max_time_ms=45.6)\n</code></pre> Here, we see that the second get resulted in a cache hit, and our average time for <code>store.get</code> dropped significantly.</p> <p>Attributes of a <code>TimeStats</code> instance can be directly accessed. <pre><code>&gt;&gt;&gt; metrics.times['store.get'].avg_time_ms\n24.4\n</code></pre></p>"},{"location":"guides/performance/#metrics-with-proxies","title":"Metrics with Proxies","text":"<p>Metrics are also tracked on proxy operations. <pre><code>&gt;&gt;&gt; proxy = store.proxy(target)\n\n# Access the proxy to force it to resolve.\n&gt;&gt;&gt; assert target_proxy[0] == 0\n\n&gt;&gt;&gt; metrics = store.metrics.get_metrics(proxy)\n&gt;&gt;&gt; metrics.times\n{\n    'factory.call': TimeStats(...)\n    'factory.resolve': TimeStats(...),\n    'store.get': TimeStats(...),\n    'store.get.connector': TimeStats(...),\n    'store.get.deserialize': TimeStats(...),\n    'store.proxy': TimeStats(...),\n    'store.put': TimeStats(...),\n    'store.put.connector': TimeStats(...),\n    'store.put.serialize': TimeStats(...),\n}\n</code></pre> Calling <code>Store.proxy()</code> internally called <code>Store.put()</code>. Accessing the proxy internally resolved the factory so we also see metrics about the <code>factory</code> and <code>store.get</code>.</p> <p>Warning</p> <p>For metrics to appropriately be tracked when a proxy is resolved, the <code>Store</code> needs to be registered globally by setting <code>register=True</code> in the constructor or by manually registering with <code>register_store()</code>. Otherwise, the factory will initialize a second <code>Store</code> to register and record its metrics to the second instance.</p>"},{"location":"guides/performance/#metrics-for-batch-operations","title":"Metrics for Batch Operations","text":"<p>For batch <code>Store</code> operations, metrics are recorded for the entire batch. I.e., the batch of keys is treated as a single super key.</p> <pre><code>&gt;&gt;&gt; keys = store.put_batch(['value1', 'value2', 'value3'])\n&gt;&gt;&gt; metrics = store.metrics.get_metrics(keys)\n&gt;&gt;&gt; metrics.times\n{\n    'store.put_batch.serialize': TimeStats(...),\n    'store.put_batch.connector': TimeStats(...),\n    'store.put_batch': TimeStats(...)\n}\n</code></pre>"},{"location":"guides/performance/#aggregating-metrics","title":"Aggregating Metrics","text":"<p>Rather than accessing metrics associated with a specific key (or batched key), time statistics can be aggregated over all keys.</p> <p><pre><code>&gt;&gt;&gt; store.metrics.aggregate_times()\n{\n    'factory.call': TimeStats(...),\n    'factory.resolve': TimeStats(...),\n    'store.get': TimeStats(...),\n    'store.get.connector': TimeStats(...),\n    'store.get.deserialize': TimeStats(...),\n    'store.proxy': TimeStats(...),\n    'store.put': TimeStats(...),\n    'store.put.connector': TimeStats(...),\n    'store.put.serialize': TimeStats(...),\n    'store.put_batch': TimeStats(...),\n    'store.put_batch.connector': TimeStats(...),\n    'store.put_batch.serialize': TimeStats(...),\n}\n</code></pre> Each of these <code>TimeStats</code> represents the aggregate over all keys.</p> <p>The Python code used to generate the above examples can be found at github.com/proxystore/proxystore/examples/store_metrics.py.</p>"},{"location":"guides/proxy-futures/","title":"Proxy Futures","text":"<p>Last updated 1 November 2023</p> <p>This guide walks through the use of the <code>Store.future()</code> interface and associated <code>Future</code>.</p> <p>Note</p> <p>Some familiarity with ProxyStore is assumed. Check out the Get Started guide and Concepts page to learn more about ProxyStore's core concepts.</p> <p>Warning</p> <p>The <code>Store.future()</code> and <code>Future</code> interfaces are experimental features and may change in future releases.</p> <p>The <code>Future</code> interface enables a data producer to preemptively send a proxy to a data consumer before the target data has been created. The consumer of the target data proxy will block when the proxy is first used and resolved until the producer has created the target data.</p> <p>Here is a trivial example using a <code>Store</code> and <code>LocalConnector</code>. The <code>future.proxy()</code> method is used to create a <code>Proxy</code> which will resolve to the result of the future.</p> example.py<pre><code>from proxystore.connectors.local import LocalConnector\nfrom proxystore.store import Store\nfrom proxystore.store.future import Future\n\nwith Store('proxy-future-example', LocalConnector()) as store:\n    future: Future[str] = store.future()\n    proxy = future.proxy()\n\n    future.set_result('value')\n    assert future.result() == 'value'\n    assert proxy == 'value'\n</code></pre> <p>Info</p> <p>Not all <code>Connector</code> implementations are compatible with the <code>Store.future()</code> interface. The <code>Connector</code> instance used to initialize the <code>Store</code> must also implement the <code>DeferrableConnector</code> protocol. A <code>NotImplementedError</code> will be raised when calling <code>Store.future()</code> if the connector is not an instance of <code>DeferrableConnector</code>. Many of the out-of-the-box implementations implement the <code>DeferrableConnector</code> protocol such as the <code>EndpointConnector</code>, <code>FileConnector</code>, and <code>RedisConnector</code>.</p> <p>The power of <code>Future</code> comes when the data producer and consumer are executing independently in time and space (i.e., execution occurs in different processes, potentially on different systems, and in an undefined order). The <code>Future</code> enables the producer and consumer to share a data dependency, while allowing the consumer to eagerly start execution before the data dependencies are fully satisfied.</p> <p>Consider the following example where we have a client which invokes two functions, <code>foo()</code> and <code>bar()</code> on remote processes. <code>foo()</code> will produce an object needed by <code>bar()</code>, but we want to start executing <code>foo()</code> and <code>bar()</code> at the same time. (We could even start <code>bar()</code> before <code>foo()</code>!)</p> client.py<pre><code>from proxystore.connectors.redis import RedisConnector\nfrom proxystore.store import Store\nfrom proxystore.store.future import Future\n\nclass MyData:\n    ...\n\ndef foo(future: Future[MyData]) -&gt; None:\n    data: MyData = compute(...)\n    future.set_result(data)\n\ndef bar(data: MyData) -&gt; None:\n    # Computation not involving data can execute freely.\n    compute(...)\n    # Computation using data will block until foo\n    # sets the result of the future.\n    compute(data)\n\n\nwith Store('proxy-future-example', RedisConnector(...)) as store:\n    future: Future[MyData] = store.future()\n\n    # The invoke_remote function will execute the function with\n    # the provided on arguments on an arbitrary remote process.\n    foo_result_future = invoke_remote(foo, future)\n    bar_result_future = invoke_remote(bar, future.proxy())\n\n    # Wait on the functions to finish executing.\n    foo_result_future.result()\n    bar_result_future.result()\n</code></pre> <p>In this example, <code>foo()</code> and <code>bar()</code> started executing at the same time. This allows <code>bar()</code> to eagerly execute code which does not depend on the data produced by <code>foo()</code>. <code>bar()</code> will only block once the data is needed by the computation.</p>"},{"location":"guides/relay-serving/","title":"Relay Serving","text":"<p>A relay server facilitates establishing peer to peer connections between two ProxyStore <code>Endpoints</code>. Hosting your own relay server is simple if you have a host accessible from the internet (e.g., a compute instance from a cloud provider or a machine behind a NAT with an open port) and the ProxyStore package installed.</p>"},{"location":"guides/relay-serving/#local-serving","title":"Local Serving","text":"<p>The <code>proxystore-relay</code> CLI is installed with the ProxyStore package and is used to serve a relay server instance.</p> <pre><code>$ proxystore-relay --port 8700\n</code></pre> <p>This relay server would be accessible at <code>ws://localhost:8700</code>. For example, an endpoint can be configure with this URI and will connect this instance when started.</p> <pre><code>$ proxystore-endpoint configure my-endpoint --relay-server ws://localhost:8700\n$ proxystore-endpoint start my-endpoint --no-detach\n</code></pre> <p>Here you would see the endpoint register with the relay server instance. See the Endpoints Overview for more on how endpoints interact with a relay server.</p>"},{"location":"guides/relay-serving/#enabling-tls","title":"Enabling TLS","text":"<p>In the above example, we connected to the relay with <code>ws://</code> which indicates that the connection is unencrypted. The relay can be served using TLS encryption if a valid SSL certificate is provided.</p> <p>Alert</p> <p>This guide will not describe how to create a valid SSL certificate and private key file because the steps can change depending on the environment. The rest of the guide assumes <code>cert.pem</code> and the corresponding <code>privkey.pem</code> exist.</p> <p>Advanced serving, such as TLS encryption, requires a relay configuration file.</p> relay.toml<pre><code>port = 8700\ncertfile = \"cert.pem\"\nkeyfile = \"privkey.pem\"\n</code></pre> <p>The relay can be started using the <code>relay.toml</code> file and will be accessible at <code>wss://localhost:8700</code> (note the change in protocol from <code>ws://</code> to <code>wss://</code>).</p> <pre><code>$ proxystore-relay --config relay.toml\n</code></pre>"},{"location":"guides/relay-serving/#logging-behavior","title":"Logging Behavior","text":"<p>The relay logs to <code>stdout</code> at the <code>INFO</code> level and above by default. This behavior can be changed via the <code>--log-level</code> and <code>--log-dir</code> CLI options or via the configuration file.</p> <p>Note</p> <p>CLI options can be combined with a configuration file, and CLI options will override the values in the configuration file if both are provided.</p> <p>The logging configuration is set in the <code>[logging]</code> section. All configurations are optional with defaults defined in <code>RelayLoggingConfig</code>.</p> relay.toml<pre><code>[logging]\nlog_dir = \"/path/to/log/dir\"\ndefault_log_level = \"INFO\"\nwebsockets_log_level = \"WARNING\"\ncurrent_client_interval = 60\ncurrent_client_limit = 32\n</code></pre>"},{"location":"guides/relay-serving/#user-authentication","title":"User Authentication","text":"<p>A relay provides no user authentication by default. This means that any client can connect to any other client as long as they know the client's UUID. This may be suitable for internal or development purposes, but users should take extra precautions to ensure sensitive data is not exposed.</p> <p>The relay implementation supports serving with Globus Auth. The following describes the steps required to create a Globus developer application and serve the relay with Globus Auth.</p> <p>Note</p> <p>The following guide is based on Action Provider Tools.</p>"},{"location":"guides/relay-serving/#register-an-application","title":"Register an Application","text":"<p>Reference: https://docs.globus.org/api/auth/developer-guide/#register-app</p> <ol> <li>Visit the    Globus Developer Dashboard    and sign in.</li> <li>Select the option to \"Register a portal, science gateway, or other    application you host.\"</li> <li> <p>Create a new project or register the application under an existing project    if you have one.</p> <ul> <li>The \"App Name\" is the name displayed on the Globus login and user   consent pages when users request access tokens.</li> <li>The redirect can be the standard Globus Auth callback:   <code>https://auth.globus.org/v2/web/auth-code</code>.</li> <li>The remaining options can be left to the default or adjusted to your   needs.</li> </ul> </li> <li> <p>Register the application and navigate to the application dashboard under the    project your application was registered to.</p> </li> <li>Record the client UUID and create a new client secret. Save the client    secret because it will not be accessible if you lose it.</li> </ol>"},{"location":"guides/relay-serving/#configure-scopes","title":"Configure Scopes","text":"<p>Reference: https://docs.globus.org/api/auth/reference/#create_scope</p> <p>Here we will add a new scope to our application. This is necessary because clients of our relay will need to request this scope for the relay server to authenticate the clients.</p> <p>Note</p> <p>Some of these steps use the <code>jq</code> command which is not installed by default on most machines but is very helpful for formatting the JSON responses in a readable format.</p> <ol> <li>Export your client UUID and secret.    <pre><code>$ export PROXYSTORE_GLOBUS_CLIENT_ID=...\n$ export PROXYSTORE_GLOBUS_CLIENT_SECRET=...\n</code></pre></li> <li>Inspect current scopes of the application.    <pre><code>$ curl -s --user $PROXYSTORE_GLOBUS_CLIENT_ID:$PROXYSTORE_GLOBUS_CLIENT_SECRET https://auth.globus.org/v2/api/clients/$PROXYSTORE_GLOBUS_CLIENT_ID | jq\n</code></pre>    You should see the <code>scopes</code> field is empty.</li> <li>Create a file containing our scopes document <code>scope.json</code>.    <pre><code>{\n    \"scope\": {\n        \"name\": \"Register with the ProxyStore Relay Server\",\n        \"description\": \"Register with the ProxyStore Relay Server which enables peer connection with other ProxyStore Endpoints owned by you.\",\n        \"scope_suffix\": \"relay_all\",\n        \"dependent_scopes\": [],\n        \"advertised\": true,\n        \"allow_refresh_tokens\": true\n    }\n}\n</code></pre>    The fields can be adjusted as necessary, but we suggest keeping    <code>allow_refresh_tokens</code> as <code>true</code>.</li> <li>Post the scopes document to the application.    <pre><code>$ curl -s --user $PROXYSTORE_GLOBUS_CLIENT_ID:$PROXYSTORE_GLOBUS_CLIENT_SECRET -H 'Content-Type: application/json' -XPOST https://auth.globus.org/v2/api/clients/$PROXYSTORE_GLOBUS_CLIENT_ID/scopes -d @scope.json | jq\n</code></pre></li> <li>Confirm our new scope is present in the application.    <pre><code>$ curl -s --user $PROXYSTORE_GLOBUS_CLIENT_ID:$PROXYSTORE_GLOBUS_CLIENT_SECRET https://auth.globus.org/v2/api/clients/$PROXYSTORE_GLOBUS_CLIENT_ID | jq\n</code></pre>    You will see the scopes UUID in the <code>scopes</code> field.</li> <li>Check the scope's details using the UUID found above. (Replace    <code>&lt;SCOPE_UUID&gt;</code> with the actual UUID.)    <pre><code>$ curl -s --user $PROXYSTORE_GLOBUS_CLIENT_ID:$PROXYSTORE_GLOBUS_CLIENT_SECRET https://auth.globus.org/v2/api/scopes/&lt;SCOPE_UUID&gt; | jq\n</code></pre></li> </ol>"},{"location":"guides/relay-serving/#update-the-relay-config","title":"Update the Relay Config","text":"<p>The <code>[auth]</code> section of the relay configuration is used to enable the authentication method of the relay server. Add the following and update the <code>client_id</code> and <code>client_secret</code> with the client UUID and secret from the application registration. The <code>audience</code> parameter should also be set to the client UUID.</p> relay.toml<pre><code>[auth]\nmethod = \"globus\"\n\n[auth.kwargs]\nclient_id = \"...\"\nclient_secret = \"...\"\naudience = \"...\"\n</code></pre> <p>The relay server will use the Globus token introspection API to authenticate users using the bearer tokens provided in the opening websocket handshake. The token introspection process will return information about the user that the token represents, including the intended audiences for the token. The relay will ensure that it is an intended audience of the token by matching against the <code>audience</code> field provided in the config.</p>"},{"location":"guides/relay-serving/#run-the-relay","title":"Run the Relay","text":"<p>After updating the configuration file, the relay can be run normally.</p> <p>Warning</p> <p>A relay server should always be served with TLS encryption when using Globus Auth for user authentication.</p> <pre><code>$ proxystore-relay --config relay.toml\n</code></pre>"},{"location":"guides/relay-serving/#connecting-as-a-client","title":"Connecting as a Client","text":"<p>The <code>RelayClient</code> can be used to connect to the server but requires some extra configuration to connect to the relay that is being served with Globus Auth.</p> <pre><code>import asyncio\n\nfrom proxystore.globus.manager import NativeAppAuthManager\nfrom proxystore.p2p.relay.client import RelayClient\n\nRELAY_APP_UUID = '...'\nRELAY_APP_SCOPE = 'relay_all'\n\nasync def main() -&gt; None:\n    manager = NativeAppAuthManager(\n        resource_server_scopes={RELAY_APP_UUID: [RELAY_APP_SCOPE]},\n    )\n    manager.login()\n    authorizer = manager.get_authorizer(RELAY_APP_UUID)\n\n    async with RelayClient(\n        'wss://localhost:8700',\n        # This Authorization header is used by the relay server to authenticate\n        # the new user connection\n        extra_headers={'Authorization': authorizer.get_authorization_header()},\n        # This is only necessary if using a self-signed SSL certificate.\n        verify_certificate=False,\n    ) as client:\n        input('Continue and disconnect?')\n\n\nif __name__ == '__main__':\n    asyncio.run(main())\n</code></pre>"},{"location":"guides/streaming/","title":"Streaming Objects with ProxyStore","text":"<p>Last updated 29 January 2024</p> <p>This guide describes the motivation for and usage of ProxyStore's streaming interface.</p> <p>Note</p> <p>Some familiarity with ProxyStore is assumed. Check out the Get Started guide and Concepts page to learn more about ProxyStore's core concepts.</p> <p>The <code>StreamProducer</code> and <code>StreamConsumer</code> interfaces decouple bulk object communication from event notifications through the use of object proxies. This enables users to mix and match bulk object communication methods (via the <code>Connector</code> interface) and message stream brokers (via the <code>Publisher</code> and <code>Subscriber</code> interfaces). Additionally, because the <code>StreamConsumer</code> yields proxies of objects from the stream, bulk data transfer only occurs between the source and true destination of the object from the stream (i.e., the process which resolves the proxy from the stream).</p>"},{"location":"guides/streaming/#use-cases","title":"Use Cases","text":"<p>The ProxyStore streaming interface can be used anywhere where one process needs to stream objects to another process, and the interface can be used to optimize the deployment via different <code>Connector</code> and <code>Publisher</code>/ <code>Subscriber</code> implementations.</p> <p>But, this model is particularly powerful for applications which dispatch remote compute tasks on objects consumed from a stream. To understand why, consider the application in Figure 1 where Process A is a data generator streaming chunks of data (i.e., arbitrary Python objects) to Process B, a dispatcher which dispatches a compute task on a remote Process C using the data chunk.</p> <p></p> <p>Figure 1: ProxyStore Streaming example.</p> <p>In this scenario, while the dispatcher is consuming from the stream, the dispatcher does not need to have the actual chunk of data; rather, it only needs to know that a chunk is ready in order to dispatch a task which will actually consume the chunk. This is where a stream of proxies is beneficial---the processes reading from the <code>StreamConsumer</code> is receiving lightweight proxies from the stream and passing those proxies along to later computation stages. The bulk data are only transmitted between the data generator and the process/node computing on the proxy of the chunk, bypassing the intermediate dispatching process.</p>"},{"location":"guides/streaming/#example","title":"Example","text":"<p>Here is an example of using the <code>StreamProducer</code> and <code>StreamConsumer</code> interfaces to stream objects using a file system and Redis server. This configuration is optimized for storage of large objects using the file system while maintaining low latency event notifications via Redis pub/sub. However, the configuration can easily be optimized for different applications or deployments but using a different <code>Connector</code> with the <code>Store</code> for data storage and/or a different <code>Publisher</code>/ <code>Subscriber</code> implementation for event notifications via a message broker.</p> producer.py<pre><code>from proxystore.connector.file import FileConnector\nfrom proxystore.store import Store\nfrom proxystore.stream import StreamProducer\nfrom proxystore.stream.shims.redis import RedisPublisher\n\nstore = Store('example', FileConnector(...)) # (1)!\npublisher = RedisPublisher(...) # (2)!\nproducer = StreamProducer(publisher, {'my-topic': store}) # (3)!\n\nfor item in ...:\n    producer.send('my-topic', item, evict=True) # (4)!\n\nproducer.close() # (5)!\n</code></pre> <ol> <li>The <code>Store</code> configuration is determined by    the producer. The    <code>StreamProducer</code> is    initialized with a mapping of topics to stores such that different    communication protocols can be used for different topics. Consider using    different <code>Connector</code>    implementations depending on your deployment or data characteristics.</li> <li>The <code>Publisher</code> is the interface    to a pub/sub channel which will be used for sending event metadata to    consumers. The    <code>StreamProducer</code> also supports    aggregation, batching, and filtering.</li> <li>In the mapping of topics to stores, the <code>None</code> key is considered the    default for when a topic is not found in the mapping. For example,    <code>{None: store}</code> will use the same store for all topics.</li> <li>The state of the <code>evict</code> flag will alter if proxies yielded by a    consumer are one-time use or not.</li> <li>Closing the <code>StreamProducer</code>    will close the <code>Publisher</code>,    all <code>Store</code> instances, and    <code>Connector</code> by default.</li> </ol> consumer.py<pre><code>from proxystore.connector.file import FileConnector\nfrom proxystore.proxy import Proxy\nfrom proxystore.stream import StreamConsumer\nfrom proxystore.stream.shims.redis import RedisSubscriber\n\nsubscriber = RedisSubscriber(...)  # (1)!\nconsumer = StreamConsumer(subscriber)  # (2)!\n\nfor item in consumer: # (3)!\n    assert isinstance(item, Proxy)  # (4)!\n\nconsumer.close() # (5)!\n</code></pre> <ol> <li>The <code>Subscriber</code> is the interface    to the same pub/sub channel that the producer is publishing event metadata    to. These events are consumed by the    <code>StreamConsumer</code> and used to    generate proxies of the objects in the stream.</li> <li>The <code>StreamConsumer</code> does not    need to be initialized with a <code>Store</code>. Stream    events will contain the necessary metadata for the consumer to get the    appropriate <code>Store</code> to use for resolving    objects in the stream.</li> <li>Iterating on a    <code>StreamConsumer</code> will    block until new proxies are available and yield those proxies. Iteration    will stop once the <code>Publisher</code>    is closed via the    <code>StreamProducer</code>.</li> <li>The yielded proxies point to objects in the    <code>Store</code>, and the state of the <code>evict</code> flag    inside the proxy's factory is determined in    <code>StreamProducer.send()</code>.</li> <li>Closing the <code>StreamConsumer</code> will close    the <code>Subscriber</code>,    all <code>Store</code> instances, and    <code>Connector</code> by default.</li> </ol> <p>Tip</p> <p>By default, iterating on a <code>StreamConsumer</code> yields only a proxy of the next object in the stream. The <code>iter_with_metadata()</code>, <code>iter_objects()</code>, and <code>iter_objects_with_metadata()</code> methods provide additional mechanisms for iterating over stream data.</p>"},{"location":"guides/streaming/#multi-producermulti-consumer","title":"Multi-Producer/Multi-Consumer","text":"<p>The <code>StreamProducer</code> and <code>StreamConsumer</code> can support multi-producer and multi-consumer deployments, respectively. However, it is not a requirement that the <code>Publisher</code> or <code>Subscriber</code> protocols to implements multi-producer or multi-consumer support. In other words, it is up to each <code>Publisher</code>/ <code>Subscriber</code> implementation to decide on and document their support for these features, and users should confirm that the specific implementations or configurations parameters produce the behavior they want.</p> <p>Multi-producer. If a <code>Publisher</code> supports multiple producers, typically no changes are required on when initializing the corresponding <code>StreamProducer</code>. Each producer process can simply initialize the <code>Publisher</code> and <code>StreamProducer</code> and begin sending objects to the stream.</p> <p>Multi-consumer. If a <code>Subscriber</code> support multiple consumers, attention should be given to the manner in which the consumers behave. If all consumers receive the full stream (i.e., each consumer receives each object in the stream), then the the <code>evict</code> flag of <code>StreamProducer.send()</code> should be set to <code>False</code>. This ensures that the first consumer to resolve a proxy from the stream does not delete the object data for the other consumers, but this also means that object cleanup must be handled manually by the application. Otherwise, the store will fill up with the entire stream of objects. On the other hand, if each object in the stream is only received by one consumer, then it may be safe to set <code>evict=True</code>.</p>"},{"location":"publications/","title":"Publications","text":""},{"location":"publications/#citing-proxystore","title":"Citing ProxyStore","text":"<p>If you use ProxyStore or any of this code in your work, please cite the following two papers.</p> <ul> <li>Accelerating Communications in Federated Applications with Transparent Object Proxies. The original ProxyStore paper. Introduces the core proxy model for distributed object management and the ProxyStore framework stack. <p>J. Gregory Pauloski, Valerie Hayot-Sasson, Logan Ward, Nathaniel Hudson, Charlie Sabino, Matt Baughman, Kyle Chard, and Ian Foster. 2023. Accelerating Communications in Federated Applications with Transparent Object Proxies. In Proceedings of the International Conference for High Performance Computing, Networking, Storage and Analysis (SC '23). Association for Computing Machinery, New York, NY, USA, Article 59, 1\u201315. https://doi.org/10.1145/3581784.3607047</p> </li> <li>Object Proxy Patterns for Accelerating Distributed Applications. Extends ProxyStore with higher-level proxy-based patterns for distributed futures, streaming, and ownership. <p>J. Gregory Pauloski, Valerie Hayot-Sasson, Logan Ward, Alexander Brace, Andr\u00e9 Bauer, Kyle Chard, Ian Foster. 2024. Object Proxy Patterns for Accelerating Distributed Applications. arXiv Preprint.</p> </li> </ul> <p>BibTeX Citations</p> <pre><code>@inproceedings{pauloski2023proxystore,\n    author = {Pauloski, J. Gregory and Hayot-Sasson, Valerie and Ward, Logan and Hudson, Nathaniel and Sabino, Charlie and Baughman, Matt and Chard, Kyle and Foster, Ian},\n    title = {{Accelerating Communications in Federated Applications with Transparent Object Proxies}},\n    address = {New York, NY, USA},\n    articleno = {59},\n    booktitle = {Proceedings of the International Conference for High Performance Computing, Networking, Storage and Analysis},\n    doi = {10.1145/3581784.3607047},\n    isbn = {9798400701092},\n    location = {Denver, CO, USA},\n    numpages = {15},\n    publisher = {Association for Computing Machinery},\n    series = {SC '23},\n    url = {https://doi.org/10.1145/3581784.3607047},\n    year = {2023}\n}\n\n@misc{pauloski2024proxystore,\n    author = {J. Gregory Pauloski and Valerie Hayot-Sasson and Logan Ward and Alexander Brace and Andr\u00e9 Bauer and Kyle Chard and Ian Foster},\n    title = {{Object Proxy Patterns for Accelerating Distributed Applications}},\n    archiveprefix = {arXiv},\n    eprint = {2407.01764},\n    primaryclass = {cs.DC},\n    url = {https://arxiv.org/abs/2407.01764},\n    year = {2024}\n}\n</code></pre>"},{"location":"publications/#featured-papers","title":"Featured Papers","text":"<p>If you use ProxyStore in your work and would like to be featured on this page, open an issue or propose a pull request on GitHub.</p> <ul> <li>J. Gregory Pauloski, Valerie Hayot-Sasson, Maxime Gonthier, Nathaniel Hudson, Haochen Pan, Sicheng Zhou, Ian Foster, and Kyle Chard. \"TaPS: A Performance Evaluation Suite for Task-based Execution Frameworks.\" 20<sup>th</sup> IEEE International Conference on e-Science. IEEE, 2024.</li> <li>Devaraj, Harish, Shaleeza Sohail, Boyang Li, Nathaniel Hudson, Matt Baughman, Kyle Chard, Ryan Chard, Enrico Casella, Ian Foster, and Omer Rana. \"RuralAI in Tomato Farming: Integrated Sensor System, Distributed Computing and Hierarchical Federated Learning for Crop Health Monitoring.\" IEEE Sensors Letters. IEEE, 2024.</li> <li>Gautham Dharuman, Logan Ward, Heng Ma, Priyanka V. Setty, Ozan Gokdemir, Sam Foreman, Murali Emani, Kyle Hippe, Alexander Brace, Kristopher Keipert, Thomas Gibbs, Ian Foster, Anima Anandkumar, Venkatram Vishwanath, and Arvind Ramanathan. \"Protein Generation via Genome-scale Language Models with Bio-physical Scoring.\" In Proceedings of the SC '23 Workshops of The International Conference on High Performance Computing, Network, Storage, and Analysis. ACM, 2023.</li> <li>Alok Kamatar, Mansi Sakarvadia, Valerie Hayot-Sasson, Kyle Chard, and Ian Foster. \"Lazy Python Dependency Management in Large-Scale Systems.\" In Proceedings of IEEE 19<sup>th</sup> International Conference on e-Science. IEEE, 2023.</li> <li>Hassan Harb, Sarah N. Elliot, Logan Ward, Ian T. Foster, Stephen J. Klippenstein, Larry A. Curtiss, and Rajeev Surendran Assary. \"Uncovering novel liquid organic hydrogen carriers: a systematic exploration of chemical compound space using cheminformatics and quantum chemical methods.\" In Digital Discovery. Royal Society of Chemistry, 2023.</li> <li>Nicholson Collier, Justin M. Wozniak, Abby Stevens, Yadu Babuji, Micka\u00ebl Binois, Arindam Fadikar, Alexandra W\u00fcrth, Kyle Chard, and Jonathan Ozik. \"Developing Distributed High-performance Computing Capabilities of an Open Science Platform for Robust Epidemic Analysis.\" arXiv, 2023.</li> <li>Logan Ward, J. Gregory Pauloski, Valerie Hayot-Sasson, Ryan Chard, Yadu Babuji, Ganesh Sivaraman, Sutanay Choudhury, Kyle Chard, Rajeev Thakur, and Ian Foster. \"Cloud Services Enable Efficient AI-Guided Simulation Workflows across Heterogeneous Resources.\" In Proceedings of Heterogeneity in Computing Workshop of the International Parallel and Distributed Processing Symposium. IEEE, 2023.</li> <li>Maxim Zvyagin et al. \"GenSLMs: Genome-scale language models reveal SARS-CoV-2 evolutionary dynamics.\" bioRxiv, 2022.</li> <li>Logan Ward, Ganesh Sivaraman, J. Gregory Pauloski, Yadu Babuji, Ryan Chard, Naveen Dandu, Paul C. Redfern, Rajeev S. Assary, Kyle Chard, Larry A. Curtiss, Rajeev Thakur, and Ian Foster. \"Colmena: Scalable machine-learning-based steering of ensemble simulations for high performance computing.\" In IEEE/ACM Workshop on Machine Learning in High Performance Computing Environments. IEEE, 2021.</li> </ul>"},{"location":"publications/#presentations","title":"Presentations","text":"<ul> <li>[Slides] \"Accelerating Communications in Federated Applications with Transparent Object Proxies\" presented at SC23. 2023.</li> <li>[Poster] \"Accelerating Communications in Federated Applications with Transparent Object Proxies\" presented at the Greater Chicago Area Systems Research Workshop (GCASR). 2023.</li> </ul>"}]}